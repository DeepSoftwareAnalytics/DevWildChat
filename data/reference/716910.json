[
    {
        "link": "https://geeksforgeeks.org/complexity-analysis-of-binary-search",
        "document": "Time complexity of Binary Search is O(log n), where n is the number of elements in the array. It divides the array in half at each step. Space complexity is O(1) as it uses a constant amount of extra space.\n\nThe time and space complexities of the binary search algorithm are mentioned below.\n\nConsider array arr[] of length N and element X to be found. There can be two cases:\n• Case1: Element is present in the array\n• Case2: Element is not present in the array. There are N Case1 and 1 Case2. So total number of cases = N+1. Now notice the following:\n• None An element at index N/2 can be found in 1\n• None Elements at index N/4 and 3N/4 can be found in 2\n• None Elements at indices N/8, 3N/8, 5N/8 and 7N/8 can be found in 3 Based on this we can conclude that elements that require:\n• x2x-1x[1, logN] because maximum comparisons = maximum time N can be halved = maximum comparisons to reach 1st element = logN. Therefore, the average complexity = (N*(logN – 1) + 1)/N+1 = N*logN / (N+1) + 1/(N+1). Here the dominant term is N*logN/(N+1) which is approximately logN. So the average case complexity is O(logN)\n\nThe worst case will be when the element is present in the first position. As seen in the average case, the comparison required to reach the first element is logN. So the time complexity for the worst case is O(logN).\n\nThe auxiliary space complexity of the Binary Search Algorithm is O(1), which means it requires a constant amount of extra space regardless of the size of the input array. This is because Binary Search is an iterative algorithm that does not require any additional data structures or recursion that grows with the input size. Although, we can also implement Binary Search recursively."
    },
    {
        "link": "https://datacamp.com/tutorial/binary-search-python",
        "document": "Extend your regression toolbox with the logistic and Poisson models and learn to train, understand, and validate them, as well as to make predictions."
    },
    {
        "link": "https://codesignal.com/learn/courses/sorting-and-searching-algorithms-in-python/lessons/mastering-binary-search-implementation-and-complexity-analysis-in-python",
        "document": "Welcome back! Today, we're adding another tool to our toolkit for algorithms and data structures — a powerful searching technique known as binary search that operates seamlessly on sorted arrays. By the end of this session, you will understand binary search, its internals, its Python implementation, and its time and space complexity. Drawing a parallel with everyday life, binary search resembles the process of finding a word in a dictionary. Instead of skimming through every page, we open the dictionary around the middle and compare our words. If our word is in the left half, we discard the right half, and vice versa. This halving process continues until we find our word — essentially, this is a binary search.\n\nBinary Search is a search algorithm operating on a sorted list or array. The strategy employed by Binary Search is similar to the process of searching for a name in a telephone directory or a word in the dictionary - you open the book in the middle and determine whether the name or word you're looking for can be found in the left (first half) or the right part (second half). If the name or word you're searching for is smaller than the one in the middle, you continue your search only in the left half. However, if it's larger, you narrow down your search to the right half. This method is iteratively repeated, reducing the search space by half each time, thereby making this search operation highly effective. In Python terms, imagine you have a sorted list of numbers as: , and you've been tasked with determining if the number 3 is present in the list. With Binary Search, it directly jumps to the middle. If the number is equal to the middle element, our search is complete. But if the number is smaller than the middle element, Binary Search discards the second half of the list and continues the search only on the first half. This process is repeated until the number is found.\n\nTo translate binary search into Python code, devise a function that takes in the sorted list and the target element. Start by establishing the boundaries of your search. Then, repeatedly halve the list until either the element is found or the list is exhausted. Let's implement binary search iteratively in Python: # We will search in the interval [low, high), where the right border is excluded # search until the length of the interval > 1 In this function, the index of the target in the sorted list is returned. If the target is not found, the function returns . Similarly, we can implement binary search using recursion — a function that calls itself until a base case is met. In the recursive version, the while loop is replaced by recursive calls to the function itself. The algorithm remains the same: find the middle, compare it with the target, and determine the next step.\n\nBinary search has excellent performance when it comes to time complexity - O(logn). This logarithmic time behavior makes binary search ideal for large datasets. This is because, with each comparison, binary search eliminates half of the elements, reducing the search time exponentially. Regarding space complexity, the iterative version of binary search has a space complexity of O(1) as it only uses a fixed amount of space to store the data. However, the recursive version has higher space complexity — O(logn) — since it uses additional space in the form of a call stack during recursive tasks.\n\nWith a clear understanding of binary search, we can now use it to solve a complex problem — searching for a target element in a rotated sorted list. This involves figuring out the rotation point and applying binary search accordingly. Consider a list like this . This list was sorted from to , but then it was rotated to the fourth position. Suppose we want to search for the number . We can see that it's in the latter half, but how does our algorithm determine this? As a bonus exercise, try to apply binary search to solve this question! We will cover the analysis of this question in the next lessons.\n\nAnd that's all for our binary search lesson! We've drawn parallels between binary search and looking up a word in a dictionary, explored the binary search algorithm and its Python implementation, learned how to analyze its time and space complexity, and seen how it can be used to solve more advanced problems like searching in a rotated sorted list. Take a moment to acknowledge your accomplishment — you're now well-equipped with the knowledge of an efficient searching algorithm!"
    },
    {
        "link": "https://geeksforgeeks.org/binary-search",
        "document": "Binary Search Algorithm is a searching algorithm used in a sorted array by repeatedly dividing the search interval in half. The idea of binary search is to use the information that the array is sorted and reduce the time complexity to O(log N).\n\nBinary search is a search algorithm used to find the position of a target value within a sorted array. It works by repeatedly dividing the search interval in half until the target value is found or the interval is empty. The search interval is halved by comparing the target element with the middle value of the search space.\n• None The data structure must be sorted.\n• None Access to any element of the data structure should take constant time.\n\nBelow is the step-by-step algorithm for Binary Search:\n• None Divide the search space into two halves by finding the middle index “mid”\n• None Compare the middle element of the search space with the key\n• key is found at middle element, the process is terminated.\n• key is not found at middle element, choose which half will be used as the next search space.\n• key is smaller than the middle element, then the left side is used for next search.\n• key is larger than the middle element, then the right side is used for next search.\n• None This process is continued until the key is found or the total search space is exhausted.\n\nTo understand the working of binary search, consider the following illustration:\n\nConsider an array arr[] = {2, 5, 8, 12, 16, 23, 38, 56, 72, 91}, and the target = 23.\n\n\n\nThe Binary Search Algorithm can be implemented in the following two ways\n\nGiven below are the pseudocodes for the approaches.\n\n// Check if x is present at mid // If x is smaller, ignore right half // If we reach here, then element was not present \"Element is not present in array\" // Check if x is present at mid // If x is smaller, ignore right half // If we reach here, then element was not present \"Element is not present in array\" // Returns index of x if it is present in arr[]. // Check if x is present at mid // If x is smaller, ignore right half // If we reach here, then element was \"Element is not present in array\" # It returns location of x in given array arr # Check if x is present at mid # If x is smaller, ignore right half # If we reach here, then the element \"Element is not present in array\" // Returns index of x if it is present in arr[] // Check if x is present at mid // If x is smaller, ignore right half // If we reach here, then element was \"Element is not present in array\" // location of x in given array arr[l..r] is present, // If the element is present at the middle // If element is smaller than mid, then // it can only be present in left subarray // Else the element can only be present // We reach here when element is not \"Element is not present in array\" // Check if x is present at mid // If we reach here, then \"Element is not present in array\"\n\n// location of x in given array arr[low..high] is present, // If the element is present at the middle // If element is smaller than mid, then // it can only be present in left subarray // Else the element can only be present \"Element is not present in array\" // location of x in given array arr[low..high] is present, // If the element is present at the middle // If element is smaller than mid, then // it can only be present in left subarray // Else the element can only be present // We reach here when element is not \"Element is not present in array\" // Returns index of x if it is present in arr[low.. // If the element is present at the // If element is smaller than mid, then // it can only be present in left subarray // Else the element can only be present // We reach here when element is not present \"Element is not present in array\" # Returns index of x in arr if present, else -1 # If element is present at the middle itself # If element is smaller than mid, then it # can only be present in left subarray # Else the element can only be present # Element is not present in the array \"Element is not present in array\" // Returns index of x if it is present in // If the element is present at the // If element is smaller than mid, then // it can only be present in left subarray // Else the element can only be present // We reach here when element is not present \"Element is not present in arrau\" // location of x in given array arr[low..high] is present, // If the element is present at the middle // If element is smaller than mid, then // it can only be present in left subarray // Else the element can only be present // We reach here when element is not \"Element is not present in array\" // of x in given array arr[low..high] // If the element is present // If element is smaller than // mid, then it can only be // Else the element can only // be present in right subarray // We reach here when element // is not present in array \"Element is not present in array\"\n• Auxiliary Space: O(1), If the recursive call stack is considered then the auxiliary space will be O(logN).\n• None Binary search can be used as a building block for more complex algorithms used in machine learning, such as algorithms for training neural networks or finding the optimal hyperparameters for a model.\n• None It can be used for searching in computer graphics such as algorithms for ray tracing or texture mapping.\n• None It can be used for searching a database.\n• None Binary search is faster than linear search, especially for large arrays.\n• None More efficient than other searching algorithms with a similar time complexity, such as interpolation search or exponential search.\n• None Binary search is well-suited for searching large datasets that are stored in external memory, such as on a hard drive or in the cloud.\n• None The array should be sorted.\n• None Binary search requires that the data structure being searched be stored in contiguous memory locations.\n• None Binary search requires that the elements of the array be comparable, meaning that they must be able to be ordered.\n\n3. What is the time complexity of Binary Search?\n\n4. What are the prerequisites for Binary Search?\n\n5. What happens if the array is not sorted for binary search?\n\n6. Can binary search be applied to non-numeric data?\n\n7. What are some common disadvantages of Binary Search?\n\n8. When should Binary Search be used?\n\n10. Is Binary Search always the best choice for searching in a sorted array?"
    },
    {
        "link": "https://stackoverflow.com/questions/45691010/python-binary-search-complexity",
        "document": "we got question in class that asks us if binary search with this algorithm:\n\ncompare to an algorithm with elif instead of the two lasts if. does it stay on same time complexity? meaning is it still log(n)?"
    },
    {
        "link": "https://mahdisaeedi.medium.com/mastering-arrays-and-lists-in-python-a-comprehensive-guide-to-data-manipulation-and-interview-42cafd445cae",
        "document": "This article aims to demystify the complexities of array and list manipulation in Python, empowering you with the knowledge to efficiently handle data structures, articulate your choices of methods, and excel in coding interviews. We’ll explore essential techniques, from basic operations to advanced problem-solving strategies, ensuring you can tackle challenges with confidence.\n\nIn this guide, we will go through the foundational and some advanced aspects of array and list manipulation in Python. We begin by dissecting the basic operations on arrays and lists, such as accessing, updating, and iterating over elements, to build a solid foundation of knowledge. From there, we delve into the practical application of the two-pointer technique, illuminating its power in simplifying complex problems. Our exploration will not stop at mere manipulation; we’ll master the art of in-place operations, learning to modify data structures directly to achieve efficient and elegant solutions.\n\nUnderstanding conditional logic and edge case handling will further refine your problem-solving arsenal, ensuring you can navigate through various scenarios with ease. We’ll tackle loop control, ensuring you can implement and manage iterative processes without falling into common pitfalls. The guide will also illuminate Python’s dynamic data types, particularly mutable lists, showcasing their flexibility and power in programming. Additionally, we’ll explore how to return multiple values from functions, a technique that can greatly enhance the versatility of your code.\n\nWe will cover the following topics in the given order:\n\nAlgorithm complexity, encompassing both time complexity and space complexity, is a fundamental concept in computer science that assesses the efficiency of algorithms in terms of execution time and memory usage, respectively. Grasping these concepts is vital for designing algorithms that are not only correct but also efficient, particularly when dealing with large datasets or constraints on computational resources.\n\nTime complexity is a measure of the amount of computational time an algorithm takes to complete as a function of the length of the input. It’s typically expressed using Big O notation, which describes the upper limit of the algorithm’s growth rate. Understanding time complexity helps predict how an algorithm will scale and is crucial for optimizing performance, especially in applications where response time is critical.\n• Linear Time, O(m + n): An algorithm is said to run in linear time if its time complexity grows linearly with the size of the input. For example, an algorithm that processes two arrays of lengths m and n in a single pass has a time complexity of O(m + n). This indicates efficient scaling, as the time increases directly with the size of the input.\n\nIf you would like to brush up on time complexities I highly recommend checking out the following article.\n\nSpace complexity measures the total amount of memory space required by an algorithm as a function of the length of the input. Like time complexity, it’s often expressed in Big O notation. Minimizing space complexity is essential for handling large data sets without exceeding system memory.\n• Constant Space, O(1): An algorithm that uses a fixed amount of memory space regardless of the input size operates in constant space. This is ideal for memory efficiency.\n• Linear Space, O(n): An algorithm that requires memory proportional to the input size has linear space complexity.\n• Performance Prediction: Complexity analysis allows developers to estimate the scalability of algorithms and predict their performance under various conditions.\n• Resource Management: Understanding the complexities helps in making informed decisions about algorithm design, especially in environments with limited computational resources.\n• Optimization: Identifying parts of the algorithm with high time or space complexity can guide optimization efforts, making them more targeted and effective.\n\nPython stands out in the programming world for its highly intuitive and flexible handling of collections of data, particularly through its implementation of dynamic lists. Unlike static arrays found in languages like C or Java, where the size and type of the array must be defined upfront, Python’s lists offer a dynamic nature that allows them to grow and shrink at runtime, accommodating a more fluid and adaptable approach to data manipulation.\n\nAt its core, a Python list is an ordered collection of items which can be of any type. This flexibility allows programmers to store a heterogeneous mix of objects within the same list, from integers and strings to more complex data structures. This feature, combined with the ability to adjust its size dynamically, makes Python lists an incredibly powerful tool for data manipulation.\n\nPython lists manage their size automatically by allocating more space than is initially required. When the number of elements exceeds the current capacity, Python allocates a larger block of memory to accommodate the growing list, copying the old elements to the new space. This process is largely transparent to the user, allowing for the seamless addition and removal of elements.\n\nPython’s approach prioritizes ease of use and flexibility. Lists in Python support a wide array of operations that make data manipulation straightforward. For example, methods such as , , and allow for easy modification of the list contents without worrying about the underlying memory allocation. Moreover, Python’s list comprehensions provide a concise and readable way to create lists, further enhancing the language's efficiency in handling collections of data.\n\nThis dynamic and flexible system does come with its own considerations, particularly regarding performance. Since Python lists are designed to be general-purpose, they can sometimes be less efficient in terms of memory and speed compared to static arrays or specialized data structures like arrays in NumPy, which are optimized for numerical operations. However, for many applications, the ease of use, readability, and flexibility of Python lists outweigh these considerations.\n\nUsing append() vs manually adding an item:\n\nThe two-pointer technique is a powerful strategy in algorithm design, especially effective in array manipulation tasks. This method involves using two pointers (or indices) to traverse the array, usually starting from the beginning and the end, or both from the same direction, depending on the problem at hand. Its utility lies in its ability to reduce complexity, both in terms of time and space, making it a popular choice for optimizing solutions.\n\nOne of the primary advantages of the two-pointer technique is its ability to simplify the solution to problems that might otherwise require nested iterations, thereby significantly reducing the time complexity. For example, in problems involving finding a pair of elements that satisfy a certain condition (such as a sum), the naive approach might involve a double loop to check all possible pairs, resulting in O(n²) time complexity. By applying the two-pointer technique, we can often reduce this to O(n), simply by moving the pointers based on the comparison with the target condition.\n\nThe two-pointer technique not only simplifies the logic of the solution but also optimizes it by minimizing unnecessary computations. It’s particularly useful in problems related to sorting, searching in a sorted array, or dealing with strings and linked lists. For example, in a sorted array, two pointers can efficiently find a pair of numbers that add up to a specific sum by incrementally moving one pointer or the other, depending on how the current sum compares to the target sum. This optimization is a direct result of leveraging the sorted nature of the array, eliminating the need for exhaustive search.\n• Finding Pairs: Whether it’s summing up to a target value or finding pairs with a given difference, the two-pointer approach efficiently navigates through the array to identify these pairs.\n• Removing Duplicates: In a sorted array, two pointers can help identify and skip duplicates, compacting the array to include only unique elements.\n• Reversing: When reversing an array or a part of it, two pointers starting from opposite ends can swap elements, moving towards the center.\n• Palindrome Checking: Checking whether a string is a palindrome can be simplified with two pointers moving inwards, comparing characters at each step.\n\nHere’s a simple implementation showcasing how the two-pointer technique can identify a pair of numbers in a sorted array that add up to a specific sum:\n\nIn-place operations refer to the technique of modifying data structures directly, without allocating additional space for a copy of the input. This approach is particularly valuable in contexts where memory efficiency is paramount, such as embedded systems, large-scale data processing, and technical interviews, where demonstrating resource-efficient coding practices can you apart from other candidates.\n\nThe key principle behind in-place operations is the manipulation of elements within the existing data structure to achieve the desired outcome. This method stands in contrast to approaches that involve creating new instances of data structures or extensively copying elements to temporary structures, thereby requiring additional memory proportional to the size of the input.\n• Memory Efficiency: By avoiding unnecessary allocations, in-place operations minimize the memory footprint of programs, an important consideration in environments with limited resources.\n• Performance Enhancement: Reducing memory usage can also lead to performance gains, primarily due to lower overhead in memory allocation and garbage collection, and better utilization of caching mechanisms.\n• Algorithmic Elegance: In-place techniques often require innovative approaches and a deeper understanding of algorithmic principles, leading to more elegant and insightful solutions.\n\nImplementing in-place operations requires a careful balance between modifying the original data and maintaining the integrity of the information being processed. Here are a few common scenarios and techniques:\n• Swapping Elements: Many sorting algorithms, like bubble sort and quicksort, rely on swapping elements to reorder them in-place.\n• Two-pointer Technique: As discussed in the context of array manipulation, the two-pointer technique can efficiently solve problems by modifying arrays in-place, such as removing duplicates or merging sorted arrays.\n• Reverse and Rotate: Operations like reversing an array or rotating it can be performed in-place by carefully swapping elements from opposite ends or cyclically shifting them.\n\nWhile in-place operations offer significant benefits, they also come with their own set of considerations:\n• Data Integrity: Directly modifying the input means that the original data is lost unless explicitly preserved. This is acceptable in many scenarios but requires careful consideration when the original data might be needed.\n• Readability and Complexity: In some cases, in-place operations can lead to code that is harder to understand and maintain, especially for complex algorithms.\n\nEdge case handling is a critical aspect of software development and algorithm design, pivotal in creating robust and reliable solutions. Edge cases refer to the extreme scenarios or unusual conditions that occur outside of normal operating parameters, often at the boundaries of an input space or in situations that are not immediately obvious. Properly anticipating and addressing these cases ensures that a program behaves correctly under all possible inputs, thereby enhancing its resilience and dependability.\n\nIgnoring edge cases can lead to unexpected behaviors, bugs, or even system failures, especially when a program encounters inputs that it wasn’t explicitly designed to handle. These issues can range from minor inconveniences to major vulnerabilities, depending on the application’s nature and context. Thus, a comprehensive understanding and thoughtful handling of edge cases are indispensable for ensuring the quality and security of software.\n• Identify Potential Edge Cases: The first step in handling edge cases is to identify them, which requires a deep understanding of the problem domain and input space. Common sources of edge cases include zero, negative values, extremely large values, null or empty inputs, and boundary conditions.\n• Use Assertions and Validations: Assertions and validations are effective tools for early detection of edge cases. They can enforce certain conditions or constraints on the inputs, ensuring that the program operates within the expected parameters.\n• Implement Fallbacks and Defaults: For situations where input may not fit the normal expected range, implementing fallback values or default behaviors can ensure that the program continues to operate smoothly, providing a graceful degradation of functionality rather than a complete failure.\n• Write Comprehensive Tests: Unit tests, integration tests, and end-to-end tests should cover edge cases to ensure that the program behaves as expected under a wide range of conditions. Testing frameworks and methodologies like Test-Driven Development (TDD) can facilitate this.\n• Code Review and Analysis: Peer reviews and static code analysis tools can help identify potential edge cases that may have been overlooked during the initial development phase.\n\nConsider a function designed to find the maximum product of any two numbers in an array. At first glance, the solution might involve simply finding the two largest numbers. However, edge cases such as negative numbers can affect the outcome. Two large negative numbers multiplied together can result in a larger product than two positive numbers. Therefore, the solution must account for this scenario.\n\nEffective edge case handling is a hallmark of high-quality software development, essential for crafting resilient and dependable applications. By systematically identifying, testing, and addressing extreme scenarios, developers can ensure that their programs function correctly across the full spectrum of possible inputs, thereby enhancing the user experience and safeguarding against potential failures.\n\nMultidimensional arrays, often referred to as matrices in the context of two dimensions or tensors in higher dimensions, are crucial data structures in computer science and programming. They are particularly indispensable for applications in linear algebra, scientific computing, computer graphics, image processing, and machine learning, where they serve as the backbone for representing and manipulating complex datasets, including images, 3D models, and multidimensional measurements.\n\nA multidimensional array is an array of arrays, where each element is itself an array that can contain either primitive data types or more arrays. In Python, these can be easily represented using nested lists, though for numerical computations, libraries like NumPy provide specialized data structures that offer more functionality and efficiency.\n• Initialization: Creating multidimensional arrays with default values or specific size is foundational and often requires specifying the dimensions (e.g., rows and columns for a matrix).\n• Accessing Elements: Elements in multidimensional arrays are accessed via multiple indices, one for each dimension (e.g., for a 2D array).\n• Iteration: Iterating over multidimensional arrays can involve nested loops or specialized functions (like in NumPy), allowing for the application of operations over each element.\n• Slicing and Dicing: Extracting sub-arrays or specific slices of a multidimensional array is a common operation, especially for tasks like cropping images or selecting specific data ranges.\n• Transformation and Manipulation: Operations like transposition (swapping rows and columns), rotation, and reshaping are crucial for data manipulation and preparation.\n\nPython’s native lists can represent multidimensional arrays but are limited in terms of performance and available operations. NumPy, a library designed for scientific computing, offers a powerful and efficient array object that is optimized for complex mathematical operations.\n\nHandling multidimensional arrays, especially in high dimensions, introduces complexity and challenges related to understanding the data structure’s layout and managing memory efficiently. Here are some best practices:\n• Understanding Data Layout: Be aware of how your programming language or library of choice stores multidimensional arrays in memory, as this can impact performance.\n• Vectorization: When using libraries like NumPy, prefer vectorized operations over explicit loops for operations on arrays, as they are usually more efficient and concise.\n• Memory Management: Especially in languages that give you control over memory allocation, managing the memory of large multidimensional arrays is critical to prevent issues like memory leaks or insufficient memory errors.\n\nRecursion is a programming technique where a function calls itself directly or indirectly, allowing for succinct solutions to problems that might otherwise require complex loops and auxiliary data structures. When applied to lists, especially those with nested structures or requiring complex manipulations, recursion can significantly simplify the code, making it easier to read and maintain. This approach is particularly useful in dealing with hierarchical data, such as file systems, organizational structures, or any form of nested lists.\n\nThe power of recursion lies in its ability to break down complex problems into simpler, more manageable parts. In the context of lists, this often means dealing with each element individually, applying the same operation to it (if it’s a sub-list), and aggregating the results in a way that mirrors the structure of the input data.\n• Base Case: Every recursive function must have a base case, which is a condition that stops the recursion. For lists, this is often an empty list or a list with a single element.\n• Recursive Step: This involves calling the same function with a subset of the original list, moving the problem closer to the base case.\n• Aggregation: Combining the results of recursive calls to construct the final output, which may involve concatenating lists, summing numbers, or any operation that reduces the results to a desired form.\n• Calculating Depth: Determine the maximum depth of nested lists by exploring each sub-list and calculating its depth recursively.\n• Manipulating Hierarchical Data: Apply transformations or filters to complex data structures represented as nested lists, handling each level of nesting with a separate recursive call.\n\nHere is an example of flatting a nested list:\n\nThis example demonstrates how recursion simplifies the process of flattening a nested list, breaking down the problem into manageable steps without the need for complex loops or stack management.\n• Recursion Depth: Python limits the depth of recursion to prevent stack overflow errors. For very deep or large nested lists, iterative solutions or increasing the recursion limit might be necessary.\n• Efficiency: Recursion can be less efficient than iterative solutions due to the overhead of function calls. Optimizations, such as tail recursion (where applicable), can mitigate this.\n• Clarity and Maintenance: While recursion can simplify code, it can also make it harder to understand for those not familiar with the technique. Clear documentation and judicious use are key.\n\nFunctional programming is a programming paradigm that treats computation as the evaluation of mathematical functions and avoids changing state and mutable data. Python, a multi-paradigm language, incorporates key functional programming concepts, allowing developers to write cleaner, more efficient code. Among the most powerful of these concepts are , , and , which provide abstract, concise ways to perform operations on lists and other iterable objects.\n\nThe function applies a given function to each item of an iterable (e.g., list, tuple) and returns an iterator. This can be used for operations like converting data types, applying a function to every element in a list, or performing mathematical operations.\n\nextracts elements from an iterable for which a function returns True. This is useful for filtering lists based on some condition, such as removing null values or filtering data that meet specific criteria.\n\napplies a function of two arguments cumulatively to the items of an iterable, from left to right, so as to reduce the iterable to a single value. This can be used for operations like summing all elements in a list, finding the maximum element, or accumulating results that depend on previous values. The function is part of the module in Python.\n• Conciseness and Clarity: By abstracting the operation from the loop that performs it, these functions can make the code more concise and easier to understand.\n• Immutability: These techniques encourage the use of immutable data structures, leading to safer, more predictable code.\n• Ease of Parallelization: Functional programming concepts lend themselves well to parallel computing, as stateless functions with no side effects are easier to execute concurrently.\n\nFunctional programming techniques are particularly useful in data processing, where operations like transformations, filtering, and aggregation are common. They allow for writing high-level, declarative code that clearly specifies what operation is being performed, without getting bogged down in the mechanics of loops and control flow.\n\nOptimizing list and array operations is crucial for enhancing the performance of Python applications, particularly in data-intensive tasks. Python offers a rich set of built-in functions for working with lists and arrays, which are often more efficient than manual implementations using loops. Understanding when and how to leverage these built-in capabilities, along with other optimization strategies, can significantly improve the speed and efficiency of your code.\n\nPython’s built-in functions and the specialized functions provided by libraries like NumPy are highly optimized for performance. They are usually implemented in C, making them faster than equivalent code written directly in Python.\n• Built-in Functions: Functions like , , , and are optimized for Python data types and should be used whenever possible.\n• NumPy Operations: When working with arrays, NumPy operations are highly optimized for numerical computations and can operate on entire arrays at once, leveraging vectorization.\n\nVectorization refers to the practice of applying operations to entire arrays instead of iterating over them element by element. This is not only syntactically cleaner but also significantly faster due to NumPy’s internal optimizations.\n\nManual loops in Python are much slower than using built-in functions or NumPy operations because of the overhead of the Python interpreter. Whenever possible, replace manual loops with built-in functions or comprehensions.\n\nList comprehensions and generator expressions offer a concise and efficient way to create and manipulate lists. They are generally faster than manual for-loop constructs for the same operation due to their optimized implementation.\n\nChoosing the right data structure can have a profound impact on performance. For example, deque (double-ended queue) from the module is more efficient for operations that involve inserting or removing elements from the ends than a list.\n\nLarge lists and arrays can consume a significant amount of memory, which can impact performance. Techniques for reducing memory usage include:\n• Using more compact data types (e.g., using or instead of or in NumPy arrays).\n• Deleting large objects or using to remove references to objects that are no longer needed.\n\nIn conclusion, mastering Python’s capabilities for array and list manipulation, along with the strategic application of functional programming techniques and the powerful features of NumPy, equips developers with a comprehensive toolkit for tackling complex data processing challenges. Whether optimizing for performance, handling large datasets, or implementing algorithms with efficiency in mind, understanding these foundational concepts is crucial. By prioritizing efficient coding practices, such as leveraging built-in functions, understanding algorithm complexity, and applying functional programming paradigms, developers can enhance the readability, maintainability, and performance of their code. This article has journeyed through key aspects essential for any Python programmer, from basic manipulations to advanced data operations, aiming to provide the knowledge needed to write elegant, efficient, and effective Python code. Embracing these techniques will not only improve your coding skills but also open up new possibilities for solving problems and implementing algorithms in the ever-evolving landscape of programming."
    },
    {
        "link": "https://labex.io/tutorials/python-how-to-handle-edge-cases-in-a-python-function-398003",
        "document": "In the realm of software development, edge cases refer to the unique or exceptional situations that can occur during the execution of a program. These are the scenarios that fall outside the normal or expected range of input or behavior, but still need to be accounted for to ensure the robustness and reliability of the application.\n\nEdge cases can arise due to a variety of reasons, such as:\n\nWhen a function or program is designed to handle a specific range of input values, edge cases can occur when the input falls outside of that range. For example, a function that calculates the area of a rectangle might encounter an edge case if the input values for length or width are negative or zero.\n\nEdge cases can also occur at the boundaries of a function's input or output range. For instance, a function that calculates the factorial of a number might encounter an edge case when the input is 0 or a very large number.\n\nEdge cases can also arise from exceptional situations that are not part of the normal program flow, such as errors, system failures, or unexpected user actions. These can include scenarios like division by zero, file not found, or network connectivity issues.\n\nEdge cases can also be related to performance-related issues, such as handling large or complex data sets, or dealing with high-volume or high-concurrency scenarios.\n\nIdentifying and handling edge cases is a crucial aspect of software development, as it helps ensure that the application can gracefully handle unexpected or exceptional situations, and provides a better user experience by anticipating and addressing potential problems."
    },
    {
        "link": "https://algocademy.com/blog/why-understanding-edge-cases-is-key-to-solving-coding-problems",
        "document": "In the world of programming and software development, the ability to solve complex coding problems efficiently is a highly sought-after skill. Whether you’re a beginner just starting your coding journey or an experienced developer preparing for technical interviews at top tech companies, mastering the art of problem-solving is crucial. One of the most important aspects of this skill is understanding and handling edge cases. In this comprehensive guide, we’ll explore why edge cases are so important, how they impact your code, and strategies for identifying and addressing them effectively.\n\nBefore diving into the importance of edge cases, let’s first define what they are. Edge cases, also known as corner cases, are situations that occur at the extreme ends of the possible range of inputs or conditions for a given problem. These are typically rare or unusual scenarios that may not be immediately obvious when designing a solution but can cause unexpected behavior or errors if not properly handled.\n\nFor example, consider a function that calculates the average of a list of numbers. Some edge cases for this problem might include:\n• A list with only one element\n\nEach of these scenarios represents an edge case that needs to be considered to ensure the function works correctly in all situations.\n\nUnderstanding and handling edge cases is crucial for several reasons:\n\nBy addressing edge cases, you make your code more robust and reliable. When your solution can handle extreme or unusual inputs, it becomes more resilient to unexpected situations and less likely to fail in real-world scenarios.\n\nConsidering edge cases often leads to better overall code quality. It forces you to think critically about your algorithm and implementation, potentially uncovering logical flaws or inefficiencies that might not be apparent when only considering typical inputs.\n\nIn user-facing applications, properly handling edge cases can significantly improve the user experience. By anticipating and gracefully handling unusual situations, you can prevent crashes, provide helpful error messages, and ensure a smooth experience for all users.\n\nFor those preparing for technical interviews, especially at major tech companies like FAANG (Facebook, Amazon, Apple, Netflix, Google), demonstrating your ability to identify and handle edge cases is crucial. Interviewers often use edge cases to assess a candidate’s problem-solving skills and attention to detail.\n\nNow that we understand the importance of edge cases, let’s explore some strategies for identifying them:\n\nConsider the extreme ends of your input range. What happens with the smallest or largest possible inputs? What about inputs at the boundaries between different categories or types?\n\n2. Think About Empty or Null Inputs\n\nAlways consider what happens when your function or algorithm receives empty collections, null values, or undefined inputs.\n\nIn dynamically typed languages or when working with user input, think about what happens if the input is of an unexpected type.\n\nFor string-based problems, consider inputs with special characters, different encodings, or unusual formatting.\n\nConsider how your solution behaves with extremely large or small inputs. This can help identify potential performance issues or numeric overflow problems.\n\nAsk yourself “What if…” questions to explore unusual scenarios. For example, “What if all elements are the same?” or “What if the input is already sorted?”\n\nOnce you’ve identified potential edge cases, the next step is to handle them effectively in your code. Here are some approaches:\n\nImplement thorough input validation at the beginning of your function or algorithm. This allows you to catch and handle invalid inputs early, preventing unexpected behavior later in the code.\n\nUse defensive programming techniques to anticipate and handle potential issues. This includes using try-except blocks, checking for null values, and using default values where appropriate.\n\nFor known edge cases, implement explicit handling logic. This might involve special return values, custom error messages, or alternative processing paths.\n\nDevelop a comprehensive test suite that includes edge cases. This helps ensure your solution works correctly for all scenarios and makes it easier to catch regressions when modifying your code.\n\nWhile edge cases can vary depending on the specific problem, here are some common categories to keep in mind:\n\nAlways consider what should happen when your function receives an empty collection (e.g., empty string, empty array) or a null/undefined value.\n\nTest your solution with inputs at the extreme ends of the valid range. For example, if working with integers, consider the minimum and maximum possible values.\n\nFor algorithms that work with collections, consider what happens when there’s only one element.\n\nTest scenarios where all elements are the same or where there are many duplicates.\n\n5. Very Large or Very Small Inputs\n\nConsider how your solution behaves with extremely large datasets or very small values that might cause precision issues.\n\nFor mathematical operations, always consider negative numbers and zero as potential inputs.\n\nIn dynamically typed languages or when working with user input, consider inputs of unexpected types or formats.\n\nFor string manipulation problems, test with special characters, Unicode symbols, and different character encodings.\n\nLet’s look at a real-world example of how considering edge cases can improve a common algorithm: binary search. Here’s a typical implementation of binary search in Python:\n\nWhile this implementation works for many cases, it doesn’t handle several important edge cases:\n• Target value smaller than the smallest element or larger than the largest element\n\nHere’s an improved version that addresses these edge cases:\n\nThis improved version handles the edge cases we identified, making the function more robust and reliable.\n\nThe Role of Edge Cases in Technical Interviews\n\nFor those preparing for technical interviews, especially at major tech companies, understanding and handling edge cases is crucial. Interviewers often use edge cases to assess a candidate’s problem-solving skills, attention to detail, and ability to write robust code.\n\nHere are some tips for addressing edge cases during technical interviews:\n• Clarify the Problem: Always ask clarifying questions about the input range, expected behavior for edge cases, and any assumptions you can make.\n• Think Aloud: As you’re solving the problem, verbalize your thought process, including how you’re considering potential edge cases.\n• Propose Test Cases: Before diving into coding, propose a set of test cases that include normal scenarios and edge cases. This demonstrates your thorough approach to problem-solving.\n• Implement Gracefully: When coding your solution, handle edge cases gracefully. This might involve input validation, error handling, or special return values.\n• Test Your Solution: After implementing your solution, walk through it with a few test cases, including edge cases, to demonstrate its correctness.\n• Discuss Trade-offs: Be prepared to discuss the trade-offs of your approach, especially in terms of how extensively you handle edge cases versus keeping the code simple and readable.\n\nUnderstanding and handling edge cases is a critical skill for any programmer, from beginners to experienced developers preparing for technical interviews at top tech companies. By considering edge cases, you create more robust, reliable, and user-friendly code. It demonstrates your attention to detail and your ability to anticipate and handle unexpected situations.\n\nAs you continue to develop your coding skills, make it a habit to always consider potential edge cases when designing and implementing your solutions. Practice identifying and handling edge cases in your coding exercises and projects. This will not only improve the quality of your code but also prepare you for the challenges you’ll face in technical interviews and real-world software development.\n\nRemember, the ability to handle edge cases effectively is what often separates good code from great code. By mastering this skill, you’ll be well on your way to becoming a more proficient and sought-after programmer in the competitive world of software development."
    },
    {
        "link": "https://linkedin.com/advice/1/how-do-you-handle-edge-cases-corner-when-designing",
        "document": "How to test your data structure for edge cases and corner cases? The second step to handle edge cases and corner cases is to test your data structure with them. This means writing test cases that cover all the possible edge cases and corner cases, as well as some normal or typical cases. You should also use debugging tools, such as print statements, breakpoints, or visualizers, to inspect the state and behavior of your data structure during the execution. You can also use online platforms, such as LeetCode, Codeforces, or HackerRank, to practice and test your data structures with various problems and test cases. Help others by sharing more (125 characters min.)\n• Unit test your data structures (or really, any piece of code that can fall victim to edge and corner cases). A good unit test should cover all of your edge and corner cases. One thing I like to do is hit my unit under test (UUT) with iterations of randomized data - making the amount of iterations sufficiently large enough that the randomness will cover the edge and corner cases.\n\nHow to fix your data structure for edge cases and corner cases? The third step to handle edge cases and corner cases is to fix your data structure if you encounter any errors or issues with them. This means identifying the root cause of the problem, and modifying your code accordingly. You should also re-test your data structure with the same or similar test cases, to ensure that your solution works correctly and efficiently. You should also document your changes and explain your reasoning, to make your code more readable and maintainable. Help others by sharing more (125 characters min.)\n• If possible, I try to identify the edge cases first and make sure my solution takes them into account from the beginning. With this in mind, you won’t get caught in a trap trying to refactor all your code because you didn’t consider essential cases. Especially within interviews, if you can communicate early what you think through edge cases may be, it will be a good sign to your interviewer and they’ll steer you in the right direction :)\n• if statements so for example in python, if [parameter var] is None or in java, if( [parameter var] == null) do X action. This could be returning a default value or to not do anything\n\nHere’s what else to consider This is a space to share examples, stories, or insights that don’t fit into any of the previous sections. What else would you like to add? Help others by sharing more (125 characters min.)\n• While programming for a Fibonacci sequence which was used as a subproblem to a bigger problem I initialized first and second result and continued to use them in a for loop starting with 3 up to the length of the array only to realize that it would break if n = 3. I realized this only after testing with multiple inputs. We fail to understand that sub problems have a ripple effect and sometimes the most simple solution is the best solution."
    },
    {
        "link": "https://stackoverflow.com/questions/33742098/border-edge-operations-on-numpy-arrays",
        "document": "Suppose I have a 3D numpy array of nonzero values and . As an example I will take a sphere of random values:\n\nFirst, I would like to find the \"border voxels\" (all nonzero values that have a zero within their neigbourhood). Second, I would like to replace all border voxels with the mean of their nonzero neighbours. So far I tried to use scipy's generic filter in the following way:\n\nFunction to apply at each element:\n\nIs this a proper way to handle this problem? I feel that I am trying to reinvent the wheel here and that there must be a shorter, nicer way to achieve the result. Are there any other suitable (numpy, scipy ) functions that I can use?\n\nI messed one thing up: I would like to replace all border voxels with the mean of their nonzero AND non-border neighbours. For this, I tried to clean up the from ali_m's code (2D case):\n\nNow I can't figure out why comes back empty?\n\nFurthermore, correct me if I am wrong but doesn't with radius 1 adress only the 6 next neighbours (euclidean distance 1)? Should I set (3D case) as radius to get the 26-neighbourhood?"
    },
    {
        "link": "https://docs.python.org/3/library/stdtypes.html",
        "document": "The following sections describe the standard types that are built into the interpreter.\n\nThe principal built-in types are numerics, sequences, mappings, classes, instances and exceptions.\n\nSome collection classes are mutable. The methods that add, subtract, or rearrange their members in place, and don’t return a specific item, never return the collection instance itself but .\n\nSome operations are supported by several object types; in particular, practically all objects can be compared for equality, tested for truth value, and converted to a string (with the function or the slightly different function). The latter function is implicitly used when an object is written by the function.\n\nThere are three distinct numeric types: integers, floating-point numbers, and complex numbers. In addition, Booleans are a subtype of integers. Integers have unlimited precision. Floating-point numbers are usually implemented using double in C; information about the precision and internal representation of floating-point numbers for the machine on which your program is running is available in . Complex numbers have a real and imaginary part, which are each a floating-point number. To extract these parts from a complex number z, use and . (The standard library includes the additional numeric types , for rationals, and , for floating-point numbers with user-definable precision.) Numbers are created by numeric literals or as the result of built-in functions and operators. Unadorned integer literals (including hex, octal and binary numbers) yield integers. Numeric literals containing a decimal point or an exponent sign yield floating-point numbers. Appending or to a numeric literal yields an imaginary number (a complex number with a zero real part) which you can add to an integer or float to get a complex number with real and imaginary parts. Python fully supports mixed arithmetic: when a binary arithmetic operator has operands of different numeric types, the operand with the “narrower” type is widened to that of the other, where integer is narrower than floating point, which is narrower than complex. A comparison between numbers of different types behaves as though the exact values of those numbers were being compared. The constructors , , and can be used to produce numbers of a specific type. All numeric types (except complex) support the following operations (for priorities of the operations, see Operator precedence): absolute value or magnitude of x a complex number with real part re, imaginary part im. im defaults to zero. conjugate of the complex number c\n• None Also referred to as integer division. For operands of type , the result has type . For operands of type , the result has type . In general, the result is a whole integer, though the result’s type is not necessarily . The result is always rounded towards minus infinity: is , is , is , and is .\n• None Not for complex numbers. Instead convert to floats using if appropriate.\n• None Conversion from to truncates, discarding the fractional part. See functions and for alternative conversions.\n• None float also accepts the strings “nan” and “inf” with an optional prefix “+” or “-” for Not a Number (NaN) and positive or negative infinity.\n• None Python defines and to be , as is common for programming languages.\n• None The numeric literals accepted include the digits to or any Unicode equivalent (code points with the property). See the Unicode Standard for a complete list of code points with the property. All types ( and ) also include the following operations: x rounded to n digits, rounding half to even. If n is omitted, it defaults to 0. For additional numeric operations see the and modules. Bitwise operations only make sense for integers. The result of bitwise operations is calculated as though carried out in two’s complement with an infinite number of sign bits. The priorities of the binary bitwise operations are all lower than the numeric operations and higher than the comparisons; the unary operation has the same priority as the other unary numeric operations ( and ). This table lists the bitwise operations sorted in ascending priority: bitwise exclusive or of x and y\n• None Negative shift counts are illegal and cause a to be raised.\n• None A left shift by n bits is equivalent to multiplication by .\n• None A right shift by n bits is equivalent to floor division by .\n• None Performing these calculations with at least one extra sign extension bit in a finite two’s complement representation (a working bit-width of or more) is sufficient to get the same result as if there were an infinite number of sign bits. The int type implements the abstract base class. In addition, it provides a few more methods: Return the number of bits necessary to represent an integer in binary, excluding the sign and leading zeros: More precisely, if is nonzero, then is the unique positive integer such that . Equivalently, when is small enough to have a correctly rounded logarithm, then . If is zero, then returns . Return the number of ones in the binary representation of the absolute value of the integer. This is also known as the population count. Example: Return an array of bytes representing an integer. The integer is represented using length bytes, and defaults to 1. An is raised if the integer is not representable with the given number of bytes. The byteorder argument determines the byte order used to represent the integer, and defaults to . If byteorder is , the most significant byte is at the beginning of the byte array. If byteorder is , the most significant byte is at the end of the byte array. The signed argument determines whether two’s complement is used to represent the integer. If signed is and a negative integer is given, an is raised. The default value for signed is . The default values can be used to conveniently turn an integer into a single byte object: However, when using the default arguments, don’t try to convert a value greater than 255 or you’ll get an . \"byteorder must be either 'little' or 'big'\" Changed in version 3.11: Added default argument values for and . Return the integer represented by the given array of bytes. The argument bytes must either be a bytes-like object or an iterable producing bytes. The byteorder argument determines the byte order used to represent the integer, and defaults to . If byteorder is , the most significant byte is at the beginning of the byte array. If byteorder is , the most significant byte is at the end of the byte array. To request the native byte order of the host system, use as the byte order value. The signed argument indicates whether two’s complement is used to represent the integer. \"byteorder must be either 'little' or 'big'\" Changed in version 3.11: Added default argument value for . Return a pair of integers whose ratio is equal to the original integer and has a positive denominator. The integer ratio of integers (whole numbers) is always the integer as the numerator and as the denominator. The float type implements the abstract base class. float also has the following additional methods. Return a pair of integers whose ratio is exactly equal to the original float. The ratio is in lowest terms and has a positive denominator. Raises on infinities and a on NaNs. Return if the float instance is finite with integral value, and otherwise: Two methods support conversion to and from hexadecimal strings. Since Python’s floats are stored internally as binary numbers, converting a float to or from a decimal string usually involves a small rounding error. In contrast, hexadecimal strings allow exact representation and specification of floating-point numbers. This can be useful when debugging, and in numerical work. Return a representation of a floating-point number as a hexadecimal string. For finite floating-point numbers, this representation will always include a leading and a trailing and exponent. Class method to return the float represented by a hexadecimal string s. The string s may have leading and trailing whitespace. Note that is an instance method, while is a class method. where the optional may by either or , and are strings of hexadecimal digits, and is a decimal integer with an optional leading sign. Case is not significant, and there must be at least one hexadecimal digit in either the integer or the fraction. This syntax is similar to the syntax specified in section 6.4.4.2 of the C99 standard, and also to the syntax used in Java 1.5 onwards. In particular, the output of is usable as a hexadecimal floating-point literal in C or Java code, and hexadecimal strings produced by C’s format character or Java’s are accepted by . Note that the exponent is written in decimal rather than hexadecimal, and that it gives the power of 2 by which to multiply the coefficient. For example, the hexadecimal string represents the floating-point number , or : Applying the reverse conversion to gives a different hexadecimal string representing the same number: For numbers and , possibly of different types, it’s a requirement that whenever (see the method documentation for more details). For ease of implementation and efficiency across a variety of numeric types (including , , and ) Python’s hash for numeric types is based on a single mathematical function that’s defined for any rational number, and hence applies to all instances of and , and all finite instances of and . Essentially, this function is given by reduction modulo for a fixed prime . The value of is made available to Python as the attribute of . CPython implementation detail: Currently, the prime used is on machines with 32-bit C longs and on machines with 64-bit C longs. Here are the rules in detail:\n• None If is a nonnegative rational number and is not divisible by , define as , where gives the inverse of modulo .\n• None If is a nonnegative rational number and is divisible by (but is not) then has no inverse modulo and the rule above doesn’t apply; in this case define to be the constant value .\n• None If is a negative rational number define as . If the resulting hash is , replace it with .\n• None The particular values and are used as hash values for positive infinity or negative infinity (respectively).\n• None For a number , the hash values of the real and imaginary parts are combined by computing , reduced modulo so that it lies in . Again, if the result is , it’s replaced with . To clarify the above rules, here’s some example Python code, equivalent to the built-in hash, for computing the hash of a rational number, , or : Assumes m and n are integers, with n positive. # Remove common factors of P. (Unnecessary if m and n already coprime.) # Fermat's Little Theorem: pow(n, P-1, P) is 1, so # pow(n, P-2, P) gives the inverse of n modulo P.\n\nThere are three basic sequence types: lists, tuples, and range objects. Additional sequence types tailored for processing of binary data and text strings are described in dedicated sections. The operations in the following table are supported by most sequence types, both mutable and immutable. The ABC is provided to make it easier to correctly implement these operations on custom sequence types. This table lists the sequence operations sorted in ascending priority. In the table, s and t are sequences of the same type, n, i, j and k are integers and x is an arbitrary object that meets any type and value restrictions imposed by s. The and operations have the same priorities as the comparison operations. The (concatenation) and (repetition) operations have the same priority as the corresponding numeric operations. if an item of s is equal to x, else if an item of s is equal to x, else the concatenation of s and t equivalent to adding s to itself n times slice of s from i to j with step k index of the first occurrence of x in s (at or after index i and before index j) total number of occurrences of x in s Sequences of the same type also support comparisons. In particular, tuples and lists are compared lexicographically by comparing corresponding elements. This means that to compare equal, every element must compare equal and the two sequences must be of the same type and have the same length. (For full details see Comparisons in the language reference.) Forward and reversed iterators over mutable sequences access values using an index. That index will continue to march forward (or backward) even if the underlying sequence is mutated. The iterator terminates only when an or a is encountered (or when the index drops below zero).\n• None While the and operations are used only for simple containment testing in the general case, some specialised sequences (such as , and ) also use them for subsequence testing:\n• None Values of n less than are treated as (which yields an empty sequence of the same type as s). Note that items in the sequence s are not copied; they are referenced multiple times. This often haunts new Python programmers; consider: What has happened is that is a one-element list containing an empty list, so all three elements of are references to this single empty list. Modifying any of the elements of modifies this single list. You can create a list of different lists this way: Further explanation is available in the FAQ entry How do I create a multidimensional list?.\n• None If i or j is negative, the index is relative to the end of sequence s: or is substituted. But note that is still .\n• None The slice of s from i to j is defined as the sequence of items with index k such that . If i or j is greater than , use . If i is omitted or , use . If j is omitted or , use . If i is greater than or equal to j, the slice is empty.\n• None The slice of s from i to j with step k is defined as the sequence of items with index such that . In other words, the indices are , , , and so on, stopping when j is reached (but never including j). When k is positive, i and j are reduced to if they are greater. When k is negative, i and j are reduced to if they are greater. If i or j are omitted or , they become “end” values (which end depends on the sign of k). Note, k cannot be zero. If k is , it is treated like .\n• None Concatenating immutable sequences always results in a new object. This means that building up a sequence by repeated concatenation will have a quadratic runtime cost in the total sequence length. To get a linear runtime cost, you must switch to one of the alternatives below:\n• None if concatenating objects, you can build a list and use at the end or else write to an instance and retrieve its value when complete\n• None if concatenating objects, you can similarly use or , or you can do in-place concatenation with a object. objects are mutable and have an efficient overallocation mechanism\n• None for other types, investigate the relevant class documentation\n• None Some sequence types (such as ) only support item sequences that follow specific patterns, and hence don’t support sequence concatenation or repetition.\n• None raises when x is not found in s. Not all implementations support passing the additional arguments i and j. These arguments allow efficient searching of subsections of the sequence. Passing the extra arguments is roughly equivalent to using , only without copying any data and with the returned index being relative to the start of the sequence rather than the start of the slice. The only operation that immutable sequence types generally implement that is not also implemented by mutable sequence types is support for the built-in. This support allows immutable sequences, such as instances, to be used as keys and stored in and instances. Attempting to hash an immutable sequence that contains unhashable values will result in . The operations in the following table are defined on mutable sequence types. The ABC is provided to make it easier to correctly implement these operations on custom sequence types. In the table s is an instance of a mutable sequence type, t is any iterable object and x is an arbitrary object that meets any type and value restrictions imposed by s (for example, only accepts integers that meet the value restriction ). item i of s is replaced by x slice of s from i to j is replaced by the contents of the iterable t the elements of are replaced by those of t removes the elements of from the list appends x to the end of the sequence (same as ) removes all items from s (same as ) creates a shallow copy of s (same as ) extends s with the contents of t (for the most part the same as ) inserts x into s at the index given by i (same as ) retrieves the item at i and also removes it from s removes the first item from s where is equal to x reverses the items of s in place\n• None If k is not equal to , t must have the same length as the slice it is replacing.\n• None The optional argument i defaults to , so that by default the last item is removed and returned.\n• None raises when x is not found in s.\n• None The method modifies the sequence in place for economy of space when reversing a large sequence. To remind users that it operates by side effect, it does not return the reversed sequence.\n• None and are included for consistency with the interfaces of mutable containers that don’t support slicing operations (such as and ). is not part of the ABC, but most concrete mutable sequence classes provide it.\n• None The value n is an integer, or an object implementing . Zero and negative values of n clear the sequence. Items in the sequence are not copied; they are referenced multiple times, as explained for under Common Sequence Operations. Lists are mutable sequences, typically used to store collections of homogeneous items (where the precise degree of similarity will vary by application). Lists may be constructed in several ways:\n• None Using a pair of square brackets to denote the empty list:\n• None Using the type constructor: or The constructor builds a list whose items are the same and in the same order as iterable’s items. iterable may be either a sequence, a container that supports iteration, or an iterator object. If iterable is already a list, a copy is made and returned, similar to . For example, returns and returns . If no argument is given, the constructor creates a new empty list, . Many other operations also produce lists, including the built-in. Lists implement all of the common and mutable sequence operations. Lists also provide the following additional method: This method sorts the list in place, using only comparisons between items. Exceptions are not suppressed - if any comparison operations fail, the entire sort operation will fail (and the list will likely be left in a partially modified state). accepts two arguments that can only be passed by keyword (keyword-only arguments): key specifies a function of one argument that is used to extract a comparison key from each list element (for example, ). The key corresponding to each item in the list is calculated once and then used for the entire sorting process. The default value of means that list items are sorted directly without calculating a separate key value. The utility is available to convert a 2.x style cmp function to a key function. reverse is a boolean value. If set to , then the list elements are sorted as if each comparison were reversed. This method modifies the sequence in place for economy of space when sorting a large sequence. To remind users that it operates by side effect, it does not return the sorted sequence (use to explicitly request a new sorted list instance). The method is guaranteed to be stable. A sort is stable if it guarantees not to change the relative order of elements that compare equal — this is helpful for sorting in multiple passes (for example, sort by department, then by salary grade). For sorting examples and a brief sorting tutorial, see Sorting Techniques. CPython implementation detail: While a list is being sorted, the effect of attempting to mutate, or even inspect, the list is undefined. The C implementation of Python makes the list appear empty for the duration, and raises if it can detect that the list has been mutated during a sort. Tuples are immutable sequences, typically used to store collections of heterogeneous data (such as the 2-tuples produced by the built-in). Tuples are also used for cases where an immutable sequence of homogeneous data is needed (such as allowing storage in a or instance). Tuples may be constructed in a number of ways:\n• None Using a pair of parentheses to denote the empty tuple:\n• None Using a trailing comma for a singleton tuple: or\n• None Using the built-in: or The constructor builds a tuple whose items are the same and in the same order as iterable’s items. iterable may be either a sequence, a container that supports iteration, or an iterator object. If iterable is already a tuple, it is returned unchanged. For example, returns and returns . If no argument is given, the constructor creates a new empty tuple, . Note that it is actually the comma which makes a tuple, not the parentheses. The parentheses are optional, except in the empty tuple case, or when they are needed to avoid syntactic ambiguity. For example, is a function call with three arguments, while is a function call with a 3-tuple as the sole argument. Tuples implement all of the common sequence operations. For heterogeneous collections of data where access by name is clearer than access by index, may be a more appropriate choice than a simple tuple object. The type represents an immutable sequence of numbers and is commonly used for looping a specific number of times in loops. The arguments to the range constructor must be integers (either built-in or any object that implements the special method). If the step argument is omitted, it defaults to . If the start argument is omitted, it defaults to . If step is zero, is raised. For a positive step, the contents of a range are determined by the formula where and . For a negative step, the contents of the range are still determined by the formula , but the constraints are and . A range object will be empty if does not meet the value constraint. Ranges do support negative indices, but these are interpreted as indexing from the end of the sequence determined by the positive indices. Ranges containing absolute values larger than are permitted but some features (such as ) may raise . Ranges implement all of the common sequence operations except concatenation and repetition (due to the fact that range objects can only represent sequences that follow a strict pattern and repetition and concatenation will usually violate that pattern). The value of the start parameter (or if the parameter was not supplied) The value of the stop parameter The value of the step parameter (or if the parameter was not supplied) The advantage of the type over a regular or is that a object will always take the same (small) amount of memory, no matter the size of the range it represents (as it only stores the , and values, calculating individual items and subranges as needed). Range objects implement the ABC, and provide features such as containment tests, element index lookup, slicing and support for negative indices (see Sequence Types — list, tuple, range): Testing range objects for equality with and compares them as sequences. That is, two range objects are considered equal if they represent the same sequence of values. (Note that two range objects that compare equal might have different , and attributes, for example or .) Changed in version 3.2: Implement the Sequence ABC. Support slicing and negative indices. Test objects for membership in constant time instead of iterating through all items. Changed in version 3.3: Define ‘==’ and ‘!=’ to compare range objects based on the sequence of values they define (instead of comparing based on object identity).\n• None The linspace recipe shows how to implement a lazy version of range suitable for floating-point applications."
    },
    {
        "link": "https://docs.python.org/3/library/decimal.html",
        "document": "The module provides support for fast correctly rounded decimal floating-point arithmetic. It offers several advantages over the datatype:\n• None Decimal “is based on a floating-point model which was designed with people in mind, and necessarily has a paramount guiding principle – computers must provide an arithmetic that works in the same way as the arithmetic that people learn at school.” – excerpt from the decimal arithmetic specification.\n• None Decimal numbers can be represented exactly. In contrast, numbers like and do not have exact representations in binary floating point. End users typically would not expect to display as as it does with binary floating point.\n• None The exactness carries over into arithmetic. In decimal floating point, is exactly equal to zero. In binary floating point, the result is . While near to zero, the differences prevent reliable equality testing and differences can accumulate. For this reason, decimal is preferred in accounting applications which have strict equality invariants.\n• None The decimal module incorporates a notion of significant places so that is . The trailing zero is kept to indicate significance. This is the customary presentation for monetary applications. For multiplication, the “schoolbook” approach uses all the figures in the multiplicands. For instance, gives while gives .\n• None Unlike hardware based binary floating point, the decimal module has a user alterable precision (defaulting to 28 places) which can be as large as needed for a given problem:\n• None Both binary and decimal floating point are implemented in terms of published standards. While the built-in float type exposes only a modest portion of its capabilities, the decimal module exposes all required parts of the standard. When needed, the programmer has full control over rounding and signal handling. This includes an option to enforce exact arithmetic by using exceptions to block any inexact operations.\n• None The decimal module was designed to support “without prejudice, both exact unrounded decimal arithmetic (sometimes called fixed-point arithmetic) and rounded floating-point arithmetic.” – excerpt from the decimal arithmetic specification.\n\nThe module design is centered around three concepts: the decimal number, the context for arithmetic, and signals.\n\nA decimal number is immutable. It has a sign, coefficient digits, and an exponent. To preserve significance, the coefficient digits do not truncate trailing zeros. Decimals also include special values such as , , and . The standard also differentiates from .\n\nThe context for arithmetic is an environment specifying precision, rounding rules, limits on exponents, flags indicating the results of operations, and trap enablers which determine whether signals are treated as exceptions. Rounding options include , , , , , , , and .\n\nSignals are groups of exceptional conditions arising during the course of computation. Depending on the needs of the application, signals may be ignored, considered as informational, or treated as exceptions. The signals in the decimal module are: , , , , , , , and .\n\nFor each signal there is a flag and a trap enabler. When a signal is encountered, its flag is set to one, then, if the trap enabler is set to one, an exception is raised. Flags are sticky, so the user needs to reset them before monitoring a calculation.\n\nThe usual start to using decimals is importing the module, viewing the current context with and, if necessary, setting new values for precision, rounding, or enabled traps: Decimal instances can be constructed from integers, strings, floats, or tuples. Construction from an integer or a float performs an exact conversion of the value of that integer or float. Decimal numbers include special values such as which stands for “Not a number”, positive and negative , and : If the signal is trapped, accidental mixing of decimals and floats in constructors or ordering comparisons raises an exception: The significance of a new Decimal is determined solely by the number of digits input. Context precision and rounding only come into play during arithmetic operations. If the internal limits of the C version are exceeded, constructing a decimal raises : Decimals interact well with much of the rest of Python. Here is a small decimal floating-point flying circus: And some mathematical functions are also available to Decimal: The method rounds a number to a fixed exponent. This method is useful for monetary applications that often round results to a fixed number of places: As shown above, the function accesses the current context and allows the settings to be changed. This approach meets the needs of most applications. For more advanced work, it may be useful to create alternate contexts using the Context() constructor. To make an alternate active, use the function. In accordance with the standard, the module provides two ready to use standard contexts, and . The former is especially useful for debugging because many of the traps are enabled: Contexts also have signal flags for monitoring exceptional conditions encountered during computations. The flags remain set until explicitly cleared, so it is best to clear the flags before each set of monitored computations by using the method. The flags entry shows that the rational approximation to pi was rounded (digits beyond the context precision were thrown away) and that the result is inexact (some of the discarded digits were non-zero). Individual traps are set using the dictionary in the attribute of a context: Most programs adjust the current context only once, at the beginning of the program. And, in many applications, data is converted to with a single cast inside a loop. With context set and decimals created, the bulk of the program manipulates the data no differently than with other Python numeric types.\n\nConstruct a new object based from value. value can be an integer, string, tuple, , or another object. If no value is given, returns . If value is a string, it should conform to the decimal numeric string syntax after leading and trailing whitespace characters, as well as underscores throughout, are removed: Other Unicode decimal digits are also permitted where appears above. These include decimal digits from various other alphabets (for example, Arabic-Indic and Devanāgarī digits) along with the fullwidth digits through . If value is a , it should have three components, a sign ( for positive or for negative), a of digits, and an integer exponent. For example, returns . If value is a , the binary floating-point value is losslessly converted to its exact decimal equivalent. This conversion can often require 53 or more digits of precision. For example, converts to . The context precision does not affect how many digits are stored. That is determined exclusively by the number of digits in value. For example, records all five zeros even if the context precision is only three. The purpose of the context argument is determining what to do if value is a malformed string. If the context traps , an exception is raised; otherwise, the constructor returns a new Decimal with the value of . Changed in version 3.2: The argument to the constructor is now permitted to be a instance. Changed in version 3.3: arguments raise an exception if the trap is set. By default the trap is off. Changed in version 3.6: Underscores are allowed for grouping, as with integral and floating-point literals in code. Decimal floating-point objects share many properties with the other built-in numeric types such as and . All of the usual math operations and special methods apply. Likewise, decimal objects can be copied, pickled, printed, used as dictionary keys, used as set elements, compared, sorted, and coerced to another type (such as or ). There are some small differences between arithmetic on Decimal objects and arithmetic on integers and floats. When the remainder operator is applied to Decimal objects, the sign of the result is the sign of the dividend rather than the sign of the divisor: The integer division operator behaves analogously, returning the integer part of the true quotient (truncating towards zero) rather than its floor, so as to preserve the usual identity : The and operators implement the and operations (respectively) as described in the specification. Decimal objects cannot generally be combined with floats or instances of in arithmetic operations: an attempt to add a to a , for example, will raise a . However, it is possible to use Python’s comparison operators to compare a instance with another number . This avoids confusing results when doing equality comparisons between numbers of different types. Changed in version 3.2: Mixed-type comparisons between instances and other numeric types are now fully supported. In addition to the standard numeric properties, decimal floating-point objects also have a number of specialized methods: Return the adjusted exponent after shifting out the coefficient’s rightmost digits until only the lead digit remains: returns seven. Used for determining the position of the most significant digit with respect to the decimal point. Return a pair of integers that represent the given instance as a fraction, in lowest terms and with a positive denominator: The conversion is exact. Raise OverflowError on infinities and ValueError on NaNs. Return the canonical encoding of the argument. Currently, the encoding of a instance is always canonical, so this operation returns its argument unchanged. Compare the values of two Decimal instances. returns a Decimal instance, and if either operand is a NaN then the result is a NaN: This operation is identical to the method, except that all NaNs signal. That is, if neither operand is a signaling NaN then any quiet NaN operand is treated as though it were a signaling NaN. Compare two operands using their abstract representation rather than their numerical value. Similar to the method, but the result gives a total ordering on instances. Two instances with the same numeric value but different representations compare unequal in this ordering: Quiet and signaling NaNs are also included in the total ordering. The result of this function is if both operands have the same representation, if the first operand is lower in the total order than the second, and if the first operand is higher in the total order than the second operand. See the specification for details of the total order. This operation is unaffected by context and is quiet: no flags are changed and no rounding is performed. As an exception, the C version may raise InvalidOperation if the second operand cannot be converted exactly. Compare two operands using their abstract representation rather than their value as in , but ignoring the sign of each operand. is equivalent to . This operation is unaffected by context and is quiet: no flags are changed and no rounding is performed. As an exception, the C version may raise InvalidOperation if the second operand cannot be converted exactly. Just returns self, this method is only to comply with the Decimal Specification. Return the absolute value of the argument. This operation is unaffected by the context and is quiet: no flags are changed and no rounding is performed. Return the negation of the argument. This operation is unaffected by the context and is quiet: no flags are changed and no rounding is performed. Return a copy of the first operand with the sign set to be the same as the sign of the second operand. For example: This operation is unaffected by context and is quiet: no flags are changed and no rounding is performed. As an exception, the C version may raise InvalidOperation if the second operand cannot be converted exactly. Return the value of the (natural) exponential function at the given number. The result is correctly rounded using the rounding mode. Alternative constructor that only accepts instances of or . Note is not the same as . Since 0.1 is not exactly representable in binary floating point, the value is stored as the nearest representable value which is . That equivalent value in decimal is . From Python 3.2 onwards, a instance can also be constructed directly from a . Fused multiply-add. Return self*other+third with no rounding of the intermediate product self*other. Return if the argument is canonical and otherwise. Currently, a instance is always canonical, so this operation always returns . Return if the argument is a finite number, and if the argument is an infinity or a NaN. Return if the argument is either positive or negative infinity and otherwise. Return if the argument is a (quiet or signaling) NaN and otherwise. Return if the argument is a normal finite number. Return if the argument is zero, subnormal, infinite or a NaN. Return if the argument is a quiet NaN, and otherwise. Return if the argument has a negative sign and otherwise. Note that zeros and NaNs can both carry signs. Return if the argument is a signaling NaN and otherwise. Return if the argument is subnormal, and otherwise. Return if the argument is a (positive or negative) zero and otherwise. Return the natural (base e) logarithm of the operand. The result is correctly rounded using the rounding mode. Return the base ten logarithm of the operand. The result is correctly rounded using the rounding mode. For a nonzero number, return the adjusted exponent of its operand as a instance. If the operand is a zero then is returned and the flag is raised. If the operand is an infinity then is returned. is a logical operation which takes two logical operands (see Logical operands). The result is the digit-wise of the two operands. is a logical operation. The result is the digit-wise inversion of the operand. is a logical operation which takes two logical operands (see Logical operands). The result is the digit-wise of the two operands. is a logical operation which takes two logical operands (see Logical operands). The result is the digit-wise exclusive or of the two operands. Like except that the context rounding rule is applied before returning and that values are either signaled or ignored (depending on the context and whether they are signaling or quiet). Similar to the method, but the comparison is done using the absolute values of the operands. Like except that the context rounding rule is applied before returning and that values are either signaled or ignored (depending on the context and whether they are signaling or quiet). Similar to the method, but the comparison is done using the absolute values of the operands. Return the largest number representable in the given context (or in the current thread’s context if no context is given) that is smaller than the given operand. Return the smallest number representable in the given context (or in the current thread’s context if no context is given) that is larger than the given operand. If the two operands are unequal, return the number closest to the first operand in the direction of the second operand. If both operands are numerically equal, return a copy of the first operand with the sign set to be the same as the sign of the second operand. Used for producing canonical values of an equivalence class within either the current context or the specified context. This has the same semantics as the unary plus operation, except that if the final result is finite it is reduced to its simplest form, with all trailing zeros removed and its sign preserved. That is, while the coefficient is non-zero and a multiple of ten the coefficient is divided by ten and the exponent is incremented by 1. Otherwise (the coefficient is zero) the exponent is set to 0. In all cases the sign is unchanged. For example, and both normalize to the equivalent value . Note that rounding is applied before reducing to simplest form. In the latest versions of the specification, this operation is also known as . Return a string describing the class of the operand. The returned value is one of the following ten strings.\n• None , indicating that the operand is negative infinity.\n• None , indicating that the operand is a negative normal number.\n• None , indicating that the operand is negative and subnormal.\n• None , indicating that the operand is a negative zero.\n• None , indicating that the operand is a positive zero.\n• None , indicating that the operand is positive and subnormal.\n• None , indicating that the operand is a positive normal number.\n• None , indicating that the operand is positive infinity.\n• None , indicating that the operand is a quiet NaN (Not a Number).\n• None , indicating that the operand is a signaling NaN. Return a value equal to the first operand after rounding and having the exponent of the second operand. Unlike other operations, if the length of the coefficient after the quantize operation would be greater than precision, then an is signaled. This guarantees that, unless there is an error condition, the quantized exponent is always equal to that of the right-hand operand. Also unlike other operations, quantize never signals Underflow, even if the result is subnormal and inexact. If the exponent of the second operand is larger than that of the first then rounding may be necessary. In this case, the rounding mode is determined by the argument if given, else by the given argument; if neither argument is given the rounding mode of the current thread’s context is used. An error is returned whenever the resulting exponent is greater than or less than . Return , the radix (base) in which the class does all its arithmetic. Included for compatibility with the specification. Return the remainder from dividing self by other. This differs from in that the sign of the remainder is chosen so as to minimize its absolute value. More precisely, the return value is where is the integer nearest to the exact value of , and if two integers are equally near then the even one is chosen. If the result is zero then its sign will be the sign of self. Return the result of rotating the digits of the first operand by an amount specified by the second operand. The second operand must be an integer in the range -precision through precision. The absolute value of the second operand gives the number of places to rotate. If the second operand is positive then rotation is to the left; otherwise rotation is to the right. The coefficient of the first operand is padded on the left with zeros to length precision if necessary. The sign and exponent of the first operand are unchanged. Test whether self and other have the same exponent or whether both are . This operation is unaffected by context and is quiet: no flags are changed and no rounding is performed. As an exception, the C version may raise InvalidOperation if the second operand cannot be converted exactly. Return the first operand with exponent adjusted by the second. Equivalently, return the first operand multiplied by . The second operand must be an integer. Return the result of shifting the digits of the first operand by an amount specified by the second operand. The second operand must be an integer in the range -precision through precision. The absolute value of the second operand gives the number of places to shift. If the second operand is positive then the shift is to the left; otherwise the shift is to the right. Digits shifted into the coefficient are zeros. The sign and exponent of the first operand are unchanged. Return the square root of the argument to full precision. Convert to a string, using engineering notation if an exponent is needed. Engineering notation has an exponent which is a multiple of 3. This can leave up to 3 digits to the left of the decimal place and may require the addition of either one or two trailing zeros. For example, this converts to . Identical to the method. The name has been kept for compatibility with older versions. Round to the nearest integer, signaling or as appropriate if rounding occurs. The rounding mode is determined by the parameter if given, else by the given . If neither parameter is given then the rounding mode of the current context is used. Round to the nearest integer without signaling or . If given, applies rounding; otherwise, uses the rounding method in either the supplied context or the current context. Decimal numbers can be rounded using the function: If ndigits is not given or , returns the nearest to number, rounding ties to even, and ignoring the rounding mode of the context. Raises if number is an infinity or if it is a (quiet or signaling) NaN. If ndigits is an , the context’s rounding mode is respected and a representing number rounded to the nearest multiple of is returned; in this case, is equivalent to . Returns if number is a quiet NaN. Raises if number is an infinity, a signaling NaN, or if the length of the coefficient after the quantize operation would be greater than the current context’s precision. In other words, for the non-corner cases:\n• None if ndigits is positive, return number rounded to ndigits decimal places;\n• None if ndigits is zero, return number rounded to the nearest integer;\n• None if ndigits is negative, return number rounded to the nearest multiple of . The , , , and methods expect their arguments to be logical operands. A logical operand is a instance whose exponent and sign are both zero, and whose digits are all either or .\n\nContexts are environments for arithmetic operations. They govern precision, set rules for rounding, determine which signals are treated as exceptions, and limit the range for exponents. Each thread has its own current context which is accessed or changed using the and functions: Return the current context for the active thread. Set the current context for the active thread to c. You can also use the statement and the function to temporarily change the active context. Return a context manager that will set the current context for the active thread to a copy of ctx on entry to the with-statement and restore the previous context when exiting the with-statement. If no context is specified, a copy of the current context is used. The kwargs argument is used to set the attributes of the new context. For example, the following code sets the current decimal precision to 42 places, performs a calculation, and then automatically restores the previous context: # Round the final result back to the default precision Using keyword arguments, the code would be the following: Raises if kwargs supplies an attribute that doesn’t support. Raises either or if kwargs supplies an invalid value for an attribute. Changed in version 3.11: now supports setting context attributes through the use of keyword arguments. New contexts can also be created using the constructor described below. In addition, the module provides three pre-made contexts: This is a standard context defined by the General Decimal Arithmetic Specification. Precision is set to nine. Rounding is set to . All flags are cleared. All traps are enabled (treated as exceptions) except , , and . Because many of the traps are enabled, this context is useful for debugging. This is a standard context defined by the General Decimal Arithmetic Specification. Precision is set to nine. Rounding is set to . All flags are cleared. No traps are enabled (so that exceptions are not raised during computations). Because the traps are disabled, this context is useful for applications that prefer to have result value of or instead of raising exceptions. This allows an application to complete a run in the presence of conditions that would otherwise halt the program. This context is used by the constructor as a prototype for new contexts. Changing a field (such a precision) has the effect of changing the default for new contexts created by the constructor. This context is most useful in multi-threaded environments. Changing one of the fields before threads are started has the effect of setting system-wide defaults. Changing the fields after threads have started is not recommended as it would require thread synchronization to prevent race conditions. In single threaded environments, it is preferable to not use this context at all. Instead, simply create contexts explicitly as described below. The default values are = , = , and enabled traps for , , and . In addition to the three supplied contexts, new contexts can be created with the constructor. Creates a new context. If a field is not specified or is , the default values are copied from the . If the flags field is not specified or is , all flags are cleared. prec is an integer in the range [ , ] that sets the precision for arithmetic operations in the context. The rounding option is one of the constants listed in the section Rounding Modes. The traps and flags fields list any signals to be set. Generally, new contexts should only set traps and leave the flags clear. The Emin and Emax fields are integers specifying the outer limits allowable for exponents. Emin must be in the range [ , ], Emax in the range [ , ]. The capitals field is either or (the default). If set to , exponents are printed with a capital ; otherwise, a lowercase is used: . The clamp field is either (the default) or . If set to , the exponent of a instance representable in this context is strictly limited to the range . If clamp is then a weaker condition holds: the adjusted exponent of the instance is at most . When clamp is , a large normal number will, where possible, have its exponent reduced and a corresponding number of zeros added to its coefficient, in order to fit the exponent constraints; this preserves the value of the number but loses information about significant trailing zeros. For example: A clamp value of allows compatibility with the fixed-width decimal interchange formats specified in IEEE 754. The class defines several general purpose methods as well as a large number of methods for doing arithmetic directly in a given context. In addition, for each of the methods described above (with the exception of the and methods) there is a corresponding method. For example, for a instance and instance , is equivalent to . Each method accepts a Python integer (an instance of ) anywhere that a Decimal instance is accepted. Resets all of the flags to . Resets all of the traps to . Creates a new Decimal instance from num but using self as context. Unlike the constructor, the context precision, rounding method, flags, and traps are applied to the conversion. This is useful because constants are often given to a greater precision than is needed by the application. Another benefit is that rounding immediately eliminates unintended effects from digits beyond the current precision. In the following example, using unrounded inputs means that adding zero to a sum can change the result: This method implements the to-number operation of the IBM specification. If the argument is a string, no leading or trailing whitespace or underscores are permitted. Creates a new Decimal instance from a float f but rounding using self as the context. Unlike the class method, the context precision, rounding method, flags, and traps are applied to the conversion. Returns a value equal to which is the minimum exponent value for subnormal results. When underflow occurs, the exponent is set to . The usual approach to working with decimals is to create instances and then apply arithmetic operations which take place within the current context for the active thread. An alternative approach is to use context methods for calculating within a specific context. The methods are similar to those for the class and are only briefly recounted here. Returns the absolute value of x. Return the sum of x and y. Compares the values of the two operands numerically. Compares two operands using their abstract representation. Compares two operands using their abstract representation, ignoring sign. Returns a copy of x with the sign set to 0. Returns a copy of x with the sign inverted. Copies the sign from y to x. Return x divided by y, truncated to an integer. Divides two numbers and returns the integer part of the result. Returns if x is canonical; otherwise returns . Returns if x is finite; otherwise returns . Returns if x is infinite; otherwise returns . Returns if x is a qNaN or sNaN; otherwise returns . Returns if x is a normal number; otherwise returns . Returns if x is a quiet NaN; otherwise returns . Returns if x is negative; otherwise returns . Returns if x is a signaling NaN; otherwise returns . Returns if x is subnormal; otherwise returns . Returns if x is a zero; otherwise returns . Returns the exponent of the magnitude of the operand’s MSD. Applies the logical operation and between each operand’s digits. Invert all the digits in x. Applies the logical operation or between each operand’s digits. Applies the logical operation xor between each operand’s digits. Compares two values numerically and returns the maximum. Compares the values numerically with their sign ignored. Compares two values numerically and returns the minimum. Compares the values numerically with their sign ignored. Minus corresponds to the unary prefix minus operator in Python. Return the product of x and y. Returns the number closest to x, in direction towards y. Returns an indication of the class of x. Plus corresponds to the unary prefix plus operator in Python. This operation applies the context precision and rounding, so it is not an identity operation. Return to the power of , reduced modulo if given. With two arguments, compute . If is negative then must be integral. The result will be inexact unless is integral and the result is finite and can be expressed exactly in ‘precision’ digits. The rounding mode of the context is used. Results are always correctly rounded in the Python version. results in , and if is not trapped, then results in . Changed in version 3.3: The C module computes in terms of the correctly rounded and functions. The result is well-defined but only “almost always correctly rounded”. With three arguments, compute . For the three argument form, the following restrictions on the arguments hold:\n• None all three arguments must be integral\n• None at least one of or must be nonzero\n• None must be nonzero and have at most ‘precision’ digits The value resulting from is equal to the value that would be obtained by computing with unbounded precision, but is computed more efficiently. The exponent of the result is zero, regardless of the exponents of , and . The result is always exact. Returns a value equal to x (rounded), having the exponent of y. Just returns 10, as this is Decimal, :) The sign of the result, if non-zero, is the same as that of the original dividend. Returns , where n is the integer nearest the exact value of (if the result is 0 then its sign will be the sign of x). Returns if the two operands have the same exponent. Returns the first operand after adding the second value its exp. Return the difference between x and y. Convert to a string, using engineering notation if an exponent is needed. Engineering notation has an exponent which is a multiple of 3. This can leave up to 3 digits to the left of the decimal place and may require the addition of either one or two trailing zeros.\n\nThe use of decimal floating point eliminates decimal representation error (making it possible to represent exactly); however, some operations can still incur round-off error when non-zero digits exceed the fixed precision. The effects of round-off error can be amplified by the addition or subtraction of nearly offsetting quantities resulting in loss of significance. Knuth provides two instructive examples where rounded floating-point arithmetic with insufficient precision causes the breakdown of the associative and distributive properties of addition: The module makes it possible to restore the identities by expanding the precision sufficiently to avoid loss of significance: The number system for the module provides special values including , , , , and two zeros, and . Infinities can be constructed directly with: . Also, they can arise from dividing by zero when the signal is not trapped. Likewise, when the signal is not trapped, infinity can result from rounding beyond the limits of the largest representable number. The infinities are signed (affine) and can be used in arithmetic operations where they get treated as very large, indeterminate numbers. For instance, adding a constant to infinity gives another infinite result. Some operations are indeterminate and return , or if the signal is trapped, raise an exception. For example, returns which means “not a number”. This variety of is quiet and, once created, will flow through other computations always resulting in another . This behavior can be useful for a series of computations that occasionally have missing inputs — it allows the calculation to proceed while flagging specific results as invalid. A variant is which signals rather than remaining quiet after every operation. This is a useful return value when an invalid result needs to interrupt a calculation for special handling. The behavior of Python’s comparison operators can be a little surprising where a is involved. A test for equality where one of the operands is a quiet or signaling always returns (even when doing ), while a test for inequality always returns . An attempt to compare two Decimals using any of the , , or operators will raise the signal if either operand is a , and return if this signal is not trapped. Note that the General Decimal Arithmetic specification does not specify the behavior of direct comparisons; these rules for comparisons involving a were taken from the IEEE 854 standard (see Table 3 in section 5.7). To ensure strict standards-compliance, use the and methods instead. The signed zeros can result from calculations that underflow. They keep the sign that would have resulted if the calculation had been carried out to greater precision. Since their magnitude is zero, both positive and negative zeros are treated as equal and their sign is informational. In addition to the two signed zeros which are distinct yet equal, there are various representations of zero with differing precisions yet equivalent in value. This takes a bit of getting used to. For an eye accustomed to normalized floating-point representations, it is not immediately obvious that the following calculation returns a value equal to zero:\n\nQ. It is cumbersome to type . Is there a way to minimize typing when using the interactive interpreter? A. Some users abbreviate the constructor to just a single letter: Q. In a fixed-point application with two decimal places, some inputs have many places and need to be rounded. Others are not supposed to have excess digits and need to be validated. What methods should be used? A. The method rounds to a fixed number of decimal places. If the trap is set, it is also useful for validation: # Validate that a number does not exceed two places Q. Once I have valid two place inputs, how do I maintain that invariant throughout an application? A. Some operations like addition, subtraction, and multiplication by an integer will automatically preserve fixed point. Others operations, like division and non-integer multiplication, will change the number of decimal places and need to be followed-up with a step: In developing fixed-point applications, it is convenient to define functions to handle the step: Q. There are many ways to express the same value. The numbers , , , and all have the same value at various precisions. Is there a way to transform them to a single recognizable canonical value? A. The method maps all equivalent values to a single representative: Q. When does rounding occur in a computation? A. It occurs after the computation. The philosophy of the decimal specification is that numbers are considered exact and are created independent of the current context. They can even have greater precision than current context. Computations process with those exact inputs and then rounding (or other context operations) is applied to the result of the computation: Q. Some decimal values always print with exponential notation. Is there a way to get a non-exponential representation? A. For some values, exponential notation is the only way to express the number of significant places in the coefficient. For example, expressing as keeps the value constant but cannot show the original’s two-place significance. If an application does not care about tracking significance, it is easy to remove the exponent and trailing zeroes, losing significance, but keeping the value unchanged: Q. Is there a way to convert a regular float to a ? A. Yes, any binary floating-point number can be exactly expressed as a Decimal though an exact conversion may take more precision than intuition would suggest: Q. Within a complex calculation, how can I make sure that I haven’t gotten a spurious result because of insufficient precision or rounding anomalies. A. The decimal module makes it easy to test results. A best practice is to re-run calculations using greater precision and with various rounding modes. Widely differing results indicate insufficient precision, rounding mode issues, ill-conditioned inputs, or a numerically unstable algorithm. Q. I noticed that context precision is applied to the results of operations but not to the inputs. Is there anything to watch out for when mixing values of different precisions? A. Yes. The principle is that all values are considered to be exact and so is the arithmetic on those values. Only the results are rounded. The advantage for inputs is that “what you type is what you get”. A disadvantage is that the results can look odd if you forget that the inputs haven’t been rounded: The solution is either to increase precision or to force rounding of inputs using the unary plus operation: Alternatively, inputs can be rounded upon creation using the method: Q. Is the CPython implementation fast for large numbers? A. Yes. In the CPython and PyPy3 implementations, the C/CFFI versions of the decimal module integrate the high speed libmpdec library for arbitrary precision correctly rounded decimal floating-point arithmetic . uses Karatsuba multiplication for medium-sized numbers and the Number Theoretic Transform for very large numbers. The context must be adapted for exact arbitrary precision arithmetic. and should always be set to the maximum values, should always be 0 (the default). Setting requires some care. The easiest approach for trying out bignum arithmetic is to use the maximum value for as well : For inexact results, is far too large on 64-bit platforms and the available memory will be insufficient: On systems with overallocation (e.g. Linux), a more sophisticated approach is to adjust to the amount of available RAM. Suppose that you have 8GB of RAM and expect 10 simultaneous operands using a maximum of 500MB each: # Maximum number of digits for a single operand using 500MB in 8-byte words # with 19 digits per word (4-byte and 9 digits for the 32-bit build): # Fill the available precision with nines: File , line , in : In general (and especially on systems without overallocation), it is recommended to estimate even tighter bounds and set the trap if all calculations are expected to be exact."
    },
    {
        "link": "https://docs.python.org/3/library/functions.html",
        "document": "The Python interpreter has a number of functions and types built into it that are always available. They are listed here in alphabetical order.\n\nOpen file and return a corresponding file object. If the file cannot be opened, an is raised. See Reading and Writing Files for more examples of how to use this function. file is a path-like object giving the pathname (absolute or relative to the current working directory) of the file to be opened or an integer file descriptor of the file to be wrapped. (If a file descriptor is given, it is closed when the returned I/O object is closed unless closefd is set to .) mode is an optional string that specifies the mode in which the file is opened. It defaults to which means open for reading in text mode. Other common values are for writing (truncating the file if it already exists), for exclusive creation, and for appending (which on some Unix systems, means that all writes append to the end of the file regardless of the current seek position). In text mode, if encoding is not specified the encoding used is platform-dependent: is called to get the current locale encoding. (For reading and writing raw bytes use binary mode and leave encoding unspecified.) The available modes are: open for writing, truncating the file first open for exclusive creation, failing if the file already exists open for writing, appending to the end of file if it exists The default mode is (open for reading text, a synonym of ). Modes and open and truncate the file. Modes and open the file with no truncation. As mentioned in the Overview, Python distinguishes between binary and text I/O. Files opened in binary mode (including in the mode argument) return contents as objects without any decoding. In text mode (the default, or when is included in the mode argument), the contents of the file are returned as , the bytes having been first decoded using a platform-dependent encoding or using the specified encoding if given. Python doesn’t depend on the underlying operating system’s notion of text files; all the processing is done by Python itself, and is therefore platform-independent. buffering is an optional integer used to set the buffering policy. Pass 0 to switch buffering off (only allowed in binary mode), 1 to select line buffering (only usable when writing in text mode), and an integer > 1 to indicate the size in bytes of a fixed-size chunk buffer. Note that specifying a buffer size this way applies for binary buffered I/O, but (i.e., files opened with ) would have another buffering. To disable buffering in , consider using the flag for . When no buffering argument is given, the default buffering policy works as follows:\n• None Binary files are buffered in fixed-size chunks; the size of the buffer is chosen using a heuristic trying to determine the underlying device’s “block size” and falling back on . On many systems, the buffer will typically be 4096 or 8192 bytes long.\n• None “Interactive” text files (files for which returns ) use line buffering. Other text files use the policy described above for binary files. encoding is the name of the encoding used to decode or encode the file. This should only be used in text mode. The default encoding is platform dependent (whatever returns), but any text encoding supported by Python can be used. See the module for the list of supported encodings. errors is an optional string that specifies how encoding and decoding errors are to be handled—this cannot be used in binary mode. A variety of standard error handlers are available (listed under Error Handlers), though any error handling name that has been registered with is also valid. The standard names include:\n• None to raise a exception if there is an encoding error. The default value of has the same effect.\n• None ignores errors. Note that ignoring encoding errors can lead to data loss.\n• None causes a replacement marker (such as ) to be inserted where there is malformed data.\n• None will represent any incorrect bytes as low surrogate code units ranging from U+DC80 to U+DCFF. These surrogate code units will then be turned back into the same bytes when the error handler is used when writing data. This is useful for processing files in an unknown encoding.\n• None is only supported when writing to a file. Characters not supported by the encoding are replaced with the appropriate XML character reference .\n• None (also only supported when writing) replaces unsupported characters with escape sequences. newline determines how to parse newline characters from the stream. It can be , , , , and . It works as follows:\n• None When reading input from the stream, if newline is , universal newlines mode is enabled. Lines in the input can end in , , or , and these are translated into before being returned to the caller. If it is , universal newlines mode is enabled, but line endings are returned to the caller untranslated. If it has any of the other legal values, input lines are only terminated by the given string, and the line ending is returned to the caller untranslated.\n• None When writing output to the stream, if newline is , any characters written are translated to the system default line separator, . If newline is or , no translation takes place. If newline is any of the other legal values, any characters written are translated to the given string. If closefd is and a file descriptor rather than a filename was given, the underlying file descriptor will be kept open when the file is closed. If a filename is given closefd must be (the default); otherwise, an error will be raised. A custom opener can be used by passing a callable as opener. The underlying file descriptor for the file object is then obtained by calling opener with (file, flags). opener must return an open file descriptor (passing as opener results in functionality similar to passing ). The following example uses the dir_fd parameter of the function to open a file relative to a given directory: 'This will be written to somedir/spamspam.txt' The type of file object returned by the function depends on the mode. When is used to open a file in a text mode ( , , , , etc.), it returns a subclass of (specifically ). When used to open a file in a binary mode with buffering, the returned class is a subclass of . The exact class varies: in read binary mode, it returns an ; in write binary and append binary modes, it returns an , and in read/write mode, it returns an . When buffering is disabled, the raw stream, a subclass of , , is returned. See also the file handling modules, such as , (where is declared), , , , and . The and arguments may have been modified or inferred from the original call.\n• None used to be raised, it is now an alias of .\n• None is now raised if the file opened in exclusive creation mode ( ) already exists.\n• None The file is now non-inheritable.\n• None If the system call is interrupted and the signal handler does not raise an exception, the function now retries the system call instead of raising an exception (see PEP 475 for the rationale).\n• None On Windows, opening a console buffer may return a subclass of other than . Changed in version 3.11: The mode has been removed.\n\nReturn a proxy object that delegates method calls to a parent or sibling class of type. This is useful for accessing inherited methods that have been overridden in a class. The object_or_type determines the method resolution order to be searched. The search starts from the class right after the type. For example, if of object_or_type is and the value of type is , then searches . The attribute of the class corresponding to object_or_type lists the method resolution search order used by both and . The attribute is dynamic and can change whenever the inheritance hierarchy is updated. If the second argument is omitted, the super object returned is unbound. If the second argument is an object, must be true. If the second argument is a type, must be true (this is useful for classmethods). When called directly within an ordinary method of a class, both arguments may be omitted (“zero-argument ”). In this case, type will be the enclosing class, and obj will be the first argument of the immediately enclosing function (typically ). (This means that zero-argument will not work as expected within nested functions, including generator expressions, which implicitly create nested functions.) There are two typical use cases for super. In a class hierarchy with single inheritance, super can be used to refer to parent classes without naming them explicitly, thus making the code more maintainable. This use closely parallels the use of super in other programming languages. The second use case is to support cooperative multiple inheritance in a dynamic execution environment. This use case is unique to Python and is not found in statically compiled languages or languages that only support single inheritance. This makes it possible to implement “diamond diagrams” where multiple base classes implement the same method. Good design dictates that such implementations have the same calling signature in every case (because the order of calls is determined at runtime, because that order adapts to changes in the class hierarchy, and because that order can include sibling classes that are unknown prior to runtime). For both use cases, a typical superclass call looks like this: # This does the same thing as: In addition to method lookups, also works for attribute lookups. One possible use case for this is calling descriptors in a parent or sibling class. Note that is implemented as part of the binding process for explicit dotted attribute lookups such as . It does so by implementing its own method for searching classes in a predictable order that supports cooperative multiple inheritance. Accordingly, is undefined for implicit lookups using statements or operators such as . Also note that, aside from the zero argument form, is not limited to use inside methods. The two argument form specifies the arguments exactly and makes the appropriate references. The zero argument form only works inside a class definition, as the compiler fills in the necessary details to correctly retrieve the class being defined, as well as accessing the current instance for ordinary methods. For practical suggestions on how to design cooperative classes using , see guide to using super()."
    },
    {
        "link": "https://codedamn.com/news/python/how-to-represent-infinity-in-python",
        "document": "Greetings, codedamn community! Today we’ll be diving deep into a fascinating aspect of Python programming – the representation of Infinity. This concept is a must-know for every developer who wishes to delve into the complexities of mathematical operations and computations in Python. So, let’s explore the infinite and beyond!\n\nPython, like many other programming languages, provides a way to represent infinity in code. In mathematics, infinity is a concept describing something without any bound or larger than any number. Python uses a floating-point representation to denote infinity, which can be positive or negative. If you’re coming from a different programming language, you might find this quite useful as the concept of infinity is handled similarly in many languages.\n\nTo represent positive infinity in Python, we use , and for negative infinity, we use .\n\nPython allows arithmetic operations with infinity, which are quite easy to understand. Let’s explore some examples:\n\nAs you can see, any operation with infinity tends to result in infinity (or negative infinity), except when dividing a number by infinity, which results in zero.\n\nPython provides a built-in function to check if a number is infinity. This function is part of the math module, so you need to import it before usage.\n\nInfinity comes in handy when you want to set a variable that is always greater or smaller than the other numbers in your program. Let’s see how comparisons work with infinity:\n\n1. Can infinity be used with integers in Python?\n\nNo, infinity can only be used with floating-point numbers in Python.\n\n2. How can I check if a number is not infinity in Python?\n\nYou can use the function to check if a number is not infinity.\n\n3. Can infinity be used in Python arrays and data structures?\n\nYes, you can use infinity values in Python arrays and other data structures like lists, sets, and dictionaries.\n\nInfinity in Python is a powerful concept that can be leveraged in a variety of ways, especially when dealing with mathematical computations and comparisons. Remember that it’s always represented as a floating-point number and that Python provides built-in functions to work with it.\n\nFor more in-depth information about floating-point arithmetic and the representation of infinity in Python, you can visit the official Python documentation here.\n\nHappy coding, and remember – the possibilities with Python are infinite!"
    },
    {
        "link": "https://docs.python.org/3/reference/datamodel.html",
        "document": "Objects are Python’s abstraction for data. All data in a Python program is represented by objects or by relations between objects. (In a sense, and in conformance to Von Neumann’s model of a “stored program computer”, code is also represented by objects.) Every object has an identity, a type and a value. An object’s identity never changes once it has been created; you may think of it as the object’s address in memory. The operator compares the identity of two objects; the function returns an integer representing its identity. CPython implementation detail: For CPython, is the memory address where is stored. An object’s type determines the operations that the object supports (e.g., “does it have a length?”) and also defines the possible values for objects of that type. The function returns an object’s type (which is an object itself). Like its identity, an object’s type is also unchangeable. The value of some objects can change. Objects whose value can change are said to be mutable; objects whose value is unchangeable once they are created are called immutable. (The value of an immutable container object that contains a reference to a mutable object can change when the latter’s value is changed; however the container is still considered immutable, because the collection of objects it contains cannot be changed. So, immutability is not strictly the same as having an unchangeable value, it is more subtle.) An object’s mutability is determined by its type; for instance, numbers, strings and tuples are immutable, while dictionaries and lists are mutable. Objects are never explicitly destroyed; however, when they become unreachable they may be garbage-collected. An implementation is allowed to postpone garbage collection or omit it altogether — it is a matter of implementation quality how garbage collection is implemented, as long as no objects are collected that are still reachable. CPython implementation detail: CPython currently uses a reference-counting scheme with (optional) delayed detection of cyclically linked garbage, which collects most objects as soon as they become unreachable, but is not guaranteed to collect garbage containing circular references. See the documentation of the module for information on controlling the collection of cyclic garbage. Other implementations act differently and CPython may change. Do not depend on immediate finalization of objects when they become unreachable (so you should always close files explicitly). Note that the use of the implementation’s tracing or debugging facilities may keep objects alive that would normally be collectable. Also note that catching an exception with a … statement may keep objects alive. Some objects contain references to “external” resources such as open files or windows. It is understood that these resources are freed when the object is garbage-collected, but since garbage collection is not guaranteed to happen, such objects also provide an explicit way to release the external resource, usually a method. Programs are strongly recommended to explicitly close such objects. The … statement and the statement provide convenient ways to do this. Some objects contain references to other objects; these are called containers. Examples of containers are tuples, lists and dictionaries. The references are part of a container’s value. In most cases, when we talk about the value of a container, we imply the values, not the identities of the contained objects; however, when we talk about the mutability of a container, only the identities of the immediately contained objects are implied. So, if an immutable container (like a tuple) contains a reference to a mutable object, its value changes if that mutable object is changed. Types affect almost all aspects of object behavior. Even the importance of object identity is affected in some sense: for immutable types, operations that compute new values may actually return a reference to any existing object with the same type and value, while for mutable objects this is not allowed. For example, after , a and b may or may not refer to the same object with the value one, depending on the implementation. This is because is an immutable type, so the reference to can be reused. This behaviour depends on the implementation used, so should not be relied upon, but is something to be aware of when making use of object identity tests. However, after , c and d are guaranteed to refer to two different, unique, newly created empty lists. (Note that assigns the same object to both e and f.)"
    }
]