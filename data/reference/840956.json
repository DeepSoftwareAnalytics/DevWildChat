[
    {
        "link": "https://developer.mozilla.org/en-US/docs/Learn_web_development/Core/Scripting/JSON",
        "document": "JavaScript Object Notation (JSON) is a standard text-based format for representing structured data based on JavaScript object syntax. It is commonly used for transmitting data in web applications (e.g., sending some data from the server to the client, so it can be displayed on a web page, or vice versa). You'll come across it quite often, so in this article, we give you all you need to work with JSON using JavaScript, including parsing JSON so you can access data within it, and creating JSON. An understanding of HTML and the fundamentals of CSS, familiarity with JavaScript basics as covered in previous lessons.\n• What JSON is — a very commonly used data format based on JavaScript object syntax.\n• That JSON can also contain arrays.\n• Retrieve JSON as a JavaScript object using mechanisms available in Web APIs (for example, in the Fetch API).\n• Converting between objects and text using and .\n\nNo, really, what is JSON? JSON is a text-based data format following JavaScript object syntax. It represents structured data as a string, which is useful when you want to transmit data across a network. Even though it closely resembles JavaScript object literal syntax, it can be used independently from JavaScript. Many programming environments feature the ability to read (parse) and generate JSON. In JavaScript, the methods for parsing and generating JSON are provided by the object. Note: Converting a string to a native object is called deserialization, while converting a native object to a string so it can be transmitted across the network is called serialization. A JSON string can be stored in its own file, which is basically just a text file with an extension of , and a MIME type of .\n\nAs described above, JSON is a string whose format very much resembles JavaScript object literal format. The following is a valid JSON string representing an object. Note how it is also a valid JavaScript object literal — just with some more syntax restrictions. { \"squadName\": \"Super hero squad\", \"homeTown\": \"Metro City\", \"formed\": 2016, \"secretBase\": \"Super tower\", \"active\": true, \"members\": [ { \"name\": \"Molecule Man\", \"age\": 29, \"secretIdentity\": \"Dan Jukes\", \"powers\": [\"Radiation resistance\", \"Turning tiny\", \"Radiation blast\"] }, { \"name\": \"Madame Uppercut\", \"age\": 39, \"secretIdentity\": \"Jane Wilson\", \"powers\": [ \"Million tonne punch\", \"Damage resistance\", \"Superhuman reflexes\" ] }, { \"name\": \"Eternal Flame\", \"age\": 1000000, \"secretIdentity\": \"Unknown\", \"powers\": [ \"Immortality\", \"Heat Immunity\", \"Inferno\", \"Teleportation\", \"Interdimensional travel\" ] } ] } If you load this JSON in your JavaScript program as a string, you can parse it into a normal object and then access the data inside it using the same dot/bracket notation we looked at in the JavaScript object basics article. For example:\n• First, we have the variable name — .\n• Inside that, we want to access the property, so we use .\n• contains an array populated by objects. We want to access the second object inside the array, so we use .\n• Inside this object, we want to access the property, so we use .\n• Inside the property is an array containing the selected hero's superpowers. We want the third one, so we use . The key takeaway is that there's really nothing special about working with JSON; after you've parsed it into a JavaScript object, you work with it just like you would with an object declared using the same object literal syntax. Note: We've made the JSON seen above available inside a variable in our JSONTest.html example (see the source code). Try loading this up and then accessing data inside the variable via your browser's JavaScript console.\n\nAbove we mentioned that JSON text basically looks like a JavaScript object inside a string. We can also convert arrays to/from JSON. The below example is perfectly valid JSON: You have to access array items (in its parsed version) by starting with an array index, for example . The JSON can also contain a single primitive. For example, , , or are all valid JSON.\n\nTo begin with, make local copies of our heroes.html and style.css files. The latter contains some simple CSS to style our page, while the former contains some very simple body HTML, plus a element to contain the JavaScript code we will be writing in this exercise: We have made our JSON data available on our GitHub, at https://mdn.github.io/learning-area/javascript/oojs/json/superheroes.json. We are going to load the JSON into our script, and use some nifty DOM manipulation to display it, like this:\n\nThe top-level function looks like this: To obtain the JSON, we use an API called Fetch. This API allows us to make network requests to retrieve resources from a server via JavaScript (e.g. images, text, JSON, even HTML snippets), meaning that we can update small sections of content without having to reload the entire page. In our function, the first four lines use the Fetch API to fetch the JSON from the server:\n• we declare the variable to store the GitHub URL\n• we use the URL to initialize a new object.\n• we make the network request using the function, and this returns a object\n• we retrieve the response as JSON using the function of the object. Note: The API is asynchronous. You can learn about asynchronous functions in detail in our Asynchronous JavaScript module, but for now, we'll just say that we need to add the keyword before the name of the function that uses the fetch API, and add the keyword before the calls to any asynchronous functions. After all that, the variable will contain the JavaScript object based on the JSON. We are then passing that object to two function calls — the first one fills the with the correct data, while the second one creates an information card for each hero on the team, and inserts it into the .\n\nNow that we've retrieved the JSON data and converted it into a JavaScript object, let's make use of it by writing the two functions we referenced above. First of all, add the following function definition below the previous code: Here we first create an h1 element with , set its to equal the property of the object, then append it to the header using . We then do a very similar operation with a paragraph: create it, set its text content and append it to the header. The only difference is that its text is set to a template literal containing both the and properties of the object.\n\nNext, add the following function at the bottom of the code, which creates and displays the superhero cards: function populateHeroes(obj) { const section = document.querySelector(\"section\"); const heroes = obj.members; for (const hero of heroes) { const myArticle = document.createElement(\"article\"); const myH2 = document.createElement(\"h2\"); const myPara1 = document.createElement(\"p\"); const myPara2 = document.createElement(\"p\"); const myPara3 = document.createElement(\"p\"); const myList = document.createElement(\"ul\"); myH2.textContent = hero.name; myPara1.textContent = `Secret identity: ${hero.secretIdentity}`; myPara2.textContent = `Age: ${hero.age}`; myPara3.textContent = \"Superpowers:\"; const superPowers = hero.powers; for (const power of superPowers) { const listItem = document.createElement(\"li\"); listItem.textContent = power; myList.appendChild(listItem); } myArticle.appendChild(myH2); myArticle.appendChild(myPara1); myArticle.appendChild(myPara2); myArticle.appendChild(myPara3); myArticle.appendChild(myList); section.appendChild(myArticle); } } To start with, we store the property of the JavaScript object in a new variable. This array contains multiple objects that contain the information for each hero. Next, we use a for...of loop to loop through each object in the array. For each one, we:\n• Create several new elements: an , an , three s, and a .\n• Set the to contain the current hero's .\n• Fill the three paragraphs with their , , and a line saying \"Superpowers:\" to introduce the information in the list.\n• Store the property in another new constant called — this contains an array that lists the current hero's superpowers.\n• Use another loop to loop through the current hero's superpowers — for each one we create an element, put the superpower inside it, then put the inside the element ( ) using .\n• The very last thing we do is to append the , s, and inside the ( ), then append the inside the . The order in which things are appended is important, as this is the order they will be displayed inside the HTML. Note: If you are having trouble getting the example to work, try referring to our heroes-finished.html source code (see it running live also.) Note: If you are having trouble following the dot/bracket notation we are using to access the JavaScript object, it can help to have the superheroes.json file open in another tab or your text editor, and refer to it as you look at our JavaScript. You should also refer back to our JavaScript object basics article for more information on dot and bracket notation.\n\nThe above example was simple in terms of accessing the JavaScript object, because we converted the network response directly into a JavaScript object using . But sometimes we aren't so lucky — sometimes we receive a raw JSON string, and we need to convert it to an object ourselves. And when we want to send a JavaScript object across the network, we need to convert it to JSON (a string) before sending it. Luckily, these two problems are so common in web development that a built-in JSON object is available in browsers, which contains the following two methods:\n• : Accepts a JSON string as a parameter, and returns the corresponding JavaScript object.\n• : Accepts an object as a parameter, and returns the equivalent JSON string. You can see the first one in action in our heroes-finished-json-parse.html example (see the source code) — this does exactly the same thing as the example we built up earlier, except that:\n• we retrieve the response as text rather than JSON, by calling the method of the response\n• we then use to convert the text to a JavaScript object. The key snippet of code is here: As you might guess, works the opposite way. Try entering the following lines into your browser's JavaScript console one by one to see it in action: let myObj = { name: \"Chris\", age: 38 }; myObj; let myString = JSON.stringify(myObj); myString; Here we're creating a JavaScript object, then checking what it contains, then converting it to a JSON string using — saving the return value in a new variable — then checking it again."
    },
    {
        "link": "https://jsonlint.com/mastering-json-format",
        "document": "Mastering JSON Format: Advantages, Best Practices and Comparison with Other Data Formats\n\nJSON, standing for JavaScript Object Notation, is already a big player in today's era of data interchange. I'll delve into what makes JSON so standout. It's a text-based, language-independent format that allows for the easy and structured exchange of information. Boasting simplicity and being exceptionally lightweight, JSON is king when it comes to data transfer across your favorite web applications.\n\nOne undeniable charm of JSON is its compatibility. It's like that friend we all need — flexible and gets along with everyone. Whether you're coding in Python, JavaScript, or C++, JSON functions seamlessly across these and many more languages. Importantly, its plain text nature makes it readable to both humans and machines.\n\nThe beauty of JSON lies in its structure. Information is stored in a \"key: value\" pair format, which in essence is like a collection of Lego blocks. These 'blocks' or data objects can be assembled in various ways to form meaningful data structures.\n\nAn example of a simple JSON object could be:\n\nThis structure makes JSON adaptable and extendable. You can add, modify, and delete key-value pairs without disrupting the system, offering unparalleled flexibility in data storage.\n\nIn addition to supporting these object structures, JSON also supports arrays (ordered sequence of values), which further simplifies complex data representation. For instance, if you wanted to add job details for John Doe, it’d look something like this:\n\nLeveraging the power of arrays and objects, JSON can efficiently store virtually any data structure. Indeed, it is the backbone that drives today's internet, actively shaping the ways we store, retrieve, and process data.\n\nLooking into the wonderful world of JSON, it's clear there are a multitude of benefits when using this format. Let's dive deeper into why JSON makes such a significant impact in data interchange.\n\nFirstly, simplicity and readability play a key role in JSON's popularity. The structure is easy-to-follow, mimicking a simple key-value pair that anyone, coder or not, can grasp. It's this simplicity that helps developers quickly read, write or edit the data - a feature that doesn't go unnoticed in the fast-paced world of technology.\n\nJSON also shines in its compatibility with various programming languages. Languages such as JavaScript, Python, Ruby and many others natively support JSON. What does this mean? Simply put, JSON can readily integrate with these languages without any need for additional libraries. Now that's efficient.\n\nAnother winning feature of JSON is its support for arrays and objects. This ability to handle complex data through a recognized syntax makes JSON superior in data representation to many other formats. Whether you're dealing with multi-level arrays or nested objects, JSON has you covered.\n\nOne more advantage of JSON to highlight is its lightweight nature. JSON's format, without the need for end tags or closing tags, leads to reduced data redundancy and less data overall. This means faster data transmission and smoother execution – an essential requirement in today's digital age.\n\nIn this internet era, JSON's importance in shaping how data is stored, retrieved, and processed is undeniable. From simple inventory lists to intricate game data, JSON delivers with reliability and flexibility.\n\nAs we delve further into the nitty-gritty of JSON, it's paramount we draw comparisons between JSON and other data formats. Two main competitors of JSON that come to mind are XML and CSV. Understanding where JSON stands in relation to these will help define its unique value more accurately.\n\nXML, just like JSON, is human-readable and used widely for data exchange. But where JSON really shines is in its simplicity. Rather than the verbose and complex syntax of XML that can quickly clutter your screen, JSON stays minimal and clean, something I absolutely appreciate. JSON's format is also more condense which leads to quicker data transmissions.\n\nWell, then we have CSV. While it's true that CSV files are typically smaller, they lack the depth of JSON. In a CSV, it's challenging to represent hierarchical or multi-dimensional data. JSON, on the other hand, as we discussed earlier, has robust support for arrays and objects. It's like comparing a black-and-white photo to a 3D movie; the depth that JSON provides far outshines a mere CSV's capabilities.\n\nLet's not forget one of JSON's formidable advantages - compatibility with various programming languages. XML requires parsers to be readable in different programming languages, and CSV files often need custom parsing solutions, both of which can be cumbersome for developers. With JSON, that isn't necessary - it's supported natively in many programming languages, easing integration and reducing development time.\n\nBut before we lean too far into JSON's corner, it's worth mentioning that there are scenarios where other formats may be more suitable. Binary formats like Protobuf or Avro might provide better performance for massive or complex datasets. The world of data formats isn't black and white - there are shades of grey that give room for all, each with its own use cases.\n\nMoving forward, we'll dissect how JSON is leveraged in web development, and its role in shaping APIs. By highlighting its advantages and pointing out certain usage pitfalls, this deep dive into JSON seeks to arm you with the knowledge to efficiently utilize JSON in your own projects.\n\nUnderstanding the syntax is fundamental to appreciating JSON's beauty. It's this simplicity and readability that make JSON a desirable format. JSON structures data in name-value pairs, much like a JavaScript object. Yet, it's not limited to a particular set of programming languages. Its universal syntax is what allowed me to integrate it in various environments easily.\n\nThe first thing to look at is data types that JSON supports. It can handle simple data types like strings, numbers, and Booleans – true or false. At the same time, it embraces compound types such as arrays and other JSON objects. Being adept with these data types can make the information representation more effective.\n\nLet's take a look at a JSON object:\n\nIn this JSON object, you can see different types of data. The name is a string, the age a number, isVaccinated a Boolean, and familyNames an array of strings.\n\nWhen it comes to arrays, they are enclosed in square brackets. Each value is separated by a comma. Here's an example of a JSON array:\n\nThis array represents a list of people, each person being a JSON object itself.\n\nNext, we'll discuss how the JSON format shapes the landscape of web development, and how it’s used in creating user-friendly and feature-rich APIs. For developers seeking to use JSON in their projects, gaining a good grasp of the format and its syntax will be time well spent.\n\nParsing JSON data is a crucial skill in web development, making it an area that I must delve into due to its immense importance. It's necessary to understand that the process varies depending on the programming language you're using. In this regard, let's look at parsing JSON data using two popular languages, JavaScript and Python.\n\nParsing in JavaScript is straightforward. JavaScript natively supports JSON through the JSON object. To parse JSON using JavaScript, developers use the JSON.parse() method, converting the JSON data into a JavaScript object.\n\nIn this JavaScript example, we are converting a JSON string into a JavaScript object using the JSON.parse method. The alert function then displays the name value, \"John\".\n\nParsing in Python, on the other hand, requires the python 'json' library. Developers invoke the json.loads() method to parse JSON data.\n\nIn our Python example, after importing the json module, we invoke the json.loads() function to parse the JSON data into a python dictionary. The print function then outputs the name value, which is \"John\".\n\nTake note that converting JSON data into another data structure (for instance, a Python dictionary or JavaScript object) is called deserialization. It's an essential part of using JSON format in web development, allowing you to process the data as per your needs. As you work with JSON, remember to keep the syntax rules in mind to ensure data integrity. The ease with which JSON integrates into your coding process is what makes it a front runner in data interchange formats.\n\nMoving onward, let's delve into a crucial element associated with JSON - that's right, we're talking about JSON schema validation. This integral feature of JSON ensures code standardization, guarantees the integrity of data, and promotes a smooth coding process.\n\nSo what is JSON schema validation? Essentially, it's a powerful tool that validates your JSON data and checks if it adheres to the predefined specifications. And yes, it does all of this before you import that data into your JavaScript or Python environments, saving you from potential headaches.\n\nHere's how it works. When you're transferring data between applications using JSON, the data structure should be predictable and standardized. JSON schema validation, as its name suggests, is like a blueprint or a model for your data. It outlines what your data should look like - what elements it should contain, what data types those elements should be, whether certain fields are required or optional, and even the acceptable range of values for certain elements.\n\nApplying JSON schema validation can significantly improve your overall coding experience. It enables you to catch and address inconsistencies and errors early on, reducing debugging efforts. It helps maintain consistent data structures across multiple applications, which really comes in handy for large-scale projects involving various teams.\n\nTake a look at this simple example of JSON schema:\n\nIn this example, the schema defines an object that needs to have two properties, and . should be a string, whereas should be an integer and cannot be a negative value.\n\nNow that we've understood the concept of JSON schema validation, we'll be moving onto another exciting topic- creating custom JSON schemas. This will require another deep dive and you'll need your concentration caps on for this one. So, let's proceed...\n\nBest Practices for Using JSON\n\nJSON format is intuitive and offers a lot of flexibility, but to get the most out of it, it's crucial to follow certain best practices. These practices streamline the coding process, aid readability and optimize data interchange.\n\nFirst, always keep the JSON structure clean and organized. JSON data is represented in name-value pairs, meaning proper structuring ensures data integrity. It's easy to fall prey to messy code when dealing with complex data, so I emphasize consistency and neatness.\n\nSecondly, utilize JSON schema validation to its fullest extent. As explained before, JSON schema validation ensures code standardization and aids in catching inconsistencies early. A well-implemented validation process helps maintain the robustness of data interchange.\n\nIn addition, when dealing with large strings of data, it's better to use arrays rather than multiple name-value pairs. Data arrays in JSON are simple to understand and can hold data more efficiently than multiple name-value pairs.\n\nWhen creating custom JSON schemas for complex data, remember to keep things as simple as possible. Simplicity is the key to meaningful data representation in JSON.\n\nBelow, I've compiled a basic guide to JSON best practices:\n• Maintain clean, organized structure: Do this by using consistent name-value pairs and avoid nesting data unnecessarily.\n• Use arrays for large strings of data: Arrays are easier to manage and are intuitive for other developers.\n\nThese practices don't just apply to JSON -- they're a solid foundation for any data interchange format. The true power of these principles shines through when they're used consistently throughout a project. Get into this habit, and you'll see a marked improvement in your coding efficiency. While working with JSON, you'll soon discover other practices that can boost your experience - shaping and tailoring these guidelines to your workflow is equally important.\n\nIn the next section, we'll delve into comparing JSON with other data interchange formats - looking at where JSON stands out and where it might not be the best option. That's for another discussion though, so let's place the bookmark here.\n\nSo we've seen how JSON's simplicity and readability make it a powerful tool for data interchange. Its schema validation feature is a game changer, ensuring code standardization and catching errors early. I've shared some best practices for using JSON, like maintaining a clean structure, using arrays for large data strings, and keeping schemas simple. Remember, these aren't exclusive to JSON and can be applied to other data interchange formats too. In the next section, we'll dive into how JSON stacks up against other data formats. Stay tuned!"
    },
    {
        "link": "https://w3c.github.io/json-ld-bp",
        "document": "Coming up with a data format for your API is a common problem. It can be hard to choose between different data representations, what names you want to pick, and even harder if you want to leave room for extensibility. How do you make all these decisions? How do you make your API easy to use so people can use short strings to reference common things, but URLs to enable people to come up with their own so it isn't limiting? How can you make it easy for other people to add their own data in and make it interoperable? How do you consume data from other similar apps? There are technologies that can help you do this. Now, it isn't perfect – sometimes it won't solve your problem, but it could maybe solve a lot of them. The use of JSON on the web has grown immensely in the last decade, particularly with the explosion of APIs that eschew XML in favor of what is considered to be a more developer friendly format which is directly compatible with JavaScript. As a result, different sites have chosen their own proprietary representations for interacting with their sites, sometimes described using frameworks such as [[swagger]] which imply a particular URI composition for interacting with their services. This practice leads to vendor-specific semantic silos, where the meaning of a particular JSON document makes sense only by programming directly to the API documentation for a given service. As services grow they often introduce incompatible changes leading to a Version 2 or Version 3 of their API requiring developers to update client code to properly handle JSON documents. In many cases, even small changes can lead to incompatibilities. Additionally, composing information from multiple APIs becomes problematic, due to namespace or document format conventions that may differ between API endpoints. Moreover, the same principles are often repeated across different endpoints using arbitrary identifiers (name, email, website, etc.); the community needs to learn to stop repeating itself ( concept) and reuse common conventions, although this does not necessarily have to mean using exactly the same identifiers within the JSON itself (see JSON-LD Context). This Note proposes to outline a number of best practices for API designers or JSON developers based on the principles of separation of data model from syntax, the use of discoverable identifiers describing document contents, and general organizing principles that allow documents to be machine understandable (read, interpreted as JSON-LD using Linked Data, RDF and RDFS vocabulary, and data model principles). Key among these is the notion of vocabulary re-use, so that each endpoint does not need to separately describe the properties and structure of their JSON documents. Schema.org provides a great example of doing this, and includes an extension mechanism that may already be familiar to API designers. JSON-LD is JSON, and good JSON-LD is first and foremost good JSON. Since it is also Linked Data, developers and especially data publishers may find further useful advice at Data on the Web Best Practices [[dwbp]] and [[ld-bp]].\n\nPublish data using developer friendly JSON JSON [[json]] is the most popular format for publishing data through APIs; developers like it, it is easy to parse, and it is supported natively in most programming languages. For example, the following is reasonably idiomatic JSON which can also be interpreted as JSON-LD, given the appropriate context. { \"name\": \"Barack Obama\", \"givenName\": \"Barack\", \"familyName\": \"Obama\", \"jobTitle\": \"44th President of the United States\" } Use a top-level object JSON documents may be in the form of a object, or an array of objects. For most purposes, developers need a single entry point, so the JSON SHOULD be in the form of a single top-level object. Use native values When possible, property values SHOULD use native JSON datatypes such as numbers (integer, decimal and floating point) and booleans (`true` and `false`). JSON has a single numeric type, so using native representation of numbers can lose precision. Assume arrays are unordered JSON specifies that the values in an array are ordered, however in many cases arrays are also used for values which are unordered. Unless specified within the JSON-LD Context, multiple array values SHOULD be presumed to be unordered. (See in [[JSON-LD]]). Use well-known identifiers when describing data By sticking to basic JSON data expression, and providing a JSON-LD Context, all keys used within a JSON document can have unambiguous meaning, as they bind to URLs which describe their meaning. By adding an `@context` entry, the previous example can now be interpreted as JSON-LD. { ****\"@context\": \"http://schema.org\"****, \"name\": \"Barack Obama\", \"givenName\": \"Barack\", \"familyName\": \"Obama\", \"jobTitle\": \"44th President of the United States\" } When expanding such a data representation, a JSON-LD processor replaces these terms with the URIs they expand to (as well as making property values unambiguous): [ { \"http://schema.org/familyName\": [{\"@value\": \"Obama\"}], \"http://schema.org/givenName\": [{\"@value\": \"Barack\"}], \"http://schema.org/jobTitle\": [{\"@value\": \"44th President of the United States\"}], \"http://schema.org/name\": [{\"@value\": \"Barack Obama\"}] } ] Expanded form is not useful as is, but is necessary for performing further algorithmic transformations of JSON-LD data and is useful when validating that JSON-LD entity descriptions say what the publisher means. Provide one or more types for JSON objects Principles of Linked Data dictate that messages SHOULD be self describing, which includes adding a `type` to such messages. Many APIs use JSON messages where the type of information being conveyed is inferred from the retrieval endpoint. For example, when retrieving information about a Github Commit, you might see the following response: { \"sha\": \"7638417db6d59f3c431d3e1f261cc637155684cd\", \"url\": \"https://api.github.com/repos/octocat/Hello-World/git/commits/7638417db6d59f3c431d3e1f261cc637155684cd\", \"author\": { \"date\": \"2014-11-07T22:01:45Z\", \"name\": \"Scott Chacon\", \"email\": \"schacon@gmail.com\" }, \"committer\": { \"date\": \"2014-11-07T22:01:45Z\", \"name\": \"Scott Chacon\", \"email\": \"schacon@gmail.com\" }, \"message\": \"added readme, because im a good github citizen\n\n\", \"tree\": { \"url\": \"https://api.github.com/repos/octocat/Hello-World/git/trees/691272480426f78a0138979dd3ce63b77f706feb\", \"sha\": \"691272480426f78a0138979dd3ce63b77f706feb\" }, \"parents\": [ { \"url\": \"https://api.github.com/repos/octocat/Hello-World/git/commits/1acc419d4d6a9ce985db7be48c6349a0475975b5\", \"sha\": \"1acc419d4d6a9ce985db7be48c6349a0475975b5\" } ] } The only way to know this is a commit s to infer it based on the published API documentation, and the fact that it was returned from an endpoint defined for retrieving information about commits. { \"@context\": \"http://schema.org\", \"id\": \"http://www.wikidata.org/entity/Q76\", ****\"type\": \"Person\"****, \"name\": \"Barack Obama\", \"givenName\": \"Barack\", \"familyName\": \"Obama\", \"jobTitle\": \"44th President of the United States\" } Identify objects with a unique identifier Entities described in JSON objects often describe web resources having a URL; entity descriptions SHOULD use an identifier uniquely identifying that entity. In this case, using the resource location as the identity of the object is consistent with this practice. Adding an `id` entry (an alias for `@id`) allows the same person to be referred to from different locations. { \"@context\": \"http://schema.org\", ****\"id\": \"http://www.wikidata.org/entity/Q76\"****, \"type\": \"Person\", \"name\": \"Barack Obama\", \"givenName\": \"Barack\", \"familyName\": \"Obama\", \"jobTitle\": \"44th President of the United States\" } There can be ambiguity if an identifier describes the entity description, or directly represents that entity itself. As an example, Barack Obama may have a Wikidata entry `http://www.wikidata.org/entity/Q76`, but it would be a mistake to say that `http://www.wikidata.org/entity/Q76` is Barack Obama. However, it is common to use this pattern, particularly if the type of the entity describes a Person, rather than a WebPage. Things not strings When describing attributes, entity references SHOULD be used instead of string literals. In some cases, when describing an attribute of an entity, it is tempting to using string values which have no independent meaning. Such values are often used for well known things. A JSON-LD context can define a term for such values, which allow them to appear as strings within the message, but be associated with specific identifiers. In this case, the property must be defined with type `@vocab` so that values will be interpreted relative to a vocabulary rather than the file location. { \"@context\": [\"http://schema.org\", ****{ \"gender\": {\"@id\": \"schema:gender\", \"@type\": \"@vocab\"} }****], \"id\": \"http://www.wikidata.org/entity/Q76\", \"type\": \"Person\", \"name\": \"Barack Obama\", \"givenName\": \"Barack\", \"familyName\": \"Obama\", \"jobTitle\": \"44th President of the United States\", ****\"gender\": \"Male\"**** } Nest referenced inline objects When multiple related entity descriptions are provided inline, related entities SHOULD be nested. For example, when relating one entity to another, where the related entity is described in the same message: { \"@context\": \"http://schema.org\", \"id\": \"http://www.wikidata.org/entity/Q76\", \"type\": \"Person\", \"name\": \"Barack Obama\", \"givenName\": \"Barack\", \"familyName\": \"Obama\", \"jobTitle\": \"44th President of the United States\", ****\"spouse\": { \"id\": \"http://www.wikidata.org/entity/Q13133\", \"type\": \"Person\", \"name\": \"Michelle Obama\", \"spouse\": \"http://www.wikidata.org/entity/Q76\" }**** } In this example, the `spouse` relationship is bi-directional, we have arbitrarily rooted the message with Barack Obama, and created a symmetric relationship from Michelle back to Barack by reference, rather than by nesting. When describing an inverse relationship, use a referenced property FIXME\n\nExternal references SHOULD use typed term When using a property intended to reference another entity, properties SHOULD be defined to type string values as being references. For example, the `schema:image` property a `Thing` to an `Image`: { \"@context\": \"http://schema.org\", \"id\": \"http://www.wikidata.org/entity/Q76\", \"type\": \"Person\", \"name\": \"Barack Obama\", \"givenName\": \"Barack\", \"familyName\": \"Obama\", \"jobTitle\": \"44th President of the United States\", ****\"image\": \"https://commons.wikimedia.org/wiki/File:President_Barack_Obama.jpg\"**** } This will be interpreted as a reference, rather than a string literal, because (at the time of publication), the schema.org JSON-LD Context defines `image` to be of type `@id`: If not defined as such in a remote context, terms may be (re-) defined in a local context: { \"@context\": [\"http://schema.org\", ****{ \"image\": { \"@id\": \"schema:image\", \"@type\": \"@id\"} }****], \"id\": \"http://www.wikidata.org/entity/Q76\", \"type\": \"Person\", \"name\": \"Barack Obama\", \"givenName\": \"Barack\", \"familyName\": \"Obama\", \"jobTitle\": \"44th President of the United States\", \"image\": \"https://commons.wikimedia.org/wiki/File:President_Barack_Obama.jpg\" } Ordering of array elements Unless specifically described ordered as an `@list`, do not depend on the order of elements in an array. By default, arrays in JSON-LD do not convey any ordering of contained elements . However, for the processing of contexts, the ordering of elements in arrays does matter. When writing array-based contexts, this fact should be kept in mind. Ordered contexts in arrays allow inheritance and overriding of context entries. When processing the following example, the first `name` entry will be overridden by the second `name` entry. { \"@context\": [ { \"id\": \"@id\", \"name\": \"http://schema.org/name\" }, { \"name\": \"http://xmlns.com/foaf/0.1/name\" } ], \"@id\": \"http://www.wikidata.org/entity/Q76\", ****\"name\": \"Barack Obama\"**** } Order is important when processing protected terms. While the first example will cause a term redefinition error, the second example will not throw this error. { \"@context\": [ { \"@version\": 1.1, \"name\": { \"@id\": \"http://schema.org/name\", \"@protected\": true } }, { \"name\": \"http://xmlns.com/foaf/0.1/name\" } ], \"@id\": \"http://www.wikidata.org/entity/Q76\", ****\"name\": \"Barack Obama\"**** } { \"@context\": [ { \"name\": \"http://xmlns.com/foaf/0.1/name\" }, { \"@version\": 1.1, \"Person\": \"http://schema.org/Person\", \"knows\": \"http://schema.org/knows\", \"name\": { \"@id\": \"http://schema.org/name\", \"@protected\": true } } ], \"@id\": \"http://www.wikidata.org/entity/Q76\", ****\"name\": \"Barack Obama\"**** }\n\nWhile most use of JSON-LD SHOULD NOT require a client to change the data representation, JSON-LD does allow the use of various algorithms to re-shape a JSON-LD document. These require the use of the JSON-LD Context, which is typically represented using a link to a remote document. Because it is remote, processing time can be severely impacted by the time it takes to retrieve this context. Cache JSON-LD Contexts Services providing a JSON-LD Context SHOULD set HTTP cache-control headers to allow liberal caching of such contexts, and clients SHOULD attempt to use a locally cached version of these documents. Typically, libraries used to process JSON-LD documents should do this for you. (See also [[json-ld-best-practice-caching]])."
    },
    {
        "link": "https://docs.oracle.com/en/database/oracle/oracle-database/21/adjsn/json-data.html",
        "document": "Standard JSON values, scalars, objects, and arrays are described.\n\nAccording to the JSON standard, a JSON value is one of the following JSON-language data types: object, array, number, string, Boolean (value or ), or null (value ). All values except objects and arrays are scalar.\n\nA JSON value of is a value as far as SQL is concerned. It is not , which in SQL represents the absence of a value (missing, unknown, or inapplicable data). In particular, SQL condition returns false for a JSON value, and SQL condition returns true.\n\nStandard JSON has no date data type (unlike both XML and JavaScript). A date is represented in standard JSON using the available standard data types, such as string. There are some de facto standards for converting between dates and JSON strings. But typically programs using standard JSON data must, one way or another, deal with date representation conversion.\n\nA JavaScript object is an associative array, or dictionary, of zero or more pairs of property names and associated JSON values.Foot 2 A JSON object is a JavaScript object literal.Foot 3 It is written as such a property list enclosed in braces ( , ), with name–value pairs separated by commas ( ), and with the name and value of each pair separated by a colon ( ). (Whitespace before or after the comma or colon is optional and insignificant.)\n\nIn JSON each property name and each string value must be enclosed in double quotation marks ( ). In JavaScript notation, a property name used in an object literal can be, but need not be, enclosed in double quotation marks. It can also be enclosed in single quotation marks ( ).\n\nAs a result of this difference, in practice, data that is represented using unquoted or single-quoted property names is sometimes referred to loosely as being represented in JSON, and some implementations of JSON, including the Oracle Database implementation, support the lax syntax that allows the use of unquoted and single-quoted property names.\n\nA string in JSON is composed of Unicode characters, with backslash ( ) escaping. A JSON number (numeral) is represented in decimal notation, possibly signed and possibly including a decimal exponent.\n\nAn object property is typically called a field. It is sometimes called a key, but this documentation generally uses “field” to avoid confusion with other uses here of the word “key”. An object property name–value pair is often called an object member (but sometimes member can mean just the property). Order is not significant among object members.\n\nA JavaScript array has zero or more elements. A JSON array is represented by brackets ( , ) surrounding the representations of the array elements (also called items), which are separated by commas ( ), and each of which is an object, an array, or a scalar value. Array element order is significant. (Whitespace before or after a bracket or comma is optional and insignificant.)\n\nThis example shows a JSON object that represents a purchase order, with top-level field names , , , , , , , and .\n• Most of the fields here have string values. For example: field has value .\n• Fields and have numeric values: and .\n• Field has an object as its value. This object has three members, with fields , , and . Field has a string value ( ).\n• The value of field is an object with fields , , , , and . Field has a numeric value; the others have string values.\n• Field has an array as value. This array has two elements, each of which is an object. Each of these objects has two members: fields and with their values.\n• Field has the Boolean value .\n• Field has an array as value. This array has two elements, each of which is an object. Each of these objects has three members, with fields , , and .\n• Fields and have numeric values. Field has an object as value, with fields , , and . Field has a string value. Fields and have numeric values."
    },
    {
        "link": "https://stackoverflow.com/questions/12806386/is-there-any-standard-for-json-api-response-format",
        "document": "Do standards or best practices exist for structuring JSON responses from an API? Obviously, every application's data is different, so that much I'm not concerned with, but rather the \"response boilerplate\", if you will. An example of what I mean:\n\nAssuming you question is about REST webservices design and more precisely concerning success/error. I think there are 3 different types of design.\n• None Use only HTTP Status code to indicate if there was an error and try to limit yourself to the standard ones (usually it should suffice).\n• Pros: It is a standard independent of your api.\n• Cons: Less information on what really happened.\n• None Use HTTP Status + json body (even if it is an error). Define a uniform structure for errors (ex: code, message, reason, type, etc) and use it for errors, if it is a success then just return the expected json response.\n• Pros: Still standard as you use the existing HTTP status codes and you return a json describing the error (you provide more information on what happened).\n• Cons: The output json will vary depending if it is a error or success.\n• None Forget the http status (ex: always status 200), always use json and add at the root of the response a boolean responseValid and a error object (code,message,etc) that will be populated if it is an error otherwise the other fields (success) are populated.\n• None Pros: The client deals only with the body of the response that is a json string and ignores the status(?). It's up to you to choose :) Depending on the API I would choose 2 or 3 (I prefer 2 for json rest apis). Another thing I have experienced in designing REST Api is the importance of documentation for each resource (url): the parameters, the body, the response, the headers etc + examples. I would also recommend you to use jersey (jax-rs implementation) + genson (java/json databinding library). You only have to drop genson + jersey in your classpath and json is automatically supported.\n• None Solution 2 is the hardest to implement but the advantage is that you can nicely handle exceptions and not only business errors, initial effort is more important but you win on the long term.\n• None Solution 3 is the easy to implement on both, server side and client but it's not so nice as you will have to encapsulate the objects you want to return in a response object containing also the responseValid + error.\n\nI will not be as arrogant to claim that this is a standard so I will use the \"I prefer\" form. I prefer terse response (when requesting a list of /articles I want a JSON array of articles). In my designs I use HTTP for status report, a 200 returns just the payload. 400 returns a message of what was wrong with request: If there was error with processing on my side, I return 501 with a message: {\"message\" : \"Could not connect to data store.\"} From what I've seen quite a few REST-ish frameworks tend to be along these lines. JSON is supposed to be a payload format, it's not a session protocol. The whole idea of verbose session-ish payloads comes from the XML/SOAP world and various misguided choices that created those bloated designs. After we realized all of it was a massive headache, the whole point of REST/JSON was to KISS it, and adhere to HTTP. I don't think that there is anything remotely standard in either JSend and especially not with the more verbose among them. XHR will react to HTTP response, if you use jQuery for your AJAX (like most do) you can use / and / callbacks to capture errors. I can't see how encapsulating status reports in JSON is any more useful than that.\n\nFor what it's worth I do this differently. A successful call just has the JSON objects. I don't need a higher level JSON object that contains a success field indicating true and a payload field that has the JSON object. I just return the appropriate JSON object with a 200 or whatever is appropriate in the 200 range for the HTTP status in the header. However, if there is an error (something in the 400 family) I return a well-formed JSON error object. For example, if the client is POSTing a User with an email address and phone number and one of these is malformed (i.e. I cannot insert it into my underlying database) I will return something like this: Important bits here are that the \"field\" property must match the JSON field exactly that could not be validated. This allows clients to know exactly what went wrong with their request. Also, \"message\" is in the locale of the request. If both the \"emailAddress\" and \"phoneNumber\" were invalid then the \"errors\" array would contain entries for both. A 409 (Conflict) JSON response body might look like this: { \"description\" : \"Already Exists\" \"errors\" : [ { \"field\" : \"phoneNumber\", \"message\" : \"Phone number already exists for another user.\" } ], } With the HTTP status code and this JSON the client has all they need to respond to errors in a deterministic way and it does not create a new error standard that tries to complete replace HTTP status codes. Note, these only happen for the range of 400 errors. For anything in the 200 range I can just return whatever is appropriate. For me it is often a HAL-like JSON object but that doesn't really matter here. The one thing I thought about adding was a numeric error code either in the the \"errors\" array entries or the root of the JSON object itself. But so far we haven't needed it.\n\nThe point of JSON is that it is completely dynamic and flexible. Bend it to whatever whim you would like, because it's just a set of serialized JavaScript objects and arrays, rooted in a single node. What the type of the rootnode is is up to you, what it contains is up to you, whether you send metadata along with the response is up to you, whether you set the mime-type to or leave it as is up to you (as long as you know how to handle the edge cases). Build a lightweight schema that you like.\n\n Personally, I've found that analytics-tracking and mp3/ogg serving and image-gallery serving and text-messaging and network-packets for online gaming, and blog-posts and blog-comments all have very different requirements in terms of what is sent and what is received and how they should be consumed. So the last thing I'd want, when doing all of that, is to try to make each one conform to the same boilerplate standard, which is based on XML2.0 or somesuch. That said, there's a lot to be said for using schemas which make sense to you and are well thought out.\n\n Just read some API responses, note what you like, criticize what you don't, write those criticisms down and understand why they rub you the wrong way, and then think about how to apply what you learned to what you need.\n\nI used to follow this standard, was pretty good, easy, and clean on the client layer. Normally, the HTTP status 200, so that's a standard check which I use at the top. and I normally use the following JSON I also use a template for the API's dynamic response; try { // query and what not. response.payload = new { data = new { pagination = new Pagination(), customer = new Customer(), notifications = 5 } } // again something here if we get here success has to be true // I follow an exit first strategy, instead of building a pyramid // of doom. response.success = true; } catch(Exception exception){ response.success = false; response.message = exception.GetStackTrace(); _logger.Fatal(exception, this.GetFacadeName()) } return response; { \"success\": boolean, \"message\": \"some message\", \"payload\": { \"data\" : [] \"message\": \"\" ... // put whatever you want to here. } } on the client layer I would use the following: if(response.code != 200) { // woops something went wrong. return; } if(!response.success){ console.debug ( response.message ); return; } // if we are here then success has to be true. if(response.payload) { .... } notice how I break early avoiding the pyramid of doom.\n\nThere is no lawbreaking or outlaw standard other than common sense. If we abstract this like two people talking, the standard is the best way they can accurately understand each other in minimum words in minimum time. In our case, 'minimum words' is optimizing bandwidth for transport efficiency and 'accurately understand' is the structure for parser efficiency; which ultimately ends up with the less the data, and the common the structure; so that it can go through a pin hole and can be parsed through a common scope (at least initially). Almost in every cases suggested, I see separate responses for 'Success' and 'Error' scenario, which is kind of ambiguity to me. If responses are different in these two cases, then why do we really need to put a 'Success' flag there? Is it not obvious that the absence of 'Error' is a 'Success'? Is it possible to have a response where 'Success' is TRUE with an 'Error' set? Or the way, 'Success' is FALSE with no 'Error' set? Just one flag is not enough? I would prefer to have the 'Error' flag only, because I believe there will be less 'Error' than 'Success'. Also, should we really make the 'Error' a flag? What about if I want to respond with multiple validation errors? So, I find it more efficient to have an 'Error' node with each error as child to that node; where an empty (counts to zero) 'Error' node would denote a 'Success'."
    },
    {
        "link": "https://stackoverflow.com/questions/25983090/is-sanitizing-json-necessary",
        "document": "I think it's a well-known best practice on the web to mistrust any input. The sentence\n\nis probably the most cited quote with respect to input validation. Now, for HTML you can use tools such as DOMPurify to sanitize it.\n\nMy question is if I have a Node.js server running Express and body-parser middleware to receive and parse JSON, do I need to run any sanitizing as well?\n\nMy (maybe naive?) thoughts on this are that JSON is only data, no code, and if somebody sends invalid JSON, body-parser (which uses internally) will fail anyway, so I know that my app will receive a valid JavaScript object. As long as I don't run eval on that or call a function, I should be fine, shouldn't I?"
    },
    {
        "link": "https://stackoverflow.com/questions/14125782/how-to-sanitize-user-input-text-so-that-it-can-be-used-in-javascript-json",
        "document": "I have a web app in which I allow some large text entry using text fields. This text is saved to a database and then later it is sent back to the user as a field in a JSON response. In the browser, I attempt to simply convert it to an using , but this sometimes fails depending on what the user put in the field.\n\nI think that right now, the text has single quotes in it, and those are breaking the browser-side Javascript before I can call on it.\n\nWhat's the best way to sanitize this data so that, ideally, I can just parse it back to an with minimal cleansing after it has been saved?"
    },
    {
        "link": "https://bito.ai/resources/sanitize-input-javascript-javascript-explained",
        "document": "Sanitizing input in Javascript is an essential step of any web development process, as it helps protect application users from malicious input attacks. When sanitizing input, developers are ensuring that user data is sanitized before being received, handled, or stored by a program. In this article, we will be discussing what sanitize input is, the benefits of sanitizing input in Javascript, and some tools for implementing and detecting unsanitized input in your existing codebase.\n\nSanitizing input in Javascript is a process of cleaning and validating user-inputed data. This includes ensuring that data is formatted correctly, removing any malicious code, and eliminating any errors from being entered. It also includes checking for malicious scripts and other forms of attack vectors. Sanitizing data is important for security and the stability of an application, as a malicious input can have severe impacts, such as leaking private user data or crashing the system.\n\nIn addition to the security benefits, sanitizing input can also improve the user experience. By validating user input, applications can provide more accurate feedback and prevent users from entering invalid data. This can help reduce frustration and improve the overall user experience.\n\nSanitizing input in Javascript has countless benefits, including enhanced security, performance, usability, and robustness. By sanitizing input, developers are better protected against malicious inputs, denied services attacks, and errors in their code. It also makes the application overall more stable and secure, as unanticipated events are no longer likely to occur. Additionally, sanitized input can help to improve your application’s performance by eliminating errors and preventing malicious attacks.\n\nSanitizing input also helps to improve the user experience by ensuring that the data entered is valid and consistent. This helps to reduce the amount of time spent debugging and troubleshooting, as well as reducing the risk of data loss or corruption. Furthermore, sanitizing input can help to improve the overall robustness of the application, as it ensures that the data is always valid and consistent.\n\nHow to Implement Sanitization in Javascript\n\nImplementing sanitize input in Javascript can be done in several different ways. The simplest implementation is to always escape user input before it is processed by your application. Escaping user input is a process used to limit the potential for malicious inputs to be sent to your application. Additionally, you can use the HTML encode and decode functions – which convert a string of characters into the appropriate HTML code – to reduce the potential for malicious inputs.Depending on your use case, the way you sanitize might differ. Here’s how to implement basic sanitization in JavaScript for a few common scenarios\n\nIf you’re inserting user input into the DOM, you should avoid using methods like which can execute arbitrary JavaScript. Instead:\n\nUse to safely insert text into the DOM:\n\nIf you must insert HTML, consider using a library like DOMPurify to sanitize the input:\n\nIf you’re interacting with a database, especially SQL-based ones, you must guard against SQL injection attacks. While parameterized queries are the best solution, for JavaScript-side sanitization:\n• Use libraries or frameworks that provide parameterized query support.\n\nIf you’re taking URLs as input and redirecting or making requests based on those URLs, ensure they are safe.\n\nIf you’re accepting JSON input, always parse it with the native method, which will prevent the execution of arbitrary JavaScript..\n\nSanitizing user input in Javascript is a common practice amongst developers. Here are some of the most common methods used to sanitize user input:\n• Validation – validating user input to ensure it meets a set of parameters.\n• Input sanitation – eliminating any malicious or invalid characters that may be contained within the user’s input.\n• Input encoding – encoding the user’s input into an accepted format before sanitization.\n• Input filtering – filtering out any malicious content from the user’s input before it can be accessed.\n\nIt is important to note that these methods should be used in combination with one another to ensure the highest level of security. Additionally, developers should also consider using a third-party library to help with sanitizing user input, as this can help to reduce the amount of time and effort spent on manual sanitization.\n\nFailing to sanitize user input can have disastrous consequences for your application, as it opens the door for malicious inputs to be processed by your application. These malicious inputs could result in confidential data being stolen, denial of service attacks, or other forms of exploitation. Therefore, it’s critical to sanitize user input before processing or storing it.\n\nSanitizing user input involves validating the data to ensure it meets certain criteria, such as being of the correct type, length, and format. It also involves filtering out any potentially malicious content, such as HTML tags, JavaScript code, and SQL queries. By taking these steps, you can ensure that your application is secure and protected from malicious attacks.\n\nBest Practices for Writing Secure Code in Javascript\n\nWriting secure code in Javascript is essential for any application’s security. Here are some best practices for writing secure code:\n• Sanitize all user input before processing or storing it.\n• Never trust user-inputted data – always validate and filter it.\n• Always use a secure connection when requesting or transmitting user data.\n• Encode all user input correctly before processing or storing it.\n• Use libraries such as DOMPurify to filter malicious content from user input.\n\nIt is also important to use secure authentication methods such as two-factor authentication and to use secure passwords. Additionally, it is important to keep your code up to date with the latest security patches and to use secure coding practices such as avoiding the use of global variables and using secure coding libraries.\n\nDetecting unsanitized inputs in your code can be a tricky process, as they are often hard to spot unless you already know what to look out for. Luckily, there are numerous tools available that make detecting unsanitized inputs easier. These tools can detect malicious inputs, validate user input, and even scan your source code for suspicious behaviour.\n\nOne of the most popular tools for detecting unsanitized inputs is the OWASP Zed Attack Proxy (ZAP). ZAP is an open-source tool that can detect and alert you to any potential security vulnerabilities in your code. It can also be used to scan your source code for any malicious inputs, and can even be used to test your code against a variety of attack scenarios. Additionally, ZAP can be used to detect and block any malicious requests that are sent to your application.\n\nSanitizing user input is an essential step for any web development process. By sanitizing user input in Javascript, developers are able to minimize the risk of malicious inputs being processed, as well as improving the stability and performance of their application. Furthermore, there are numerous tools available that make detecting unsanitized inputs easier. Knowing these things is essential for developing secure applications.\n\nIt is important to remember that sanitizing user input is only one part of the security process. Developers should also ensure that their applications are regularly tested for vulnerabilities, and that they are using the latest security protocols. Additionally, developers should be aware of the potential risks associated with user input, and take steps to mitigate them."
    },
    {
        "link": "https://medium.com/@AlexanderObregon/json-schema-a-guide-to-validating-your-json-data-9f225b2a17ef",
        "document": "JSON (JavaScript Object Notation) is a lightweight data-interchange format that is both easy to read and write and easy to parse and generate for machines. However, making sure the data within a JSON object is valid and meets certain criteria can be a challenge. That’s where JSON Schema comes in. JSON Schema is a powerful tool for validating the structure and data types of JSON data. In this article, we’ll explore how to use JSON Schema to validate your JSON data.\n\nJSON Schema is a vocabulary that allows you to annotate and validate JSON documents. It provides a clear, human-readable, and machine-readable schema language to describe the expected structure, data types, and constraints for JSON data. By using JSON Schema, you can ensure that your JSON data is consistent, adheres to specific rules, and is easier to work with across different applications and services.\n\nValidating JSON data against a JSON Schema ensures that the data conforms to the expected structure, data types, and various constraints specified in the schema. This process is important for maintaining data integrity and reliability in applications. We’ll use the popular “ajv” library in JavaScript to demonstrate this validation process. Here’s how to effectively utilize JSON Schema for data validation:\n\nFirst, you need to install the AJV library, which is a fast JSON Schema validator. To install AJV, run the following command in your terminal:\n\nCreate a JavaScript file, for example, . In this file, you will set up the AJV instance:\n\nDefine a schema that your JSON data should adhere to. The schema specifies the structure, constraints, and types of data expected. Here is a more detailed schema example that includes multiple data types and validation keywords:\n\nNow, create a JSON object that represents the data you want to validate. This data should follow the structure defined by the schema:\n\nUse the AJV library to validate your JSON data against the schema. The method will return a boolean indicating whether the data is valid, and if not, it will populate with the details:\n\nIf your JSON data is valid according to the schema, the console will display “JSON data is valid”. If there are any discrepancies, the console will output the errors, providing specific details on what did not match the schema expectations.\n\nJSON Schema is a powerful tool for ensuring the consistency and validity of your JSON data. By using JSON Schema to define the structure and constraints of your data, you can save time and prevent bugs by catching issues early in the development process. With the wide range of libraries available, it’s easy to integrate JSON Schema validation into your existing projects and workflows."
    },
    {
        "link": "https://blog.klipse.tech/javascript/2021/09/30/data-validation-with-json-schema.html",
        "document": "According to the principles of Data-Oriented Programming, we should represent data with generic and immutable data structures, like immutable hash maps and immutable vectors. At first sight, it might seem that it means to live in the wild.\n\nIn fact, it is possible – and advised – to maintain a data schema in Data-Oriented Programming.\n\nThe major difference between this kind of data validation and the way data is validated with static types is that data schema should be separated from data representation.\n\nThe purpose of this article is to explain the rationale behind this data validation approach.\n\nThis article is made of 4 parts:\n• How to express a data schema using JSON Schema\n• How to validate data against a JSON Schema\n• The benefits of separating between data schema and data representation\n• The costs of separating between data schema and data representation\n\nThis article is an interactive version of the article published on JavaScript Works.\n\nThink about handling a request in a library management system for the addition of an author to the system. To keep things simple, imagine that such a request contains only basic information about the author:\n• Their first name\n• Their last name\n• Optionally, the number of books they have written\n\nIn Data-Oriented Programming, we represent the request data in our program as a string map that is expected to have three fields:\n\nUsing JSON Schema, we represent the data schema of the request with the following map:\n\nA couple of remarks regarding the syntax of this JSON Schema:\n• Data is expected to be a map (in JSON, a map is called an object)\n• Only and fields are required\n• must be an integer (when it is provided)\n\nIn order to check whether a piece of data conforms to a data schema, we use a data validation library for our preferred programming language.\n\nThe complete list of data validation libraries is available here.\n\nFor instance, in JavaScript, using Ajv JSON Schema validator, we validate a piece of data using the function. As you might expect, when a piece of data is valid, returns :\n\nWhen a piece of data is invalid (e.g. using instead of ), returns :\n\nWhen a piece of data is invalid, we can easily get details about data validation failures in a human readable format:\n\nA couple of remarks regarding validation with :\n• By default, Ajv stores only the first data validation error. We use to store all errors.\n• Data validation errors are stored internally as an array. In order to get a human readable string, we use function.\n\nThe benefits of separating between data schema and data representation\n\nWhen we separate data schema from data representation in our programs, our programs benefit from:\n• Freedom to choose what data should be validated\n\nWhen data schema is separated from data representation we are free to instantiate data without specifying its expected shape. Such a freedom is useful in various situations. For example:\n• We want to experiment with code quickly\n• Data has already been validated\n\nIn classic Object-Oriented Programming and in some statically typed Functional Programming, each and every piece of data must have a predefined shape (either a class or a data type). During the exploration phase of coding, where we don’t know yet what is the exact shape of our data, being forced to update the type definition each time we update our data model slows us down. In Data-Oriented Programming, we can develop at a fast pace during the exploration phase, by delaying the data schema definition to a later phase.\n\nOne common refactoring pattern is the split phase refactoring where you basically split a single large function into multiple smaller functions, with a private scope. Those functions are called with data that has already been validated by the large function. In Data-Oriented Programming, we are free to not specify the shape of the arguments of the inner functions, relying on the data validation that has already occurred.\n\nSuppose we want to display some information about an author, like their full name and whether they are considered as prolific or not.\n\nFirst, we define the data schema for the author data:\n\nThen, we write a function that first check whether data is valid and then displays the information about he author:\n\nNotice that the first thing we do inside the body of is to validate that the argument passed to the function is valid.\n\nNow, let’s apply the split phase refactoring pattern to this simplistic example and split the body of in two inner functions:\n• : Display whether the author is prolific or not\n\nHaving the data schema separated from the data representation allows us not to specify a data schema for the arguments of the inner functions and . It makes the refactoring process a bit smoother.\n\nIn some cases, the inner functions are more complicated and it makes sense to specify a data schema for their arguments. Data-Oriented Programming gives us the freedom to choose!\n\nIn Object-Oriented Programming, allowing a class member to be optional is not easy. For instance, in Java one needs a special construct like the class introduced in Java 8.\n\nIn Data-Oriented Programming, it is natural to declare a field as optional in a map. In fact in JSON Schema, by default every field is optional. In order to make a field non-optional, we have to include its name in the array as for instance in the author schema in the following code snippet where only and are required while is optional.\n\nLet’s illustrate how the validation function deals with optional fields: A map without a field is considered to be valid:\n\nHowever, a map with a field where the value is not an interger is considered to be invalid:\n\nIn Data-Oriented Programming, data validation occurs at run time. It allows us to define data validation conditions that go beyond the type of a field. For instance, we might want to make sure that a field is not only a string but a string with a maximal number of characters or a number comprised in a range of numbers.\n\nFor instance, here is a JSON Schema that expects and to be strings of less than 100 characters and to be a number between and :\n\nJSON Schema supports many other advanced data validation conditions, like regular expression validation for string fields or number fields that should be a multiple of a given number.\n\nWhen the data schema is defined as data, we can leverage tools that generate data model visualization: with tools like JSON Schema Viewer and Malli we can generate a UML diagram out of a JSON Schema. For instance, the following JSON Schema defines the shape of a field that is an array of books where each book is a map.\n\nThe tools we just mentioned can generate the following UML diagram from the JSON Schema:\n\nAn interesting way to leverage data schema for function arguments is to automatically generate unit tests. Let’s change a bit the function into a function called that – instead of displaying the author info – returns the author info as a string.\n\nWe are going to generate a unit test for by generating random input data that conforms to . For that purpose, we use a library like JSON Schema Faker.\n\nThen we call with the random data:\n\nDepending on what the function does, we might expect different things. In the case of , we expect the output to be a string that starts with the word . Let’s create a schema for the return value of :\n\nHere is the code of our unit test:\n\nThe costs of separating between data schema and data representation\n\nThere is no such thing as a free lunch. Separating between data schema and data representation comes at a cost:\n• Loose connection between data and its schema\n\nCost #1: Loose connection between data and its schema\n\nBy definition, when we separate between data schema and data representation, the connection between data and its schema is looser that when we represent data with classes. Moreover, the schema definition language (e.g. JSON Schema) is not part of the programming language. It is up to the developer to decide where data validation is necessary and where it is superfluous.\n\nAs the idiom says, with great power comes great responsibility.\n\nAs we mentioned earlier, there exist implementations of JSON Schema validation in most programming languages. When data validation occurs at run time it takes some time to run the data validation while in Object-Oriented programming, data validation occurs usually at compile time.\n\nThis drawback is mitigated by the fact that even in Object-Oriented programming some parts of the data validation occur at run time. For instance, the conversion of a request JSON payload into an object occurs at run time. Moreover, in Data-Oriented Programming, it is quite common to have some data validation parts enabled only during development and to disable them when the system runs in production.\n\nAs a consequence, the performance hit is not significant.\n\nIn Data-Oriented Programming, data is represented with immutable generic data structures. When additional information about the shape of the data is required, we are free to define a data schema (e.g. in JSON Schema).\n\nKeeping the data schema separate from the data representation leaves the developer free to decide where and when data should be validated. Moreover, data validation occurs at run-time. As a consequence, we can express data validation conditions that go beyond the static data types (e.g. the string length).\n\nHowever, as the idiom says, with great power comes great responsibility. It’s up to the developer to decide what data should be validated."
    }
]