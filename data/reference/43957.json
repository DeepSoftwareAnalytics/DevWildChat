[
    {
        "link": "https://blog.paperspace.com/numpy-optimization-vectorization-and-broadcasting",
        "document": "In Part 1 of our series on writing efficient code with NumPy we cover why loops are slow in Python, and how to replace them with vectorized code. We also dig deep into how broadcasting works, along with a few practical examples.\n\nLibraries that speed up linear algebra calculations are a staple if you work in fields like machine learning, data science or deep learning. NumPy, short for Numerical Python, is perhaps the most famous of the lot, and chances are you've already used it. However, merely using NumPy arrays in place of vanilla Python lists hardly does justice to the capabilities that NumPy has to offer.\n\nIn this series I will cover best practices on how to speed up your code using NumPy, how to make use of features like vectorization and broadcasting, when to ditch specialized features in favor of vanilla Python offerings, and a case study where we will use NumPy to write a fast implementation of the K-Means clustering algorithm.\n\nAs far as this part is concerned, I will be covering:\n• How to properly time your code to compare vanilla Python to optimized NumPy code.\n• Why are loops slow in Python?\n• What vectorization is, and how to vectorize your code.\n• What broadcasting is, with examples demonstrating its applications.\n\nIn order to really appreciate the speed boosts NumPy provides, we must come up with a way to measure the running time of a piece of code.\n\nWe can use Python's module for this.\n\nThe problem with this method is that measuring a piece of code only once does not give us a robust estimate of its running time. The code may run slower or faster for a particular iteration due to various processes in the background, for instance. It is therefore prudent to compute the average running time over many runs to get a robust estimate. To accomplish this, we use Python's module.\n\nThe method has three arguments:\n• is a string that contains the necessary imports to run our snippet.\n• is the string describing our code snippet.\n• is the number of runs over which the experiment has to be run.\n\ncan also be used to measure the run times of functions too, but only functions which don't take any arguments. For this, we can pass the function name (not the function call) to the method.\n\nIf you are using an iPython console or Jupyter Notebook, you can use the magic command. The output is much more detailed than for the normal call.\n\nWhenever one is looking for bottlenecks in code, especially python code, loops are a usual suspect. Compared to languages like C/C++ , Python loops are relatively slower. While there are quite a few reasons why that is the case, I want to focus on one particular reason: the dynamically typed nature of Python.\n\nPython first goes line-by-line through the code, compiles the code into bytecode, which is then executed to run the program. Let's say the code contains a section where we loop over a list. Python is dynamically typed, which means it has no idea what type of objects are present in the list (whether it's an integer, a string or a float). In fact, this information is basically stored in every object itself, and Python can not know this in advance before actually going through the list. Therefore, at each iteration python has to perform a bunch of checks every iteration like determining the type of variable, resolving it's scope, checking for any invalid operations etc.\n\nContrast this with C, where arrays are allowed to be consisting of only one data type, which the compiler knows well ahead of time. This opens up possibility of many optimizations which are not possible in Python. For this reason, we see loops in python are often much slower than in C, and nested loops is where things can really get slow.\n\nOK! So loops can slow your code. So what to do now? What if we can restrict our lists to have only one data type that we can let Python know in advance? Can we then skip some of the per-iteration type checking Python does to speed up our code. NumPy does something similar. NumPy allows arrays to only have a single data type and stores the data internally in a contiguous block of memory. Taking advantage of this fact, NumPy delegates most of the operations on such arrays to optimized, pre-compiled C code under the hood.\n\nIn fact, most of the functions you call using NumPy in your python code are merely wrappers for underlying code in C where most of the heavy lifting happens. In this way, NumPy can move the execution of loops to C, which is much more efficient than Python when it comes to looping. Notice this can be only done as the array enforces the elements of the array to be of the same kind. Otherwise, it would not be possible to convert the Python data types to native C ones to be executed under the hood.\n\nLet's take an example. Let's write a short piece of code that takes two arrays and performs element-wise multiplication. We put the code in a function just so that we can conveniently time our code later.\n\nDon't worry about not storing the value each iteration. The point of this exercise to merely see the performance of certain operations and not really bother about the results. We just want to see how a particular number of multiplication operations take.\n\nHowever, if we were using NumPy arrays, we would not need to write a loop. We can simply do this like shown below.\n\nHow does this happen? This is because internally, NumPy delegates the loop to pre-compiled, optimized C code under the hood. This process is called vectorization of the multiplication operator. Technically, the term vectorization of a function means that the function is now applied simultaneously over many values instead of a single value, which is how it looks from the python code ( Loops are nonetheless executed but in C)\n\nNow that we have used a vectorized function in place of the loop, does it provide us with a boost in speed? We run repeat the experiment 5 times ( flag) , with the code being executed 10000 times ( flag ) over each run.\n\nThe following is my output.\n\nTimes on your machine may differ depending upon processing power and other tasks running in background. But you will nevertheless notice considerable speedups to the tune of about 20-30x when using the NumPy's vectorized solution.\n\nNote that I'm using the magic here because I am running the experiments in the Jupyter cell. If you are using plain python code, then you would have to use function. The output of the function is merely the total time which you will have to divide with number of iterations.\n\nAlso, from now on, when I mention the phrase vectorizing a loop, what I mean is taking a loop and implementing the same functionality using one of NumPy's vectorized functions.\n\nIn addition to vectorizing a loop which performs operations on two arrays of equal size, we can also vectorize a loop which performs operations between an array and a scalar. For example, the loop:\n\nCan be vectorized as:\n\nLet's now take a practical example. Something that you will encounter often if you are working with vision based Machine Learning. Let's suppose you have two images and you want to compute the L2 distance between them. This can be described by\n\nThis simply means take a squared difference of each pixel present in the RGB image and then add these differences up. We compare the running times for a loop-based and a vectorized implementation. However notice that in our previous comparison, we used a Python list for the loop version and a NumPy array for the vectorized version. Can it be the case that it's the NumPy array, and not vectorization that makes the difference (that is, can python loops using NumPy arrays be equally fast? )\n\nTo validate that, in this example we will use NumPy array for both the loop and the vectorized version to see what really gives us the speed benefits. The loop operation requires the use of a triply nested loop, which is where things can get painfully slow. (Generally, the more deeply nested your loop is, slower would be the execution)\n\nLet us now measure the time taken by our scripts over 100 runs, repeated 3 times. Running the loop based version can take a while.\n\nWe see that the vectorized version is about 2500 times faster than the loop version. Not bad!\n\nWhat happens if we want to vectorize a loop where we are dealing with arrays that don't have similar sizes?\n\nLet's start with a very simple example. Suppose I have a matrix of shape containing 3 rows and 4 columns. Now, lets say that I want to add a column vector to each of the columns in the grid. To make this clear, this is what I am trying to achieve.\n\nThis can be accomplished in a couple of ways. We can loop over the columns of the matrix, and add each columns.\n\nHowever, if the number of columns in our original array are increased to a very large number, the code described above will run slow as we are looping over the number of columns in Python. How about making a matrix of equal size as the original array with identical columns ? (We will refer this approach as column-stacking approach)\n\nThis gives us a much faster solution. While this approach worked well in case of a 2-dimensional array, applying the same approach with higher dimensional arrays can be a bit tricky.\n\nThe good news, however, is that NumPy provides us with a feature called Broadcasting, which defines how arithmetic operations are to be performed on arrays of unequal size. According to the SciPy docs page on broadcasting,\n\nUnder the hood, NumPy does something similar to our column-stacking approach. However, we don't have to worry about stacking arrays in multiple directions explicitly.\n\nLet us now understand the rules of Broadcasting in NumPy. These are the certain constraints that the definition above talks about. Two arrays must fulfill these conditions for the smaller of them to be broadcasted over the larger one.\n\nBefore we begin, one important definition we need to know is the rank of the array in NumPy. The rank is the total number of dimensions a NumPy array has. For example, an array of shape (3, 4) has a rank of 2 and array of shape (3, 4, 3) has a rank of 3. Now onto the rules.\n• To deem which two arrays are suitable for operations, NumPy compares the shape of the two arrays dimension-by-dimension starting from the trailing dimensions of the arrays working it's way forward. (from right to left)\n• Two dimensions are said to be compatible if both of them are equal, or either one of them is 1.\n• If both the dimensions are unequal and neither of them is 1, then NumPy will throw an error and halt.\n\nWe first consider the case where the ranks of the two arrays we are dealing with are the same. The following image demonstrates which set of arrays are compatible and which aren't.\n\nAs you can see, we work from left to right. In case of the second example on the right, we start working from left, but when we arrive at the 2nd dimension (4 and 5 for both arrays resp.), we see there's a difference and neither of them is 1. Therefore, trying to do an operation with them leads to an error\n\nIn the first example on the left, we encounter different dimensions in the 3rd dimension ( 1 and 6 for both arrays respectively). However, according to rule 2, these dimensions are compatible. Every other dimension is the same. So we can perform arithmetic operation with the two arrays.\n\nArrays having unequal ranks can be operated upon as well subject to certain conditions. Again, we apply the rule of moving from left to right and comparing the two arrays. Let's consider the following examples.\n\nIn the image above, we see in the first case, the first array has the rank of 4 while the second array is the rank of 3. We can compare from left to right for 3 dimensions, after which the second array has no dimensions. In order to compare two such arrays, Numpy appends forward dimensions of size 1 to the smaller array so that it has a rank equal to the larger array. So all the comparisons above can be treated as.\n\nNow, comparisons can be easily made.\n\nNote that I use italics for appending because this is just a way to visualize what NumPy is doing. Internally, there is no appending.\n\nWhat happens during Broadcasting\n\nWhile it's easy to understand how an operation is performed when both the dimensions are similar, let's now understand how an operation is performed when one of the dimensions is 1 (Rule 2).\n\nFor this consider our example from above where we wanted to add a column vector to all columns of a matrix. The shapes of the arrays are and , which cannot be added according to rules of broadcasting. However, if we shape the column vector of shape to , the two shapes become compatible.\n\nBut wait, what exactly happened? How did the second dimensions, 4 and 1 for and respectively reconcile?\n\nIn such cases, NumPy will perform the operation as if the second array, of size was an array of shape . The values in the dimension having size 1 (In this case the second dimension of the original array was of shape ) will be repeated across 4 dimensions now to create an array of shape (3, 4). To understand this, consider the second array, and the value of it's second dimension.\n\nNow, the newly created array, of the shape (3, 4) will have the repeated values in it's second dimension. To aid our imagination, we use the function which gives us an idea of how the new broadcasted array is created.\n\nAs you can see, the values in the second dimension (which original had size 1),has been repeated 4 times to create a dimension of size 4.\n\nTo pictorially represent what's going on, the array is repeated across it's second dimension 4 times to create an equal array.\n\nThis is exactly what we did with our column-stack operation! The result of the addition is what we wanted!\n\nLet's consider the case for a 3-D array of shapes (3, 4, 5) and (1, 4, 5)\n\nIn reality, no new array is actually created. The repeated array is merely a mental tool to image how the operation would be performed. Instead, the computation is repeated across multiple dimensions without creation of a new array. This is akin to broadcasting values of the dimension of the first array having size 1 across multiple positions to the values in the dimension of the second array having size of more than 1. Hence, this process is termed as broadcasting.\n\nA practical example: Adding color to an Image\n\nLet's suppose you have an image, and for each pixel, you want to increase red values by 10, green values by 5 and blue values by 15.\n\nThis can be easily accomplished by broadcasting. An image is represented as a matrix having a shape (H, W, C) if we read it in using OpenCV. Let's read an image!\n\nNow, the channels are encoded in the third dimension of this array. We want to add 10, 5, 15 to the first channel described by , second channel described by , and third channel described by respectively. This can be easily done using the following piece of code.\n\nThe shape of our image is whereas our color vector has shape . On addition, this array will be resized to and subsequently, each color value will be broadcasted across the the R, G, B channels respectively.\n\nHowever, some applications of deep learning require the image to be stored in format . In that case our image would have the shape . In order to to do the same operation, we will have to reshape our color vector to shape ( so that it's compatible. Then, we can easily add the two.\n\nOne thing that has always aided me when it comes to vectorization and broadcasting is to visualize whatever goes on in a loop as an operation being performed on an array\n\nSuppose, we have two arrays of unequal size. We want to take a product of every combination of elements of the two arrays and then sum them up. For example, for arrays and , the sum would be\n\nUsing loops, that is how we do it,\n\nSimply enough right? But this is a nested loop, and if the sizes of these arrays becomes too large, then the running times will be increase too.\n\nHow do we get rid of these two loops and come up with a vectorized solution instead. For this, pay attention to what the loop variables and are doing. goes from 1 to 3 while goes from 4 to 5. In the loop, we have every possible combination of which we multiply and then sum.\n\nCan we have a array, a 2-D one, whose indices represent product of every such combination? If yes, we can have a NumPy array to represent this array and we can do away with loops and simply sum the elements of the array! This is how the array would look like.\n\nThis is nothing but the product of two arrays..\n\nBut wait, notice how values of are repeated across columns of the first array and values of are repeated across rows of the second array. Does this look familiar? Notice if we reshape our original and arrays to and respectively and multiply the two arrays, then they would be broadcasted like the following.\n\nThis is exactly what we want! We can now implement this in code.\n\nPhew! That was one detailed post! Truth be said, vectorization and broadcasting are two cornerstones of writing efficient code in NumPy and that is why I thought the topics warranted such a long discussion. I encourage you to come up with toy examples to get a better grasp of the concepts.\n\nIn the next part, we will use the things we covered in this post to optimize a naive implementation of the K-Means clustering algorithm (implemented using Python lists and loops) using vectorization and broadcasting, achieving speed-ups of 70x!"
    },
    {
        "link": "https://pythonlikeyoumeanit.com/Module3_IntroducingNumpy/VectorizedOperations.html",
        "document": "In this section, we will:\n• None Define the term vectorization, as it is used in the context of Python/NumPy.\n• None Prescribe the use of NumPy’s vectorized functions for performing optimized numerical computations on arrays.\n• None Compare the performance of a simple non-vectorized computation to a vectorized one.\n• None Describe how unary, binary, and sequential functions are defined on NumPy arrays.\n• None Provide a brief overview of linear algebra functions and logical operations.\n\nThe ND-array can be utilized in mathematical expressions to perform mathematical computations using an array’s entries. In general, NumPy implements mathematical functions such that, when a function acts on an array, the mathematical operation is applied to each entry in the array. # `x ** 2` squares each entry in the array `x` # of each entry in the array `x` # Slices return arrays, thus you can operate # on these too. Add .5 to each entry in row-0 Similarly, mathematical operations performed between two arrays are designed to act on the corresponding pairs of entries between the two arrays: # `x + y` will add the corresponding entries of There are also mathematical operations which are designed to operate on sequences of numbers, such as the sum function. NumPy’s sequential functions can act on an array’s entries as if they form a single sequence, or act on subsequences of the array’s entries, according to the array’s axes. # summing over all of the array's entries # summing over the rows, within each column We will use this section to provide a more thorough overview of the various mathematical functions that are provided by NumPy, as well as the behavior of its sequential mathematical operations. However, we must first understand that NumPy performs these “vectorized operations” in a highly-optimized fashion, such that pure Python code can never rival its efficiency. By the end of this section, “vectorized operation” will become a phrase of endearment.\n\nRecall that NumPy’s ND-arrays are homogeneous: an array can only contain data of a single type. For instance, an array can contain 8-bit integers or 32-bit floating point numbers, but not a mix of the two. This is in stark contrast to Python’s lists and tuples, which are entirely unrestricted in the variety of contents they can possess; a given list could simultaneously contain strings, integers, and other objects. This restriction on an array’s contents comes at a great benefit; in “knowing” that an array’s contents are homogeneous in data type, NumPy is able to delegate the task of performing mathematical operations on the array’s contents to optimized, compiled C code. This is a process that is referred to as vectorization. The outcome of this can be a tremendous speedup relative to the analogous computation performed in Python, which must painstakingly check the data type of every one of the items as it iterates over the arrays, since Python typically works with lists with unrestricted contents. In the context of high-level languages like Python, Matlab, and R, the term vectorization describes the use of optimized, pre-compiled code written in a low-level language (e.g. C) to perform mathematical operations over a sequence of data. This is done in place of an explicit iteration written in the native language code (e.g. a “for-loop” written in Python). Consider, for instance, the task of summing the integers 0-9,999 stored in an array. Calling NumPy’s function cues optimized C code to iterate over the integers in the array and tally the sum. is therefore a “vectorized” function. Let’s time how long it takes to compute this sum: Now let’s compare this to the time required to explicitly loop over the array in Python and tally up the sum. Python is unable to take advantage of the fact that the array’s contents are all of a single data type - it has to check, for every iteration, if it is dealing with an integer, a string, a floating point number, etc, just as it does when iterating over a list. This will slow down the computation massively. # sum an array by explicitly looping over the array in Python # this takes 822 microseconds on my computer Timed on my computer, the sum is over 50 times faster when performed in using NumPy’s vectorized function! This should make it clear that, whenever computational efficiency is important, one should avoid performing explicit for-loops over long sequences of data in Python, be them lists or NumPy arrays. NumPy provides a whole suite of vectorized functions. In fact, the name of the game when it comes to leveraging NumPy to do computations over arrays of numbers is to exclusively leverage its vectorized functions. The following computations all invoke vectorized functions: # multiply 2 with each number in the array # subtract the corresponding entries of the two arrays # Take the \"dot product\" of the two arrays # \"dot product\" means: multiply their corresponding entries and sum the result All of the mathematical functions that are introduced in the remainder of this section perform vectorized operations. NumPy provides highly-optimized functions for performing mathematical operations on arrays of numbers. Performing extensive iterations (e.g. via ‘for-loops’) in Python to perform repeated mathematical computations should nearly always be replaced by the use of vectorized functions on arrays. This informs the entire design paradigm of NumPy.\n\nWe will now take some time to survey the various types of vectorized mathematical functions that NumPy supplies, and how these mathematical operations, which traditionally are defined on individual numbers, are applied to arrays of numbers. We will look at\n• None functions that operate on sequences of numbers: \\(f(\\{x_i\\}_{i=0}^{n-1})\\) These represent a substantial portion of the essential mathematical tools in the NumPy library. An exhaustive list of NumPy’s mathematical functions is available in the official documentation. A unary function is a mathematical function that only accepts one operand (i.e. argument): \\(f(x)\\). NumPy supplies many familiar unary functions: This is by no means an exhaustive list of the available unary functions, for example the hyperbolic and inverse trigonometric functions are available too. These familiar functions are defined to work on individual numbers (i.e. “scalars”), not sequences of numbers. How, then, does NumPy implement these functions so that they behave in a coherent way when operating on arrays? The answer is that it maps the function over the array - applying \\(f(x)\\) to each element within the array, and producing a new array as a result (i.e. the input array is not overwritten). # x is not overwritten by this; a new array This process generalizes to arrays of any dimensionality and shape. # example of a unary function operating on a 2D array Because slicing returns an array, you can utilize these in mathematical operations as well Applying a unary NumPy function, \\(f(x)\\), to an N-dimensional array will apply \\(f(x)\\) elementwise on the array. Take the natural-logarithm of the 1st and 3rd element in the 3rd-row of , producing a shape-(2,) result. A binary function has the form \\(f(x,y)\\). The arithmetic operations are all binary functions: The “modulo” function (“mod” for short), denoted by \\(\\%\\), is defined to return the remainder of division: \\(5 \\% 3 = 2\\) It is important to note that NumPy arrays know how to “override” the standard mathematical operators so that they invoke vectorized functions. For example, suppose and are NumPy arrays; calling ends up calling “under the hood”. Thus we can safely use the standard math operators between NumPy arrays, and fast vectorized functions will be used for us. As indicated in this table, these NumPy functions can be called by invoking the familiar Python math-operators, when used in the context of NumPy arrays. Here are some other common binary functions: There are two cases that we must consider when working with binary functions, in the context of NumPy arrays:\n• None When both operands of the function are arrays (of the same shape).\n• None When one operand of the function is a scalar (i.e. a single number) and the other is an array. Similar to the behavior of unary functions applied to an array, a binary function will operate on two same-shape arrays by applying the function to their pairwise elements. # pair-wise addition of elements in `x` and `y` This process generalizes to arrays of any dimensionality and shape, as long as the two operands have the same shape. You can apply binary NumPy functions to arrays of unlike shapes. For instance, you may want to add a single shape-(2,) array with ten of such arrays, which are stored as a single shape-(10,2) array. This process is known as broadcasting, and will be covered in detail in a later section. # example of a binary function operating on two 2D arrays # add column-0 of `x` and row-1 of `y` Applying a binary NumPy-function, \\(f(x,y)\\), to two same-shape arrays will apply \\(f(x,y)\\) to each of their pairwise elements, producing an array of the same shape as either of the operands. Add the four quadrants of , producing a shape-(2, 2) output. By now, you may be able to guess NumPy’s behavior when you perform feed a binary function a scalar (i.e. a single number) and an array: the function is applied elementwise on the array, with each application filling one of the function’s arguments, and the single scalar provided everywhere as the other operand. This matches exactly the behavior seen in traditional linear algebra. This process generalizes to an array of any dimensionality and shape. # examples of a binary function operating on a scalar & an array Applying a binary NumPy function, \\(f(x,y)\\), to an array and a scalar amounts to “distributing” the function elementwise over the array, everywhere utilizing the scalar as the other operand for the binary function. A sequential function expects a variable-length sequence of numbers as an input, and produces a single number as an output: \\(f(\\{x_i\\}_{i=0}^{n-1})\\). The following are some sequential NumPy functions: Index of the Maximum Value of \\(\\{x_i\\}_{i=0}^{n-1}\\) Index of the Minimum Value of \\(\\{x_i\\}_{i=0}^{n-1}\\) The implementation of sequential NumPy functions is straightforward when working with 1-dimensional arrays: # can also be invoked as `x.sum()` # can also be invoked as `x.mean()` How do these functions behave when they are fed multi-dimensional arrays? By default, NumPy’s sequential functions treat any multidimensional array as if it had been reshaped to a 1-dimensional array. For example: # as if it is a single sequence of numbers, by default This default behavior of sequential NumPy functions can be overwritten by specifying the keyword argument within the sequential function. This is a very useful and common thing to do. We will carefully study what the axis argument is used for in these and other NumPy functions. Specifying the Keyword Argument in Sequential NumPy Functions Let’s delve into the meaning of the argument by first seeing it in action: # i.e. sum over the rows, within each column # i.e. sum over the columns, within each row # negative axis-indices can be used too # i.e. sum the array as if it were a 1D sequence (default behavior) The argument thus specifies which axis or axes are traversed to produce the input sequences for the sequential function to act on. One sequence is designated for each valid combination of indices of the non-traversed axes. For example, says: “for each of the columns of , sum over its rows”. Thus the following sequences are summed over: x[:, 0] -> array([0, 2, 4]) # traverse all rows within column-0 x[:, 1] -> array([1, 3, 5]) # traverse all rows within column-1 Thus each column of is summed over, producing a shape-(2,) array containing the result of the two sums. Similarly, produces a shape-(3,) array, which stores the sum along each of the three rows in . You can also supply multiple axes to the keyword argument by specifying them in a “tuple” of integers (using a list instead of a tuple will not work). cues NumPy to traverse both of ’s axes, designating the entirety of ’s contents as the sequence, and summing to the single sequence into one number. Recall that this matches the default behavior when no keyword argument is specified. All sequential NumPy functions have an keyword argument that can be specified. is to be fed a single integer or a tuple of integers, which indicate which array axes are to be traversed to designate the sequences of array data to be operated on. A sequence is generated for each valid combination of indices for the non-traversed axes. By default, all of the input-array’s axes are included, thus the entire content of the array is treated as a single sequence. The key to understanding the keyword argument, when working with multi-dimensional arrays, is to be comfortable with how array traversal works in NumPy. Refer to Section 5 of this module for a refresher on this topic. Consider the following shape-(4,2,3) array: We can think of this array as possessing four, 2x3 sheets of numbers. Traversing along axis-0 of amounts to stepping from sheet to sheet, given each valid combination of axis-1 and axis-2 indices. Thus says: “for each combination of row and column, take the mean along the sheets of ”. Therefore six distinct sequences within are designated for this sequential function to act on: x[:, 0, 0] -> array([ 0, 6, 12, 18]) {mean = 9} x[:, 0, 1] -> array([ 1, 7, 13, 19]) {mean = 10} x[:, 0, 2] -> array([ 2, 8, 14, 20]) {mean = 11} x[:, 1, 0] -> array([ 3, 9, 15, 21]) {mean = 12} x[:, 1, 1] -> array([ 4, 10, 16, 22]) {mean = 13} x[:, 1, 2] -> array([ 5, 11, 17, 23]) {mean = 14} Also, notice that the set of valid combinations of axis-1 and axis-2 indices corresponds to the two-by-three grid associated with they layout of a sheet. NumPy will return the six mean values in a shape-(2,3) array, so that the correspondence between each sequence and its mean-value is unambiguous: Recall that NumPy uses row-major ordering (a.k.a C-ordering) when traversing arrays. Suppose we specify two axes, say axis-0 and axis-2; traversing these two axes amounts to stepping along the sheets and columns of , for each axis-1 index. Thus two sequences are produced: These observations lead us to the following general result: If \\(X\\) is an \\(N\\)-dimensional array, and \\(j\\) (with \\(j \\leq N\\)) axes are specified in the keyword argument for a sequential NumPy function, then a \\(N-j\\)-dimensional array will be produced by this function. The shape of the result will be that of \\(X\\), but with the entries associated with those \\(j\\) axes removed. A digital image is simply an array of numbers, which instructs a grid of pixels on a monitor to shine light of specific colors, according to the numerical values in that array. An RGB-image can thus be stored as a 3D NumPy array of shape-\\((V, H, 3)\\). \\(V\\) is the number of pixels along the vertical direction, \\(H\\) is the number of pixels along the horizontal, and the size-3 dimension stores the red, blue, and green color values for a given pixel. Thus a \\((32, 32, 3)\\) array would be a 32x32 RBG image. It is common to work with a collection of images. Suppose we want to store N images in a single array; thus we now consider a 4D shape-\\((N, V, H, 3)\\) array. Let’s collect some statistics on a collection of images. For the sake of convenience, let’s simply generate a 4D-array of random numbers as a placeholder for real image data. We will generate 100, 32x32 RGB images: Now, compute the following:\n• None The total sum of all the values in the array.\n• None The minimum blue value, respective to each image.\n• None The standard deviation among all the RGB values in all the images, respective to each pixel position (thus you should produce a shape-(32, 32) array of values).\n• None The maximum red-value in the top-left quadrant, respective to each image.\n\nNumPy provides a suite of logical operations that can operate on arrays. Many of these map logical operations over array entries in the same fashion as NumPy’s mathematical functions. These functions return either a single boolean object, or a boolean-type array. # check which entries of `x` are less than 6 Recall from the Essentials of Python module that, due to effect of floating point numbers having limited numerical precision, that you should never rely on two floating point numbers being exactly equal. Rather, you should require that they are sufficiently “close” in value. In this same vein, you ought not check that the entries of two float-type arrays are precisely equal. Towards this end, the function can be used to verify that all corresponding pairs of entries between two arrays are approximately equal in value: # checking if two arrays match, using `np.allclose`"
    },
    {
        "link": "https://linkedin.com/pulse/vectorization-broadcasting-numpy-ashok-k-sahoo-lm5xc",
        "document": "In the realm of computer science, there exists a concept known as vectorization, a technique that transforms the conventional approach of using explicit loops into streamlined array operations capable of executing simultaneously. This innovative process enables the application of a series of operations across entire data structures, such as arrays or matrices, in a single stroke, rather than painstakingly handling each element one by one as shown in the Figure 1. The advantages of vectorization are particularly evident in terms of performance, as the operations tend to be carried out at a more fundamental level, utilizing machine-level instructions or compiled code, thereby circumventing the sluggishness associated with traditional loops.\n\nNumPy leverages vectorization by applying operations across entire arrays without explicit loops in Python. These operations are handled by highly optimized, pre-compiled C functions, making them much faster. For instance, multiplying two arrays element-wise in NumPy is vectorized:\n\nHere, the multiplication is vectorized and runs much faster than looping over each element.\n\nBroadcasting is a feature that empowers NumPy to execute operations on arrays even when their shapes are not aligned. This elegant process involves the automatic expansion of one array, allowing it to conform to the dimensions of another. Rather than creating explicit duplicates of the data, NumPy opts for a more efficient approach, \"broadcasting\" the smaller arrays so that they seamlessly adapt to the larger arrays during various computations. It follows specific rules to stretch the dimensions of arrays so that element-wise operations are possible. For example:\n\nTogether, these concepts allow NumPy to perform fast, efficient numerical computations in a way that's both high-level (easy for the programmer) and high-performance."
    },
    {
        "link": "https://numpy.org/doc/stable/user/basics.broadcasting.html",
        "document": "The term broadcasting describes how NumPy treats arrays with different shapes during arithmetic operations. Subject to certain constraints, the smaller array is “broadcast” across the larger array so that they have compatible shapes. Broadcasting provides a means of vectorizing array operations so that looping occurs in C instead of Python. It does this without making needless copies of data and usually leads to efficient algorithm implementations. There are, however, cases where broadcasting is a bad idea because it leads to inefficient use of memory that slows computation.\n\nNumPy operations are usually done on pairs of arrays on an element-by-element basis. In the simplest case, the two arrays must have exactly the same shape, as in the following example:\n\nNumPy’s broadcasting rule relaxes this constraint when the arrays’ shapes meet certain constraints. The simplest broadcasting example occurs when an array and a scalar value are combined in an operation:\n\nThe result is equivalent to the previous example where was an array. We can think of the scalar being stretched during the arithmetic operation into an array with the same shape as . The new elements in , as shown in Figure 1, are simply copies of the original scalar. The stretching analogy is only conceptual. NumPy is smart enough to use the original scalar value without actually making copies so that broadcasting operations are as memory and computationally efficient as possible.\n\nThe code in the second example is more efficient than that in the first because broadcasting moves less memory around during the multiplication ( is a scalar rather than an array).\n\nWhen operating on two arrays, NumPy compares their shapes element-wise. It starts with the trailing (i.e. rightmost) dimension and works its way left. Two dimensions are compatible when If these conditions are not met, a ValueError: operands could not be broadcast together exception is thrown, indicating that the arrays have incompatible shapes. Input arrays do not need to have the same number of dimensions. The resulting array will have the same number of dimensions as the input array with the greatest number of dimensions, where the size of each dimension is the largest size of the corresponding dimension among the input arrays. Note that missing dimensions are assumed to have size one. For example, if you have a array of RGB values, and you want to scale each color in the image by a different value, you can multiply the image by a one-dimensional array with 3 values. Lining up the sizes of the trailing axes of these arrays according to the broadcast rules, shows that they are compatible: When either of the dimensions compared is one, the other is used. In other words, dimensions with size 1 are stretched or “copied” to match the other. In the following example, both the and arrays have axes with length one that are expanded to a larger size during the broadcast operation:\n\nA set of arrays is called “broadcastable” to the same shape if the above rules produce a valid result. For example, if is (5,1), is (1,6), is (6,) and is () so that d is a scalar, then a, b, c, and d are all broadcastable to dimension (5,6); and\n• None a acts like a (5,6) array where is broadcast to the other columns,\n• None b acts like a (5,6) array where is broadcast to the other rows,\n• None c acts like a (1,6) array and therefore like a (5,6) array where is broadcast to every row, and finally,\n• None d acts like a (5,6) array where the single value is repeated. Here are some more examples: Here are examples of shapes that do not broadcast: # second from last dimensions mismatched An example of broadcasting when a 1-d array is added to a 2-d array: : operands could not be broadcast together with shapes (4,3) (4,) As shown in Figure 2, is added to each row of . In Figure 3, an exception is raised because of the incompatible shapes. A one dimensional array added to a two dimensional array results in broadcasting if number of 1-d array elements matches the number of 2-d array columns. When the trailing dimensions of the arrays are unequal, broadcasting fails because it is impossible to align the values in the rows of the 1st array with the elements of the 2nd arrays for element-by-element addition. Broadcasting provides a convenient way of taking the outer product (or any other outer operation) of two arrays. The following example shows an outer addition operation of two 1-d arrays: In some cases, broadcasting stretches both arrays to form an output array larger than either of the initial arrays. Here the index operator inserts a new axis into , making it a two-dimensional array. Combining the array with , which has shape , yields a array.\n\nBroadcasting comes up quite often in real world problems. A typical example occurs in the vector quantization (VQ) algorithm used in information theory, classification, and other related areas. The basic operation in VQ finds the closest point in a set of points, called in VQ jargon, to a given point, called the . In the very simple, two-dimensional case shown below, the values in describe the weight and height of an athlete to be classified. The represent different classes of athletes. Finding the closest point requires calculating the distance between observation and each of the codes. The shortest distance provides the best match. In this example, is the closest class indicating that the athlete is likely a basketball player. # the broadcast happens here In this example, the array is stretched to match the shape of the array: The basic operation of vector quantization calculates the distance between an object to be classified, the dark square, and multiple known codes, the gray circles. In this simple case, the codes represent individual classes. More complex cases use multiple codes per class. Typically, a large number of , perhaps read from a database, are compared to a set of . Consider this scenario: The three-dimensional array, , is a consequence of broadcasting, not a necessity for the calculation. Large data sets will generate a large intermediate array that is computationally inefficient. Instead, if each observation is calculated individually using a Python loop around the code in the two-dimensional example above, a much smaller array is used. Broadcasting is a powerful tool for writing short and usually intuitive code that does its computations very efficiently in C. However, there are cases when broadcasting uses unnecessarily large amounts of memory for a particular algorithm. In these cases, it is better to write the algorithm’s outer loop in Python. This may also produce more readable code, as algorithms that use broadcasting tend to become more difficult to interpret as the number of dimensions in the broadcast increases."
    },
    {
        "link": "https://aungzanbaw.medium.com/beginner-guide-to-vectorization-broadcasting-indexing-in-numpy-2389612b1342",
        "document": "In previous decades, the rise of ML (DL) draw everyone from different background, many academia (logicians, mathematicians, neurologist etc), scientists/engineers (computing on Matlab, Octave) and especially programmers. Google the term “AI hype cycle” and you’ll see how Artificial General Intelligence(AGI) flip the coin & now we had narrow/weak ML or should i say Deep Artificial Neural Networks everywhere. In order to emerge complex systems, we need more than that, pattern formation, collective behavior, nonlinear dynamics, evolution & adaptation just to name a few. I am not here to show you those but humble building blocks that are part of ML system in production.\n\nMany weak AIs depend upon vector/matrix friendly programming languages like Python & R. Both languages support arrays/vectors operation out of the box & we need more, Numpy to the rescue. This short article will cover 3 useful topics Vectorization, Broadcasting and Indexing.\n\nQ: Let’s address the elephant in the room, why vector or multiple-dimension array processing ?\n\nA: Vector processor, way faster than general purpose registers especially on modern CPU\n• Multimedia applications need fast arithmetic operations on the large scale of integers or floating-point processing\n\nPlease dive detail of computer architectures at Flynn’s taxonomy. And feel free to skip two session if you’re familiar with basic concepts.\n\nList, build-in data type of python can created either using list function or primitive\n\nNote: please don’t use this .mat() function but stick with .array() method since they are defecto standard in Numpy and many function/operation return array(numpy.ndarray) not matrix(numpy.matrix) data type.\n\nI assume you have basic python skills here, otherwise this freecodecamp course will help you. Let’s create evenly spaced values using arange() function and reshape into interesting shape of matrices.\n\nThese two arrays are in 18 elements starting with zero, for first array you should be reading from left to right like “2 reshaped arrays, which are in 3 rows X 3 columns”. You got it for arr2 then “3 reshaped arrays in 2 rows X 3 columns format”.\n\nNumpy arrays are extremely fast, store in continuous memory block of memory in short.\n\nTo put into layman’s terms a single instruction perform over each individual element of an array on single core of CPU in parallel manner. Vectorized operation can replace traditional for loops, run faster, work on different matrix dimension size. Take away — it’s just array expression replacing explicit for-loop.\n\nTo explain about snippet, we are using lambda(nameless/anonymous function) to double the input value i and we pass that into Numpy’s vectorize method as instruction[lambda named sqr ] then pass the data [matrix].\n\nVectorize function is just for convenience it won’t run any faster and also np.array is already aware of vectorization.\n\nMany examples in this article refer this variable called [matrix].\n\nFrom previous example np.vectorize( ) function work on different matrix dimensions, this is known as broadcasting. Meaning rules like same shape don’t constraint here to perform any operation.\n\nSimple example would be following snippet and you can find the theory behind it.\n\nWe’ll start with very basic 1D and work up to multi-dimension arrays.\n\nLet’s jump into randomly accessing to an array. We will select 2 elements from the matrix, then we will access using first wrapper size(3), it will be both column/row .\n\nTo be fancy we will access group of them using normal list and np_array.\n\nLet’s switch our gear to Boolean indexing, what we’d seen above is just Integer indexing. Boolean indexing is useful to get rid of unwanted data, replacing null/None or incomplete data, other tasks like masking, filtering etc.\n\nSlicing, we will be using : column operator to access row or column in steps manner, or all elements.\n\narray[[row, column]] and array [start:end:step] can use interchangeable.\n\nWe can combine Boolean indexing with slicing too, it’s getting more interesting.\n\nPut famous logical and/or/not, not only for filtering but also replacing & slicing.\n\nI had covered some of advance indexing topic here but as always please reference official doc for more information.\n\nLet’s continue with useful Numpy function, using same old data [matrix]\n\nAnother useful trick would be flatten the matrix into vector either row or column. Flatten and reshape are exactly the same except the one with -1 and column orientation.\n\nI hope you get the essence of vectorization and other tricks provided by Numpy. Happy learning, please provide your feedback on comment."
    },
    {
        "link": "https://numpy.org/doc/2.2/reference/generated/numpy.mgrid.html",
        "document": "An instance which returns a dense (or fleshed out) mesh-grid when indexed, so that each returned argument has the same shape. The dimensions and number of the output arrays are equal to the number of indexing dimensions. If the step length is not a complex number, then the stop is not inclusive.\n\nHowever, if the step length is a complex number (e.g. 5j), then the integer part of its magnitude is interpreted as specifying the number of points to create between the start and stop values, where the stop value is inclusive."
    },
    {
        "link": "https://numpy.org/doc/2.0/reference/generated/numpy.mgrid.html",
        "document": "An instance which returns a dense (or fleshed out) mesh-grid when indexed, so that each returned argument has the same shape. The dimensions and number of the output arrays are equal to the number of indexing dimensions. If the step length is not a complex number, then the stop is not inclusive.\n\nHowever, if the step length is a complex number (e.g. 5j), then the integer part of its magnitude is interpreted as specifying the number of points to create between the start and stop values, where the stop value is inclusive."
    },
    {
        "link": "https://numpy.org/devdocs/reference/generated/numpy.mgrid.html",
        "document": "An instance which returns a dense (or fleshed out) mesh-grid when indexed, so that each returned argument has the same shape. The dimensions and number of the output arrays are equal to the number of indexing dimensions. If the step length is not a complex number, then the stop is not inclusive.\n\nHowever, if the step length is a complex number (e.g. 5j), then the integer part of its magnitude is interpreted as specifying the number of points to create between the start and stop values, where the stop value is inclusive."
    },
    {
        "link": "https://docs.vultr.com/python/third-party/numpy/meshgrid",
        "document": "The function in Python is a vital tool in numerical computing, often used to create a coordinate grid or meshgrid. This grid is fundamental in fields such as physics, engineering, and graphical computing where spatial operations and visualizations are required. The function generates matrices from vectors representing coordinates in Cartesian or higher-dimensional space.\n\nIn this article, you will learn how to use the function to generate grids that represent matrices of coordinates. This includes generating simple two-dimensional grids, configuring the indexing mode, and applying the function in three-dimensional space.\n• None Define two vectors that represent the range of x and y coordinates.\n• None Use to generate the grid. This code sets up coordinate vectors and . The function then processes these vectors to output matrices and , where holds repeated rows of x-values and holds repeated columns of y-values.\n• None Examine the matrices and to understand their structure.\n• None Each entry in the matrix corresponds to an x-coordinate, while each entry in the matrix corresponds to a y-coordinate. Outputs when you print and : On executing these statements, the output displays repeating rows for and repeating columns for . This layout facilitates operations over a 2D grid where each ( , ) pair can represent a point in space.\n• None Realize there are two indexing modes in : \"xy\" (default) and \"ij\".\n• None Use the parameter to configure the mode. By setting , the function switches to matrix indexing ( ), where the first axis corresponds to the vertical direction, flipping the roles of and . This is especially useful for matrix operations where alignment with axes is critical.\n• None Define an additional vector and generate matrices for three-dimensional coordinates. In this scenario, considers an additional z-axis and produces three matrices , , and , each corresponding to coordinates along the x, y, and z axes, respectively. This three-dimensional grid is essential in applications that involve volume scanning or 3D visualizations.\n\nThe function is a powerful tool in Python that simplifies the creation of coordinate grids. Whether dealing with two-dimensional or three-dimensional spaces, this function efficiently transforms coordinate vectors into matrices suitable for vectorized evaluations and operations. Exploring different indexing modes further enhances its flexibility, making it a crucial function for computational applications that involve spatial data. With the examples provided, harness the capability of to support complex operations involving multi-dimensional data arrays."
    },
    {
        "link": "https://geeksforgeeks.org/numpy-meshgrid-function",
        "document": "Thefunction is used to create a rectangular grid out of two given one-dimensional arrays representing the Cartesian indexing or Matrix indexing. Meshgrid function is somewhat inspired from MATLAB. Consider the below figure with X-axis ranging from -4 to 4 and Y-axis ranging from -5 to 5. So there are a total of (9 * 11) = 99 points marked in the figure each with a X-coordinate and a Y-coordinate. For any line parallel to the X-axis, the X-coordinates of the marked points respectively are -4, -3, -2, -1, 0, 1, 2, 3, 4. On the other hand, for any line parallel to the Y-axis, the Y-coordinates of the marked points from bottom to top are -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5. Thefunction returns two 2-Dimensional arrays representing the X and Y coordinates of all the points.\n\nBelow is the code:The output of coordinates by meshgrid can also be used for plotting functions within the given coordinate range.We observe that x_1 is a row repeated matrix whereas y_1 is a column repeated matrix. One row of x_1 and one column of y_1 is enough to determine the positions of all the points as the other values will get repeated over and over. So we can edit above code as follows:This will produce the following output:\n\nThe shape of x_1 changed from (11, 9) to (1, 9) and that of y_1 changed from (11, 9) to (11, 1) The indexing of Matrix is however different. Actually, it is the exact opposite of Cartesian indexing.For the matrix shown above, for a given row Y-coordinate increases as 0, 1, 2, 3 from left to right whereas for a given column X-coordinate increases from top to bottom as 0, 1, 2. The two 2-dimensional arrays returned from Matrix indexing will be the transpose of the arrays generated by the previous program. The following code can be used for obtaining Matrix indexing:Thecan also be added in the meshgrid function of Matrix indexing. In this case, the shape of x_2 will change from (9, 11) to (9, 1) and that of y_2 will change from (9, 11) to (1, 11)."
    }
]