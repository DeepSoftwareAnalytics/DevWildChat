[
    {
        "link": "https://konfuzio.com/en/tesseract-tutorial",
        "document": "At first part of our comprehensive guide to Tesseract, we showed you how to install the software without errors and prepare it for efficient use. Now it's time to get practical.\n\nWe explain what you need to keep in mind when using Tesseract OCR to achieve good results as quickly as possible. In doing so, we also show what you can do if the results are not (yet) convincing and which best practices you can follow.\n\nYou can use the Tesseract software in this way:\n\nTesseract lets you extract text from images in various formats, including JPG, PNG and TIFF. To do this, you just need to specify the image file from which you want to extract the text.\n\nThe software supports many common languages and fonts. You can also customize and train the tool to recognize additional languages or fonts. For example, if you work with images in Asian fonts, you can configure Tesseract to automatically read these fonts.\n\nTo use Tesseract for text extraction from PDF files, you should use the OCR engine directly with a configuration file. One possible configuration file that can be repeatedly applied to multi-page PDFs is the batch processing file. With this you can process multi-page PDF documents without extracting each page manually.\n\nThis way you can avoid storage or processing problems that unnecessarily consume resources of your computer or server.\n\nTesseract is a versatile OCR engine that you can use not only as a standalone tool in a batch environment, but also integrate as a component in other applications. The use of Tesseract is possible due to the availability of wrapper libraries that provide an application programming interface (API).\n\nPython is a programming language that is widely used for developing versatile applications. One of the most popular applications is optical character recognition (OCR), where it is used as a backend tool for OCR algorithms. Python's OCR capabilities are extended by the \"pytesseract\" library, which provides a straightforward interface for running Tesseract OCR from code written in Python.\n\nTo work with Tesseract OCR in Python, you need to install the pytesseract library via the Python package manager \"pip\". After installation, you can use the pytesseract library to create OCR applications quickly and easily.\n\nPytesseract is supported by powerful OCR functionalities such as OpenCV, Leptonica and Pillow. The robust pytesseract library is extended by the Python OCR wrapper \"PYOCR\", which provides an optimized interface for executing Tesseract API calls. Other specialized Python OCR libraries, such as \"Textract\", can also be used to extract text and information from documents, PDFs and other media formats.\n\nAmong the most common use cases of Python and Tesseract OCR are the\n• the digitization of workflows in accounts payable,\n• the archiving of documents and\n• the extraction of vehicle identification numbers (VIN) from images and forms.\n\nApplying Python OCR in these areas can result in significant time and cost savings, improved accuracy, and streamlined workflows.\n\nTess4J is a powerful and user-friendly Java library that provides wrapper methods for using the Tesseract OCR engine. With Tess4J, developers can easily integrate OCR functionalities into their Java projects.\n\nTo work with Tess4J, you need to download the library files and import them into your project. Once integrated, you can call the Tess4J methods to read text from images or PDF files. Besides, you can choose the language and font and edit the OCR results.\n\nTess4J is compatible with various platforms, including Windows, Linux and macOS. This makes it a versatile and reliable OCR solution for a wide range of Java-based applications.\n\nTesseract.NET enables seamless integration of Tesseract with C# applications. It provides a well-documented C# wrapper for Tesseract's OCR engine that lets you easily extract text from images and PDF files.\n\nAfter installing the Tesseract.NET library, you can easily add it to your project by referencing the DLL file. This gives you access to all the functions of the Tesseract OCR engine.\n\nTo use Tesseract.NET for OCR functions, you can load an image or PDF file using the Image class in C# and then pass the image to the Tesseract engine for text extraction. You can also specify the language and font to be used during the OCR process.\n\nYou can then further process and analyze the OCR results obtained within your C# application. Tesseract.NET provides a set of methods for extracting text, bounding boxes and confidence values from the OCR results, which can be used to implement a variety of OCR functions in your application.\n\nIt easily integrates with Microsoft Azure, so you can run the Tesseract OCR engine in the cloud. This lets you perform OCR on large amounts of data without straining the resources of your on-premises computer.\n\nEspecially with handwritten or low-quality text, the Tesseract software has a hard time delivering high-quality results. However, you can take OCR quality to a new level with the following measures:\n\nTo better prepare images for extraction with OCR, you can take these steps:\n\nThe quality of Tesseract's OCR results can be significantly affected by the scaling and resizing of the input images. It is therefore important that the images are of the correct size and resolution.\n\nIf this is not the case, the Tesseract OCR engine has several parameters for scaling and resizing images, including a specific scale and aspect ratio. You can apply these parameters to the input images as required to achieve optimal OCR results. You can also apply custom parameters as needed.\n\nBinarization and thresholding allow image information to be reduced to a binary format that can be more easily used as a template for text recognition with Tesseract.\n\nIn this way, the background of the image can be suppressed or smoothed to eliminate distracting effects. You can improve readability in areas with poor lighting this way. This makes it easier for the Tesseract OCR engine to extract the text from the image.\n\nThresholding images - also called thresholding - reduces noise in the image. It involves dividing the target image into several color channels and setting the threshold for each channel individually. The technique is used to obtain a clearer image of the text and reduce possible sources of error for Tesseract.\n\nNoise is often caused by using poor equipment or by poor lighting conditions when capturing images. To reduce these noise sources, you can use median filtering, bilateral filtering, and adaptive thresholding, among others.\n\nAt the Median filtering the median of neighborhood pixels of an image is calculated to produce a smoother version of the image. This method is particularly effective at removing salt-and-pepper noise, which is caused by pixel-by-pixel variations in image brightness.\n\nAt the Bilateral filtering a weighting factor is calculated on each pixel in the image based on the frame rate and a spatial position. This method is particularly effective in removing Gaussian noise caused by random brightness and color variations in the image.\n\nWith the adaptive Threshold method the threshold is automatically adjusted based on the characteristics of the image. This method is particularly effective in removing uneven lighting conditions in the image caused by the use of poor equipment or poor lighting conditions.\n\nIn Python code snippets, you can implement these methods as follows:\n\nAlthough noise reduction can be helpful to improve OCR quality, it also has limitations. Too much noise reduction can cause important details and information in the image to be lost. In addition, some types of noise cannot be completely removed, which can lead to errors in text recognition.\n\nRotation and perspective correction makes it possible to rectify text in images that were taken at an angle or distorted. By automatically detecting skew, Leptonica can detect image files that need rotation adjustments. This also applies to images that need perspective correction. The Tesseract software can rectify these itself, increasing the readability of the text.\n\nTo increase the recognition accuracy of Tesseract OCR, you should carefully select the language models and fonts. The tool currently supports over 100 languages, including English, German, French, Spanish, Russian and Chinese. You can easily embed the language models in the Tesseract directory and update them that way. This way you'll improve the recognition accuracy for specific languages.\n\nHowever, when processing documents, it may happen that only certain languages or fonts need to be recognized. In such cases, it is possible to set the language and font options so that only the required languages or fonts are recognized. In this way, you improve recognition accuracy, as Tesseract-OCR filters out unnecessary information.\n\nMoreover, it is possible to restrict the word lists of the Tesseract software to improve the recognition accuracy. This feature allows you to restrict word lists to specific words or even characters.\n\nTo printed texts and Manuscripts into digital texts, Tesseract OCR uses machine learning and neural networks:\n\nLSTM networks are recurrent neural networks used for processing sequences. They are particularly effective in processing long sequences. This is because they are able to store specific information over a long period of time. These properties make them ideal for use in text recognition (OCR).\n\nTheir ability to analyze sequences allows them to detect and correct error patterns that traditional OCR algorithms may miss.\n\nIn addition, LSTM networks have pre-trained models that can be used in OCR enhancement. You can also adapt these models to the specific requirements of OCR with little effort.\n\nIn practice, LSTM networks are mainly used to recognize handwritten texts and old documents with high accuracy - where OCR algorithms have problems.\n\nThe Tesseract OCR engine can be extended by or even replaced by deep learning frameworks like TensorFlow and PyTorch. Before you start the integration, you should install the Tesseract binaries and the required language data package on your system. This way you will ensure that all the features of the OCR engine are accessible. Once Tesseract is successfully installed, you can load OCR models and pass them as tensors to the frameworks to segment images and recognize text.\n\nTensorFlow is a machine learning framework developed by Google that provides a wealth of tools to support deep learning networks. It is a leading open source framework used by researchers and developers around the world to build powerful deep learning models.\n\nSince Tesseract is an OCR engine, it can be integrated directly into TensorFlow to improve accuracy for text recognition. For this, you can install Tesseract as a separate component, making it available to TensorFlow.\n\nPyTorch is an open source platform based on Python that provides developers with a comprehensive way to create and run complex deep learning projects. The integration of Tesseract with PyTorch enables improved OCR quality based on the benefits of neural networks and deep learning methods.\n\nTo integrate Tesseract OCR with PyTorch, you need to install the PyTorch framework library and connect it to Tesseract. You can then create neural networks that are adaptive and can adapt to a variety of data and text formats.\n\nAs an example, you could use the following code in PyTorch to create an OCR application with Tesseract:\n\nTesseract has become an important tool for automating business processes and for mobile devices. Which areas of application are particularly common? What are the limitations of the engine? And what best practices can you follow to achieve optimal results with the software?\n\nThe following 4 application examples show the versatility of Tesseract in practice:\n\nAs a rule, hospitals and doctors' offices keep medical records in written form. In large quantities, these are therefore difficult to search. Tesseract can digitize these records, organize them - and thus make them easily searchable. Doctors and nurses can thus automatically analyze large volumes of medical records and extract important information. This leads to more efficient diagnosis and treatment of patients.\n\nFinancial documents such as bank statements, Invoices and tax returns are still often created in writing. Searching these is therefore time-consuming. Tesseract can index and categorize these documents quickly and automatically. Banks can thus automatically read in checks, for example, and thus significantly reduce the manual workload.\n\nIn the logistics industry, it is important to be able to quickly access information such as package numbers, inventory figures and shipping addresses. Tesseract enables automatic recognition of product labels and Barcodes. This leads to faster and more accurate recording of inventories. In this way, companies in logistics can increase their efficiency and avoid bottlenecks in inventory management.\n\nTesseract can be embedded as a component in mobile apps to recognize text within images on mobile devices. This is particularly useful for applications such as translation and text recognition apps.\n\nTo achieve the most error-free results with Tesseract, keep these practices and tips in mind:\n\nTesseract OCR is a complex software that is not always easy to understand. If you want to go deeper into how the tool works or need further support, these sources will help you:\n\nThe official documentation for Tesseract provides a comprehensive guide to using, installing and setting up the OCR engine. Key chapters include Tesseract's modules and features, the different language options, and how to use Tesseract with various programming languages and deep learning frameworks such as Python, C++, Java, and TensorFlow.\n\nThe documentation also explains the basic concepts of OCR to help users better understand the technology. There are also numerous practical application examples and tutorials that can help you successfully use the OCR engine.\n\nIf you want to understand and use more complex functions of Tesseract, you should take a look at the offer of Tesseract courses. You can find a wide range of topics and levels on the web. Courses can be found for example on YouTube.\n\nTesseract has an active community of users and developers focused on improving the usability and effectiveness of the OCR engine. The community meets regularly at conferences and meetings to share ideas and discover new ways to improve the software.\n\nThe Tesseract Community also offers a wide range of online resources. Among other things, you will find discussion forums and mailing lists that users use for questions and a general exchange.\n\nDeveloped by HP Laps and Google, the Tesseract OCR engine is a powerful tool for optical character recognition. Its wide availability on Windows, macOS, and on virtually all popular Linux distributions, as well as its compatibility with mobile devices, make it a popular choice for OCR extraction tasks.\n\nTesseract is an open source engine that users can easily download and use. Its accuracy rate is comparable to that of proprietary software, so no expensive licenses are required.\n\nHowever, Tesseract is not the best choice for every OCR extraction task. In particular, the software often has problems with special fonts and languages other than English. This is where an important trend comes into play: the integration of artificial intelligence into OCR. Here, machine learning helps improve accuracy by training OCR systems to better identify and recognize patterns using large data sets. AI-based OCR systems are therefore increasingly capable of reliably recognizing images with low resolution, handwritten text or illegible characters.\n\nKonfuzio is a provider for intelligent document processing with AI-based OCR. The on Deep Computer Vision based tool has been trained on over 100,000 documents.\n\nIn practice, therefore, you can use Konfuzio, for example, to create large amounts of unstructured data, such as texts, e-mails, and contracts, and gain valuable insights from them - even when the input file quality is low."
    },
    {
        "link": "https://tesseract.patagames.com/help",
        "document": "If you are not redirected automatically, follow this link to the default topic."
    },
    {
        "link": "https://tesseract-ocr.github.io/tessdoc",
        "document": "This user manual is for Tesseract versions . For versions , and older, see the documentation for old versions.\n\nTesseract is an open source text recognition (OCR) Engine, available under the Apache 2.0 license.\n• Major version 5 is the current stable version and started with release 5.0.0 on November 30, 2021.\n• Newer minor versions and bugfix versions are available from GitHub.\n• Latest source code is available from main branch on GitHub. Open issues can be found in issue tracker, and planning documentation.\n\nTesseract can be used directly via command line, or (for programmers) by using an API to extract printed text from images. It supports a wide variety of languages. Tesseract doesn’t have a built-in GUI, but there are several available from the 3rdParty page. External tools, wrappers and training projects for Tesseract are listed under AddOns.\n\nTesseract can be used in your own project, under the terms of the Apache License 2.0. It has a fully featured API, and can be compiled for a variety of targets including Android and the iPhone. See the 3rdParty and AddOns pages for samples of what has been done with it.\n\nIf you have a question, first read the documentation, particularly the FAQ to see if your problem is addressed there. If not, search the Issues List, Tesseract user forum, and if you still can’t find what you need, please ask your question in Tesseract user forum Google group.\n\nTesseract is free software, so if you want to pitch in and help, please do! If you find a bug and fix it yourself, the best thing to do is to attach the patch to your bug report in the Issues List.\n\nTesseract 4.0 added a new OCR engine based on LSTM neural networks. It works well on x86/Linux with official Language Model data available for 100+ languages and 35+ scripts. See 4.0x-Changelog for more details.\n\nTesseract 5.x.x source code is available in the branch of the repository. The branch is using semver versioning because C++ code modernization caused API incompatibility with 4.x release.\n\nBinaries are available from:\n\nFor detailed information about the different types of models, see Data Files.\n\nModel files for version are available from tessdata tagged 4.00. It has models from November 2016. The individual language file links are available from the following link.\n\nModel files for version and later are available from tessdata tagged 4.0.0. It has legacy models from September 2017 that have been updated with Integer versions of LSTM models. This set of traineddata files has support for both the legacy recognizer with and for LSTM models with . These models are available from the following Github repo.\n\nTwo more sets of traineddata, trained at Google, are made available in the following Github repos. These do not have the legacy models and only have LSTM models usable with .\n\nLanguage model traineddata files same as listed above for version can be used with Tesseract . These are available from:\n• DAS 2016 tutorial slides Slides #2, #6, #7 have information about LSTM integration in Tesseract 4.0x.\n\nTraining with (a.k.a Tesseract 4 training) is unsupported/abandoned. Please use scripts from tesseract-ocr/tesstrain for training.\n• Train Tesseract LSTM with make from Single Line Images and Groundtruth Transcription\n• Training LSTM Tesseract 5 - based on detailed Tesseract 4 tutorial and guide by Ray Smith"
    },
    {
        "link": "https://stackoverflow.com/questions/10947399/how-to-implement-and-do-ocr-in-a-c-sharp-project",
        "document": "I ve been searching for a while and all that i ve seen some OCR library requests. I would like to know how to implement the purest, easy to install and use OCR library with detailed info for installation into a C# project.\n\nIf posible, I just wanna implement it like a usual dll reference...\n\nAlso a little OCR code example would be nice, such as:\n\nSo please consider that I'm not familiar to OCR projects and give me an answer like talking to a dummy.\n\nEdit: I guess people misunderstood my request. I wanted to know how to implement those open source OCR libraries to a C# project and how to use them. The link given as dup is not giving answers that I requested at all."
    },
    {
        "link": "https://medium.com/turkcell/tesseract-ocr-implementation-in-net-core-spring-boot-6f876a5d4ae5",
        "document": "Tesseract OCR is open source. Since 2006 it is developed by Google.🤙\n\nBasically, this technology recognises text inside images, such as scanned photos,documents, screenshots and pdf. OCR technology is used to convert virtually any kind of images containing scanned /written /taken text into machine-readable text data.\n\nTesseract was originally developed at Hewlett-Packard Laboratories Bristol and at Hewlett-Packard Co, Greeley Colorado between 1985 and 1994, with some more changes made in 1996 to port to Windows, and some C++izing in 1998. In 2005 Tesseract was open sourced by HP.\n\nTesseract has unicode (UTF-8) support, and can recognize more than 100 languages “out of the box”.\n\nTesseract supports various output formats: plain text, hOCR (HTML), PDF, invisible-text-only PDF, TSV. The master branch also has experimental support for ALTO (XML) output."
    },
    {
        "link": "https://stackoverflow.com/questions/69145807/take-a-screenshot-behind-window-in-c-sharp-winform",
        "document": "If you want a solution without hiding, moving, minimizing etc., you need the following approach:\n• EnumWindows() to iterate all windows. This will give you the windows top to bottom.\n• Don't forget to exclude your own window\n• Exclude windows that are invisible. Check out GetWindowLongPtr with and compare against\n• GetWindowRect() to get their size\n• PrintWindow() to get a bitmap of the window, no matter whether it's in the background\n• Create a bitmap with the size of the VirtualScreen\n• Paint the windows in reverse order (bottom to top) using DrawImage()\n\nI found that this is quite fast (514 ms on a 2560x1440 screen with 20 visible windows to draw).\n• since it sends a WM_PRINT message to the application, you can not capture applications that are \"not responding\"\n• For me, Firefox does not render well. It's missing page contents.\n• For me, control panel content appears black, although it's there when getting a screenshot of the whole screen."
    },
    {
        "link": "https://learn.microsoft.com/en-us/visualstudio/ide/create-csharp-winform-visual-studio?view=vs-2022",
        "document": "Tutorial: Create a Windows Forms app in Visual Studio with C#\n\nIn this tutorial, you create a simple C# application that has a Windows-based user interface (UI). The app has a button that changes the text of a label. This simple app has all the components used for more complicated Windows Forms programs.\n\nFirst, create a C# application project. The project type comes with all the template files you need to create your application.\n\nAfter you select your C# project template and name your project, Visual Studio opens a form for you. A form is a Windows user interface. Create a Hello World application by adding controls to the form. Then run the app.\n• If you don't see the Toolbox option, you can open it from the menu bar. Select View > Toolbox or Ctrl+Alt+X.\n• None Select the Pin icon to dock the Toolbox window.\n• None Select the Button control and then drag it onto the form.\n• None In the Properties window, locate Text, change the name from Button1 to , and then select Enter. If you don't see the Properties window, you can open it from the menu bar. Select View > Properties Window or F4.\n• None In the Design section of the Properties window, change the name from Button1 to , and then select Enter. If you alphabetized the list in the Properties window, Button1 appears in the (DataBindings) section, instead. You can dock or anchor the controls on your form to help with automatic placement and sizing, when the form changes size. After you add a button control to create an action, add a label control to receive the text.\n• None Select the Label control from the Toolbox. Then drag it onto the form and drop it beneath the Click this button.\n• None In either the Design section or the (DataBindings) section of the Properties window, change the name of Label1 to . Then select Enter.\n• None In the Form1.cs [Design] window, double-click the Click this button to open the Form1.cs window. Alternatively, you can expand Form1.cs in Solution Explorer, and then choose View Code or select F7 from the shortcut menu on Form1.cs.\n• None In the Form1.cs window, after the private void line, type or enter as shown in the following screenshot.\n\nAfter you select your C# project template and name your project, Visual Studio opens a form for you. A form is a Windows user interface. Create a Hello World application by adding controls to the form. Then run the app.\n• If you don't see the Toolbox option, you can open it from the menu bar. Select View > Toolbox or Ctrl+Alt+X.\n• None Expand Common Controls and select the Pin icon to dock the Toolbox window.\n• None Select the Button control and then drag it onto the form.\n• None In the Properties window, locate Text. Change the name from button1 to , and then select Enter. If you don't see the Properties window, you can open it from the menu bar. Select View > Properties Window or F4.\n• None In the Design section of the Properties window, change the name from button1 to , and then select Enter. If you alphabetized the list in the Properties window, Button1 appears in the (DataBindings) section, instead. You can dock or anchor the controls on your form to help with automatic placement and sizing, when the form changes size. After you add a button control to create an action, add a label control to receive the text.\n• None Select the Label control from the Toolbox. Then drag it onto the form and drop it beneath the Click this button.\n• None In either the Design section or the (DataBindings) section of the Properties window, change the name of label1 to . Then select Enter.\n• None In the Form1.cs [Design] window, double-click the Click this button to open the Form1.cs window. Alternatively, you can expand Form1.cs in Solution Explorer, and then choose Form1.\n• None In the Form1.cs window, after the private void line, type or enter as shown in the following screenshot.\n• None Select the Start button to run the application. Several things happen. In the Visual Studio IDE, the Diagnostics Tools window opens, and an Output window opens, too. But outside of the IDE, a Form1 dialog box appears. It includes your Click this button and text that says label1.\n• None Select the Click this button in the Form1 dialog box. Notice that the label1 text changes to Hello World!.\n• None Close the Form1 dialog box to stop running the app.\n\nCongratulations on completing this tutorial. To learn more, continue with the following tutorial:\n\nOr try these other tutorials:"
    },
    {
        "link": "https://stackoverflow.com/questions/16382237/capture-and-save-screenshot-as-you-click-windows-c-sharp",
        "document": "First up, sorry for the long question but I want to make sure I include everything that I have come across and done so far.\n\nI want to make a C# Windows Application for the tutorials team that will serve as an alternative for the boring manual task they perform of pressing Alt+PrtSc for each window that appears while performing the steps of a tutorial and paste it in ms paint to save the image to a folder so that it can be later inserted in the tutorial document.\n\nThere are different ways to capture the snapshot of the desktop or only a part of it. I could even manage to take snapshots of the controls in my WinForms app however; capturing the screenshot of any window (along with the mouse pointer) as soon as you click and saving it turned out to be a little tricky.\n\nI came across this post that has details of capturing and saving the screenshot using Win32 API. This and this post talk about using saving a part of the desktop by using only .NET Framework and it works well but it's not exactly what I need. I did come across some freeware and other commercial software that do a lot more and a little bit of this too but I'd prefer to make something simple and customized.\n\nRight now, my form has a browse button to select a folder (to save images to) and another button named START. Its name changes to STOP when clicked and remains depressed (until clicked again to stop).\n\nSay, the team has to put together a setup and install tutorial of a software and the welcome screen of the wizard is up. With the app started, an image of each window of the install wizard should be saved (along with the mouse pointer) as you keep clicking buttons like Continue, I Accept, Next ... Next and Finish.\n\nI hope I could explain clearly. Any help will be appreciated. Thanks in advance."
    },
    {
        "link": "https://learn.microsoft.com/en-us/visualstudio/get-started/csharp/tutorial-windows-forms-picture-viewer-layout?view=vs-2022",
        "document": "In this series of three tutorials, you create a Windows Forms application that loads a picture and displays it. The Visual Studio Integrated Design Environment (IDE) provides the tools you need to create the app.\n\nIn this first tutorial, you learn how to:\n\nTo create a new Windows Forms App with .NET, follow the tutorial Create a Windows Forms app with .NET. See the Desktop Guide on Windows Forms .NET to learn more.\n• You need Visual Studio to complete this tutorial. Visit the Visual Studio downloads page for a free version.\n• The .NET desktop development workload. To verify or install this workload in Visual Studio, select Tools > Get Tools and Features. For more information, see Change workloads or individual components.\n\nWhen you create a picture viewer, the first step is to create a Windows Forms App project.\n\nVisual Studio creates a solution for your app. A solution is a container for all of the projects and files needed by your app.\n\nAt this point, Visual Studio displays an empty form in the Windows Form Designer.\n\nYour picture viewing app contains a picture box, a checkbox, and four buttons, which you add in the next tutorial. The layout element controls their location on the form. This section shows you how to change the title of your form, resize the form, and add a layout element.\n• None In your project, select the Windows Forms Designer. The tab reads Form1.cs [Design] for C# or Form1.vb [Design] for Visual Basic.\n• None The Properties window now displays properties for the form. The Properties window is usually in the lower right of Visual Studio. This section controls various properties, such as foreground and background color, title text that appears at the top of the form, and the size of the form. If you don't see Properties, select View > Properties Window.\n• None Find the Text property in the Properties window. Depending on how the list is sorted, you might need to scroll down. Enter the value Picture Viewer, and then choose Enter. Your form now has the text Picture Viewer in its title bar. You can display properties by category or alphabetically. Use the buttons on the Properties window to switch back and forth.\n• None Select the form, again. Select the form's lower-right drag handle. The handle is a small white square in the lower-right corner of the form. Drag the handle to resize the form so the form is wider and a bit taller. If you look at the Properties window, the Size property is different. You can also change the size of the form by changing the Size property.\n• None On the left side of the Visual Studio IDE, select the Toolbox tab. If you don't see it, select View > Toolbox from the menu bar or Ctrl+Alt+X.\n• None Select the small triangle symbol next to Containers to open the group.\n• None Double-click TableLayoutPanel in the Toolbox. You can also drag a control from the toolbox onto the form. The TableLayoutPanel control appears in your form. After you add your TableLayoutPanel, if a window appears inside your form with the title TableLayoutPanel Tasks, select anywhere inside the form to close it.\n• None Select the TableLayoutPanel. You can verify what control is selected by looking at the Properties window.\n• None With the TableLayoutPanel selected, find the Dock property, which has the value None. Select the dropdown arrow and then select Fill, which is the large button in the middle of the dropdown menu. Docking refers to how a window is attached to another window or area. The TableLayoutPanel now fills the entire form. If you resize the form again, the TableLayoutPanel stays docked, and resizes itself to fit.\n• None In the form, select the TableLayoutPanel. In the upper-right corner, there's a small black triangle button. Select the triangle to display the control's task list.\n• None Select Edit Rows and Columns to display the Column and Row Styles dialog box.\n• None Select Column1 and set its size to 15 percent. Be sure the Percent option is selected.\n• None Select Column2 and set it to 85 percent.\n• None From Show at the top of the Column and Row Styles dialog box, select Rows. Set Row1 to 90 percent and Row2 to 10 percent. Select OK to save your changes. Your TableLayoutPanel now has a large top row, a small bottom row, a small left column, and a large right column.\n\nWhen you create a Windows Forms App project, you build a program that runs. At this stage, your Picture Viewer app doesn't do much. For now, it displays an empty window that shows Picture Viewer in the title bar.\n\nTo run the app, follow these steps.\n• None Use one of the following methods:\n• On the toolbar, select the Start button. Visual Studio runs your app. A window with the title Picture Viewer appears. Look at the Visual Studio IDE toolbar. More buttons appear on the toolbar when you run an application. These buttons let you do things like stop and start your app, and help you track down any errors.\n• None Use one of the following methods to stop your app:\n• On the toolbar, select the Stop Debugging button.\n• Select X in the upper corner of the Picture Viewer window. When you run your app from inside the Visual Studio IDE, it's called debugging. You run your application to find and fix bugs. You follow the same procedure to run and debug other programs. To learn more about debugging, see First look at the debugger.\n\nAdvance to the next tutorial to learn how to add controls to your Picture Viewer program."
    },
    {
        "link": "https://cyotek.com/blog/capturing-screenshots-using-csharp-and-p-invoke",
        "document": "Capturing screenshots using C# and p/invoke\n\nI was recently updating some documentation and wanted to programmatically capture some screenshots of the application in different states. This article describes how you can easily capture screenshots in your own applications.\n\nThis article makes use of a number of Win32 API methods. Although you may not have much call to use them directly in day to day .NET (not to mention Microsoft wanting everyone to use universal \"apps\" these days), they are still extraordinarily useful and powerful.\n\nThis article does assume you know the basics of platform invoke so I won't cover it here. In regards to the actual API's I'm using, you can find lots of information about them either on MSDN, or PInvoke.net.\n\nA number of the API's used in this article are GDI calls. Generally, when you're using the Win32 GDI API, you need to do things in pairs. If something is created (pens, brushes, bitmaps, icons etc.), then it usually needs to be explicitly destroyed when finished with (there are some exceptions just to keep you on your toes). Although there haven't been GDI limits in Windows for some time now (as far as I know!), it's still good not to introduce memory leaks. In addition, device contexts always have a number of objects associated with them. If you assign a new object to a context, you must restore the original object when you're done. I'm a little rusty with this so hopefully I'm not missing anything out.\n\nSetting up a device context for use with BitBlt\n\nTo capture a screenshot, I'm going to be using the API. This copies information from one device context to another, meaning I'm going to need a source and destination context to process.\n\nThe source is going to be the desktop, so first I'll use the and calls to obtain this. As calling essentially places a lock on it, I also need to release it when I'm finished with it.\n\nNow for the destination - for this, I'm going to create a memory context using . When you call this API, you pass in an existing DC and the new one will be created based on that.\n\nThere's still one last step to perform - by itself, that memory DC isn't hugely useful. We need to create and assign a GDI bitmap to it. To do this, first create a bitmap using and then attach it to the DC using . will also return the relevant old object which we need to restore (again using ) when we're done. We also use to clean up the bitmap.\n\nAlthough this might seem like a lot of effort, it's not all that different from using objects implementing in C#, just C# makes it a little easier with things like the statement.\n\nWith the above setup out the way, we have a device context which provides access to a bitmap of the desktop, and we have a new device context ready to transfer data to. All that's left to do is make the call.\n\nIf you've ever used the method of a object before, this call should be fairly familiar - we pass in the DC to write too, along with the upper left corner where data will be copied ( in this example), followed by the and of the rectangle - this applies to both the source and destination. Finally, we pass in the source device context, and the upper left corner where data will be copied from, along with flags that detail how the data will be copied.\n\nIn my old VB6 days, I would just use (direct copy), but in those days windows were simpler things. The flag ensures the call works properly with layered windows.\n\nIf the call fails, I throw a new object without any parameters - this will take care of looking up the result code for the failure and filling in an appropriate message.\n\nNow that our destination bitmap has been happily \"painted\" with the specified region from the desktop we need to get it into .NET-land. We can do this via the static method of the class - this method accepts a GDI bitmap handle and return a fully fledged .NET object from it.\n\nPutting it all together\n\nAs the above code is piecemeal, the following helper method will accept a which describes which part of the desktop you want to capture and will then return a object containing the captured information.\n\nNow that we have this method, we can use it in various ways as demonstrated below.\n\nIf you want to capture a window in your application, you could call with the value of the property of your . But if you want to capture an external window then you're going to need to go back to the Win32 API. The function will return any window's boundaries.\n\nWin32 has its own version of .NET's structure, named . This differs slightly from the .NET version in that it has and properties, not and . The class has a helper method, which constructs a from left, top, right and bottom properties which means you don't need to perform the subtraction yourself.\n\nAs a slight variation on the previous section, you can use the API call to get the handle of the active window.\n\n.NET offers the static class which provides access to all monitors on your system via the property. You can use the method to find out which monitor a form is hosted on, and get the region that represents the monitor - with or without areas covered by the task bar and other app bars. This means it trivial to capture the contents of a given monitor.\n\nIt is also quite simple to capture the entire desktop without having to know all the details of monitor arrangements. We just need to enumerate the available monitors and use to merge two rectangles together. When this is complete, you'll have one rectangle which describes all available monitors.\n\nOf course, you could just call with a custom rectangle to pick up some arbitrary part of the desktop. The above helpers are just that, helpers!\n\nAlthough I don't have a high DPI monitor, I did temporarily scale the display to 125% to test that the correct regions were still captured. I tested with a manifest stating that the application supported high DPI and again without, in both cases the correct sized images were captured.\n\nA demonstration program for the techniques in this article is available from the links below. It's also available on GitHub."
    }
]