[
    {
        "link": "https://stackoverflow.com/questions/22164680/appending-a-string-when-throwing-an-error-in-c",
        "document": "I'm sure this is something simple, but wasn't able to find any other posts clearly specifying this, though I'm sure there must be one buried somewhere.\n\nIn C++, when using a try catch block in the below manner, how can I append a string variable to the error message?\n\nI get an unhandled exception when trying to do this. Is it something to do with what type is passed back? Appears to be returning a string versus a char*. if that is correct, would that cause the issue? How would I adjust for this? I tried adding an additional catch (const string my_msg), but that did not work, either."
    },
    {
        "link": "https://isocpp.org/wiki/faq/exceptions",
        "document": "What good can using exceptions do for me? The basic answer is: Using exceptions for error handling makes your code simpler, cleaner, and less likely to miss errors. But what’s wrong with “good old and -statements”? The basic answer is: Using those, your error handling and your normal code are closely intertwined. That way, your code gets messy and it becomes hard to ensure that you have dealt with all errors (think “spaghetti code” or a “rat’s nest of tests”).\n\nFirst of all there are things that just can’t be done right without exceptions. Consider an error detected in a constructor; how do you report the error? You throw an exception. That’s the basis of RAII (Resource Acquisition Is Initialization), which is the basis of some of the most effective modern C++ design techniques: A constructor’s job is to establish the invariants for the class (create the environment in which the member functions are to run) and that often requires the acquisition of resources, such as memory, locks, files, sockets, etc.\n\nImagine that we did not have exceptions, how would you deal with an error detected in a constructor? Remember that constructors are often invoked to initialize/construct objects in variables:\n\nThe or (output file stream) constructor could either set the variable into a “bad” state (as does by default) so that every subsequent operation fails. That’s not ideal. For example, in the case of , your output simply disappears if you forget to check that the open operation succeeded. For most classes that results are worse. At least, we would have to write:\n\nThat’s an extra test per object (to write, to remember or forget). This gets really messy for classes composed of several objects, especially if those sub-objects depend on each other. For more information see The C++ Programming Language section 8.3, Chapter 14, and Appendix E or the (more academic) paper Exception safety: Concepts and techniques.\n\nSo writing constructors can be tricky without exceptions, but what about plain old functions? We can either return an error code or set a non-local variable (e.g., ). Setting a global variable doesn’t work too well unless you test it immediately (or some other function might have re-set it). Don’t even think of that technique if you might have multiple threads accessing the global variable. The trouble with return values are that choosing the error return value can require cleverness and can be impossible:\n\nThere is no possible value for to return: Every possible is the correct answer for some and there is no correct answer for the most negative number in the twos-complement representation. In such cases, we would need to return pairs of values (and as usual remember to test) See Stroustrup’s Beginning programming book for more examples and explanations.\n\nCommon objections to the use of exceptions:\n• “But exceptions are expensive!” Not really. Modern C++ implementations reduce the overhead of using exceptions to a few percent (say, 3%) and that’s compared to no error handling. Writing code with error-return codes and tests is not free either. As a rule of thumb, exception handling is extremely cheap when you don’t throw an exception. It costs nothing on some implementations. All the cost is incurred when you throw an exception: that is, “normal code” is faster than code using error-return codes and tests. You incur cost only when you have an error.\n• “But in JSF++ Stroustrup himself bans exceptions outright!” JSF++ is for hard-real time and safety-critical applications (flight control software). If a computation takes too long someone may die. For that reason, we have to guarantee response times, and we can’t – with the current level of tool support – do that for exceptions. In that context, even free store allocation is banned! Actually, the JSF++ recommendations for error handling simulate the use of exceptions in anticipation of the day where we have the tools to do things right, i.e. using exceptions.\n• “But throwing an exception from a constructor invoked by causes a memory leak!” Nonsense! That’s an old-wives’ tale caused by a bug in one compiler – and that bug was immediately fixed over a decade ago.\n\nHow do I use exceptions?\n\nSee The C++ Programming Language section 8.3, Chapter 14, and Appendix E. The appendix focuses on techniques for writing exception-safe code in demanding applications, and is not written for novices.\n\nIn C++, exceptions are used to signal errors that cannot be handled locally, such as the failure to acquire a resource in a constructor. For example:\n\nDo not use exceptions as simply another way to return a value from a function. Most users assume – as the language definition encourages them to – that ** exception-handling code is error-handling code **, and implementations are optimized to reflect that assumption.\n\nA key technique is resource acquisition is initialization (sometimes abbreviated to RAII), which uses classes with destructors to impose order on resource management. For example:\n\nIf the “use f” part of fct() throws an exception, the destructor is still invoked and the file is properly closed. This contrasts to the common unsafe usage:\n\nIf the “use ” part of throws an exception – or simply does a return – the file isn’t closed. In C programs, is an additional hazard.\n\nWhat shouldn’t I use exceptions for?\n\nC++ exceptions are designed to support error handling.\n• Use only to signal an error (which means specifically that the function couldn’t do what it advertised, and establish its postconditions).\n• Use only to specify error handling actions when you know you can handle an error (possibly by translating it to another type and rethrowing an exception of that type, such as catching a and rethrowing a ).\n• Do not use to indicate a coding error in usage of a function. Use assert or other mechanism to either send the process into a debugger or to crash the process and collect the crash dump for the developer to debug.\n• Do not use if you discover unexpected violation of an invariant of your component, use assert or other mechanism to terminate the program. Throwing an exception will not cure memory corruption and may lead to further corruption of important user data.\n\nThere are other uses of exceptions – popular in other languages – but not idiomatic in C++ and deliberately not supported well by C++ implementations (those implementations are optimized based on the assumption that exceptions are used for error handling).\n\nIn particular, do not use exceptions for control flow. is not simply an alternative way of returning a value from a function (similar to ). Doing so will be slow and will confuse most C++ programmers who are rightly used to seeing exceptions used only for error handling. Similarly, is not a good way of getting out of a loop.\n\nWhat are some ways / / can improve software quality?\n\nBy eliminating one of the reasons for statements.\n\nThe commonly used alternative to / / is to return a return code (sometimes called an error code) that the caller explicitly tests via some conditional statement such as . For example, , and work this way: the caller is supposed to test the return value to see if the function succeeded.\n\nAlthough the return code technique is sometimes the most appropriate error handling technique, there are some nasty side effects to adding unnecessary statements:\n• Degrade quality: It is well known that conditional statements are approximately ten times more likely to contain errors than any other kind of statement. So all other things being equal, if you can eliminate conditionals / conditional statements from your code, you will likely have more robust code.\n• Slow down time-to-market: Since conditional statements are branch points which are related to the number of test cases that are needed for white-box testing, unnecessary conditional statements increase the amount of time that needs to be devoted to testing. Basically if you don’t exercise every branch point, there will be instructions in your code that will never have been executed under test conditions until they are seen by your users/customers. That’s bad.\n• Increase development cost: Bug finding, bug fixing, and testing are all increased by unnecessary control flow complexity.\n\nSo compared to error reporting via return-codes and , using / / is likely to result in code that has fewer bugs, is less expensive to develop, and has faster time-to-market. Of course if your organization doesn’t have any experiential knowledge of / / , you might want to use it on a toy project first just to make sure you know what you’re doing — you should always get used to a weapon on the firing range before you bring it to the front lines of a shooting war.\n\nI’m still not convinced: a 4-line code snippet shows that return-codes aren’t any worse than exceptions; why should I therefore use exceptions on an application that is orders of magnitude larger?\n\nBecause exceptions scale better than return-codes.\n\nThe problem with a 4-line example is that it has only 4 lines. Give it 4,000 lines and you’ll see the difference.\n\nHere’s a classic 4-line example, first with exceptions:\n\nHere’s the same example, this time using return-codes ( stands for “return code”):\n\nPeople point to those “toy” examples and say, “Exceptions don’t improve coding or testing or maintenance cost in that; why should I therefore use them in a ‘real’ project?”\n\nReason: exceptions help you with real-world applications. You won’t likely see much if any benefit on a toy example.\n\nIn the real world, the code that detects a problem must typically propagate error information back to a different function that will handle the problem. This “error propagation” often needs to go through dozens of functions — calls calls , etc., and a problem is discovered way down in (or ). The information about the problem needs to get propagated all the way back to , because only has enough context to actually know what should be done about the problem. In an interactive app, is typically up near the main event loop, but no matter what, the code that detects the problem often isn’t the same as the code that handles the problem, and the error information needs to get propagated through all the stack frames in between.\n\nExceptions make it easy to do this “error propagation”:\n\nOnly the code that detects the error, , and the code that handles the error, , have any clutter.\n\nHowever using return-codes forces “error propagation clutter” into all the functions in between those two. Here is the equivalent code that uses return codes:\n\nThe return-code solution “spreads out” the error logic. Functions through have explicit, hand-written code related to propagating the error condition back up to . That is badness:\n• It clutters functions through with extra decision logic — the most common cause of bugs.\n• It increases the bulk of the code.\n• It clouds the simplicity of the programming logic in functions through .\n• It requires the return value to perform two distinct duties — functions through will need to handle both “my function succeeded and the result is ” and “my function failed and the error information is ”. When the types of and differ, you sometimes need extra by-reference parameters to propagate both the “successful” and “unsuccessful” cases to the caller.\n\nIf you look very narrowly at and in the above examples, exceptions won’t give you much of an improvement. But if you instead open your eyes to the big picture, you will see a substantial difference in all the functions in between.\n\nConclusion: one of the benefits of exception handling is a cleaner, simpler way to propagate error information back to the caller that can handle the error. Another benefit is your function doesn’t need extra machinery to propagate both the “successful” and “unsuccessful” cases back to the caller. Toy examples often don’t emphasize either error propagation or handling of the two-return-types problem, therefore they don’t represent Real World code.\n\nHow do exceptions simplify my function return type and parameter types?\n\nWhen you use return codes, you often need two or more distinct return values: one to indicate that the function succeeded and to give the computed result, and another to propagate the error information back to the caller. If there are, say, 5 ways the function could fail, you could need as many as 6 different return values: the “successful computation” return value, and a possibly different package of bits for each of the 5 error cases.\n\nLet’s simplify it down to two cases:\n• “I succeeded and the result is .”\n• “I failed and the error information is .”\n\nLet’s work a simple example: we would like to create a class that supports the four arithmetic operations: add, subtract, multiply and divide. This is an obvious place for overloaded operators, so let’s define them:\n\nIt’s very easy to use:\n\nBut then we have a problem: handling errors. Adding numbers could cause overflow, dividing could cause divide-by-zero or underflow, etc. Whoops. How can we report both the “I succeeded and the result is ” as well as “I failed and the error information is ”?\n\nIf we use exceptions, it’s easy. Think of exceptions as a separate return type that gets used only when needed. So we just define all the exceptions and throw them when needed:\n\nBut if we use return codes instead of exceptions, life gets hard and messy. When you can’t shove both the “good” number and the error information (including details about what went wrong) inside the object, you will probably end up using extra by-reference parameters to handle one of the two cases: either “I succeeded” or “I failed” or both. Without loss of generality, I will handle the computed result via a normal return value and the “I failed” case via a by-reference parameter, but you can just as easily do the opposite. Here’s the result:\n\nNow here’s how to use it — this code is equivalent to the above:\n\nThe point of this is that you normally have to muck up the interface of functions that use return codes, particularly if there is more error information to propagate back to the caller. For example, if there are 5 error conditions and the “error information” requires different data structures, you might end up with a fairly messy function interface.\n\nNone of this clutter happens with exceptions. Exceptions can be thought of as a separate return value, as if the function automatically “grows” new return types and return values based on what the function can throw.\n\nNote: Please don’t write me saying that you propose using return codes and storing the error information in a namespace-scope, global or static variable, such as . That isn’t thread-safe. Even if you don’t have multiple threads today, you rarely want to permanently prevent anyone in the future from using your class with multiple threads. Certainly if you do, you should write lots and lots of BIG UGLY COMMENTS warning future programmers that your code is not thread-safe, and that it probably can’t be made thread-safe without a substantial rewrite.\n\nWhat does it mean that exceptions separate the “good path” (or “happy path”) from the “bad path”?\n\nIt’s another benefit of exceptions over return-codes.\n\nThe “good path” (sometimes called the “happy path”) is the control-flow path that happens when everything goes well — when there are no problems.\n\nThe “bad path” (or “error path”) is the path that control-flow takes when something goes wrong — when there is a problem.\n\nExceptions, when done right, separate the happy path from the error path.\n\nHere is a simple example: function is suppoesd to call functions , , and , in sequence, as shown below. If any of those fail with a “foo” or “bar” error, is to handle the error immediately then return successfully. If any other error occurs, is to propagate the error information back to the caller.\n\nHere is the code if exceptions are used:\n\nThe “good” path and the “bad” path are cleanly separated. The “good” (or “happy”) path is the body of the block — you can read that linearly, and if there are no errors, control flows in a simplistic path through those lines. The “bad” path is the body of the block and the body of any matching blocks in any caller.\n\nUsing return codes instead of exception clutters this to the point where it is difficult to see the relatively simple algorithm. The “good” (“happy”) and “bad” paths are hopelessly intermixed:\n\nBy intermixing the good/happy path with the bad/error path, it’s harder to see what the code is supposed to do. Contrast that with the version that used exceptions, which is almost self-documenting — the basic functionality is very obvious.\n\nI’m interpreting the previous FAQs as saying exception handling is easy and simple; did I get it right?\n\nNo! Wrong! Stop! Go back! Do not collect $200.\n\nThe message isn’t that exception handling is easy and simple. The message is that exception handling is worth it. The benefits outweigh the costs.\n\nHere are some of the costs:\n• Exception handling is not a free lunch. It requires discipline and rigor. To understand those disciplines, you really should read the rest of the FAQ and/or one of the excellent books on the subject.\n• Exception handling is not a panacea. If you work with a team that is sloppy and undisciplined, your team will likely have problems no matter whether they use exceptions or return codes. Incompetent carpenters do bad work even if they use a good hammer.\n• Exception handling is not one-size-fits-all. Even when you have decided to use exceptions rather than return codes, that doesn’t mean you use them for everything. This is part of the discipline: you need to know when a condition should be reported via return-code and when it should be reported via an exception.\n• Exception handling is a convenient whipping boy. If you work with people who blame their tools, beware of suggesting exceptions (or anything else that is new, for that matter). People whose ego is so fragile that they need to blame someone or something else for their screw-ups will invariably blame whatever “new” technology was used. Of course, ideally you will work with people who are emotionally capable of learning and growing: with them, you can make all sorts of suggestions, because those sorts of people will find a way to make it work, and you’ll have fun in the process.\n\nFortunately there is plenty of wisdom and insight on the proper use of exceptions. Exception handling is not new. The industry as a whole has seen many millions of lines of code and many person-centuries of effort using exceptions. The jury has returned its verdict: exceptions can be used properly, and when they are used properly, they improve code.\n\nException handling seems to make my life more difficult; that must mean exception handling itself is bad; clearly I’m not the problem, right??\n\nYou absolutely might be the problem!\n\nThe C++ exception handling mechanism can be powerful and useful, but if you have the wrong mindset, the result can be a mess. It’s a tool; use it properly and it will help you; but don’t blame the tool if you use it improperly.\n\nIf you’re getting bad results, for instance, if your code seems unnecessarily convoluted or overly cluttered with blocks, you might be suffering from a wrong mindset. This FAQ gives you a list of some of those wrong mindsets.\n\nWarning: do not be simplistic about these “wrong mindsets.” They are guidelines and ways of thinking, not hard and fast rules. Sometimes you will do the exact opposite of what they recommend — do not write me about some situation that is an exception (no pun intended) to one or more of them — I guarantee that there are exceptions. That’s not the point.\n\nHere are some “wrong exception-handling mindsets” in no apparent order:\n• The return-codes mindset: This causes programmers to clutter their code with gobs of blocks. Basically they think of a as a glorified return code, and a / as a glorified “if the return code indicates an error” test, and they put one of these blocks around just about every function that can .\n• The Java mindset: In Java, non-memory resources are reclaimed via explicit / blocks. When this mindset is used in C++, it results in a large number of unnecessary blocks, which, compared with RAII, clutters the code and makes the logic harder to follow. Essentially the code swaps back and forth between the “good path” and the “bad path” (the latter meaning the path taken during an exception). With RAII, the code is mostly optimistic — it’s all the “good path,” and the cleanup code is buried in destructors of the resource-owning objects. This also helps reduce the cost of code reviews and unit-testing, since these “resource-owning objects” can be validated in isolation (with explicit / blocks, each copy must be unit-tested and inspected individually; they cannot be handled as a group).\n• Organizing the exception classes around the physical thrower rather than the logical reason for the throw: For example, in a banking app, suppose any of five subsystems might throw an exception when the customer has insufficient funds. The right approach is to throw an exception representing the reason for the throw, e.g., an “insufficient funds exception”; the wrong mindset is for each subsystem to throw a subsystem-specific exception. For example, the subsystem might throw objects of class , the subsystem might throw objects of class , etc. This often leads to extra / blocks, e.g., to catch a , repackage it into a , then throw the latter. In general, exception classes should represent the problem, not the chunk of code that noticed the problem.\n• Using the bits / data within an exception object to differentiate different categories of errors: Suppose the subsystem in our banking app throws exceptions for bad account numbers, for attempting to liquidate an illiquid asset, and for insufficient funds. When these three logically distinct kinds of errors are represented by the same exception class, the catchers need to say to figure out what the problem really was. If your code wants to handle only bad account numbers, you need to the master exception class, then use to determine whether it is one you really want to handle, and if not, to rethrow it. In general, the preferred approach is for the error condition’s logical category to get encoded into the type of the exception object, not into the data of the exception object.\n• Designing exception classes on a subsystem by subsystem basis: In the bad old days, the specific meaning of any given return-code was local to a given function or API. Just because one function uses the return-code of 3 to mean “success,” it was still perfectly acceptable for another function to use 3 to mean something entirely different, e.g., “failed due to out of memory.” Consistency has always been preferred, but often that didn’t happen because it didn’t need to happen. People coming with that mentality often treat C++ exception-handling the same way: they assume exception classes can be localized to a subsystem. That causes no end of grief, e.g., lots of extra blocks to then a repackaged variant of the same exception. In large systems, exception hierarchies must be designed with a system-wide mindset. Exception classes cross subsystem boundaries — they are part of the intellectual glue that holds the architecture together.\n• Use of raw (as opposed to smart) pointers: This is actually just a special case of non-RAII coding, but I’m calling it out because it is so common. The result of using raw pointers is, as above, lots of extra / blocks whose only purpose in life is to an object then re- the exception.\n• Confusing logical errors with runtime situations: For example, suppose you have a function that must never be called with nullptr. However you discover that somebody somewhere is sometimes passing nullptr anyway. There are two possibilities: either they are passing nullptr because they got bad data from an external user (for example, the user forgot to fill in a field and that ultimately resulted in a nullptr) or they just plain made a mistake in their own code. In the former case, you should throw an exception since it is a runtime situation (i.e., something you can’t detect by a careful code-review; it is not a bug). In the latter case, you should definitely fix the bug in the caller’s code. You can still add some code to write a message in the log-file if it ever happens again, and you can even throw an exception if it ever happens again, but you must not merely change the code within ; you must, must, MUST fix the code in the caller(s) of .\n\nThere are other “wrong exception-handling mindsets,” but hopefully those will help you out. And remember: don’t take those as hard and fast rules. They are guidelines, and there are exceptions to each.\n\nI have too many try blocks; what can I do about it?\n\nYou might have the mindset of return codes even though you are using the syntax of / / . For instance, you might put a try block around just about every call:\n\nAlthough this uses the / / syntax, the overall structure is very similar to the way things are done with return codes, and the consequent software development/test/maintenance costs are basically the same as they were for return codes. In other words, this approach doesn’t buy you much over using return codes. In general, it is bad form.\n\nOne way out is to ask yourself this question for each try block: “Why am I using a try block here?” There are several possible answers:\n• Your answer might be, “So I can actually handle the exception. My catch clause deals with the error and continues execution without throwing any additional exceptions. My caller never knows that the exception occurred. My catch clause does not throw any exceptions and it does not return any error-codes.” In that case, you leave the try block as-is — it is probably good.\n• Your answer might be, “So I can have a catch clause that does blah blah blah, after which I will rethrow the exception.” In this case, consider changing the try block into an object whose destructor does blah blah blah. For instance, if you have a try block whose catch clause closes a file then rethrows the exception, consider replacing the whole thing with a object whose destructor closes the file. This is commonly called RAII.\n• Your answer might be, “So I can repackage the exception: I catch a , extract the details, then throw a .” When that happens, consider a better hierarchy of exception objects that doesn’t require this catch/repackage/rethrow idea. This often involves broadening the meaning of , though obviously you shouldn’t go too far.\n• There are other answers as well, but the above are some common ones that I’ve seen.\n\nMain point is to ask “Why?”. If you discover the reason you’re doing it, you might find that there are better ways to achieve your goal.\n\nHaving said all this, there are, unfortunately, some people who have the return-code-mindset burned so deeply into their psyche that they just can’t seem to see any alternatives. If that is you, there is still hope: get a mentor. If you see it done right, you’ll probably get it. Style is sometimes caught, not just taught.\n\nCan I throw an exception from a constructor? From a destructor?\n• For constructors, yes: You should throw an exception from a constructor whenever you cannot properly initialize (construct) an object. There is no really satisfactory alternative to exiting a constructor by a . For more details, see here.\n• For destructors, not really: You can throw an exception in a destructor, but that exception must not leave the destructor; if a destructor exits by emitting an exception, all kinds of bad things are likely to happen because the basic rules of the standard library and the language itself will be violated. Don’t do it. For more details, see here.\n\nFor examples and detailed explanations, see Appendix E of TC++PL3e.\n\nThere is a caveat: Exceptions can’t be used for some hard-real time projects. For example, see the JSF air vehicle C++ coding standards.\n\nHow can I handle a constructor that fails?\n\nConstructors don’t have a return type, so it’s not possible to use return codes. The best way to signal constructor failure is therefore to throw an exception. If you don’t have the option of using exceptions, the “least bad” work-around is to put the object into a “zombie” state by setting an internal status bit so the object acts sort of like it’s dead even though it is technically still alive.\n\nThe idea of a “zombie” object has a lot of down-side. You need to add a query (“inspector”) member function to check this “zombie” bit so users of your class can find out if their object is truly alive, or if it’s a zombie (i.e., a “living dead” object), and just about every place you construct one of your objects (including within a larger object or an array of objects) you need to check that status flag via an statement. You’ll also want to add an to your other member functions: if the object is a zombie, do a no-op or perhaps something more obnoxious.\n\nIn practice the “zombie” thing gets pretty ugly. Certainly you should prefer exceptions over zombie objects, but if you do not have the option of using exceptions, zombie objects might be the “least bad” alternative.\n\nNote: if a constructor finishes by throwing an exception, the memory associated with the object itself is cleaned up — there is no memory leak. For example:\n\nThere is some fine print on this topic, so you need to keep reading. Specifically you need to know how to prevent memory leaks if the constructor itself allocates memory, and you also need to be aware of what happens if you use “placement” rather than the ordinary used in the sample code above.\n\nHow can I handle a destructor that fails?\n\nWrite a message to a log-file. Terminate the process. Or call Aunt Tilda. But do not throw an exception!\n\nThe C++ rule is that you must never throw an exception from a destructor that is being called during the “stack unwinding” process of another exception. For example, if someone says , the stack will be unwound so all the stack frames between the\n\nwill get popped. This is called stack unwinding.\n\nDuring stack unwinding, all the local objects in all those stack frames are destructed. If one of those destructors throws an exception (say it throws a object), the C++ runtime system is in a no-win situation: should it ignore the and end up in the\n\nwhere it was originally headed? Should it ignore the and look for a\n\nhandler? There is no good answer — either choice loses information.\n\nSo the C++ language guarantees that it will call at this point, and kills the process. Bang you’re dead.\n\nThe easy way to prevent this is never throw an exception from a destructor. But if you really want to be clever, you can say never throw an exception from a destructor while processing another exception. But in this second case, you’re in a difficult situation: the destructor itself needs code to handle both throwing an exception and doing “something else”, and the caller has no guarantees as to what might happen when the destructor detects an error (it might throw an exception, it might do “something else”). So the whole solution is harder to write. So the easy thing to do is always do “something else”. That is, never throw an exception from a destructor.\n\nOf course the word never should be “in quotes” since there is always some situation somewhere where the rule won’t hold. But certainly at least 99% of the time this is a good rule of thumb.\n\nHow should I handle resources if my constructors may throw exceptions?\n\nEvery data member inside your object should clean up its own mess.\n\nIf a constructor throws an exception, the object’s destructor is not run. If your object has already done something that needs to be undone (such as allocating some memory, opening a file, or locking a semaphore), this “stuff that needs to be undone” must be remembered by a data member inside the object.\n\nFor example, rather than allocating memory into a raw data member, put the allocated memory into a “smart pointer” member object, and the destructor of this smart pointer will the object when the smart pointer dies. The template is an example of such as “smart pointer.” You can also write your own reference counting smart pointer. You can also use smart pointers to “point” to disk records or objects on other machines.\n\nBy the way, if you think your class is going to be allocated into a smart pointer, be nice to your users and create a within your class:\n\nThat simplifies the syntax of all the code that uses your objects: your users can say instead of :\n\nHow do I change the string-length of an array of to prevent memory leaks even if/when someone throws an exception?\n\nIf what you really want to do is work with strings, don’t use an array of in the first place, since arrays are evil. Instead use an object of some -like class.\n\nFor example, suppose you want to get a copy of a string, fiddle with the copy, then append another string to the end of the fiddled copy. The array-of- approach would look something like this:\n\nUsing s like this is tedious and error prone. Why not just use an object of some class? Your compiler probably supplies a -like class, and it’s probably just as fast and certainly it’s a lot simpler and safer than the code that you would have to write yourself. For example, if you’re using the class from the standardization committee, your code might look something like this:\n\nThe version requires you to write around three times more code than you would have to write with the version. Most of the savings came from ’s automatic memory management: in the version, we didn’t need to write any code…\n• to reallocate memory when we grow the string.\n• to anything at the end of the function.\n• to and re- any exceptions.\n\nC++, unlike just about every other language with exceptions, is very accomodating when it comes to what you can throw. In fact, you can throw anything you like. That begs the question then, what should you throw?\n\nGenerally, it’s best to throw objects, not built-ins. If possible, you should throw instances of classes that derive (ultimately) from the class. By making your exception class inherit (ultimately) from the standard exception base-class, you are making life easier for your users (they have the option of catching most things via ), plus you are probably providing them with more information (such as the fact that your particular exception might be a refinement of or whatever).\n\nThe most common practice is to throw a temporary:\n\nHere, a temporary of type is created and thrown. Class inherits from class which (ultimately) inherits from class .\n\nIn keeping with the C++ tradition of “there’s more than one way to do that” (translation: “give programmers options and tradeoffs so they can decide what’s best for them in their situation”), C++ allows you a variety of options for catching.\n• You can catch by value.\n• You can catch by reference.\n• You can catch by pointer.\n\nIn fact, you have all the flexibility that you have in declaring function parameters, and the rules for whether a particular exception matches (i.e., will be caught by) a particular catch clause are almost exactly the same as the rules for parameter compatibility when calling a function.\n\nGiven all this flexibility, how do you decide what to catch? Simple: unless there’s a good reason not to, catch by reference. Avoid catching by value, since that causes a copy to be made and the copy can have different behavior from what was thrown. Only under very special circumstances should you catch by pointer.\n\nBut MFC seems to encourage the use of catch-by-pointer; should I do the same?\n\nDepends. If you’re using MFC and catching one of their exceptions, by all means, do it their way. Same goes for any framework: when in Rome, do as the Romans. Don’t try to force a framework into your way of thinking, even if “your” way of thinking is “better.” If you decide to use a framework, embrace its way of thinking — use the idioms that its authors expected you to use.\n\nBut if you’re creating your own framework and/or a piece of the system that does not directly depend on MFC, then don’t catch by pointer just because MFC does it that way. When you’re not in Rome, you don’t necessarily do as the Romans. In this case, you should not. Libraries like MFC predated the standardization of exception handling in the C++ language, and some of these libraries use a backwards-compatible form of exception handling that requires (or at least encourages) you to catch by pointer.\n\nThe problem with catching by pointer is that it’s not clear who (if anyone) is responsible for deleting the pointed-to object. For example, consider the following:\n\nThere are three basic problems here:\n• It might be tough to decide whether to within the clause. For example, if object is inaccessible to the scope of the clause, such as when it’s buried in the private part of some class or is within some other compilation unit, it might be tough to figure out what to do.\n• If you solve the first problem by consistently using in the (and therefore consistently using in the ), then exceptions always use the heap which can cause problems when the exception was thrown because the system was running low on memory.\n• If you solve the first problem by consistently not using in the (and therefore consistently not using in the ), then you probably won’t be able to allocate your exception objects as locals (since then they might get destructed too early), in which case you’ll have to worry about thread-safety, locks, semaphores, etc. ( objects are not intrinsically thread-safe).\n\nThis isn’t to say it’s not possible to work through these issues. The point is simply this: if you catch by reference rather than by pointer, life is easier. Why make life hard when you don’t have to?\n\nThe moral: avoid throwing pointer expressions, and avoid catching by pointer, unless you’re using an existing library that “wants” you to do so.\n\nWhat does (without an exception object after the keyword) mean? Where would I use it?\n\nYou might see code that looks something like this:\n\nIn this example, the statement means “re-throw the current exception.” Here, a function caught an exception (by non-const reference), modified the exception (by adding information to it), and then re-threw the exception. This idiom can be used to implement a simple form of stack-trace, by adding appropriate catch clauses in the important functions of your program.\n\nAnother re-throwing idiom is the “exception dispatcher”:\n\nThis idiom allows a single function ( ) to be re-used to handle exceptions in a number of other functions.\n\nIf you try this, you might be surprised at run-time when your clause is entered, and not your clause. This happens because you didn’t throw polymorphically. In function , the statement throws an object with the same type as the static type of the expression . In other words, it throws an instance of . The statement behaves as-if the thrown object is copied, as opposed to making a “virtual copy”.\n\nNote that the statement has been moved into a virtual function. The statement will exhibit polymorphic behavior, since is declared and was passed by reference. As before, the thrown object will be of the static type of the argument in the statement, but within , that static type is , not .\n\nWhen I throw this object, how many times will it be copied?\n\nObjects that are thrown must have a publicly accessible copy-constructor. The compiler is allowed to generate code that copies the thrown object any number of times, including zero. However even if the compiler never actually copies the thrown object, it must make sure the exception class’s copy constructor exists and is accessible.\n\nBecause C++ supports an alternative that is almost always better: The “resource acquisition is initialization” technique. The basic idea is to represent a resource by a local object, so that the local object’s destructor will release the resource. That way, the programmer cannot forget to release the resource. For example:\n\nIn a system, in the worst case we need a “resource handle” class for each resource. However, we don’t have to have a “finally” clause for each acquisition of a resource. In realistic systems, there are far more resource acquisitions than kinds of resources, so the “resource acquisition is initialization” technique leads to less code than use of a “finally” construct.\n\nAlso, have a look at the examples of resource management in Appendix E of TC++PL3e.\n\nWhy can’t I resume after catching an exception?\n\nIn other words, why doesn’t C++ provide a primitive for returning to the point from which an exception was thrown and continuing execution from there?\n\nBasically, someone resuming from an exception handler can never be sure that the code after the point of throw was written to deal with the execution just continuing as if nothing had happened. An exception handler cannot know how much context to “get right” before resuming. To get such code right, the writer of the throw and the writer of the catch need intimate knowledge of each others code and context. This creates a complicated mutual dependency that wherever it has been allowed has led to serious maintenance problems.\n\nStroustrup seriously considered the possibility of allowing resumption when he designed the C++ exception handling mechanism and this issue was discussed in quite some detail during standardization. See the exception handling chapter of The Design and Evolution of C++.\n\nIf you want to check to see if you can fix a problem before throwing an exception, call a function that checks and then throws only if the problem cannot be dealt with locally. A is an example of this."
    },
    {
        "link": "https://guvi.in/hub/cpp/best-practices-and-tips-for-working-with-strings-in-cpp",
        "document": ""
    },
    {
        "link": "https://insights.sei.cmu.edu/documents/3679/2006_017_001_51723.pdf",
        "document": ""
    },
    {
        "link": "https://ashvardanian.com/posts/painful-strings",
        "document": "Criticizing software is easy, yet the C++ and C standard libraries have withstood the test of time admirably. Nevertheless, they are not perfect. Especially the , , and headers. The first two alone bring in over 20,000 lines of code, slowing the compilation of every translation unit by over 100 milliseconds. Most of that code seems dated, much slower than LibC, and equally error-prone, with interfaces that are very hard to distinguish.\n\nThis is not a new problem, and I don’t have an exhaustive list of all the issues with STL and LibC, but some issues became very noticeable when upgrading StringZilla to v3. The upgrade makes it largely compatible with STL, stateful allocators aside. Now it covers most of C++ 20 strings functionality in a C++ 11 compatible form, also adding dynamic (runtime) dispatch for SIMD-accelerated functions. It also provides a few extensions, that are not present in STL, but are common in other languages. For most code bases, replacing and with and should now be a drop-in replacement.\n• What’s missing in C++, but exists in other languages?\n• And how can we make it up to 10x faster?\n\nLet’s start with a question. The has 14 variants of with different argument order and meaning. Can you guess what they do?\n\nI definitely can’t… despite testing this functionality last week. Those seven calls produce six different results.\n\nThis complexity is likely a byproduct of the standard library’s evolutionary path:\n• was welcomed in C++ 98.\n• made its debut in C++ 17.\n• joined the roster in C++ 20.\n\nI’ve noticed a trend of preferring these newer constructs in reverse order. Absent non-owning views and slices, you’re bound to lug around references to the original strings. Doing so, you need to pass additional integer arguments to specify the range of the original string you want to operate on.\n\nThis raises another inquiry - why opt for integers over iterators? And more crucially, how thorough are the checks on these integer parameters?\n\nMost containers in the C++ standard library have an and an method.\n• The is fast, unchecked, and can lead to undefined behavior.\n• The method is slower, checked, and throws an exception on out-of-bounds access.\n\nEasy to remember when it’s just one argument per function. What if you have two arguments? Common sense suggests that argument checking is either done for both or for neither. Documentation suggests otherwise.\n\nThe method is the one-dimensional sibling of the zero-dimensional . Instead of returning one scalar, it returns a string slice. The kicker is that the method has a boundary check for the first argument but not for the second. Moreover, unless you enable “warnings as errors”, the compiler won’t even warn you about the negative arguments\n\nIt’s debatable, but Python’s support for negative indices is more intuitive. Without it, you need to write instead of . With StringZilla, you can use negative indices and get the expected results:\n\nWe can’t have all the good things for now. Due to language constraints, the syntax is impossible. So I’ve used an for the indices, and an underscore-prefixed literal for the view.\n\nContinuing the topic of extended functionality, there are some very basic utilities missing in STL. This includes lazy ranges for , , and bulk .\n\nMany production code bases have utility functions like:\n\nGoing from worst to best, they allocate memory at least for the , and reallocate when it needs to grow. Each allocation can be orders of magnitude more expensive than the search itself. StringZilla provides lazily-evaluated ranges to avoid those, similar to Rust and some other systems languages. Implementing them in C++ is not trivial and took about 400 lines of expression templates. Now, StringZilla supports overlapping and non-overlapping substring search ranges. Splits. By string. By character. By character-set delimiters. In normal and reverse order. All SIMD-accelerated.\n\nFor $N$ matches, the split functions will report $N + 1$ matches, potentially including empty strings. Ranges provide and forward-iterators and have a few convenience methods as well:\n\nA special case of is . It’s one of the most neglected functions in Python strings. StringZilla brings them to C++, returning a simple , that can be unpacked with structured bindings.\n\nAnother way to know that the functionality is missing in STL is its frequency on StackOverflow and presence in Boost. Boost has a function, which is not in STL. The is a very different beast. It replaces one predefined string slice with the given input. The Boost function returns all occurrences of a substring with another substring, combining bulk-search functionality with several or calls. StringZilla supports that out of the box.\n\nMemory allocators are broken in C++, the same as in most languages. That’s not a big deal for most applications, but it is a problem in IoT and Big Data applications. The Unum stack is designed for the latter.\n\nIn Big Data, efficient software would always work in a memory-starved environment. Even if you have 2 TB of RAM on a CPU socket, you will reach a point where 100% is used, you can’t allocate more, but you also can’t .\n\nThe fact that most containers in STL raise exceptions when memory allocations fail is an issue. That’s why StringZilla provides “try” versions of all allocation functions and explicitly marks all public interfaces with and .\n\nThis might be a niche use case. A more common one is concatenating multiple strings together. The STL provides and , but those are inefficient if many invocations are performed.\n\nThe efficient approach would be pre-allocating the memory and copying the strings into it.\n\nThat’s mouthful and error-prone. StringZilla provides a more convenient function, which takes variadic arguments. It also overrides the to concatenate strings lazily without any allocations.\n\nSoftware developers often need to generate random strings for testing purposes. The STL provides and , that can be used with StringZilla.\n\nMouthful and slow. StringZilla provides a C native method - and a convenient C++ wrapper - . Similar to Python it also defines the commonly used character sets. It uses precomputed multiplication and shift tables to avoid module and division operations. Those are used to sample from the given alphabet fairly and are slow on most CPU architectures.\n\nC++ is synonymous with performance. The STL is not. Every major shop in town has homegrown hash tables or prefers open-source alternatives to and . The is not an exception. For some operations, it calls down to LibC, which is much more optimized in general but still doesn’t reach the hardware potential and doesn’t cover all the needs of the C++ class. The can only be used for substring search on NULL-terminated strings. The is better and can be used with . But there is a catch - there is no reverse search in LibC. So, only one evaluation order is optimized. Let’s see the numbers for exact search performance.\n\nThe library has a lot of “work in progress” functionality that goes far beyond the “standard needs”. It packs Levenshtein edit distances, Needleman-Wunsch alignment scores for Bioinformatics, Rabin fingerprints for fuzzy matching, and fast Radix-based sorting. As it matures, it might be worth suggesting as a new baseline implementation for the standard library of C++ and the strings in other programming languages. Until then, it’s an easy-to-install tool for performance-sensitive applications. Give it a chance and let me know if there is some functionality you would like to see in the next release 🤗"
    },
    {
        "link": "https://educatedguesswork.org/posts/memory-management-3",
        "document": "This is the third post in my planned multipart series on memory management. In part I we covered the basics of memory allocation and how it works in C, and in part II we covered the basics of C++ memory management, including the RAII idiom for memory management. In this post, we'll be looking at a powerful technique called \"smart pointers\" that lets you use RAII-style idioms but for pointers rather than objects.\n\nWhy do you want pointers? #\n\nRecall from before that I said that if you want to use RAII you need to store an actual object on the stack, not a pointer to the object, because if the object is on the heap, it won't be cleaned up when the function exits. This is an annoying limitation.\n\nFor example, suppose we want to write a function which hashes the contents of the file, returning a single string containing the hash. With just one hash function, that might look like this:\n\nOur hash function is just an object with two methods:\n• which returns the hash value.\n\nThis works fine, but what happens if we want to support more than one hash function, for instance SHA-1, SHA-256, etc. One way to do this is to have the caller of the function provide the name in a string, i.e.,\n\nInternally, we'd have what's called a factory functionthat makes a hashing object given the string name. I.e.,\n\nAll of the concrete hashers (e.g., ) inherit from and returns an instance of the desired hash object. Because of inheritance, we can just assign all of them to . This gives us a function like the following:\n\nSo far so good, but now instead of having an instance of on the stack we have an instance of on the heap and it leaks when the function returns. So much for RAII. Fortunately, it's possible to recover RAII semantics in a generic way using a \"smart pointer\".\n\nWhat's a smart pointer and why is it smart? #\n\nAt a high level, a smart pointer is an object that can be used as if it were a pointer but has better semantics. For instance, C++ provides stack-like RAII properties for objects on the heap. It gets used like this:\n\nThis is literally the only change we have to make. From there on, we can use , which is actually a holding ,as if it were a . When goes out of scope out the end of the function, the pointer it's holding will be freed, just as if the hasher object itself were on the stack.\n\nC++ has a number of different smart pointer types built into it, but first I want to look at how you actually implement a smart pointer.\n\nSuppose, for example, we want to implement a -like for . For starters, we need a class that holds a and destroys it on destruction:\n\nThis is actually enough to give us RAII behavior: we can create a in the usual way and when it goes out of scope it will be destroyed along with the hasher object inside:\n\nThis isn't really a smart pointer, though, it's just a container for the object. If we want to do anything with object inside, we somehow need to get at the pointer. The obvious thing is to just provide a function called that gives you the pointer:\n\nThis is called \"unboxing\" because we have the pointer in a box (the smart pointer) but now we take it out to use it. Unboxing will work, but now we have to change all the code which previously used as if it were a pointer to use :\n\nYuck! Not only is this a pain in the ass, but it undercuts the whole thing we are trying to do here, which is to avoid having to work with the raw pointer.\n\nFortunately, C++ has a feature that makes this unnecessary because we can use operator overloading. In part II, we overloaded the copy assignment operator but here we are going to overload the operator instead so that acts like . The code for that looks like this:\n\nYou don't need to worry too much about the syntax, but the net effect is that when you use with it acts like you were using with the internal pointer, which is what we want. Here's our new code:\n\nThe only line that's changed from our original code is the one marked where we create the but now we've eliminated the memory leak.\n\nThis is a smart pointer after the fact, but it's kind of a dumb one. There are at least two big problems:\n\nIt's good to be unique #\n\nConsider the following code:\n\nAs we saw in part I, this will invoke the copy constructor. Because we haven't defined a copy constructor, we end up with the default one which makes a shallow copy, with the result that and both point to the same instance of . When the function ends they will both try to it, which leads to a double free, with the following error:\n\nAs expected, the destructor for fires twice, but with the same pointer ( ). In this case, the implementation has chosen to generate an error and crash the program for the double (note that the error is in because this C++ implementation of is based on ), but that's just whoever wrote it doing you a favor. As noted in post I, anything could happen at this point, but whatever it is is likely to be bad. This is definitely a defect and quite possibly a vulnerability.\n\nWhat we want to do is make this case impossible, which is to say to make actually unique. By this point it should be clear how to do this: we're going to overload the copy constructor and the copy assignment operator. With what we know now, the obvious thing to do is to just make them abort, like so:\n\nThis works in some sense, but it's a runtime error, which means that our program will crash if we try to copy a but that the compiler won't catch it so the program will still compile. Moreover, there's no guarantee that the failure will be this safe; it could easily be a serious vulnerability via use after free.\n\nWhat we really want is a compile time guarantee. The old way to do this was to make the copy constructor so that it wasn't possible to call it, but the new way (as of C++-11) is to mark it with :\n\nIf we then try to construct a new from an existing one, we get the somewhat helpful error:\n\nIf we do the same thing for the copy assignment operator, we've then prevented anyone from making a second pointing to the same underling object. Well, sort of.\n\nIt's true that if we do all of this you can't make another from an existing one, but nothing stops you from making two s from the same pointer:\n\nThe obvious answer is \"don't do that then\" but we're just depending on programmer discipline, because the compiler won't stop you. How is it to know you didn't want that outcome (and later we'll see an example of where this kind of thing is totally legitimate, if slightly inadvisable)?\n\nOK, so now have a unique pointer, but this is pretty limited. While we don't want to be able to make a copy of a unique pointer (that's what makes it unique), sometimes we want to move an object from one unique pointer to another. For example, suppose we have created an object but we want to store it in a container, like a vector. This presents two problems:\n• We want the vector to own it so our destructor doesn't destroy it when it goes out of scope.\n• The vector may need to move the object around when it reallocates its own memory to grow or shrink.\n\nThe key thing here is that we want to preserve the uniqueness guarantee. After we do , we want to be holding the pointer and not to be.\n\nUnsurprisingly, we're going to do this with the move assignment operator, which we saw in part I. It looks something like this:\n\nThe move assignment operator does two things:\n• It sets the field in the new smart pointer (the one being moved to) to point to the object that is being held.\n• It invalidates the field in the original pointer (the one being moved away from) by setting it to .\n\nPut together, these will prevent the object from being destroyed when the source smart pointer is destroyed. We also want to make sure that any use of the old smart pointer fails cleanly, so we should add a check in the implementation:\n\nWe'll also need to implement the move constructor, which is basically the same as the move assignment operator.\n\nThis is all fine, but note that we haven't written a generic unique pointer class, but instead one that only works for . If we want one for a new class called we need to write it all again, or rather we need to take the class and globally replace with (and better hope you don't have anything called because it will become ). Fortunately, C++ offers a better way of doing this: templates.\n\nThe idea with templates is to let the compiler do that search and replace for you, which obviously works a lot better than text replacement. We do this by making a version of the class with a placeholder typename (conventionally ) instead of the actual concrete typename, like so:\n\nNote that we're going to call this rather than to avoid confusing it with C++'s built-in implementation.\n\nThe syntax tells C++ that this is a template and that the name of the placeholder type is (as an aside, you can have multiple placeholder types). When you actually go to use the template class, you tell it what type you want to make a unique pointer for and the compiler replaces the s with that typename, producing a new version of the class that is customized just for that type (technical term: instantiating the template).\n\nThe syntax should be familiar by now:\n\nImportantly, and are totally different classes, as you can see if you try to stuff a into , provoking the following super-helpful compiler error message:\n\nThis isn't a complete implementation of a unique pointer, but it illustrates the essential features.\n\nThe good news is that if you only use smart pointers and not regular pointers, then your programs will be a lot safer. This isn't to say that there can't be any memory errors because there are other ways to do unsafe stuff, but to a first order you won't have to worry about memory leaks or use after free. The problem here is that nothing in C++ restricts you to just using smart pointers.\n\nFor example, with unique pointers:\n• You can create a raw pointer and then add it to a smart pointer, but this doesn't invalidate the original raw pointer; you just end up with both the copy in the smart pointer (the \"boxed\" version) and the original one in the raw pointer (the \"unboxed\" version).\n• You can get an unboxed copy of the pointer just by doing . This doesn't invalidate the boxed version the way that does.\n\nBoth of these violate the uniqueness guarantee of , so if you do either of them, then you're back in the situation where you have to worry about manually managing memory and C++ won't protect you.\n\nThe natural thing to say is \"I'll just work with boxed pointers\", and to some extent you can do that (though again, C++ won't stop you from unboxing stuff, you just have to not do it) but it's very common to have to work with code that doesn't know about smart pointers, and then you end up unboxing them, at which point you're back in the soup.\n\nOne common situation where you end up having to sort of unbox unique pointers is when you want to pass them to a function, as in:\n\nAs expected, this fails because passing by value would require making a copy of , which would violate the uniqueness invariant. We could move but then we couldn't use it later, when what we really want is to just let do something with temporarily but keep ownership. One way around this would just be to pass a pointer to , like so:\n\nThis will work, but what it's really doing is working around the uniqueness rule: we only have one object holding onto the inner but we've got multiple variables pointing at the , one in and one passed as a pointer to . So, technically we haven't unboxed the inner pointer, but we've unboxed which has all the same problems as before. C++ also has a feature called \"references\", where the callee (in this case ) can just ask for what's effectively a pointer to the object without modifying the call site, and you could ask for a reference to but this still has the problem that you can copy the references around, so it's possible to have a reference to outlive . This isn't to say that it's not possible to safely use references or pointers to a , just that you have to be careful to follow the rules because the compiler won't help you out. (Aside: in production code you should use references rather than pointers, but I'm trying to keep new syntax to a minimum).\n\nIt's also quite common to have situations where you actually want to have two pointers to the same underlying object. For example, suppose that we're building an HR application and we want to keep track of people's managers. It's normal for two people to have two managers, but we can't copy so things get tricky. Fortunately, isn't the only type of smart pointer. For this task, the tool we want is called .\n\nUnlike a , multiple instances can point to a given object, just like with a regular pointer (or, if you're used to a programming language like Python, JavaScript, or Go, just like you happens all the time). keeps track of how many instances there are (the \"reference count\"). When you copy a the reference count increases by one. When a instance is destroyed the reference count decreases by one. If the reference count reaches zero, that means that there are no s to the object and it's destroyed.\n\nFor example, consider the following code:\n\nWhen run, this produces the output:\n\nNote that when both and point to the object, then they also share the same reference count (2). When we reset , telling it to forget about the object, then the reference count drops to 1 and then when we reset , then the reference count drops to zero and the object is destroyed.\n\nOnce we have a shared pointer we can use it to pass an object around without unboxing it:\n\nWhen we pass to , it makes a copy of , incrementing the reference count. Then when returns, that copy is destroyed, decrementing the reference count. The same thing happens when we want to have multiple pointers to the same object, as in the case of storing a pointer to an employee's manager.\n\nIt's worth taking a quick look at how works. The code below shows the core of a homegrown implementation, focusing on the new stuff.\n\nThe key intuition is that we need somewhere to store the reference count, and that needs to be shared between the different instances of so that they have the same view of the reference. This means that it can't be stored in any one copy in case that copy goes out of scope. Instead, we allocate a new object which stores the reference count and every instance of just points to the single instance, as shown here:\n\nIn this case, it also stores the pointer to the owned object, though that could in principle also go in the class, with each one having its own copy of the pointer, which is what Windows seems to do.\n\nConsider the following (potentially more complicated than necessary) code, which models a trivial family with one parent and one child. We want each parent to know its own child and and each child to know its own parent so that we can go from parent to child and vice versa.\n\nWhen we run code, we would expect to get the following output:\n\nHowever, in practice we get nothing. The reason is simple: and aren't actually being destroyed. But why not? To debug this, let's add some instrumentation:\n\nIt's a little tricky to print out the reference counts after has completed, because if we return then we'll have a reference to it in the caller and don't expect it to be destroyed. What we want is to somehow keep ahold of without having a reference to it. We can do this if we unbox via and return it, allowing us to look inside:\n\nYou may have figured out what's going on here, but if not, it's helpful to walk through things step by step and look at the structure, as shown in the following diagram.\n• First, we allocate a new instance of , storing a pointer to it in the shared pointer local variable , with reference count=1.\n• We then allocate a new instance of , passing it a shared pointer to . The constructor for copies the pointer to to its own internal shared pointer, incrementing the reference count to 2. We then assign the new to the local shared pointer .\n• We then tell our instance of about our new instance of with the function, which copies the shared pointer into its own internal shared pointer, incrementing the reference count to 2.\n• Finally, when returns, both local shared pointer instances are destroyed, decrementing the corresponding reference counts, with the result that each shared pointer now has reference count 1.\n\nThe reason that neither nor is being destroyed is that each is being owned by a shared pointer with reference count 1, held by the other: holding a shared pointer to and holding a shared pointer to parent. Nothing else is pointing to either, except for the the unboxed pointer to the that we leaked for debugging purposes, which you can ignore as it has no effect on the reference count (you can easily reproduce this effect without returning that as we did in the original program). Each object is keeping the other alive, but they're not otherwise relevant.\n\nWhat we've done here is reproduce the classic problem with reference counting for memory management: circular references. The basic assumption behind a reference counting system like shared pointers is that it assumes that the shared pointers are laid out in what programmers call a directed acyclic graph (DAG), which is to say that there are no loops where if you follow the shared pointers from object A you eventually get back to A. If there are, then you can end up with objects which can't be freed even if all the references external to the loop are destroyed. In this case, the memory will be inaccessible but can't be freed.\n\nOK, so we have some data which can't be freed? Is that such a big deal. It's important to recognize that when you are using RAII, this kind of error is not just a matter of wasted resource but a correctness issue because object destruction can have visible side effects.\n\nAs a simple, consider the following trivial code:\n\nThis just writes to the file . However, there's a lot hiding under that \"just\", because the program doesn't address the disk hardware directly. Instead, it uses the \"system call\" to ask the operating system to write some stuff to the disk, which sets off a long chain of other events which I won't go into here. Each call to is somewhat expensive, so programs typically will buffer up individual writes internally and then flush the buffer when it gets full or, critically, when the file is closed. In this code, that is hidden by the use of RAII, which just magically takes care of things when the function returns, but what's really happening is something like this:\n\nIf something interferes with being destroyed, then some data may be left in the buffers, with the result that will be truncated. We can reproduce this by calling at the end of .\n\nAs the name suggests, causes the program to exit, and it never returns, which means that never returns, which means that is never destroyed (or, rather, that the destructor never runs, because of course all the program memory is freed), which means that anything still in the buffers is never written to disk. On my computer (a Mac) the result of this program is a file containing only the letter , so presumably is still in the buffer, lost to us forever. The same thing would happen if instead we had some bug that prevented the object from being destroyed, such as it was held by some circular reference as above.\n\nNote that the exact behavior you observe will depend on the precise buffering strategy employed by your C++ implementation, as the standard doesn't appear to prescribe one behavior. In fact, the astute observer will note that I didn't end the write with a , which adds a line feed to the end of the line; on my machine this seems to cause the buffer to flush.\n\nThe key point here is that many nontrivial uses of RAII depend on the destructors actually executing at the right time, so defects like circular references, while not precisely a memory leak in the technical sense (each object is being pointed to by something), can lead to serious correctness issues.\n\nIt's totally reasonable to want to make data structures which have reference loops, so if we can't just use shared pointers, what do we do? One option would be to have one of the pointers just be unboxed, but this undercuts the whole purpose of using smart pointers in the first place. What we instead need is a different kind of smart pointer called a \"weak pointer\".\n\nUnlike other types of smart pointer, a weak pointer doesn't keep the pointed to object alive (in C++ jargon, it doesn't \"own\" it). This means that the object might be destroyed while you are holding the weak pointer. This means that you can have circular references as long as the reference in one direction is a weak pointer, because that breaks the cycle.\n\nBecause the object might be destroyed out from under you, in order to ensure that a weak pointer is safely used, then, you need to temporarily convert the weak pointer into a shared pointer using the method. This shared pointer keeps the object while you use it and when it goes out of scope, you're still holding the weak pointer. For example:\n\nImportantly, if the underlying object has already been destroyed (because the shared pointer reference count went to 0), the method can fail, in which case the resulting shared pointer will have the value (pointing to nothing). This is an inherent consequence of the fact that the weak pointer doesn't keep the object alive.\n\nWhile I'm not going to go into all the details of how to implement weak pointers here (there are a number of techniques) I do want to note that one way to implement it is for the shared pointer object to maintain two reference counts, one strong, one weak. When the strong reference count goes to zero, you destroy the object being held. When both the strong and weak pointer counts are zero, you destroy the object itself; this allows the weak pointer to continue to exist and point to valid memory—though just to the object—even if all the shared pointers have been destroyed. This doesn't violate the RAII correctness guarantees described above because the object is still destroyed, but it does mean that there is some overhead from a weak pointer hanging around even if the shared pointers are all gone.\n\nWhen you have to unbox #\n\nWe now have , , and , which means we're all set, right? Well, maybe. If you're writing totally new code, then these three smart pointers are basically all you need, but if you have to deal with older code which doesn't use smart pointers, then you can run into problems.\n\nConsider the following simple C-style API for timers.\n\nThis is a bit abstruse, due to a combination of C's limited semantics and arcane syntax, but what it says is that you pass in three arguments:\n• A function to call when the timeout expires\n• An argument to pass to the function\n\nIn a modern language, you would either pass a object that encapsulated the callback and the context or, even better, a closure that encapsulated all the relevant state, but neither of these is available in C, so instead we have this.\n\nYou use this API this way:\n\nWhen the timer expires, gets called with a pointer to the string provided as the third argument. Note that this can actually be a pointer to any type of object (that's what ) means, and it's the job of the callback to know what type of pointer it actually is and use it appropriately. The means \"treat this as if it contains a string\", which better be true or things can turn very ugly very fast.\n\nThis is all fine, though a bit fiddly, but what happens if we want to pass some dynamically allocated object to the callback? In C, static strings are stored in the data segment so you don't need to allocate or free them, but what if we had a dynamically constructed string? In that case, we may need to free the object in the callback, like so:\n\nWe're back to C-style memory management here, but what if we want to work with an object which is owned by a smart pointer? We could unbox the pointer, like so:\n\nThis works as long as outlives the timer, but there are situations where you don't know the respective lifetimes. For instance, consider what happens if you are making some kind of network request and want to set a timer in case the request takes too long. In this case, it could be either the request error handler or the timer that is the last use of the object, which is exactly the kind of problem that shared pointers are designed to help you manage! What you actually want to do is to pass the shared pointer to the callback handler, but this impoverished API precludes that.\n\nOne way to manage this situation is to move the reference count from outside the object (as in shared pointer) to inside the object. For instance, we can require that any managed object expose a reference counting interface like so:\n\nInternally, the object has to maintain a reference counter which is incremented whenever is called. When is called, the reference counter is decremented. If the reference count reaches 0, will destroy the object using , which is safe to do as long as you are super-careful. The implementation of the smart pointer itself looks sort of like , except that it calls the and functions rather than directly incrementing and decrementing its own reference count.\n\nIf we adapt our program to use a reference counted pointer it looks like this:\n\nNote that unlike shared pointers, this still requires some attention to the reference count. In particular, before we unbox the pointer and pass it to we need to manually increment the reference counter. The reason for this is that the object is essentially being owned by the timer infrastructure, and if we didn't do that, then when returned, the object would be destroyed as the smart pointer went out of scope.\n\nPerhaps less obviously, we have to manage what happens when the takes ownership of an object: does it increment the reference count or not? You need an option to have it leave the reference count alone so that when it takes ownership in the callback we don't end up with a reference count of 2 rather than 1 (because it's being handed off from the timer infrastructure to the callback). In this code I've opted to only have that variant and force objects to self-initialize with a reference count of 1, but another alternative is to have a flag of some kind that tells the constructor whether to increment or not.\n\nC++ doesn't have a standard implementation of this kind of reference counted pointer, but the popular Boost C++ library project provides a version called intrusive_ptr, though it works a little differently than what I've sketched above.\n\nFirefox makes very extensive use of internally reference counted counted pointers using the template (the sketch above is sort of modeled on Firefox's implementation). The decision to use this design is very old (long predating my time at Mozilla) and dates from a time when C++ didn't have good smart pointers. Once that changed and good smart pointers were widely available, there were a number of debates about which type to use (I was on Team use the C++ standard) and so now Firefox contains a mix of both styles. I don't know what decisions people would have been made starting from scratch (though Chrome seems to use the standard smart pointers a lot more, which is where I got used to it).\n\nAs should be clear from the discussion above, unless you're writing totally greenfield code, it's very hard to avoid having to unbox pointers sometime. In my experience, engineers seem to have two attitudes towards this reality:\n• Discourage it and make you work if you want to unbox.\n• Lean into it and make it as easy as possible to unbox.\n\nOne of the core loci of this debate is whether you should be able to implicitly convert a smart pointer to a raw pointer, like so.\n\nNote that basically all smart pointers in C++ implement some unboxing method like and so that you can access methods and properties; the question is whether you automatically convert to in other contexts. Ordinarily this wouldn't work in C or C++ because and are totally different types and you can't just assign one to the other. However, you can make it work by implementing it explicitly as part of .\n\nThe argument for implementing automatic conversion this is that it makes it easy when you inevitably have to unbox; the argument against it is that it's all too easy to unbox accidentally and that you should have to do it explicitly. C++'s smart pointers force you to call . Firefox's do not and in fact discourage calling . I think this is the wrong answer but was not able to persuade enough people to get it changed; it's easy to add affordances like this, but much harder to remove them once people start to rely on them and you need to change all the relying code.\n\nThis is all baked in #\n\nOne important thing to realize is that smart pointers aren't some new piece of C++ syntax; they're just a new combination of a number of existing C++ features, namely:\n• Overloading the copy constructor, copy assignment operator, etc. provide the appropriate functionality for copying and assignment.\n• Overloading (and sometimes automatic conversation) to make the smart pointer act like a regular pointer.\n\nThat's why we're able to implement our own smart pointers that do the same thing as the ones shipped with the C++ library. This kind of thing is something you see a lot with powerful languages like C++: people realize that they can put together existing features in new ways to produce new functionality that wasn't built into the language.\n\nThe major reason this is all so messy is that smart pointers are layered onto C++'s previously existing unsafe memory management system. This means that you can always opt out of smart pointers and use unboxed pointers, at which point you've given up all your safety guarantees. This is actually something you have to do sometimes—especially when you are working with legacy code—but the lack of compiler enforcement encourages you to do that rather than figuring out how to do things safely without unboxing. Next up, we'll be looking at a language which was built to be safe from the ground up: Rust."
    },
    {
        "link": "https://stackoverflow.com/questions/29688900/c-memory-management-raii-smart-pointers-and-gc",
        "document": "Here are my thoughts of C++ Memeory management, please feel free to comment.\n\nMemory can be allocated in stack or heap.\n\nIf two nested stacks need to share data, use RAII allocating memory in stack, like below:\n\nIf two parallel stacks need to share data (not class member fields), memory must be allocated in heap, use Smart Points or GC. For example:"
    },
    {
        "link": "https://dev.to/10xlearner/memory-management-and-raii-4f20",
        "document": "Hi dear reader, I’m Xavier Jouvenot and in this article, we are going to talk about Memory Management, more specifically in C++, even if the concept can be extended to other languages. This post was inspired by a rule from the first chapter of Code Craft, by Pete Goodliffe, on Defensive programming\n\nWhy should you even care about memory management ?\n\nThis is a fair question.We are 2020, some languages have tried several way to remove this task away from the programmer. For example, some languages don’t let the possibility to the programmer to dynamically allocate memory, while some other have integrated a garbage collector system which is supposed to do that for us, isn’t it ? 🤔\n\nSadly, even a garbage collector can’t magically handle all memory management, and even if you restrict yourself to language without dynamic memory allocation, you should understand how static memory allocation works for this language, to use it more intelligently. Whatever the case, it is important for you to understand how the memory is managed by your system, so that you can understand what is happening more accurately.\n\nIn C and C++, as long as you don’t use pointers and dynamic allocations, you are good, the memory is handle for you by the Stack. But when you will use (and you will probably have to use), dynamic allocation, then, you should be careful about how you manage you memory to avoid corrupting your memory, using invalid memory, memory leaks, and all other problems related to dynamic allocation. 😮\n\nIn C and before C++11, the only way to use memory allocation available were to use the keywords ,or , and ,or .The first are for allocating dynamic memory space, taking the ownership on some memory, and the seconds one are for freeing allocated memory, releasing the memory on which we had ownership.\n\nThose methods gave and still give to the developer to do whatever they want about memory management, so the responsibility is completely in the developer hands. If use badly, you could end up trying to free a memory block that was yours or forget to free some memory blocks, and end up with some weird undefined behavior. This made the task difficult for many programmers, so much that many developers are still afraid of doing memory management.\n\nBut some developers reflected on it and came up with techniques and principles that could allow us to use dynamic allocation without risks, and this is what we are going to see now 😉\n\nRAII , as the title said, stands for \"Resource Allocation Is Initialization\".This is a principle which state that when allocating some memory, you should define its lifetime.\n\nFor stack-allocated objects, the RAII is granted by the system.Each variable/object will be deleted at the end of the scope in which it was created.But for heap-allocated objects, RAII is not granted by the system.So you have to make sure that every object dynamically allocated will be destroyed at the end of the scope in which it was created.This requires some discipline, but avoid a lot of pain when you have to find the origin of a memory leak with tools like valgrind.\n\nLuckily for us, in C++11, some objects call smart pointers were standardized to help us integrate RAII principle in our code base ! 😃\n\n And if you still use older C++, you can extract the concept of those smart pointers to integrate similar objects in your code base. 😉\n\nThe first smart-pointer, and probably the most used, is .This smart pointer owns a pointer to a dynamically allocated element, and free the memory dynamically when it’s destroyed.Let’s take an example\n\nHere you have some dynamic allocation happening with the , and it is encapsulate by the smart pointer so that, at the end of scope, the memory dynamically allocated in the variable will be free automatically. No need to add a keyword, so add too much or too little of them.It also work as a member of an object:\n\nHere, you have a class which store the value given during the construction into the heap using a .When the variable will be destroyed at the end of the scope, then, the memory allocated dynamically in the member of the object will also be free automatically, no need to add any delete in the class destructor ! Pretty cool, isn’t it ?! 😄\n\nTo make the thing even easier for the developer, in C++14, the function std::make_unique has been added, which allows use to avoid unnecessary copy during the creation of an element in the heap AND , when combined with the keyword makes code even simpler to read and write!\n\nHere, even the keyword has disappeared ! And the variable is a ready to be used. 🙂\n\n So now, you code can be free from and keywords ! 🍾\n\nBut, even if the is a game changer in memory management, this isn’t a silver bullet either! It has its own limitation !Indeed, since it has the ownership on the memory allocated by it, it is difficult to have some memory shared between objects. Luckily for us, the next smart pointer will help us to do just that. 😉\n\nLike , is a smart pointer, but unlike which has the ownership over the object it points at, has a shared ownership over the object it points at.This mean that you can have several owning the same object whereas if you try to do that with , the first to be destroy will destroy the object pointed, and the other will point to not-owned memory which will trigger undefined behavior in your program.\n\nIndeed, if several hold the ownership on the same object, then the object will be destroyed only when the last pointing at it will be destroyed.Moreover, as for the smart pointer you have the function template , you have the function template std::make_shared which does the same for .\n\nUsing only , you will probably encounter one last case in your program.For now, we have been talking about the case where are the pointers want to have the ownership.But what if you what to have some pointers with the ownership over an object and some without any ownership to the same object ? 🤔\n\nI suppose you could use raw pointers, as they are not owning anything and check all the time if the element pointed is still valid somehow unless the are all destroy between your check and when you want to use the object pointed. You can imagine this case for a connection to a service where one entity in your program as the ownership, and the other part of you program only want to access the connection if it is valid, for example.\n\nTo facilitate such situation, there is a last smart pointer, which is non-owning, named std::weak_ptr. This smart pointer has a reference to an object owned by at least one , and can take the shared ownership if you want to, so that you won’t have a problem if when accessing the object pointed, the other are destroyed.\n\nI encourage you too look at examples online, and play with it on godbolt to master how and work together 😉\n\nWhat about \"regular\" pointer then ?\n\nNow that we have smart pointers, we can ask ourselves if there is a need for regular raw pointers.Actually, there are still some use for it. If you want to use inheritance and dynamic_cast, for example, then you may want to use raw pointers.\n\nBut the more we advance in C++, the less likely we will be to need raw pointers.For example, before C++17, you could have used raw pointers to point to an object that could or not be there, but now, you should prefer using std::optional.\n\nIf I have to resume the point of this article in 4 words, it would be \"Please, use smart pointers\" 😆\n\nMore seriously, every programmer should have a notion of how memory is managed by the language he uses, so that we would understand what is going when the program has a problem with memory management. And more especially C++ developer, since all those tools, the smart pointers are available to us, we should definitely use the one that match perfectly our needs in each situation.\n\nThank you all for reading this article ! If you want more information, I recommend you with the talk of Herb Sutter named \"Leak Freedom in C++… By Default\"And until my next article, have an splendid day 😉\n\nIf only they could talk"
    },
    {
        "link": "https://stackoverflow.com/questions/48719612/is-smart-pointer-a-good-practice-of-raii",
        "document": "To start with, here is a discussion of RAII&Smart Pointer.\n\n I've always thought that Smart Pointer like is a good practice of RAII because it gets the heap memory resource at constructor like\n\nand could free the memory at right time through reference counting and its destructor.\n\n However, this morning my collegue told me that:\n\n\"smart pointer is not what i thought to be RAII. The only thing that can strictly be called as RAII in the STL is , the others are nothing more than RRID. \"\n\nSo did i get something wrong? Or what my collegue said actually made non-sense?"
    },
    {
        "link": "https://arbisoft.com/blogs/efficient-memory-management-in-c-techniques-tools-and-best-practices",
        "document": "\n• None Arbisoft is your one-stop shop when it comes to your eLearning needs. Our Ed-tech services are designed to improve the learning experience and simplify educational operations. Companies that we have worked with\n• None “Arbisoft has been a valued partner to edX since 2013. We work with their engineers day in and day out to advance the Open edX platform and support our learners across the world.”\n• None Get cutting-edge travel tech solutions that cater to your users’ every need. We have been employing the latest technology to build custom travel solutions for our clients since 2007. Companies that we have worked with\n• None “Arbisoft has been my most trusted technology partner for now over 15 years. Arbisoft has very unique methods of recruiting and training, and the results demonstrate that. They have great teams, great positive attitudes and great communication.”\n• None As a long-time contributor to the healthcare industry, we have been at the forefront of developing custom healthcare technology solutions that have benefitted millions. Companies that we have worked with\n• None I wanted to tell you how much I appreciate the work you and your team have been doing of all the overseas teams I've worked with, yours is the most communicative, most responsive and most talented.\n• None We take pride in meeting the most complex needs of our clients and developing stellar fintech solutions that deliver the greatest value in every aspect. Companies that we have worked with\n• None “Arbisoft is an integral part of our team and we probably wouldn't be here today without them. Some of their team has worked with us for 5-8 years and we've built a trusted business relationship. We share successes together.”\n• None Unlock innovative solutions for your e-commerce business with Arbisoft’s seasoned workforce. Reach out to us with your needs and let’s get to work! Companies that we have worked with\n• None The development team at Arbisoft is very skilled and proactive. They communicate well, raise concerns when they think a development approach wont work and go out of their way to ensure client needs are met.\n• None Arbisoft is a holistic technology partner, adept at tailoring solutions that cater to business needs across industries. Partner with us to go from conception to completion! Companies that we have worked with\n• None “The app has generated significant revenue and received industry awards, which is attributed to Arbisoft’s work. Team members are proactive, collaborative, and responsive”."
    }
]