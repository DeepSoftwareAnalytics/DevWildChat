[
    {
        "link": "https://tensorflow.org/tutorials/keras/save_and_load",
        "document": "Save and categorize content based on your preferences.\n\nStay organized with collections Save and categorize content based on your preferences.\n\nModel progress can be saved during and after training. This means a model can resume where it left off and avoid long training times. Saving also means you can share your model and others can recreate your work. When publishing research models and techniques, most machine learning practitioners share:\n• code to create the model, and\n• the trained weights, or parameters, for the model\n\nSharing this data helps others understand how the model works and try it themselves with new data.\n\nThere are different ways to save TensorFlow models depending on the API you're using. This guide uses tf.keras—a high-level API to build and train models in TensorFlow. The new, high-level format used in this tutorial is recommended for saving Keras objects, as it provides robust, efficient name-based saving that is often easier to debug than low-level or legacy formats. For more advanced saving or serialization workflows, especially those involving custom objects, please refer to the Save and load Keras models guide. For other approaches, refer to the Using the SavedModel format guide.\n\nGet an example dataset\n\nTo demonstrate how to save and load weights, you'll use the MNIST dataset. To speed up these runs, use the first 1000 examples:\n\nYou can use a trained model without having to retrain it, or pick-up training where you left off in case the training process was interrupted. The callback allows you to continually save the model both during and at the end of training.\n\nCreate a callback that saves weights only during training:\n\nThis creates a single collection of TensorFlow checkpoint files that are updated at the end of each epoch:\n\nAs long as two models share the same architecture you can share weights between them. So, when restoring a model from weights-only, create a model with the same architecture as the original model and then set its weights.\n\nNow rebuild a fresh, untrained model and evaluate it on the test set. An untrained model will perform at chance levels (~10% accuracy):\n\nThen load the weights from the checkpoint and re-evaluate:\n\nThe callback provides several options to provide unique names for checkpoints and adjust the checkpointing frequency.\n\nTrain a new model, and save uniquely named checkpoints once every five epochs:\n\nNow, review the resulting checkpoints and choose the latest one:\n\nTo test, reset the model, and load the latest checkpoint:\n\nWhat are these files?\n\nThe above code stores the weights to a collection of checkpoint-formatted files that contain only the trained weights in a binary format. Checkpoints contain:\n• One or more shards that contain your model's weights.\n• An index file that indicates which weights are stored in which shard.\n\nIf you are training a model on a single machine, you'll have one shard with the suffix:\n\nTo save weights manually, use . By default, —and the method in particular—uses the TensorFlow Checkpoint format with a extension. To save in the HDF5 format with a extension, refer to the Save and load models guide.\n\nCall to save a model's architecture, weights, and training configuration in a single zip archive.\n\nAn entire model can be saved in three different file formats (the new format and two legacy formats: , and ). Saving a model as automatically saves in the latest format.\n\nYou can switch to the SavedModel format by:\n\nYou can switch to the H5 format by:\n\nSaving a fully-functional model is very useful—you can load them in TensorFlow.js (Saved Model, HDF5) and then train and run them in web browsers, or convert them to run on mobile devices using TensorFlow Lite (Saved Model, HDF5)\n\n*Custom objects (for example, subclassed models or layers) require special attention when saving and loading. Refer to the Saving custom objects section below.\n\nThe new Keras v3 saving format, marked by the extension, is a more simple, efficient format that implements name-based saving, ensuring what you load is exactly what you saved, from Python's perspective. This makes debugging much easier, and it is the recommended format for Keras.\n\nThe section below illustrates how to save and restore the model in the format.\n\nTry running evaluate and predict with the loaded model:\n\nThe SavedModel format is another way to serialize models. Models saved in this format can be restored using and are compatible with TensorFlow Serving. The SavedModel guide goes into detail about how to the SavedModel. The section below illustrates the steps to save and restore the model.\n\nThe SavedModel format is a directory containing a protobuf binary and a TensorFlow checkpoint. Inspect the saved model directory:\n\nThe restored model is compiled with the same arguments as the original model. Try running evaluate and predict with the loaded model:\n\nKeras provides a basic legacy high-level save format using the HDF5 standard.\n\nNow, recreate the model from that file:\n\nKeras saves models by inspecting their architectures. This technique saves everything:\n• The model's training configuration (what you pass to the method)\n• The optimizer and its state, if any (this enables you to restart training where you left off)\n\nKeras is not able to save the optimizers (from ) since they aren't compatible with checkpoints. For v1.x optimizers, you need to re-compile the model after loading—losing the state of the optimizer.\n\nIf you are using the SavedModel format, you can skip this section. The key difference between high-level /HDF5 formats and the low-level SavedModel format is that the /HDF5 formats uses object configs to save the model architecture, while SavedModel saves the execution graph. Thus, SavedModels are able to save custom objects like subclassed models and custom layers without requiring the original code. However, debugging low-level SavedModels can be more difficult as a result, and we recommend using the high-level format instead due to its name-based, Keras-native nature.\n\nTo save custom objects to and HDF5, you must do the following:\n• Define a method in your object, and optionally a classmethod.\n• returns a JSON-serializable dictionary of parameters needed to recreate the object.\n• uses the returned config from to create a new object. By default, this function will use the config as initialization kwargs ( ).\n• Pass the custom objects to the model in one of three ways:\n• Register the custom object with the decorator. (recommended)\n• Directly pass the object to the argument when loading the model. The argument must be a dictionary mapping the string class name to the Python class. E.g.,\n• Use a with the object included in the dictionary argument, and place a call within the scope.\n\nRefer to the Writing layers and models from scratch tutorial for examples of custom objects and .\n\n# Permission is hereby granted, free of charge, to any person obtaining a # copy of this software and associated documentation files (the \"Software\"), # to deal in the Software without restriction, including without limitation # the rights to use, copy, modify, merge, publish, distribute, sublicense, # and/or sell copies of the Software, and to permit persons to whom the # Software is furnished to do so, subject to the following conditions: # The above copyright notice and this permission notice shall be included in # all copies or substantial portions of the Software. # THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR # IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, # FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL # THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER # LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING # FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER"
    },
    {
        "link": "https://machinelearningmastery.com/save-load-keras-deep-learning-models",
        "document": "Keras is a simple and powerful Python library for deep learning.\n\nSince deep learning models can take hours, days, and even weeks to train, it is important to know how to save and load them from a disk.\n\nIn this post, you will discover how to save your Keras models to files and load them up again to make predictions.\n\nAfter reading this tutorial, you will know:\n• How to save model weights and model architecture in separate files\n• How to save model architecture in both YAML and JSON format\n• How to save model weights and architecture into a single file for later use\n\nKick-start your project with my new book Deep Learning With Python, including step-by-step tutorials and the Python source code files for all examples.\n• Update Mar/2017: Updated examples for changes to the Keras API\n• Update May/2019: Added section on saving and loading the model to a single file\n• Update Jun/2022: Added note about deprecated YAML format and added section about protocol buffer\n\nIf you are new to Keras or deep learning, see this step-by-step Keras tutorial.\n\nKeras separates the concerns of saving your model architecture and saving your model weights.\n\nModel weights are saved to an HDF5 format. This grid format is ideal for storing multi-dimensional arrays of numbers.\n\nThe model structure can be described and saved using two different formats: JSON and YAML.\n\nIn this post, you will look at three examples of saving and loading your model to a file:\n\nThe first two examples save the model architecture and weights separately. The model weights are saved into an HDF5 format file in all cases.\n\nThe examples will use the same simple network trained on the Pima Indians onset of diabetes binary classification dataset. This is a small dataset that contains all numerical data and is easy to work with. You can download this dataset and place it in your working directory with the filename “pima-indians-diabetes.csv” (update: download from here).\n\nConfirm that you have TensorFlow v2.x installed (e.g., v2.9 as of June 2022).\n\nNote: Saving models requires that you have the h5py library installed. It is usually installed as a dependency with TensorFlow. You can also install it easily as follows:\n\nKeras provides the ability to describe any model using JSON format with a to_json() function. This can be saved to a file and later loaded via the model_from_json() function that will create a new model from the JSON specification.\n\nThe weights are saved directly from the model using the save_weights() function and later loaded using the symmetrical load_weights() function.\n\nThe example below trains and evaluates a simple model on the Pima Indians dataset. The model is then converted to JSON format and written to model.json in the local directory. The network weights are written to model.h5 in the local directory.\n\nThe model and weight data is loaded from the saved files, and a new model is created. It is important to compile the loaded model before it is used. This is so that predictions made using the model can use the appropriate efficient computation from the Keras backend.\n\nThe model is evaluated in the same way, printing the same evaluation score.\n\nNote: Your results may vary given the stochastic nature of the algorithm or evaluation procedure, or differences in numerical precision. Consider running the example a few times and compare the average outcome.\n\nRunning this example provides the output below.\n\nThe JSON format of the model looks like the following:\n\nNote: This method only applies to TensorFlow 2.5 or earlier. If you run it in later versions of TensorFlow, you will see a RuntimeError with the message “Method has been removed due to security risk of arbitrary code execution. Please use instead.”\n\nThis example is much the same as the above JSON example, except the YAML format is used for the model specification.\n\nNote, this example assumes that you have PyYAML 5 installed:\n\nIn this example, the model is described using YAML, saved to file model.yaml, and later loaded into a new model via the model_from_yaml() function.\n\nWeights are handled the same way as above in the HDF5 format as model.h5.\n\nNote: Your results may vary given the stochastic nature of the algorithm or evaluation procedure, or differences in numerical precision. Consider running the example a few times and compare the average outcome.\n\nRunning the example displays the following output.\n\nThe model described in YAML format looks like the following:\n\nKeras also supports a simpler interface to save both the model weights and model architecture together into a single H5 file.\n\nSaving the model in this way includes everything you need to know about the model, including:\n\nThis means that you can load and use the model directly without having to re-compile it as you had to in the examples above.\n\nNote: This is the preferred way for saving and loading your Keras model.\n\nYou can save your model by calling the save() function on the model and specifying the filename.\n\nThe example below demonstrates this by first fitting a model, evaluating it, and saving it to the file model.h5.\n\nNote: Your results may vary given the stochastic nature of the algorithm or evaluation procedure, or differences in numerical precision. Consider running the example a few times and compare the average outcome.\n\nRunning the example fits the model, summarizes the model’s performance on the training dataset, and saves the model to file.\n\nYou can later load this model from the file and use it.\n\nNote that in the Keras library, there is another function doing the same, as follows:\n\nYour saved model can then be loaded later by calling the function and passing the filename. The function returns the model with the same architecture and weights.\n\nIn this case, you load the model, summarize the architecture, and evaluate it on the same dataset to confirm the weights and architecture are the same.\n\nRunning the example first loads the model, prints a summary of the model architecture, and then evaluates the loaded model on the same dataset.\n\nNote: Your results may vary given the stochastic nature of the algorithm or evaluation procedure, or differences in numerical precision. Consider running the example a few times and compare the average outcome.\n\nThe model achieves the same accuracy score, which in this case is 77%.\n\nWhile saving and loading a Keras model using HDF5 format is the recommended way, TensorFlow supports yet another format, the protocol buffer. It is considered faster to save and load a protocol buffer format, but doing so will produce multiple files. The syntax is the same, except that you do not need to provide the extension to the filename:\n\nThese will create a directory “model” with the following files:\n\nThis is also the format used to save a model in TensorFlow v1.x. You may encounter this when you download a pre-trained model from TensorFlow Hub.\n• How can I save a Keras model? in the Keras documentation\n• About Keras models in the Keras documentation\n\nIn this post, you discovered how to serialize your Keras deep learning models.\n\nYou learned how to save your trained models to files, later load them up, and use them to make predictions.\n\nYou also learned that model weights are easily stored using HDF5 format and that the network structure can be saved in either JSON or YAML format.\n\nDo you have any questions about saving your deep learning models or this post?\n\n Ask your questions in the comments, and I will do my best to answer them."
    },
    {
        "link": "https://geeksforgeeks.org/tf-keras-models-load_model-in-tensorflow",
        "document": "TensorFlow is an open-source machine-learning library developed by Google. In this article, we are going to explore the how can we load a model in TensorFlow.\n\ntf.keras.models.load_model function is used to load saved models from storage for further use. It allows users to easily retrieve trained models from disk or other storage mediums.\n\nThe syntax of the tf.keras.models.load_model function is as follows:\n• file path: This argument specifies the path to the saved model file or an h5py.File object from which to load the model.\n• custom_objects: An optional dictionary that maps names (strings) to custom classes or functions to be considered during deserialization. This parameter proves invaluable when dealing with models containing custom layers or loss functions.\n• compile : A boolean flag indicating whether to compile the loaded model after loading. When set to True, the model will be compiled, leveraging the optimizer and loss function specified during training. Conversely, setting it to False allows for skipping compilation, useful when solely interested in model inference.\n\nThis code defines a simple CNN model with three convolutional layers followed by max pooling, flattening, and two dense layers for classification. The model takes input images of size 128x128 pixels with 3 channels (RGB) and outputs a probability distribution over 10 classes using SoftMax activation.\n\nWe load a saved model from the file 'model.h5' using TensorFlow's function and then prints a summary of the loaded model, showing the model architecture, layer names, output shapes, and number of parameters.\n\nIn conclusion, the tf.keras.models.load_model function is a powerful tool for loading saved Keras models in TensorFlow. By understanding its usage and arguments, developers can seamlessly integrate saved models into their applications, enabling efficient model deployment and inference."
    },
    {
        "link": "https://keras.io/api/models/model_saving_apis/model_saving_and_loading",
        "document": "\n• filepath: or object. The path where to save the model. Must end in (unless saving the model as an unzipped directory via ).\n• overwrite: Whether we should overwrite any existing model at the target location, or instead ask the user via an interactive prompt.\n• zipped: Whether to save the model as a zipped archive (default when saving locally), or as an unzipped directory (default when saving on the Hugging Face Hub).\n\nNote that is an alias for .\n• The model's optimizer's state (if any)\n\nThus models can be reinstantiated in the exact same state.\n• filepath: or object. Path where to save the model.\n• overwrite: Whether we should overwrite any existing model at the target location, or instead ask the user via an interactive prompt.\n• zipped: Whether to save the model as a zipped archive (default when saving locally), or as an unzipped directory (default when saving on the Hugging Face Hub).\n\nNote that is an alias for .\n\nThe saved file is a archive that contains:\n• The model's optimizer's state (if any)\n\nThus models can be reinstantiated in the exact same state.\n• filepath: or object, path to the saved model file.\n• custom_objects: Optional dictionary mapping names (strings) to custom classes or functions to be considered during deserialization.\n• compile: Boolean, whether to compile the model after loading.\n• safe_mode: Boolean, whether to disallow unsafe deserialization. When , loading an object has the potential to trigger arbitrary code execution. This argument is only applicable to the Keras v3 model format. Defaults to .\n\nA Keras model instance. If the original model was compiled, and the argument is set, then the returned model will be compiled. Otherwise, the model will be left uncompiled.\n\nNote that the model variables may have different name values ( property, e.g. ) after being reloaded. It is recommended that you use layer attributes to access specific variables, e.g. ."
    },
    {
        "link": "https://pyimagesearch.com/2018/12/10/keras-save-and-load-your-deep-learning-models",
        "document": "In this tutorial, you will learn how to save and load your Keras deep learning models.\n\nThis blog post was inspired by PyImageSearch reader, Mason, who emailed in last week and asked:\n\nMason asks an excellent question — and it’s actually not as “basic” of a concept as he (and maybe even you) may think.\n\nOn the surface, saving your Keras models is as simple as calling the and function. But there’s actually more to consider than just the load and save model functions!\n\nWhat’s even more important, and sometimes overlooked by new deep learning practitioners, is the preprocessing stage — your preprocessing steps for training and validation must be identical to the training steps when loading your model and classifying new images.\n\nIn the remainder of today’s tutorial we’ll be exploring:\n• How to properly save and load your Keras deep learning models.\n• The proper steps to preprocess your images after loading your model.\n\nTo learn how to save and load your deep learning models with Keras, just keep reading!\n\n2020-06-03 Update: This blog post is now TensorFlow 2+ compatible!\n\nIn the first part of this tutorial, we’ll briefly review both (1) our example dataset we’ll be training a Keras model on, along with (2) our project directory structure. From there I will show you how to:\n• Serialize and save your Keras model to disk\n• Make predictions on new image data using your saved Keras model\n\nLet’s go ahead and get started!\n\nTo configure your system for this tutorial, I first recommend following either of these tutorials:\n• How to install TensorFlow 2.0 on Ubuntu\n• How to install TensorFlow 2.0 on macOS\n\nEither tutorial will help you configure you system with all the necessary software for this blog post in a convenient Python virtual environment.\n\nPlease note that PyImageSearch does not recommend or support Windows for CV/DL projects.\n\nThe dataset we’ll be utilizing for today’s tutorial is a subset of the malaria detection and classification dataset we covered in last week’s Deep learning and Medical Image Analysis with Keras blog post.\n\nThe original dataset consists of 27,588 images belonging to two classes:\n• Parasitized: Implying that the image contains malaria\n• Uninfected: Meaning there is no evidence of malaria in the image\n\nSince the goal of this tutorial is not medical image analysis, but rather how to save and load your Keras models, I have sampled the dataset down to 100 images.\n\nI have reduced the dataset size mainly because:\n• You should be able to run this example on your CPU (if you do not own/have access to a GPU).\n• Our goal here is to teach the basic concept of saving and loading Keras models, not train a state-of-the-art malaria detector.\n• And because of that, it’s better to work with a smaller example dataset\n\nIf you would like to read my full blog post on how to build a (near) state-of-the-art malaria classifier with the full dataset, please be sure to refer to this blog post.\n\nBe sure to grab today’s “Downloads” consisting of the reduced dataset, ResNet model, and Python scripts.\n\nOnce you’ve unzipped the files you’ll be presented with this directory structure:\n\nOur project consists of two folders in the root directory:\n• : Our reduced Malaria dataset. It is organized into training, validation, and testing sets via the “build dataset” script from last week.\n• : A package included with the downloads which contains our ResNet model class.\n\nToday, we’ll review two Python scripts as well:\n• : A demo script which will save our Keras model to disk after it has been trained.\n• : Our script that loads the saved model from disk and classifies a small selection of testing images.\n\nBy reviewing these files, you’ll quickly see how easy Keras makes saving and loading deep learning model files.\n\nBefore we can load a Keras model from disk we first need to:\n\nThe script we’re about to review will cover both of these concepts.\n\nGo ahead and open up your file and let’s get started:\n\nWe begin on Lines 2-14 by importing required packages.\n\nOn Line 3 the matplotlib backend is specified as we’ll be saving our plot to disk (in addition to our model).\n\nOur CNN is imported on Line 8. In order to use this CNN, be sure to grab the “Downloads” for today’s blog post.\n\nUsing the import, let’s parse our command line arguments:\n\nOur script requires that three arguments be provided with the command string in your terminal:\n• : The path to our dataset. We’re using a subset of the Malaria dataset that we built last week.\n• : You need to specify the path to the trained output model (i.e., where the Keras model is going to be saved). This is key for what we are covering today.\n• : The path to the training plot. By default, the figure will be named .\n\nNo modifications are needed for these lines of code. Again, you will need to type the values for the arguments in the terminal and let do the rest. If you are unfamiliar with the concept of command line arguments, see this post.\n\nWe’ll be training for epochs with a batch size of .\n\nLast week, we split the NIH Malaria Dataset into three sets, creating a corresponding directory for each:\n\nBe sure to review the script in the tutorial if you’re curious how the data split process works. For today, I’ve taken the resulting dataset that has been split (as well as made is significantly smaller for the purposes of this blog post).\n\nThe images paths are built on Lines 32-34, and the number of images in each split is grabbed on Lines 38-40.\n\nData augmentation is the process of generating new images from a dataset with random modifications. It results in a better deep learning model and I almost always recommend it (it is especially important for small datasets).\n\nData augmentation is briefly covered in my Keras Tutorial blog post. For a full dive into data augmentation be sure to read my deep learning book, Deep Learning for Computer Vision with Python.\n\nNote: The object simply performs scaling — no augmentation is actually performed. We’ll be using this object twice: once for validation rescaling and once for testing rescaling.\n\nNow that the training and validation augmentation objects are created, let’s initialize the generators:\n\nThe three generators above actually produce images on demand during training/validation/testing per our augmentation objects and the parameters given here.\n\nNow we’re going to build, compile, and train our model. We’ll also evaluate our model and print a classification report:\n\n2020-06-03 Update: Formerly, TensorFlow/Keras required use of a method called in order to accomplish data augmentation. Now, the method can handle data augmentation as well, making for more-consistent code. This also applies to the migration from to . Be sure to check out my articles about fit and fit generator as well as data augmentation.\n\nIn the code block above, we:\n• Initialize our implementation of on Lines 84-88 (from Deep Learning for Computer Vision with Python). Notice how we’ve specified because our model has two classes. You should change it to if you are working with > 2 classes.\n• Train the ResNet on the augmented Malaria dataset (Lines 91-96).\n• Make predictions on test set (Line 102) and extract the highest probability class index for each prediction (Line 106).\n\nNow that our model is trained let’s save our Keras model to disk:\n\nTo save our Keras model to disk, we simply call on the (Line 114).\n\n2020-06-03 Update: Note that for TensorFlow 2.0+ we recommend explicitly setting the (HDF5 format).\n\nYes, it is a simple function call, but the hard work before it made the process possible.\n\nIn our next script, we’ll be able to load the model from disk and make predictions.\n\nLet’s plot the training results and save the training plot as well:\n\n2020-06-03 Update: In order for this plotting snippet to be TensorFlow 2+ compatible the dictionary keys are updated to fully spell out “accuracy” sans “acc” (i.e., and ). It is semi-confusing that “val” is not spelled out as “validation”; we have to learn to love and live with the API and always remember that it is a work in progress that many developers around the world contribute to.\n\nAt this point our script is complete. Let’s go ahead and train our Keras model!\n\nTo train your Keras model on our example dataset, make sure you use the “Downloads” section of the blog post to download the source code and images themselves.\n\nFrom there, open up a terminal and execute the following command:\n\nNotice the command line arguments. I’ve specified the path to the Malaria dataset directory ( ) and the path to our destination model ( ). These command line arguments are key to the operation of this script. You can name your model whatever you’d like without changing a line of code!\n\nHere you can see that our model is obtaining ~99% accuracy on the test set.\n\nEach epoch is taking ~7 seconds on my CPU. On my GPU each epoch takes ~1 second. Keep in mind that training is faster than last week because we’re pushing less data through the network for each epoch due to the fact that I reduced today’s dataset.\n\nAfter training you can list the contents of your directory and see the saved Keras model:\n\nThe file is your actual saved Keras model.\n\nYou will learn how to load your saved Keras model from disk in the next section.\n\nNow that we’ve learned how to save a Keras model to disk, the next step is to load the Keras model so we can use it for making classifications. Open up your script and let’s get started:\n\nWe import our required packages on Lines 2-10. Most notably we need in order to load our model from disk and put it to use.\n\nOur two command line arguments are parsed on Lines 12-17:\n• : The path to the images we’d like to make predictions with.\n• : The path to the model we just saved previously.\n\nAgain, these lines don’t need to change. When you enter the command in your terminal you’ll provide values for both and .\n\nThe next step is to load our Keras model from disk:\n\nOn Line 21, to load our Keras , we call , providing the path to the model itself (contained within our parsed dictionary).\n\nGiven the , we can now make predictions with it. But first we’ll need some images to work with and a place to put our results:\n\nOn Lines 24-26, we grab a random selection of testing image paths.\n\nLine 29 initializes an empty list to hold the .\n\nLet’s loop over each of our :\n\nOn Line 32 we begin looping over our .\n\nWe begin the loop by loading our image from disk (Line 34) and preprocessing it (Lines 40-42). These preprocessing steps should be identical to those taken in our training script. As you can see, we’ve converted the images from BGR to RGB channel ordering, resized to 64×64 pixels, and scaled to the range [0, 1].\n\nA common mistake I see new deep learning practitioners make is failing to preprocess new images in the same manner as their training images.\n\nMoving on, let’s make a prediction an each iteration of the loop:\n\nIn this block we:\n• Handle channel ordering (Line 47). The TensorFlow backend default is , but don’t forget that Keras supports alternative backends as well.\n• Create a batch to send through the network by adding a dimension to the volume (Line 48). We’re just sending one image through the network at a time, but the additional dimension is critical.\n• Pass image through ResNet (Line 51), obtaining a prediction. We take the index of the max prediction (either or ) on Line 52.\n• Then we create a colored label and draw it on the original image (Lines 56-63).\n• Finally, we append the annotated image to .\n\nTo visualize our results let’s create a montage and display it on the screen:\n\nA of results is built on Line 69. Our is a 4×4 grid of images to accommodate the 16 random testing images we grabbed earlier on. Learn how this function works in my blog post, Montages with OpenCV.\n\nThe will be displayed until any key is pressed (Lines 72 and 73).\n\nTo see our script in action make sure you use the “Downloads” section of the tutorial to download the source code and dataset of images.\n\nFrom there, open up a terminal and execute the following command:\n\nHere you can see that we have:\n• Provided the path to our testing images ( ) as well as the model already residing on disk ( ) via command line argument\n• Classified each of the example images\n• Constructed an output visualization of our classifications (Figure 5)\n\nThis process was made possible due to the fact we were able to save our Keras model from disk in the training script and then load the Keras model from disk in a separate script.\n• How to train a Keras model on a dataset\n• How to serialize and save your Keras model to disk\n• How to load your saved Keras model from a separate Python script\n• How to classify new input images using your loaded Keras model\n\nYou can use the Python scripts covered in today’s tutorial as templates when training, saving, and loading your own Keras models.\n\nTo download the source code to today’s tutorial, and be notified when future blog posts are published here on PyImageSearch, just enter your email address in the form below!"
    },
    {
        "link": "https://keras.io/guides/training_with_built_in_methods",
        "document": "Author: fchollet\n\n Date created: 2019/03/01\n\n Last modified: 2023/06/25\n\n Description: Complete guide to training & evaluation with and .\n\nThis guide covers training, evaluation, and prediction (inference) models when using built-in APIs for training & validation (such as , and ).\n\nIf you are interested in leveraging while specifying your own training step function, see the guides on customizing what happens in :\n\nIf you are interested in writing your own training & evaluation loops from scratch, see the guides on writing training loops:\n\nIn general, whether you are using built-in loops or writing your own, model training & evaluation works strictly in the same way across every kind of Keras model – Sequential models, models built with the Functional API, and models written from scratch via model subclassing.\n\nWhen passing data to the built-in training loops of a model, you should either use:\n• NumPy arrays (if your data is small and fits in memory)\n\nIn the next few paragraphs, we'll use the MNIST dataset as NumPy arrays, in order to demonstrate how to use optimizers, losses, and metrics. Afterwards, we'll take a close look at each of the other options.\n\nLet's consider the following model (here, we build in with the Functional API, but it could be a Sequential model or a subclassed model as well):\n\nHere's what the typical end-to-end workflow looks like, consisting of:\n• Validation on a holdout set generated from the original training data\n\nWe'll use MNIST data for this example.\n\nWe specify the training configuration (optimizer, loss, metrics):\n\nWe call , which will train the model by slicing the data into \"batches\" of size , and repeatedly iterating over the entire dataset for a given number of .\n\nThe returned object holds a record of the loss values and metric values during training:\n\nWe evaluate the model on the test data via :\n\nNow, let's review each piece of this workflow in detail.\n\nThe method: specifying a loss, metrics, and an optimizer\n\nTo train a model with , you need to specify a loss function, an optimizer, and optionally, some metrics to monitor.\n\nYou pass these to the model as arguments to the method:\n\nThe argument should be a list – your model can have any number of metrics.\n\nIf your model has multiple outputs, you can specify different losses and metrics for each output, and you can modulate the contribution of each output to the total loss of the model. You will find more details about this in the Passing data to multi-input, multi-output models section.\n\nNote that if you're satisfied with the default settings, in many cases the optimizer, loss, and metrics can be specified via string identifiers as a shortcut:\n\nFor later reuse, let's put our model definition and compile step in functions; we will call them several times across different examples in this guide.\n\nMany built-in optimizers, losses, and metrics are available\n\nIn general, you won't have to create your own losses, metrics, or optimizers from scratch, because what you need is likely to be already part of the Keras API:\n\nIf you need to create a custom loss, Keras provides three ways to do so.\n\nThe first method involves creating a function that accepts inputs and . The following example shows a loss function that computes the mean squared error between the real data and the predictions:\n\nIf you need a loss function that takes in parameters beside and , you can subclass the class and implement the following two methods:\n• : accept parameters to pass during the call of your loss function\n• : use the targets (y_true) and the model predictions (y_pred) to compute the model's loss\n\nLet's say you want to use mean squared error, but with an added term that will de-incentivize prediction values far from 0.5 (we assume that the categorical targets are one-hot encoded and take values between 0 and 1). This creates an incentive for the model not to be too confident, which may help reduce overfitting (we won't know if it works until we try!).\n\nHere's how you would do it:\n\nIf you need a metric that isn't part of the API, you can easily create custom metrics by subclassing the class. You will need to implement 4 methods:\n• , in which you will create state variables for your metric.\n• , which uses the targets y_true and the model predictions y_pred to update the state variables.\n• , which uses the state variables to compute the final results.\n• , which reinitializes the state of the metric.\n\nState update and results computation are kept separate (in and , respectively) because in some cases, the results computation might be very expensive and would only be done periodically.\n\nHere's a simple example showing how to implement a metric that counts how many samples were correctly classified as belonging to a given class:\n\nHandling losses and metrics that don't fit the standard signature\n\nThe overwhelming majority of losses and metrics can be computed from and , where is an output of your model – but not all of them. For instance, a regularization loss may only require the activation of a layer (there are no targets in this case), and this activation may not be a model output.\n\nIn such cases, you can call from inside the call method of a custom layer. Losses added in this way get added to the \"main\" loss during training (the one passed to ). Here's a simple example that adds activity regularization (note that activity regularization is built-in in all Keras layers – this layer is just for the sake of providing a concrete example):\n\nNote that when you pass losses via , it becomes possible to call without a loss function, since the model already has a loss to minimize.\n\nConsider the following layer: it takes as inputs targets & logits, and it tracks a crossentropy loss via .\n\nYou can use it in a model with two inputs (input data & targets), compiled without a argument, like this:\n\nFor more information about training multi-input models, see the section Passing data to multi-input, multi-output models.\n\nIn the first end-to-end example you saw, we used the argument to pass a tuple of NumPy arrays to the model for evaluating a validation loss and validation metrics at the end of each epoch.\n\nHere's another option: the argument allows you to automatically reserve part of your training data for validation. The argument value represents the fraction of the data to be reserved for validation, so it should be set to a number higher than 0 and lower than 1. For instance, means \"use 20% of the data for validation\", and means \"use 60% of the data for validation\".\n\nThe way the validation is computed is by taking the last x% samples of the arrays received by the call, before any shuffling.\n\nNote that you can only use when training with NumPy data.\n\nIn the past few paragraphs, you've seen how to handle losses, metrics, and optimizers, and you've seen how to use the and arguments in , when your data is passed as NumPy arrays.\n\nAnother option is to use an iterator-like, such as a , a PyTorch , or a Keras . Let's take look at the former.\n\nThe API is a set of utilities in TensorFlow 2.0 for loading and preprocessing data in a way that's fast and scalable. For a complete guide about creating , see the tf.data documentation.\n\nYou can use to train your Keras models regardless of the backend you're using – whether it's JAX, PyTorch, or TensorFlow. You can pass a instance directly to the methods , , and :\n\nNote that the Dataset is reset at the end of each epoch, so it can be reused of the next epoch.\n\nIf you want to run training only on a specific number of batches from this Dataset, you can pass the argument, which specifies how many training steps the model should run using this Dataset before moving on to the next epoch.\n\nYou can also pass a instance as the argument in :\n\nAt the end of each epoch, the model will iterate over the validation dataset and compute the validation loss and validation metrics.\n\nIf you want to run validation only on a specific number of batches from this dataset, you can pass the argument, which specifies how many validation steps the model should run with the validation dataset before interrupting validation and moving on to the next epoch:\n\nNote that the validation dataset will be reset after each use (so that you will always be evaluating on the same samples from epoch to epoch).\n\nThe argument (generating a holdout set from the training data) is not supported when training from objects, since this feature requires the ability to index the samples of the datasets, which is not possible in general with the API.\n\nis a utility that you can subclass to obtain a Python generator with two important properties:\n• It works well with multiprocessing.\n• It can be shuffled (e.g. when passing in ).\n\nThe method should return a complete batch. If you want to modify your dataset between epochs, you may implement .\n\nTo fit the model, pass the dataset instead as the argument (no need for a argument since the dataset includes the targets), and pass the validation dataset as the argument. And no need for the argument, since the dataset is already batched!\n\nEvaluating the model is just as easy:\n\nImportantly, objects support three common constructor arguments that handle the parallel processing configuration:\n• : Number of workers to use in multithreading or multiprocessing. Typically, you'd set it to the number of cores on your CPU.\n• : Whether to use Python multiprocessing for parallelism. Setting this to means that your dataset will be replicated in multiple forked processes. This is necessary to gain compute-level (rather than I/O level) benefits from parallelism. However it can only be set to if your dataset can be safely pickled.\n• : Maximum number of batches to keep in the queue when iterating over the dataset in a multithreaded or multipricessed setting. You can reduce this value to reduce the CPU memory consumption of your dataset. It defaults to 10.\n\nBy default, multiprocessing is disabled ( ) and only one thread is used. You should make sure to only turn on if your code is running inside a Python block in order to avoid issues.\n\nAll built-in training and evaluation APIs are also compatible with and objects – regardless of whether you're using the PyTorch backend, or the JAX or TensorFlow backends. Let's take a look at a simple example.\n\nUnlike which are batch-centric, PyTorch objects are sample-centric: the method returns the number of samples, and the method returns a specific sample.\n\nTo use a PyTorch Dataset, you need to wrap it into a which takes care of batching and shuffling:\n\nNow you can use them in the Keras API just like any other iterator:\n\nWith the default settings the weight of a sample is decided by its frequency in the dataset. There are two methods to weight the data, independent of sample frequency:\n\nThis is set by passing a dictionary to the argument to . This dictionary maps class indices to the weight that should be used for samples belonging to this class.\n\nThis can be used to balance classes without resampling, or to train a model that gives more importance to a particular class.\n\nFor instance, if class \"0\" is half as represented as class \"1\" in your data, you could use .\n\nHere's a NumPy example where we use class weights or sample weights to give more importance to the correct classification of class #5 (which is the digit \"5\" in the MNIST dataset).\n\nFor fine grained control, or if you are not building a classifier, you can use \"sample weights\".\n• When training from NumPy data: Pass the argument to .\n• When training from or any other sort of iterator: Yield tuples.\n\nA \"sample weights\" array is an array of numbers that specify how much weight each sample in a batch should have in computing the total loss. It is commonly used in imbalanced classification problems (the idea being to give more weight to rarely-seen classes).\n\nWhen the weights used are ones and zeros, the array can be used as a mask for the loss function (entirely discarding the contribution of certain samples to the total loss).\n\nIn the previous examples, we were considering a model with a single input (a tensor of shape ) and a single output (a prediction tensor of shape ). But what about models that have multiple inputs or outputs?\n\nConsider the following model, which has an image input of shape (that's ) and a time series input of shape (that's ). Our model will have two outputs computed from the combination of these inputs: a \"score\" (of shape ) and a probability distribution over five classes (of shape ).\n\nLet's plot this model, so you can clearly see what we're doing here (note that the shapes shown in the plot are batch shapes, rather than per-sample shapes).\n\nAt compilation time, we can specify different losses to different outputs, by passing the loss functions as a list:\n\nIf we only passed a single loss function to the model, the same loss function would be applied to every output (which is not appropriate here).\n\nSince we gave names to our output layers, we could also specify per-output losses and metrics via a dict:\n\nWe recommend the use of explicit names and dicts if you have more than 2 outputs.\n\nIt's possible to give different weights to different output-specific losses (for instance, one might wish to privilege the \"score\" loss in our example, by giving to 2x the importance of the class loss), using the argument:\n\nYou could also choose not to compute a loss for certain outputs, if these outputs are meant for prediction but not for training:\n\nPassing data to a multi-input or multi-output model in works in a similar way as specifying a loss function in compile: you can pass lists of NumPy arrays (with 1:1 mapping to the outputs that received a loss function) or dicts mapping output names to NumPy arrays.\n\nHere's the use case: similarly as what we did for NumPy arrays, the should return a tuple of dicts.\n\nCallbacks in Keras are objects that are called at different points during training (at the start of an epoch, at the end of a batch, at the end of an epoch, etc.). They can be used to implement certain behaviors, such as:\n• Doing validation at different points during training (beyond the built-in per-epoch validation)\n• Checkpointing the model at regular intervals or when it exceeds a certain accuracy threshold\n• Changing the learning rate of the model when training seems to be plateauing\n• Doing fine-tuning of the top layers when training seems to be plateauing\n• Sending email or instant message notifications when training ends or where a certain performance threshold is exceeded\n\nCallbacks can be passed as a list to your call to :\n\nMany built-in callbacks are available\n\nThere are many built-in callbacks already available in Keras, such as:\n• : Stop training when training is no longer improving the validation metrics.\n• : periodically write model logs that can be visualized in TensorBoard (more details in the section \"Visualization\").\n\nSee the callbacks documentation for the complete list.\n\nYou can create a custom callback by extending the base class . A callback has access to its associated model through the class property .\n\nMake sure to read the complete guide to writing custom callbacks.\n\nHere's a simple example saving a list of per-batch loss values during training:\n\nWhen you're training model on relatively large datasets, it's crucial to save checkpoints of your model at frequent intervals.\n\nThe easiest way to achieve this is with the callback:\n\nThe callback can be used to implement fault-tolerance: the ability to restart training from the last saved state of the model in case training gets randomly interrupted. Here's a basic example:\n\nYou call also write your own callback for saving and restoring models.\n\nFor a complete guide on serialization and saving, see the guide to saving and serializing Models.\n\nA common pattern when training deep learning models is to gradually reduce the learning as training progresses. This is generally known as \"learning rate decay\".\n\nThe learning decay schedule could be static (fixed in advance, as a function of the current epoch or the current batch index), or dynamic (responding to the current behavior of the model, in particular the validation loss).\n\nYou can easily use a static learning rate decay schedule by passing a schedule object as the argument in your optimizer:\n\nSeveral built-in schedules are available: , , , and .\n\nA dynamic learning rate schedule (for instance, decreasing the learning rate when the validation loss is no longer improving) cannot be achieved with these schedule objects, since the optimizer does not have access to validation metrics.\n\nHowever, callbacks do have access to all metrics, including validation metrics! You can thus achieve this pattern by using a callback that modifies the current learning rate on the optimizer. In fact, this is even built-in as the callback.\n\nVisualizing loss and metrics during training with TensorBoard\n\nThe best way to keep an eye on your model during training is to use TensorBoard – a browser-based application that you can run locally that provides you with:\n• Live plots of the loss and metrics for training and evaluation\n• (optionally) Visualizations of the histograms of your layer activations\n• (optionally) 3D visualizations of the embedding spaces learned by your layers\n\nIf you have installed TensorFlow with pip, you should be able to launch TensorBoard from the command line:\n\nThe easiest way to use TensorBoard with a Keras model and the method is the callback.\n\nIn the simplest case, just specify where you want the callback to write logs, and you're good to go:\n\nFor more information, see the documentation for the callback."
    },
    {
        "link": "https://stackoverflow.com/questions/53494627/loss-in-keras-model-evaluation",
        "document": "When defining a machine learning model, we want a way to measure the performance of our model so that we could compare it with other models to choose the best one and also make sure that it is good enough. Therefore, we define some metrics like accuracy (in the context of classification), which is the proportion of correctly classified samples by the model, to measure how our model performs and whether it is good enough for our task or not.\n\nAlthough these metrics are truly comprehensible by us, however the problem is that they cannot be directly used by the learning process of our models to tune the parameters of the model. Instead, we define other measures, which are usually called loss functions or objective functions, which can be directly used by the training process (i.e. optimization). These functions are usually defined such that we expect that when their values are low we would have a high accuracy. That's why you would commonly see that the machine learning algorithms are trying to minimize a loss function with the expectation that the accuracy increases. In other words, the models are indirectly learning by optimizing the loss functions. The loss values are important during training of the model, e.g. if they are not decreasing or fluctuating then this means there is a problem somewhere that needs to be fixed.\n\nAs a result, what we are ultimately (i.e. when testing a model) concerned about is the value of metrics (like accuracy) we have initially defined and we don't care about the final value of loss functions. That's why you don't hear things like \"the loss value of a [specific model] on the ImageNet dataset is 8.732\"! That does not tell you anything whether the model is great, good, bad or terrible. Rather, you would hear that \"this model performs with 87% accuracy on the ImageNet dataset\"."
    },
    {
        "link": "https://tensorflow.org/guide/keras/training_with_built_in_methods",
        "document": "Stay organized with collections Save and categorize content based on your preferences.\n\nThis guide covers training, evaluation, and prediction (inference) models when using built-in APIs for training & validation (such as , and ).\n\nIf you are interested in leveraging while specifying your own training step function, see the Customizing what happens in guide.\n\nIf you are interested in writing your own training & evaluation loops from scratch, see the guide \"writing a training loop from scratch\".\n\nIn general, whether you are using built-in loops or writing your own, model training & evaluation works strictly in the same way across every kind of Keras model -- Sequential models, models built with the Functional API, and models written from scratch via model subclassing.\n\nThis guide doesn't cover distributed training, which is covered in our guide to multi-GPU & distributed training.\n\nWhen passing data to the built-in training loops of a model, you should either use NumPy arrays (if your data is small and fits in memory) or objects. In the next few paragraphs, we'll use the MNIST dataset as NumPy arrays, in order to demonstrate how to use optimizers, losses, and metrics.\n\nLet's consider the following model (here, we build in with the Functional API, but it could be a Sequential model or a subclassed model as well):\n\nHere's what the typical end-to-end workflow looks like, consisting of:\n• Validation on a holdout set generated from the original training data\n\nWe'll use MNIST data for this example.\n\nWe specify the training configuration (optimizer, loss, metrics):\n\nWe call , which will train the model by slicing the data into \"batches\" of size , and repeatedly iterating over the entire dataset for a given number of .\n\nThe returned object holds a record of the loss values and metric values during training:\n\nWe evaluate the model on the test data via :\n\nNow, let's review each piece of this workflow in detail.\n\nThe method: specifying a loss, metrics, and an optimizer\n\nTo train a model with , you need to specify a loss function, an optimizer, and optionally, some metrics to monitor.\n\nYou pass these to the model as arguments to the method:\n\nThe argument should be a list -- your model can have any number of metrics.\n\nIf your model has multiple outputs, you can specify different losses and metrics for each output, and you can modulate the contribution of each output to the total loss of the model. You will find more details about this in the Passing data to multi-input, multi-output models section.\n\nNote that if you're satisfied with the default settings, in many cases the optimizer, loss, and metrics can be specified via string identifiers as a shortcut:\n\nFor later reuse, let's put our model definition and compile step in functions; we will call them several times across different examples in this guide.\n\nMany built-in optimizers, losses, and metrics are available\n\nIn general, you won't have to create your own losses, metrics, or optimizers from scratch, because what you need is likely to be already part of the Keras API:\n\nIf you need to create a custom loss, Keras provides three ways to do so.\n\nThe first method involves creating a function that accepts inputs and . The following example shows a loss function that computes the mean squared error between the real data and the predictions:\n\nIf you need a loss function that takes in parameters beside and , you can subclass the class and implement the following two methods:\n• : accept parameters to pass during the call of your loss function\n• : use the targets (y_true) and the model predictions (y_pred) to compute the model's loss\n\nLet's say you want to use mean squared error, but with an added term that will de-incentivize prediction values far from 0.5 (we assume that the categorical targets are one-hot encoded and take values between 0 and 1). This creates an incentive for the model not to be too confident, which may help reduce overfitting (we won't know if it works until we try!).\n\nHere's how you would do it:\n\nIf you need a metric that isn't part of the API, you can easily create custom metrics by subclassing the class. You will need to implement 4 methods:\n• , in which you will create state variables for your metric.\n• , which uses the targets y_true and the model predictions y_pred to update the state variables.\n• , which uses the state variables to compute the final results.\n• , which reinitializes the state of the metric.\n\nState update and results computation are kept separate (in and , respectively) because in some cases, the results computation might be very expensive and would only be done periodically.\n\nHere's a simple example showing how to implement a metric that counts how many samples were correctly classified as belonging to a given class:\n\nHandling losses and metrics that don't fit the standard signature\n\nThe overwhelming majority of losses and metrics can be computed from and , where is an output of your model -- but not all of them. For instance, a regularization loss may only require the activation of a layer (there are no targets in this case), and this activation may not be a model output.\n\nIn such cases, you can call from inside the call method of a custom layer. Losses added in this way get added to the \"main\" loss during training (the one passed to ). Here's a simple example that adds activity regularization (note that activity regularization is built-in in all Keras layers -- this layer is just for the sake of providing a concrete example):\n\nNote that when you pass losses via , it becomes possible to call without a loss function, since the model already has a loss to minimize.\n\nConsider the following layer: it takes as inputs targets & logits, and it tracks a crossentropy loss via .\n\nYou can use it in a model with two inputs (input data & targets), compiled without a argument, like this:\n\nFor more information about training multi-input models, see the section Passing data to multi-input, multi-output models.\n\nIn the first end-to-end example you saw, we used the argument to pass a tuple of NumPy arrays to the model for evaluating a validation loss and validation metrics at the end of each epoch.\n\nHere's another option: the argument allows you to automatically reserve part of your training data for validation. The argument value represents the fraction of the data to be reserved for validation, so it should be set to a number higher than 0 and lower than 1. For instance, means \"use 20% of the data for validation\", and means \"use 60% of the data for validation\".\n\nThe way the validation is computed is by taking the last x% samples of the arrays received by the call, before any shuffling.\n\nNote that you can only use when training with NumPy data.\n\nIn the past few paragraphs, you've seen how to handle losses, metrics, and optimizers, and you've seen how to use the and arguments in , when your data is passed as NumPy arrays.\n\nLet's now take a look at the case where your data comes in the form of a object.\n\nThe API is a set of utilities in TensorFlow 2.0 for loading and preprocessing data in a way that's fast and scalable.\n\nFor a complete guide about creating , see the tf.data documentation.\n\nYou can pass a instance directly to the methods , , and :\n\nNote that the Dataset is reset at the end of each epoch, so it can be reused of the next epoch.\n\nIf you want to run training only on a specific number of batches from this Dataset, you can pass the argument, which specifies how many training steps the model should run using this Dataset before moving on to the next epoch.\n\nIf you do this, the dataset is not reset at the end of each epoch, instead we just keep drawing the next batches. The dataset will eventually run out of data (unless it is an infinitely-looping dataset).\n\nYou can pass a instance as the argument in :\n\nAt the end of each epoch, the model will iterate over the validation dataset and compute the validation loss and validation metrics.\n\nIf you want to run validation only on a specific number of batches from this dataset, you can pass the argument, which specifies how many validation steps the model should run with the validation dataset before interrupting validation and moving on to the next epoch:\n\nNote that the validation dataset will be reset after each use (so that you will always be evaluating on the same samples from epoch to epoch).\n\nThe argument (generating a holdout set from the training data) is not supported when training from objects, since this feature requires the ability to index the samples of the datasets, which is not possible in general with the API.\n\nBesides NumPy arrays, eager tensors, and TensorFlow , it's possible to train a Keras model using Pandas dataframes, or from Python generators that yield batches of data & labels.\n\nIn particular, the class offers a simple interface to build Python data generators that are multiprocessing-aware and can be shuffled.\n\nIn general, we recommend that you use:\n• NumPy input data if your data is small and fits in memory\n• objects if you have large datasets and you need to do distributed training\n• objects if you have large datasets and you need to do a lot of custom Python-side processing that cannot be done in TensorFlow (e.g. if you rely on external libraries for data loading or preprocessing).\n\nis a utility that you can subclass to obtain a Python generator with two important properties:\n• It works well with multiprocessing.\n• It can be shuffled (e.g. when passing in ).\n\nThe method should return a complete batch. If you want to modify your dataset between epochs, you may implement .\n\nWith the default settings the weight of a sample is decided by its frequency in the dataset. There are two methods to weight the data, independent of sample frequency:\n\nThis is set by passing a dictionary to the argument to . This dictionary maps class indices to the weight that should be used for samples belonging to this class.\n\nThis can be used to balance classes without resampling, or to train a model that gives more importance to a particular class.\n\nFor instance, if class \"0\" is half as represented as class \"1\" in your data, you could use .\n\nHere's a NumPy example where we use class weights or sample weights to give more importance to the correct classification of class #5 (which is the digit \"5\" in the MNIST dataset).\n\nFor fine grained control, or if you are not building a classifier, you can use \"sample weights\".\n• When training from NumPy data: Pass the argument to .\n• When training from or any other sort of iterator: Yield tuples.\n\nA \"sample weights\" array is an array of numbers that specify how much weight each sample in a batch should have in computing the total loss. It is commonly used in imbalanced classification problems (the idea being to give more weight to rarely-seen classes).\n\nWhen the weights used are ones and zeros, the array can be used as a mask for the loss function (entirely discarding the contribution of certain samples to the total loss).\n\nIn the previous examples, we were considering a model with a single input (a tensor of shape ) and a single output (a prediction tensor of shape ). But what about models that have multiple inputs or outputs?\n\nConsider the following model, which has an image input of shape (that's ) and a time series input of shape (that's ). Our model will have two outputs computed from the combination of these inputs: a \"score\" (of shape ) and a probability distribution over five classes (of shape ).\n\nLet's plot this model, so you can clearly see what we're doing here (note that the shapes shown in the plot are batch shapes, rather than per-sample shapes).\n\nAt compilation time, we can specify different losses to different outputs, by passing the loss functions as a list:\n\nIf we only passed a single loss function to the model, the same loss function would be applied to every output (which is not appropriate here).\n\nSince we gave names to our output layers, we could also specify per-output losses and metrics via a dict:\n\nWe recommend the use of explicit names and dicts if you have more than 2 outputs.\n\nIt's possible to give different weights to different output-specific losses (for instance, one might wish to privilege the \"score\" loss in our example, by giving to 2x the importance of the class loss), using the argument:\n\nYou could also choose not to compute a loss for certain outputs, if these outputs are meant for prediction but not for training:\n\nPassing data to a multi-input or multi-output model in works in a similar way as specifying a loss function in compile: you can pass lists of NumPy arrays (with 1:1 mapping to the outputs that received a loss function) or dicts mapping output names to NumPy arrays.\n\nHere's the use case: similarly as what we did for NumPy arrays, the should return a tuple of dicts.\n\nCallbacks in Keras are objects that are called at different points during training (at the start of an epoch, at the end of a batch, at the end of an epoch, etc.). They can be used to implement certain behaviors, such as:\n• Doing validation at different points during training (beyond the built-in per-epoch validation)\n• Checkpointing the model at regular intervals or when it exceeds a certain accuracy threshold\n• Changing the learning rate of the model when training seems to be plateauing\n• Doing fine-tuning of the top layers when training seems to be plateauing\n• Sending email or instant message notifications when training ends or where a certain performance threshold is exceeded\n\nCallbacks can be passed as a list to your call to :\n\nMany built-in callbacks are available\n\nThere are many built-in callbacks already available in Keras, such as:\n• : Stop training when training is no longer improving the validation metrics.\n• : periodically write model logs that can be visualized in TensorBoard (more details in the section \"Visualization\").\n\nSee the callbacks documentation for the complete list.\n\nYou can create a custom callback by extending the base class . A callback has access to its associated model through the class property .\n\nMake sure to read the complete guide to writing custom callbacks.\n\nHere's a simple example saving a list of per-batch loss values during training:\n\nWhen you're training model on relatively large datasets, it's crucial to save checkpoints of your model at frequent intervals.\n\nThe easiest way to achieve this is with the callback:\n\nThe callback can be used to implement fault-tolerance: the ability to restart training from the last saved state of the model in case training gets randomly interrupted. Here's a basic example:\n\nYou call also write your own callback for saving and restoring models.\n\nFor a complete guide on serialization and saving, see the guide to saving and serializing Models.\n\nA common pattern when training deep learning models is to gradually reduce the learning as training progresses. This is generally known as \"learning rate decay\".\n\nThe learning decay schedule could be static (fixed in advance, as a function of the current epoch or the current batch index), or dynamic (responding to the current behavior of the model, in particular the validation loss).\n\nYou can easily use a static learning rate decay schedule by passing a schedule object as the argument in your optimizer:\n\nSeveral built-in schedules are available: , , , and .\n\nA dynamic learning rate schedule (for instance, decreasing the learning rate when the validation loss is no longer improving) cannot be achieved with these schedule objects, since the optimizer does not have access to validation metrics.\n\nHowever, callbacks do have access to all metrics, including validation metrics! You can thus achieve this pattern by using a callback that modifies the current learning rate on the optimizer. In fact, this is even built-in as the callback.\n\nThe best way to keep an eye on your model during training is to use TensorBoard -- a browser-based application that you can run locally that provides you with:\n• Live plots of the loss and metrics for training and evaluation\n• (optionally) Visualizations of the histograms of your layer activations\n• (optionally) 3D visualizations of the embedding spaces learned by your layers\n\nIf you have installed TensorFlow with pip, you should be able to launch TensorBoard from the command line:\n\nThe easiest way to use TensorBoard with a Keras model and the method is the callback.\n\nIn the simplest case, just specify where you want the callback to write logs, and you're good to go:\n\nFor more information, see the documentation for the callback."
    },
    {
        "link": "https://projectpro.io/recipes/evaluate-keras-model",
        "document": "In machine learning, We have to first train the model and then we have to check that if the model is working properly or not. Does the model is efficient or not to predict further result. \n\nWe can evaluate the model by various metrics like accuracy, f1 score, etc.\n\nSo this recipe is a short example of how to evaluate a keras model?\n\nimport pandas as pd import numpy as np from keras.datasets import mnist from sklearn.model_selection import train_test_split from keras.models import Sequential from keras.layers import Dense from keras.layers import Dropout\n\nWe have imported pandas, numpy, mnist(which is the dataset), train_test_split, Sequential, Dense and Dropout. We will use these later in the recipe.\n\nHere we have used the inbuilt mnist dataset and stored the train data in X_train and y_train. We have used X_test and y_test to store the test data.\n\nWe have created an object model for sequential model. We can use two args i.e layers and name. Now, We are adding the layers by using 'add'. We can specify the type of layer, activation function to be used and many other things while adding the layer. \n\nHere we have added four layers which will be connected one after other.\n\nWe can compile a model by using compile attribute. Let us first look at its parameters before using it.\n• None optimizer : In this we can pass the optimizer we want to use. There are various optimizer like SGD, Adam etc.\n• None loss : In this we can pass a loss function which we want for the model\n• None metrics : In this we can pass the metric on which we want the model to be scored\n\nWe can fit a model on the data we have and can use the model after that. Here we are using the data which we have split i.e the training data for fitting the model. \n\nWhile fitting we can pass various parameters like batch_size, epochs, verbose, validation_data and so on.\n\nAfter fitting a model we want to evaluate the model. Here we are using model.evaluate to evaluate the model and it will give us the loss and the accuracy. Here we have also printed the score. As an output we get:"
    },
    {
        "link": "https://geeksforgeeks.org/difference-between-keras-modelevaluate-and-modelpredict",
        "document": "When working with machine learning models in Keras, two commonly used functions are and . These functions serve different purposes, and understanding the distinction between them is essential for properly assessing and utilizing your model.\n• Purpose is used to evaluate the performance of a trained model on a given dataset. It returns the loss value(s) and any specified metrics for the model, based on the provided data.\n• Use Case: This function is primarily used after the model has been trained to understand how well the model performs on unseen data (typically the validation or test set).\n• Working:\n• None It takes input data and corresponding true labels (targets), then calculates the loss and other metrics defined during the model's compilation.\n• None The function goes through each sample in the dataset, feeds it into the model, and compares the model's predictions to the actual labels to compute the overall performance.\n• Output is a scalar or a list of scalars, depending on whether multiple metrics were specified during the model’s compilation.\n• When to Use when you want to assess the overall performance of your model on a dataset and get a quantitative measure (like etc.) of its effectiveness.\n• Purpose is used to generate predictions from the trained model based on new input data. It does not require true labels and does not compute any metrics.\n• Use Case : This function is utilized when you want to obtain the model's predictions for new or unseen data, typically for tasks such as classification, regression, or any other type of prediction task.\n• Working : It takes input data and feeds it through the model to generate predictions. The output depends on the nature of the task (e.g., probabilities for classification tasks, continuous values for regression tasks).\n• Output is the predicted labels or values for the input data. The format of the output will match the type of model (e.g., a classification model might return a vector of probabilities).\n• When to Use when you want to make predictions on new data and obtain the model's outputs without calculating any loss or metrics.\n\nHere’s a table summarizing the differences between and :\n\nIn summary, and serve distinct roles in the machine learning workflow. is essential for assessing the model's performance in terms of loss and accuracy, while is used for making predictions on new or unseen data. Understanding when and how to use these functions is crucial for effectively working with Keras models."
    },
    {
        "link": "https://machinelearningmastery.com/use-keras-deep-learning-models-scikit-learn-python",
        "document": "Keras is one of the most popular deep learning libraries in Python for research and development because of its simplicity and ease of use.\n\nThe scikit-learn library is the most popular library for general machine learning in Python.\n\nIn this post, you will discover how you can use deep learning models from Keras with the scikit-learn library in Python.\n\nThis will allow you to leverage the power of the scikit-learn library for tasks like model evaluation and model hyper-parameter optimization.\n\nKick-start your project with my new book Deep Learning With Python, including step-by-step tutorials and the Python source code files for all examples.\n• Update Jan/2017: Fixed a bug in printing the results of the grid search.\n• Update Mar/2017: Updated example for Keras 2.0.2, TensorFlow 1.0.1 and Theano 0.9.0.\n• Update Mar/2018: Added alternate link to download the dataset as the original appears to have been taken down.\n\nKeras is a popular library for deep learning in Python, but the focus of the library is deep learning models. In fact, it strives for minimalism, focusing on only what you need to quickly and simply define and build deep learning models.\n\nThe scikit-learn library in Python is built upon the SciPy stack for efficient numerical computation. It is a fully featured library for general machine learning and provides many useful utilities in developing deep learning models. Not least of which are:\n• Evaluation of models using resampling methods like k-fold cross validation\n\nThere was a wrapper in the TensorFlow/Keras library to make deep learning models used as classification or regression estimators in scikit-learn. But recently, this wrapper was taken out to become a standalone Python module.\n\nIn the following sections, you will work through examples of using the KerasClassifier wrapper for a classification neural network created in Keras and used in the scikit-learn library.\n\nThe test problem is the Pima Indians onset of diabetes classification dataset. This is a small dataset with all numerical attributes that is easy to work with. Download the dataset and place it in your currently working directly with the name pima-indians-diabetes.csv (update: download from here).\n\nThe following examples assume you have successfully installed TensorFlow 2.x, SciKeras, and scikit-learn. If you use the system for your Python modules, you may install them with:\n\nThe KerasClassifier and KerasRegressor classes in SciKeras take an argument which is the name of the function to call to get your model.\n\nYou must define a function called whatever you like that defines your model, compiles it, and returns it.\n\nIn the example below, you will define a function that creates a simple multi-layer neural network for the problem.\n\nYou pass this function name to the KerasClassifier class by the argument. You also pass in additional arguments of and . These are automatically bundled up and passed on to the function, which is called internally by the KerasClassifier class.\n\nIn this example, you will use the scikit-learn StratifiedKFold to perform 10-fold stratified cross-validation. This is a resampling technique that can provide a robust estimate of the performance of a machine learning model on unseen data.\n\nNext, use the scikit-learn function to evaluate your model using the cross-validation scheme and print the results.\n\nNote: Your results may vary given the stochastic nature of the algorithm or evaluation procedure, or differences in numerical precision. Consider running the example a few times and compare the average outcome.\n\nRunning the example displays the skill of the model for each epoch. A total of 10 models are created and evaluated, and the final average accuracy is displayed.\n\nIn comparison, the following is an equivalent implementation with a neural network model in scikit-learn:\n\nThe role of the is to work as an adapter to make the Keras model work like a object from scikit-learn.\n\nThe previous example showed how easy it is to wrap your deep learning model from Keras and use it in functions from the scikit-learn library.\n\nIn this example, you will go a step further. The function that you specify to the argument when creating the KerasClassifier wrapper can take arguments. You can use these arguments to further customize the construction of the model. In addition, you know you can provide arguments to the function.\n\nIn this example, you will use a grid search to evaluate different configurations for your neural network model and report on the combination that provides the best-estimated performance.\n\nThe function is defined to take two arguments, and , both of which must have default values. This will allow you to evaluate the effect of using different optimization algorithms and weight initialization schemes for your network.\n\nAfter creating your model, define the arrays of values for the parameter you wish to search, specifically:\n• Initializers for preparing the network weights using different schemes\n• Epochs for training the model for a different number of exposures to the training dataset\n• Batches for varying the number of samples before a weight update\n\nThe options are specified into a dictionary and passed to the configuration of the GridSearchCV scikit-learn class. This class will evaluate a version of your neural network model for each combination of parameters (2 x 3 x 3 x 3 for the combinations of optimizers, initializations, epochs, and batches). Each combination is then evaluated using the default of 3-fold stratified cross validation.\n\nThat is a lot of models and a lot of computation. This is not a scheme you want to use lightly because of the time it will take. It may be useful for you to design small experiments with a smaller subset of your data that will complete in a reasonable time. This is reasonable in this case because of the small network and the small dataset (less than 1000 instances and nine attributes).\n\nFinally, the performance and combination of configurations for the best model are displayed, followed by the performance of all combinations of parameters.\n\nNote that in the dictionary , was used as the key for the argument to our function. The prefix is required for models in SciKeras to provide custom arguments.\n\nThis might take about 5 minutes to complete on your workstation executed on the CPU (rather than GPU). Running the example shows the results below.\n\nNote: Your results may vary given the stochastic nature of the algorithm or evaluation procedure, or differences in numerical precision. Consider running the example a few times and compare the average outcome.\n\nYou can see that the grid search discovered that using a uniform initialization scheme, rmsprop optimizer, 150 epochs, and a batch size of 10 achieved the best cross-validation score of approximately 77% on this problem.\n\nFor a fuller example of tuning hyperparameters with Keras, see the tutorial:\n• How to Grid Search Hyperparameters for Deep Learning Models in Python With Keras\n\nIn this post, you discovered how to wrap your Keras deep learning models and use them in the scikit-learn general machine learning library.\n\nYou can see that using scikit-learn for standard machine learning operations such as model evaluation and model hyperparameter optimization can save a lot of time over implementing these schemes yourself.\n\nWrapping your model allowed you to leverage powerful tools from scikit-learn to fit your deep learning models into your general machine learning process.\n\nDo you have any questions about using Keras models in scikit-learn or about this post? Ask your question in the comments, and I will do my best to answer."
    },
    {
        "link": "https://stackoverflow.com/questions/38971293/get-class-labels-from-keras-functional-model",
        "document": "When one uses flow_from_directory the problem is how to interpret the probability outputs. As in, how to map the probability outputs and the class labels as how flow_from_directory creates one-hot vectors is not known in prior.\n\nWe can get a dictionary that maps the class labels to the index of the prediction vector that we get as the output when we use\n\nThe label_map variable is a dictionary like this\n\nThen from this the relation can be derived between the probability scores and class names.\n\nBasically, you can create this dictionary by this code.\n\nThe variable name_id_map in the above code also contains the same dictionary as the one obtained from class_indices function of flow_from_directory."
    },
    {
        "link": "https://realpython.com/python-keras-text-classification",
        "document": "Imagine you could know the mood of the people on the Internet. Maybe you are not interested in its entirety, but only if people are today happy on your favorite social media platform. After this tutorial, you’ll be equipped to do this. While doing this, you will get a grasp of current advancements of (deep) neural networks and how they can be applied to text.\n\nReading the mood from text with machine learning is called sentiment analysis, and it is one of the prominent use cases in text classification. This falls into the very active research field of natural language processing (NLP). Other common use cases of text classification include detection of spam, auto tagging of customer queries, and categorization of text into defined topics. So how can you do this?\n\nBefore we start, let’s take a look at what data we have. Go ahead and download the data set from the Sentiment Labelled Sentences Data Set from the UCI Machine Learning Repository. By the way, this repository is a wonderful source for machine learning data sets when you want to try out some algorithms. This data set includes labeled reviews from IMDb, Amazon, and Yelp. Each review is marked with a score of 0 for a negative sentiment or 1 for a positive sentiment. Extract the folder into a folder and go ahead and load the data with Pandas: # Add another column filled with the source name The result will be as follows: This looks about right. With this data set, you are able to train a model to predict the sentiment of a sentence. Take a quick moment to think about how you would go about predicting the data. One way you could do this is to count the frequency of each word in each sentence and tie this count back to the entire set of words in the data set. You would start by taking the data and creating a vocabulary from all the words in all sentences. The collection of texts is also called a corpus in NLP. The vocabulary in this case is a list of words that occurred in our text where each word has its own index. This enables you to create a vector for a sentence. You would then take the sentence you want to vectorize, and you count each occurrence in the vocabulary. The resulting vector will be with the length of the vocabulary and a count for each word in the vocabulary. The resulting vector is also called a feature vector. In a feature vector, each dimension can be a numeric or categorical feature, like for example the height of a building, the price of a stock, or, in our case, the count of a word in a vocabulary. These feature vectors are a crucial piece in data science and machine learning, as the model you want to train depends on them. Let’s quickly illustrate this. Imagine you have the following two sentences: Next, you can use the provided by the scikit-learn library to vectorize sentences. It takes the words of each sentence and creates a vocabulary of all the unique words in the sentences. This vocabulary can then be used to create a feature vector of the count of the words: This vocabulary serves also as an index of each word. Now, you can take each sentence and get the word occurrences of the words based on the previous vocabulary. The vocabulary consists of all five words in our sentences, each representing one word in the vocabulary. When you take the previous two sentences and transform them with the you will get a vector representing the count of each word of the sentence: Now, you can see the resulting feature vectors for each sentence based on the previous vocabulary. For example, if you take a look at the first item, you can see that both vectors have a there. This means that both sentences have one occurrence of , which is in the first place in the vocabulary. This is considered a Bag-of-words (BOW) model, which is a common way in NLP to create vectors out of text. Each document is represented as a vector. You can use these vectors now as feature vectors for a machine learning model. This leads us to our next part, defining a baseline model.\n\nWhen you work with machine learning, one important step is to define a baseline model. This usually involves a simple model, which is then used as a comparison with the more advanced models that you want to test. In this case, you’ll use the baseline model to compare it to the more advanced methods involving (deep) neural networks, the meat and potatoes of this tutorial. First, you are going to split the data into a training and testing set which will allow you to evaluate the accuracy and see if your model generalizes well. This means whether the model is able to perform well on data it has not seen before. This is a way to see if the model is overfitting. Overfitting is when a model is trained too well on the training data. You want to avoid overfitting, as this would mean that the model mostly just memorized the training data. This would account for a large accuracy with the training data but a low accuracy in the testing data. We start by taking the Yelp data set which we extract from our concatenated data set. From there, we take the sentences and labels. The returns a NumPy array instead of a Pandas Series object which is in this context easier to work with: Here we will use again on the previous BOW model to vectorize the sentences. You can use again the for this task. Since you might not have the testing data available during training, you can create the vocabulary using only the training data. Using this vocabulary, you can create the feature vectors for each sentence of the training and testing set: You can see that the resulting feature vectors have 750 samples which are the number of training samples we have after the train-test split. Each sample has 2505 dimensions which is the size of the vocabulary. Also, you can see that we get a sparse matrix. This is a data type that is optimized for matrices with only a few non-zero elements, which only keeps track of the non-zero elements reducing the memory load. performs tokenization which separates the sentences into a set of tokens as you saw previously in the vocabulary. It additionally removes punctuation and special characters and can apply other preprocessing to each word. If you want, you can use a custom tokenizer from the NLTK library with the or use any number of the customizations which you can explore to improve the performance of your model. Note: There are a lot of additional parameters to that we forgo using here, such as adding ngrams, beacuse the goal at first is to build a simple baseline model. The token pattern itself defaults to , which is a regex pattern that says, “a word is 2 or more Unicode word characters surrounded by word boundaries.”. The classification model we are going to use is the logistic regression which is a simple yet powerful linear model that is mathematically speaking in fact a form of regression between 0 and 1 based on the input feature vector. By specifying a cutoff value (by default 0.5), the regression model is used for classification. You can use again scikit-learn library which provides the classifier: You can see that the logistic regression reached an impressive 79.6%, but let’s have a look how this model performs on the other data sets that we have. In this script, we perform and evaluate the whole process for each data set that we have: Great! You can see that this fairly simple model achieves a fairly good accuracy. It would be interesting to see whether we are able to outperform this model. In the next part, we will get familiar with (deep) neural networks and how to apply them to text classification.\n\nYou might have experienced some of the excitement and fear related to artificial intelligence and deep learning. You might have stumbled across some confusing article or concerned TED talk about the approaching singularity or maybe you saw the backflipping robots and you wonder whether a life in the woods seems reasonable after all. On a lighter note, AI researchers all agreed that they did not agree with each other when AI will exceed Human-level performance. According to this paper we should still have some time left. So you might already be curious how neural networks work. If you already are familiar with neural networks, feel free to skip to the parts involving Keras. Also, there is the wonderful Deep Learning book by Ian Goodfellow which I highly recommend if you want to dig deeper into the math. You can read the whole book online for free. In this section you will get an overview of neural networks and their inner workings, and you will later see how to use neural networks with the outstanding Keras library. In this article, you don’t have to worry about the singularity, but (deep) neural networks play a crucial role in the latest developments in AI. It all started with a famous paper in 2012 by Geoffrey Hinton and his team, which outperformed all previous models in the famous ImageNet Challenge. The challenge could be considered the World Cup in computer vision which involves classifying a large set of images based on given labels. Geoffrey Hinton and his team managed to beat the previous models by using a convolutional neural network (CNN), which we will cover in this tutorial as well. Since then, neural networks have moved into several fields involving classification, regression and even generative models. The most prevalent fields include computer vision, voice recognition and natural language processing (NLP). Neural networks, or sometimes called artificial neural network (ANN) or feedforward neural network, are computational networks which were vaguely inspired by the neural networks in the human brain. They consist of neurons (also called nodes) which are connected like in the graph below. You start by having a layer of input neurons where you feed in your feature vectors and the values are then feeded forward to a hidden layer. At each connection, you are feeding the value forward, while the value is multiplied by a weight and a bias is added to the value. This happens at every connection and at the end you reach an output layer with one or more output nodes. If you want to have a binary classification you can use one node, but if you have multiple categories you should use multiple nodes for each category: You can have as many hidden layers as you wish. In fact, a neural network with more than one hidden layer is considered a deep neural network. Don’t worry: I won’t get here into the mathematical depths concerning neural networks. But if you want to get an intuitive visual understanding of the math involved, you can check out the YouTube Playlist by Grant Sanderson. The formula from one layer to the next is this short equation: Let’s slowly unpack what is happening here. You see, we are dealing here with only two layers. The layer with nodes serves as input for the layer with nodes . In order to calculate the values for each output node, we have to multiply each input node by a weight and add a bias . All of those have to be then summed and passed to a function . This function is considered the activation function and there are various different functions that can be used depending on the layer or the problem. It is generally common to use a rectified linear unit (ReLU) for hidden layers, a sigmoid function for the output layer in a binary classification problem, or a softmax function for the output layer of multi-class classification problems. You might already wonder how the weights are calculated, and this is obviously the most important part of neural networks, but also the most difficult part. The algorithm starts by initializing the weights with random values and they are then trained with a method called backpropagation. This is done by using optimization methods (also called optimizer) like the gradient descent in order to reduce the error between the computed and the desired output (also called target output). The error is determined by a loss function whose loss we want to minimize with the optimizer. The whole process is too extensive to cover here, but I’ll refer again to the Grant Sanderson playlist and the Deep Learning book by Ian Goodfellow I mentioned before. What you have to know is that there are various optimization methods that you can use, but the most common optimizer currently used is called Adam which has a good performance in various problems. You can also use different loss functions, but in this tutorial you will only need the cross entropy loss function or more specifically binary cross entropy which is used for binary classification problems. Be sure to experiment with the various available methods and tools. Some researchers even claim in a recent article that the choice for the best performing methods borders on alchemy. The reason being that many methods are not well explained and consist of a lot of tweaking and testing. Keras is a deep learning and neural networks API by François Chollet which is capable of running on top of Tensorflow (Google), Theano or CNTK (Microsoft). To quote the wonderful book by François Chollet, Deep Learning with Python: Keras is a model-level library, providing high-level building blocks for developing deep-learning models. It doesn’t handle low-level operations such as tensor manipulation and differentiation. Instead, it relies on a specialized, well-optimized tensor library to do so, serving as the backend engine of Keras (Source) It is a great way to start experimenting with neural networks without having to implement every layer and piece on your own. For example Tensorflow is a great machine learning library, but you have to implement a lot of boilerplate code to have a model running. Before installing Keras, you’ll need either Tensorflow, Theano, or CNTK. In this tutorial we will be using Tensorflow so check out their installation guide here, but feel free to use any of the frameworks that works best for you. Keras can be installed using PyPI with the following command: You can choose the backend you want to have by opening the Keras configuration file which you can find here: If you are a Windows user, you have to replace with . The configuration file should look as follows: You can change the field there to , or , given that you have installed the backend on your machine. For more details check out the Keras backends documentation. You might notice that we use data in the configuration file. The reason for this is that neural networks are frequently used in GPUs, and the computational bottleneck is memory. By using 32 bit, we are able reduce the memory load and we do not lose too much information in the process. Now you are finally ready to experiment with Keras. Keras supports two main types of models. You have the Sequential model API which you are going to see in use in this tutorial and the functional API which can do everything of the Sequential model but it can be also used for advanced models with complex network architectures. The Sequential model is a linear stack of layers, where you can use the large variety of available layers in Keras. The most common layer is the Dense layer which is your regular densely connected neural network layer with all the weights and biases that you are already familiar with. Let’s see if we can achieve some improvement to our previous logistic regression model. You can use the and arrays that you built in our earlier example. Before we build our model, we need to know the input dimension of our feature vectors. This happens only in the first layer since the following layers can do automatic shape inference. In order to build the Sequential model, you can add layers one by one in order as follows: Before you can start with the training of the model, you need to configure the learning process. This is done with the method. This method specifies the optimizer and the loss function. Additionally, you can add a list of metrics which can be later used for evaluation, but they do not influence the training. In this case, we want to use the binary cross entropy and the Adam optimizer you saw in the primer mentioned before. Keras also includes a handy function to give an overview of the model and the number of parameters available for training: You might notice that we have 25060 parameters for the first layer and another 11 in the second one. Where did those come from? See, we have 2505 dimensions for each feature vector, and then we have 10 nodes. We need weights for each feature dimension and each node which accounts for parameters, and then we have another 10 times an added bias for each node, which gets us the 25060 parameters. In the final node, we have another 10 weights and one bias, which gets us to 11 parameters. That’s a total of 25071 parameters for both layers. Neat! You are almost there. Now it is time to start your training with the function. Since the training in neural networks is an iterative process, the training won’t just stop after it is done. You have to specify the number of iterations you want the model to be training. Those completed iterations are commonly called epochs. We want to run it for 100 epochs to be able to see how the training loss and accuracy are changing after each epoch. Another parameter you have to your selection is the batch size. The batch size is responsible for how many samples we want to use in one epoch, which means how many samples are used in one forward/backward pass. This increases the speed of the computation as it need fewer epochs to run, but it also needs more memory, and the model may degrade with larger batch sizes. Since we have a small training set, we can leave this to a low batch size: Now you can use the method to measure the accuracy of the model. You can do this both for the training data and testing data. We expect that the training data has a higher accuracy then for the testing data. Tee longer you would train a neural network, the more likely it is that it starts overfitting. Note that if you rerun the method, you’ll start off with the computed weights from the previous training. Make sure to call before you start training the model again: Now let’s evaluate the accuracy of the model: You can already see that the model was overfitting since it reached 100% accuracy for the training set. But this was expected since the number of epochs was fairly large for this model. However, the accuracy of the testing set has already surpassed our previous logistic Regression with BOW model, which is a great step further in terms of our progress. To make your life easier, you can use this little helper function to visualize the loss and accuracy for the training and testing data based on the History callback. This callback, which is automatically applied to each Keras model, records the loss and additional metrics that can be added in the method. In this case, we are only interested in the accuracy. This helper function employs the matplotlib plotting library: To use this function, simply call with the collected accuracy and loss inside the dictionary: You can see that we have trained our model for too long since the training set reached 100% accuracy. A good way to see when the model starts overfitting is when the loss of the validation data starts rising again. This tends to be a good point to stop the model. You can see this around 20-40 epochs in this training. Note: When training neural networks, you should use a separate testing and validation set. What you would usually do is take the model with the highest validation accuracy and then test the model with the testing set. This makes sure that you don’t overfit the model. Using the validation set to choose the best model is a form of data leakage (or “cheating”) to get to pick the result that produced the best test score out of hundreds of them. Data leakage happens when information outside the training data set is used in the model. In this case, our testing and validation set are the same, since we have a smaller sample size. As we have covered before, (deep) neural networks perform best when you have a very large number of samples. In the next part, you’ll see a different way to represent words as vectors. This is a very exciting and powerful way to work with words where you’ll see how to represent words as dense vectors.\n\nText is considered a form of sequence data similar to time series data that you would have in weather data or financial data. In the previous BOW model, you have seen how to represent a whole sequence of words as a single feature vector. Now you will see how to represent each word as vectors. There are various ways to vectorize text, such as:\n• Words represented by each word as a vector\n• Characters represented by each character as a vector\n• N-grams of words/characters represented as a vector (N-grams are overlapping groups of multiple succeeding words/characters in the text) In this tutorial, you’ll see how to deal with representing words as vectors which is the common way to use text in neural networks. Two possible ways to represent a word as a vector are one-hot encoding and word embeddings. The first way to represent a word as a vector is by creating a so-called one-hot encoding, which is simply done by taking a vector of the length of the vocabulary with an entry for each word in the corpus. In this way, you have for each word, given it has a spot in the vocabulary, a vector with zeros everywhere except for the corresponding spot for the word which is set to one. As you might imagine, this can become a fairly large vector for each word and it does not give any additional information like the relationship between words. Let’s say you have a list of cities as in the following example: You can use scikit-learn and the to encode the list of cities into categorical integer values like here: Using this representation, you can use the provided by scikit-learn to encode the categorical values we got before into a one-hot encoded numeric array. expects each categorical value to be in a separate row, so you’ll need to reshape the array, then you can apply the encoder: You can see that categorical integer value represents the position of the array which is and the rest is . This is often used when you have a categorical feature which you cannot represent as a numeric value but you still want to be able to use it in machine learning. One use case for this encoding is of course words in a text but it is most prominently used for categories. Such categories can be for example city, department, or other categories. This method represents words as dense word vectors (also called word embeddings) which are trained unlike the one-hot encoding which are hardcoded. This means that the word embeddings collect more information into fewer dimensions. Note that the word embeddings do not understand the text as a human would, but they rather map the statistical structure of the language used in the corpus. Their aim is to map semantic meaning into a geometric space. This geometric space is then called the embedding space. This would map semantically similar words close on the embedding space like numbers or colors. If the embedding captures the relationship between words well, things like vector arithmetic should become possible. A famous example in this field of study is the ability to map King - Man + Woman = Queen. How can you get such a word embedding? You have two options for this. One way is to train your word embeddings during the training of your neural network. The other way is by using pretrained word embeddings which you can directly use in your model. There you have the option to either leave these word embeddings unchanged during training or you train them also. Now you need to tokenize the data into a format that can be used by the word embeddings. Keras offers a couple of convenience methods for text preprocessing and sequence preprocessing which you can employ to prepare your text. You can start by using the utility class which can vectorize a text corpus into a list of integers. Each integer maps to a value in a dictionary that encodes the entire corpus, with the keys in the dictionary being the vocabulary terms themselves. You can add the parameter , which is responsible for setting the size of the vocabulary. The most common words will be then kept. I have the testing and training data prepared from the previous example: Of all the dishes, the salmon was the best, but all were great. The indexing is ordered after the most common words in the text, which you can see by the word having the index . It is important to note that the index is reserved and is not assigned to any word. This zero index is used for padding, which I’ll introduce in a moment. Unknown words (words that are not in the vocabulary) are denoted in Keras with since they can also hold some information. You can see the index of each word by taking a look at the dictionary of the object: Note: Pay close attention to the difference between this technique and the that was produced by scikit-learn’s . With , we had stacked vectors of word counts, and each vector was the same length (the size of the total corpus vocabulary). With Tokenizer, the resulting vectors equal the length of each text, and the numbers don’t denote counts, but rather correspond to the word values from the dictionary . One problem that we have is that each text sequence has in most cases different length of words. To counter this, you can use which simply pads the sequence of words with zeros. By default, it prepends zeros but we want to append them. Typically it does not matter whether you prepend or append zeros. Additionally you would want to add a parameter to specify how long the sequences should be. This cuts sequences that exceed that number. In the following code, you can see how to pad sequences with Keras: The first values represent the index in the vocabulary as you have learned from the previous examples. You can also see that the resulting feature vector contains mostly zeros, since you have a fairly short sentence. In the next part you will see how to work with word embeddings in Keras. Notice that, at this point, our data is still hardcoded. We have not told Keras to learn a new embedding space through successive tasks. Now you can use the Embedding Layer of Keras which takes the previously calculated integers and maps them to a dense vector of the embedding. You will need the following parameters:\n• : the size of the vocabulary\n• : the size of the dense vector\n• : the length of the sequence With the layer we have now a couple of options. One way would be to take the output of the embedding layer and plug it into a layer. In order to do this you have to add a layer in between that prepares the sequential input for the layer: The result will be as follows: You can now see that we have 87350 new parameters to train. This number comes from times the . These weights of the embedding layer are initialized with random weights and are then adjusted through backpropagation during training. This model takes the words as they come in the order of the sentences as input vectors. You can train it with the following: The result will be as follows: Accuracy and loss for first model This is typically a not very reliable way to work with sequential data as you can see in the performance. When working with sequential data you want to focus on methods that look at local and sequential information instead of absolute positional information. Another way to work with embeddings is by using a / or a / layer after the embedding. You can think of the pooling layers as a way to downsample (a way to reduce the size of) the incoming feature vectors. In the case of max pooling you take the maximum value of all features in the pool for each feature dimension. In the case of average pooling you take the average, but max pooling seems to be more commonly used as it highlights large values. Global max/average pooling takes the maximum/average of all features whereas in the other case you have to define the pool size. Keras has again its own layer that you can add in the sequential model: The result will be as follows: The procedure for training does not change: The result will be as follows: You can already see some improvements in our models. Next you’ll see how we can employ pretrained word embeddings and if they help us with our model. We just saw an example of jointly learning word embeddings incorporated into the larger model that we want to solve. An alternative is to use a precomputed embedding space that utilizes a much larger corpus. It is possible to precompute word embeddings by simply training them on a large corpus of text. Among the most popular methods are Word2Vec developed by Google and GloVe (Global Vectors for Word Representation) developed by the Stanford NLP Group. Note that those are different approaches with the same goal. Word2Vec achieves this by employing neural networks and GloVe achieves this with a co-occurrence matrix and by using matrix factorization. In both cases you are dealing with dimensionality reduction, but Word2Vec is more accurate and GloVe is faster to compute. In this tutorial, you’ll see how to work with the GloVe word embeddings from the Stanford NLP Group as their size is more manageable than the Word2Vec word embeddings provided by Google. Go ahead and download the 6B (trained on 6 billion words) word embeddings from here ( , 822 MB). You can find other word embeddings also on the main GloVe page. You can find the pretrained Word2Vec embeddings by Google here. If you want to train your own word embeddings, you can do so efficiently with the gensim Python package which uses Word2Vec for calculation. More details on how to do this here. Now that we got you covered, you can start using the word embeddings in your models. You can see in the next example how you can load the embedding matrix. Each line in the file starts with the word and is followed by the embedding vector for the particular word. This is a large file with 400000 lines, with each line representing a word followed by its vector as a stream of floats. For example, here are the first 50 characters of the first line: Since you don’t need all words, you can focus on only the words that we have in our vocabulary. Since we have only a limited number of words in our vocabulary, we can skip most of the 40000 words in the pretrained word embeddings: # Adding again 1 because of reserved 0 index You can use this function now to retrieve the embedding matrix: Wonderful! Now you are ready to use the embedding matrix in training. Let’s go ahead and use the previous network with global max pooling and see if we can improve this model. When you use pretrained word embeddings you have the choice to either allow the embedding to be updated during training or only use the resulting embedding vectors as they are. First, let’s have a quick look how many of the embedding vectors are nonzero: This means 95.1% of the vocabulary is covered by the pretrained model, which is a good coverage of our vocabulary. Let’s have a look at the performance when using the layer: The result will be as follows: The result will be as follows: Since the word embeddings are not additionally trained, it is expected to be lower. But let’s now see how this performs if we allow the embedding to be trained by using : The result will be as follows: The result will be as follows: You can see that it is most effective to allow the embeddings to be trained. When dealing with large training sets it can boost the training process to be much faster than without. In our case it seemed to help but not by much. This does not have to be because of pretrained word embeddings. Now it is time to focus on a more advanced neural network model to see if it is possible to boost the model and give it the leading edge over the previous models.\n\nConvolutional neural networks or also called convnets are one of the most exciting developments in machine learning in recent years. They have revolutionized image classification and computer vision by being able to extract features from images and using them in neural networks. The properties that made them useful in image processing makes them also handy for sequence processing. You can imagine a CNN as a specialized neural network that is able to detect specific patterns. If it is just another neural network, what differentiates it from what you have previously learned? A CNN has hidden layers which are called convolutional layers. When you think of images, a computer has to deal with a two dimensional matrix of numbers and therefore you need some way to detect features in this matrix. These convolutional layers are able to detect edges, corners and other kinds of textures which makes them such a special tool. The convolutional layer consists of multiple filters which are slid across the image and are able to detect specific features. This is the very core of the technique, the mathematical process of convolution. With each convolutional layer the network is able to detect more complex patterns. In the Feature Visualization by Chris Olah you can get a good intuition what these features can look like. When you are working with sequential data, like text, you work with one dimensional convolutions, but the idea and the application stays the same. You still want to pick up on patterns in the sequence which become more complex with each added convolutional layer. In the next figure you can see how such a convolution works. It starts by taking a patch of input features with the size of the filter kernel. With this patch you take the dot product of the multiplied weights of the filter. The one dimensional convnet is invariant to translations, which means that certain sequences can be recognized at a different position. This can be helpful for certain patterns in the text: Now let’s have a look how you can use this network in Keras. Keras offers again various Convolutional layers which you can use for this task. The layer you’ll need is the layer. This layer has again various parameters to choose from. The ones you are interested in for now are the number of filters, the kernel size, and the activation function. You can add this layer in between the layer and the layer: The result will be as follows: The result will be as follows: You can see that 80% accuracy seems to be tough hurdle to overcome with this data set and a CNN might not be well equipped. The reason for such a plateau might be that:\n• There are not enough training samples\n• The data you have does not generalize well CNNs work best with large training sets where they are able to find generalizations where a simple model like logistic regression won’t be able.\n\nOne crucial steps of deep learning and working with neural networks is hyperparameter optimization. As you saw in the models that we have used so far, even with simpler ones, you had a large number of parameters to tweak and choose from. Those parameters are called hyperparameters. This is the most time consuming part of machine learning and sadly there are no one-fits-all solutions ready. When you have a look at the competitions on Kaggle, one of the largest places to compete against other fellow data scientists, you can see that many of the winning teams and models have gone through a lot of tweaking and experimenting until they reached their prime. So don’t get discouraged when it gets tough and you reach a plateau, but rather think about the ways you could optimize the model or the data. One popular method for hyperparameter optimization is grid search. What this method does is it takes lists of parameters and it runs the model with each parameter combination that it can find. It is the most thorough way but also the most computationally heavy way to do this. Another common way, random search, which you’ll see in action here, simply takes random combinations of parameters. In order to apply random search with Keras, you will need to use the KerasClassifier which serves as a wrapper for the scikit-learn API. With this wrapper you are able to use the various tools available with scikit-learn like cross-validation. The class that you need is RandomizedSearchCV which implements random search with cross-validation. Cross-validation is a way to validate the model and take the whole data set and separate it into multiple testing and training data sets. There are various types of cross-validation. One type is the k-fold cross-validation which you’ll see in this example. In this type the data set is partitioned into k equal sized sets where one set is used for testing and the rest of the partitions are used for training. This enables you to run k different runs, where each partition is once used as a testing set. So, the higher k is the more accurate the model evaluation is, but the smaller each testing set is. First step for is to have a function that creates a Keras model. We will use the previous model, but we will allow various parameters to be set for the hyperparameter optimization: Next, you want to define the parameter grid that you want to use in training. This consists of a dictionary with each parameters named as in the previous function. The number of spaces on the grid is , where each of those numbers is the number of different choices for a given parameter. You can see how this could get computationally expensive very quickly, but luckily both grid search and random search are embarrassingly parallel, and the classes come with an parameter that lets you test grid spaces in parallel. The parameter grid is initialized with the following dictionary: Now you are already ready to start running the random search. In this example we iterate over each data set and then you want to preprocess the data in the same way as previously. Afterwards you take the previous function and add it to the wrapper class including the number of epochs. The resulting instance and the parameter grid are then used as the estimator in the class. Additionally, you can choose the number of folds in the k-folds cross-validation, which is in this case 4. You have seen most of the code in this snippet before in our previous examples. Besides the and , I have added a little block of code handling the evaluation: This takes a while which is a perfect chance to go outside to get some fresh air or even go on a hike, depending on how many models you want to run. Let’s take a look what we have got: Interesting! For some reason the testing accuracy is higher than the training accuracy which might be because there is a large variance in the scores during cross-validation. We can see that we were still not able to break much through the dreaded 80%, which seems to be a natural limit for this data with its given size. Remember that we have a small data set and convolutional neural networks tend to perform the best with large data sets. Another method for CV is the nested cross-validation (shown here) which is used when the hyperparameters also need to be optimized. This is used because the resulting non-nested CV model has a bias toward the data set which can lead to an overly optimistic score. You see, when doing hyperparameter optimization as we did in the previous example, we are picking the best hyperparameters for that specific training set but this does not mean that these hyperparameters generalize the best."
    },
    {
        "link": "https://stackoverflow.com/questions/68776790/model-predict-classes-is-deprecated-what-to-use-instead",
        "document": "can be replaced by the following code snippet\n\nHowever before that we need to mention the following:\n\nThis will predict the probability of the input #1 falling to one of the outputs\n\nFor Example: For Row 1 or Input 1 we can get the following if we requested 3 probability outputs [0.03745461, 0.53267044, 0.42987496]. In other words the this row says that the middle class or [1] is what the input has the highest probability to fall into\n\nTo get a numpy array that represents the index positon of the highest probabilty you will need to do the following:"
    },
    {
        "link": "https://faroit.com/keras-docs/1.2.0",
        "document": "You have just found Keras.\n\nKeras is a high-level neural networks library, written in Python and capable of running on top of either TensorFlow or Theano. It was developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research.\n\nUse Keras if you need a deep learning library that:\n• Allows for easy and fast prototyping (through total modularity, minimalism, and extensibility).\n• Supports both convolutional networks and recurrent networks, as well as combinations of the two.\n• Modularity. A model is understood as a sequence or a graph of standalone, fully-configurable modules that can be plugged together with as little restrictions as possible. In particular, neural layers, cost functions, optimizers, initialization schemes, activation functions, regularization schemes are all standalone modules that you can combine to create new models.\n• Minimalism. Each module should be kept short and simple. Every piece of code should be transparent upon first reading. No black magic: it hurts iteration speed and ability to innovate.\n• Easy extensibility. New modules are dead simple to add (as new classes and functions), and existing modules provide ample examples. To be able to easily create new modules allows for total expressiveness, making Keras suitable for advanced research.\n• Work with Python. No separate models configuration files in a declarative format. Models are described in Python code, which is compact, easier to debug, and allows for ease of extensibility.\n\nThe core data structure of Keras is a model, a way to organize layers. The main type of model is the model, a linear stack of layers. For more complex architectures, you should use the Keras functional API.\n\nStacking layers is as easy as :\n\nOnce your model looks good, configure its learning process with :\n\nIf you need to, you can further configure your optimizer. A core principle of Keras is to make things reasonably simple, while allowing the user to be fully in control when they need to (the ultimate control being the easy extensibility of the source code).\n\nYou can now iterate on your training data in batches:\n\nAlternatively, you can feed batches to your model manually:\n\nEvaluate your performance in one line:\n\nOr generate predictions on new data:\n\nBuilding a question answering system, an image classification model, a Neural Turing Machine, a word2vec embedder or any other model is just as fast. The ideas behind deep learning are simple, so why should their implementation be painful?\n\nFor a more in-depth tutorial about Keras, you can check out:\n• Getting started with the Sequential model\n• Getting started with the functional API\n\nIn the examples folder of the repository, you will find more advanced models: question-answering with memory networks, text generation with stacked LSTMs, etc.\n\nKeras uses the following dependencies:\n• HDF5 and h5py (optional, required if you use model saving/loading functions)\n• Optional but recommended if you use CNNs: cuDNN.\n\nWhen using the TensorFlow backend:\n\nWhen using the Theano backend:\n\nTo install Keras, to the Keras folder and run the install command:\n\nYou can also install Keras from PyPI:\n\nBy default, Keras will use TensorFlow as its tensor manipulation library. Follow these instructions to configure the Keras backend.\n\nYou can ask questions and join the development discussion:\n• On the Keras Slack channel. Use this link to request an invitation to the channel.\n\nYou can also post bug reports and feature requests (only) in Github issues. Make sure to read our guidelines first.\n\nWhy this name, Keras?\n\nKeras (κέρας) means horn in Greek. It is a reference to a literary image from ancient Greek and Latin literature, first found in the Odyssey, where dream spirits (Oneiroi, singular Oneiros) are divided between those who deceive men with false visions, who arrive to Earth through a gate of ivory, and those who announce a future that will come to pass, who arrive through a gate of horn. It's a play on the words κέρας (horn) / κραίνω (fulfill), and ἐλέφας (ivory) / ἐλεφαίρομαι (deceive).\n\nKeras was initially developed as part of the research effort of project ONEIROS (Open-ended Neuro-Electronic Intelligent Robot Operating System)."
    }
]