[
    {
        "link": "https://vkguide.dev/docs/chapter-4/descriptors_code",
        "document": "Now that descriptor sets are explained, let’s look at using them in practice in a minimal example. We are going to modify the codebase and shaders, so that instead of sending the final transform matrix of the object through push constant, multiplying it in the CPU, we read the camera matrix on the shader and multiply it by the object matrix, with the multiplication being done in the shader. To get that to work, we are going to need to create a uniform buffer for our camera matrices, and expose that to the shader using a single descriptor set.\n\nWe are going to create one camera buffer for each of our frames. This is so that we can overlap the data correctly, and modify the camera matrix while the GPU is rendering the last frame.\n\nGiven that we are starting to create a lot of buffers, we are going to abstract buffer creation into a function first.\n\nAdd the function declaration to the VulkanEngine class too vk_engine.cpp\n\nOn the function we will just ask for buffer size, buffer usage, and memory usage. This is all we need for basic buffer creation. This is the similar code as we use for vertex buffers.\n\nNow, we are going to add a variable to hold the camera buffer to our FrameData struct, and create a struct for the camera data.\n\nThe GPUCameraData struct just holds a few matrices we are going to need. View matrix (camera location/transform), Projection matrix (for perspective), and ViewProj, which is just both of them multiplied together, to avoid multiplying them in the shader.\n\nOn FrameData, we are adding the AllocatedBuffer for it, but we also add a that we will cache to hold the global descriptor. We will be adding a few more things to it than just the camera uniform buffer.\n\nWe are going to add another initialization function, to VulkanEngine class. Also add it to the main init function, but before call. Some of the descriptor things we initialize there will be needed when creating the pipelines.\n\nNow that the function and data is added, we need to create those camera buffers.\n\nFor creating the buffers, we are to use the Uniform Buffer usage, and memory type. Uniform buffers are the best for this sort of small, read only shader data. They have a size limitation, but they are very fast to access in the shaders.\n\nTry to run this and see if the validation layers complain. They shouldn’t.\n\nWe are going to start doing the shader data itself. First thing is modifying the shader that we use, to use the matrix there.\n\nThe new block is the CameraBuffer uniform declaration. In there, you can see that it follows the same syntax as the push constant block, but with a different . By having and , we are declaring that the CameraBuffer uniform will be grabbed from the descriptor set bound at slot 0, and it’s binding 0 within that descriptor set.\n\nIn the core of the vertex shader, we multiply the render matrix from the push-constant with the viewproj matrix on the CameraBuffer. This will get the final transformation matrix, and then we can multiply vertex position by it.\n\nLets now set it up on the cpp side. The first thing we will need is to create the descriptor set layout.\n\nAdd a new member variable to vulkan engine. We are going to use it to store the descriptor layout for our global data. Also add a member for the descriptor pool that we will need later\n\nA holds information about the shape of a descriptor set. In this case, our descriptor set is going to be a set that holds a single uniform buffer reference at binding 0.\n\nTo create a descriptor set layout, we need another CreateInfo struct. The create-info will point into an array of structs. Each of those structs will contain information about the descriptor itself. In this case, we have only a single binding, which is binding 0, and it’s a Uniform Buffer.\n\nWe now have the descriptor set layout for our descriptor created, so we need to hook it to the pipeline creation. When you create a pipeline, you also need to let the pipeline know what descriptors will be bound to it.\n\nBack into . We need to modify the creation of the by hooking the descriptor layout to it.\n\nNow our pipeline builder will connect the pipeline layout to everything, which will allow the pipelines to access the descriptor sets once we bind them.\n\nThe pipeline setup is done, so now we have to allocate a descriptor set, and bind it when rendering.\n\nBack to , we first need to create a to allocate the descriptors from.\n\nIn this case, we know exactly what we will need to allocate from the pool, which is descriptor sets that point to uniform buffers. When creating a descriptor pool, you need to specify how many descriptors of each type you will need, and what’s the maximum number of sets to allocate from it. For now, we are going to reserve 10 uniform buffer pointers/handles, and a maximum of 10 descriptor sets allocated from the pool.\n\nWe can now allocate the descriptors from it. For it, continue on the function, inside the FRAME_OVERLAP loop.\n\nWith this, We now have a descriptor stored in our frame struct. But this descriptor is not pointing to any buffer yet, so we need to make it point into our camera buffer.\n\nWe need to fill a with the data of the buffer we want to have in the descriptor set. Because we have defined that our camera buffer is on binding 0, then we need to set it here, and with enough size to hold the struct.\n\nNow we have a filled descriptor set, so we can use it when rendering. In the function, we will start by writing to the camera buffer with the current camera matrix. This is the code that we had before for the push constants, but we now fill a GPUCameraData struct, and then copy it into the buffer. If you have implemented a moving camera, you will need to modify this code.\n\nWe fill the struct, and then copy it to the buffer with the same pattern that we used when dealing with vertex buffers. First you map the buffer into a void pointer, then you memcpy the data into it, and then unmap the buffer.\n\nThe buffer now holds the proper camera data, so now we can bind it.\n\nWe will bind the set whenever we switch pipeline. Its not strictly necessary right now, as all our pipelines are the same, but it will be easier.\n\nLast thing is to modify the push constants code, to make it not multiply the matrix there, and just push constant the model matrix.\n\nIf you run the code right now, everything should be working fine. But we have now a way to let the shader read some data from a buffer, instead of having to push constant all of the data of the shader."
    },
    {
        "link": "https://vkguide.dev/docs/chapter-4/descriptors",
        "document": "Until now, we have been using push constants to upload data from CPU to GPU. While push constants are useful, there are a lot of limitations to them. For example you can’t upload an array, you can’t point to a buffer, and you can’t use textures with them. To do that, you need to use descriptor sets, which is the main way of connecting CPU data to the GPU.\n\nDescriptor sets can be very convoluted to use compared to all other similar alternatives used in other graphic APIs. For that reason we are going to start very simple with them, and use them only for buffers, and do more things with them as the chapter continues. The texture side of descriptor sets will be for chapter 5.\n\nThink of a single descriptor as a handle or pointer into a resource. That resource being a Buffer or a Image, and also holds other information, such as the size of the buffer, or the type of sampler if it’s for an image. A is a pack of those pointers that are bound together. Vulkan does not allow you to bind individual resources in shaders. They have to be grouped in the sets. If you still insist on being able to bind them individually, then you will need a descriptor set for each resource. This is very inefficient and won’t work in many hardware. If you look at this https://vulkan.gpuinfo.org/displaydevicelimit.php?name=maxBoundDescriptorSets&platform=windows , you will see that some devices will only allow up to 4 descriptor sets to be bound to a given pipeline, on PC. Due to this, we can really only use up to 4 descriptor sets in our pipelines if we want the engine to run on Intel integrated GPUs. A common and performant way of dealing with that limitation of 4 descriptors, is to group them by binding frequency.\n\nThe descriptor set number 0 will be used for engine-global resources, and bound once per frame. The descriptor set number 1 will be used for per-pass resources, and bound once per pass. The descriptor set number 2 will be used for material resources, and the number 3 will be used for per-object resources. This way, the inner render loops will only be binding descriptor sets 2 and 3, and performance will be high.\n\nDescriptor sets have to be allocated directly by the engine from a . A descriptor set allocation will typically be allocated in a section of GPU VRAM. Once a descriptor set is allocated, you need to write it to make it point into your buffers/textures. Once you bind a descriptor set and use it in a function, you can no longer modify it unless you specify the flag. When a descriptor pool is allocated, you have to tell the driver how many descriptors sets, and what number of resources you will be using. A common thing to do is to default to some high numbers, like 1000 descriptors, and when the descriptor pool is out of space, allocating a new descriptor will return with an error. Then you can just go and create a new pool to hold more descriptors.\n\nAllocating descriptor sets can be very cheap if you explicitly disallow freeing individual sets by not setting the flag. By using that flag, you are telling the driver that you want descriptors to be able to deallocate individually. If you are allocating descriptor sets per frame, you should not be using that, and then you reset the entire pool instead of individual descriptor sets. For your global descriptor sets, it’s fine to allocate them once, and reuse them from frame to frame. This is what we will be doing in the tutorial, as it also ends with simpler code.\n\nA common technique used in production engines is to have a set of descriptor pools per frame. Once a descriptor allocation fails, you create a new pool and add it to a list. When the frame is submitted and you have waited on its fence, you reset all of those descriptor pools.\n\nA freshly allocated descriptor set is just a bit of GPU memory, you need to make it point to your buffers. For that you use , which takes an array of for each of the resources that a descriptor set points to. If you were using the Update After Bind flag, it is possible to use descriptor sets, and bind them in command buffers, and update it right before submitting the command buffer. This is mostly a niche use case, and not commonly used. You can only update a descriptor set before it’s bound for the first time, unless you use that flag, in which case you can only update it before you submit the command buffer into a queue. When a descriptor set is being used, it’s immutable, and trying to update it will cause errors. The validation layers catch that. To be able to update the descriptor sets again, you need to wait until the command has finished executing.\n\nDescriptor sets bind into specific “slots” on a Vulkan pipeline. When creating a pipeline, you have to specify the layouts for each of the descriptor sets that can be bound to the pipeline. This is commonly done automatically, generated from reflection on the shader. We will be doing it manually to show how it’s done. Once you bind a pipeline in a command buffer, the pipeline has slots for the different descriptor sets, and then you can bind a set into each of the slots. If the descriptor set doesn’t match the slot, there will be errors. If you bind a descriptor set to slot 0, and then you switch pipelines by binding another one, the descriptor set will stay bound, IF the slot is the same on the new pipeline. If the slot isn’t exactly the same, then the slot will be “unbound”, and you need to bind it again. For example, let’s say we have 2 pipelines, one of which has a descriptor set 0 that binds to a buffer, and descriptor set 1 that binds to 4 images. Then the other pipeline has descriptor set 0 that binds to a buffer (same as the same slot in the other pipeline), but in descriptor set 1 it has a descriptor set that binds to 3 images, not 4. If you bind the second pipeline, the descriptor set 0 will stay bound, but the descriptor 1 will be unbound because it no longer matches. This is why we assign a frequency to the descriptor slots, to minimize binding.\n\nUsed in both the pipelines and when allocating descriptors, a is the shape of the descriptor. For example, a possible layout will be one where it binds 2 buffers and 1 image. When creating pipelines or allocating the descriptor sets themselves, you have to use the layout. In the tutorial, we will be reusing the layout object for everything, but that’s not mandatory. Descriptor set layouts can be compatible if they are the same even if they are created in two different places.\n\nDescriptor sets point into buffers, but we didn’t explain that. Right now we are creating GPU buffers that hold vertex data, but you can also create buffers that hold arbitrary data for you to use in the shaders. For that type of data, Uniform Buffers are the common thing. They are small size (up to a few kilobytes), but are very fast to read, so they are perfect for shader parameters. By creating a Uniform Buffer and writing to it from the CPU, you can send data to the GPU in a much more efficient way than push constants. We will be using it for the camera information. It is possible to have multiple descriptor sets pointing to one uniform buffer, and it’s also possible to have a big uniform buffer, and then each descriptor sets point to a section of the buffer. The shader will not know the difference."
    },
    {
        "link": "https://reddit.com/r/vulkan/comments/1e5u5t1/proper_implementation_of_multiple_descriptor_sets",
        "document": "I have a descriptor pool, which includes 1 descriptor set for each Model in the Scene, with a UBO and an Image/Texture, and binding to the model's descriptor set during the render loop.\n\nI read that it isn't the most efficient way, and that you should use less, but I'm confused as to how that would work.\n\nI originally imagined updating the descriptor set, for each model to be rendered, in a frame. So if I was looping through each Model, I would update the central descriptor set, to have Model A's texture and UBO, but then switch it around when it's Model B's turn.\n\nBut I had another idea, where I could just create one UBO, which would change contents from one model's UBO to another, and bind that to a single Descriptor Set. This seemed to be the best, but I don't know if that's true and if it could even work, or if it's best practice.\n\nAny help would be appreciated, I am new to vulkan."
    },
    {
        "link": "https://reddit.com/r/vulkan/comments/msrh2d/vulkan_best_practices_on_graphics_pipelines",
        "document": "Hi everyone, I've been learning Vulkan for a while now and I know the fundamentals. Recently I've read a bit about GPU driven rendering and bindless techniques and I really like the ideas behind it. But I would like to know more about how to aproach real world problems.\n\nHow common is this type of design on game engines or other 3D software? I know that material switches on mobile are expensive and should be avoided as much as possible, what about high end desktop GPUs? These techniques scale really nice to high polygon counts but are they worth implementing for not-so-demanding renderers too? Do you see them as \"future\", \"absolutely necessary\" for high end engines or just another tool to pick for the right job?\n\nThis is only a small part of the GPU driven rendering but to narrow down my questions a bit, I want to ask what are the best practices on pipelines, descriptor sets and shaders in general. Create pipelines and shaders per material (this is what the likes of Unreal does I think, though not necessarily on Vulkan)? Create only a few pipelines, an uber shader and use different descriptor sets for materials to access them? Limit descriptor sets too and use buffers and push constants as indices to access necessary material arrays in that uber shader? What kind of applications should use each one?\n\nAnother performance related topic I want to ask is the usage of dynamic buffers on descriptor sets. Is it always better than using separate descriptor sets or are there some cases where using separate descriptor sets are better than dynamic buffers?\n\nI know these are a lot of questions in one thread and most of the answers will be opinion based and \"depends on the use case or platform\" but that's what I want to know. I don't have experience as a professional Vulkan developer so your experiences are really appreciated. Partial answers to only some questions are also welcome. Thanks in advance."
    },
    {
        "link": "https://developer.arm.com/documentation/101897/latest/CPU-overheads/Optimizing-descriptor-sets-and-layouts-for-Vulkan",
        "document": ""
    },
    {
        "link": "https://vulkan-tutorial.com/Drawing_a_triangle/Setup/Validation_layers",
        "document": "The Vulkan API is designed around the idea of minimal driver overhead and one of the manifestations of that goal is that there is very limited error checking in the API by default. Even mistakes as simple as setting enumerations to incorrect values or passing null pointers to required parameters are generally not explicitly handled and will simply result in crashes or undefined behavior. Because Vulkan requires you to be very explicit about everything you're doing, it's easy to make many small mistakes like using a new GPU feature and forgetting to request it at logical device creation time.\n\nHowever, that doesn't mean that these checks can't be added to the API. Vulkan introduces an elegant system for this known as validation layers. Validation layers are optional components that hook into Vulkan function calls to apply additional operations. Common operations in validation layers are:\n• Checking the values of parameters against the specification to detect misuse\n• Tracking creation and destruction of objects to find resource leaks\n• Checking thread safety by tracking the threads that calls originate from\n• Logging every call and its parameters to the standard output\n\nHere's an example of what the implementation of a function in a diagnostics validation layer could look like:\n\nThese validation layers can be freely stacked to include all the debugging functionality that you're interested in. You can simply enable validation layers for debug builds and completely disable them for release builds, which gives you the best of both worlds!\n\nVulkan does not come with any validation layers built-in, but the LunarG Vulkan SDK provides a nice set of layers that check for common errors. They're also completely open source, so you can check which kind of mistakes they check for and contribute. Using the validation layers is the best way to avoid your application breaking on different drivers by accidentally relying on undefined behavior.\n\nValidation layers can only be used if they have been installed onto the system. For example, the LunarG validation layers are only available on PCs with the Vulkan SDK installed.\n\nThere were formerly two different types of validation layers in Vulkan: instance and device specific. The idea was that instance layers would only check calls related to global Vulkan objects like instances, and device specific layers would only check calls related to a specific GPU. Device specific layers have now been deprecated, which means that instance validation layers apply to all Vulkan calls. The specification document still recommends that you enable validation layers at device level as well for compatibility, which is required by some implementations. We'll simply specify the same layers as the instance at logical device level, which we'll see later on.\n\nIn this section we'll see how to enable the standard diagnostics layers provided by the Vulkan SDK. Just like extensions, validation layers need to be enabled by specifying their name. All of the useful standard validation is bundled into a layer included in the SDK that is known as .\n\nLet's first add two configuration variables to the program to specify the layers to enable and whether to enable them or not. I've chosen to base that value on whether the program is being compiled in debug mode or not. The macro is part of the C++ standard and means \"not debug\".\n\nWe'll add a new function that checks if all of the requested layers are available. First list all of the available layers using the function. Its usage is identical to that of which was discussed in the instance creation chapter.\n\nNext, check if all of the layers in exist in the list. You may need to include for .\n\nWe can now use this function in :\n\nNow run the program in debug mode and ensure that the error does not occur. If it does, then have a look at the FAQ.\n\nFinally, modify the struct instantiation to include the validation layer names if they are enabled:\n\nIf the check was successful then should not ever return a error, but you should run the program to make sure.\n\nThe validation layers will print debug messages to the standard output by default, but we can also handle them ourselves by providing an explicit callback in our program. This will also allow you to decide which kind of messages you would like to see, because not all are necessarily (fatal) errors. If you don't want to do that right now then you may skip to the last section in this chapter.\n\nTo set up a callback in the program to handle messages and the associated details, we have to set up a debug messenger with a callback using the extension.\n\nWe'll first create a function that will return the required list of extensions based on whether validation layers are enabled or not:\n\nThe extensions specified by GLFW are always required, but the debug messenger extension is conditionally added. Note that I've used the macro here which is equal to the literal string \"VK_EXT_debug_utils\". Using this macro lets you avoid typos.\n\nWe can now use this function in :\n\nRun the program to make sure you don't receive a error. We don't really need to check for the existence of this extension, because it should be implied by the availability of the validation layers.\n\nNow let's see what a debug callback function looks like. Add a new static member function called with the prototype. The and ensure that the function has the right signature for Vulkan to call it.\n\nThe first parameter specifies the severity of the message, which is one of the following flags:\n• : Informational message like the creation of a resource\n• : Message about behavior that is not necessarily an error, but very likely a bug in your application\n• : Message about behavior that is invalid and may cause crashes\n\nThe values of this enumeration are set up in such a way that you can use a comparison operation to check if a message is equal or worse compared to some level of severity, for example:\n\nThe parameter can have the following values:\n• : Some event has happened that is unrelated to the specification or performance\n• : Something has happened that violates the specification or indicates a possible mistake\n\nThe parameter refers to a struct containing the details of the message itself, with the most important members being:\n• : Array of Vulkan object handles related to the message\n\nFinally, the parameter contains a pointer that was specified during the setup of the callback and allows you to pass your own data to it.\n\nThe callback returns a boolean that indicates if the Vulkan call that triggered the validation layer message should be aborted. If the callback returns true, then the call is aborted with the error. This is normally only used to test the validation layers themselves, so you should always return .\n\nAll that remains now is telling Vulkan about the callback function. Perhaps somewhat surprisingly, even the debug callback in Vulkan is managed with a handle that needs to be explicitly created and destroyed. Such a callback is part of a debug messenger and you can have as many of them as you want. Add a class member for this handle right under :\n\nNow add a function to be called from right after :\n\nWe'll need to fill in a structure with details about the messenger and its callback:\n\nThe field allows you to specify all the types of severities you would like your callback to be called for. I've specified all types except for here to receive notifications about possible problems while leaving out verbose general debug info.\n\nSimilarly the field lets you filter which types of messages your callback is notified about. I've simply enabled all types here. You can always disable some if they're not useful to you.\n\nFinally, the field specifies the pointer to the callback function. You can optionally pass a pointer to the field which will be passed along to the callback function via the parameter. You could use this to pass a pointer to the class, for example.\n\nNote that there are many more ways to configure validation layer messages and debug callbacks, but this is a good setup to get started with for this tutorial. See the extension specification for more info about the possibilities.\n\nThis struct should be passed to the function to create the object. Unfortunately, because this function is an extension function, it is not automatically loaded. We have to look up its address ourselves using . We're going to create our own proxy function that handles this in the background. I've added it right above the class definition.\n\nThe function will return if the function couldn't be loaded. We can now call this function to create the extension object if it's available:\n\nThe second to last parameter is again the optional allocator callback that we set to , other than that the parameters are fairly straightforward. Since the debug messenger is specific to our Vulkan instance and its layers, it needs to be explicitly specified as first argument. You will also see this pattern with other child objects later on.\n\nThe object also needs to be cleaned up with a call to . Similarly to the function needs to be explicitly loaded.\n\nCreate another proxy function right below :\n\nMake sure that this function is either a static class function or a function outside the class. We can then call it in the function:\n\nAlthough we've now added debugging with validation layers to the program we're not covering everything quite yet. The call requires a valid instance to have been created and must be called before the instance is destroyed. This currently leaves us unable to debug any issues in the and calls.\n\nHowever, if you closely read the extension documentation, you'll see that there is a way to create a separate debug utils messenger specifically for those two function calls. It requires you to simply pass a pointer to a struct in the extension field of . First extract population of the messenger create info into a separate function:\n\nWe can now re-use this in the function:\n\nThe variable is placed outside the if statement to ensure that it is not destroyed before the call. By creating an additional debug messenger this way it will automatically be used during and and cleaned up after that.\n\nNow let's intentionally make a mistake to see the validation layers in action. Temporarily remove the call to in the function and run your program. Once it exits you should see something like this:\n\nIf you want to see which call triggered a message, you can add a breakpoint to the message callback and look at the stack trace.\n\nThere are a lot more settings for the behavior of validation layers than just the flags specified in the struct. Browse to the Vulkan SDK and go to the directory. There you will find a file that explains how to configure the layers.\n\nTo configure the layer settings for your own application, copy the file to the and directories of your project and follow the instructions to set the desired behavior. However, for the remainder of this tutorial I'll assume that you're using the default settings.\n\nThroughout this tutorial I'll be making a couple of intentional mistakes to show you how helpful the validation layers are with catching them and to teach you how important it is to know exactly what you're doing with Vulkan. Now it's time to look at Vulkan devices in the system."
    },
    {
        "link": "https://reddit.com/r/vulkan/comments/6alsvg/where_to_get_started_with_access_violations_on",
        "document": "There have been a few posts about issues like this: for me, my biggest problem with this is that it's usually an access violation occurring somewhere in the driver ( for me). Even with the validation layers enabled, and/or using validation layers I've built myself, it doesn't leave a lot to work with.\n\nCurrently, I only get this bug when running in release mode. The exception address seems rather huge - a hint, I think, to what's going wrong:\n\nA quick bit of googling turned up that addresses like this are sometimes used to express uninitialized values, which would make sense as this bug occurs only in release mode (when things won't be default initialized).\n\nProblem is, I don't know where to start with fixing this. I've checked the graphics pipeline info struct in the VS debugger, and nothing there has garbage data. I have a big file where I define a bunch of default base instances of the various create info structs, and I make sure to set every field to some appropriate default value.\n\nIn the last post on this, someone had mentioned that these structs can't be const. I think I pass info structs around by const reference a few times - is this a no? The default structs are also all constexpr, but I copy from these and don't believe I ever directly use one in a Vulkan function call.\n\nI guess my question is pretty much what's in the title - given the (small amount) of information I have to work with, anyone got any pointers for finding the problem beyond just going through every. single. object. and checking it for uninitialized values in release mode?"
    },
    {
        "link": "https://gpuopen.com/learn/using-the-vulkan-validation-layers",
        "document": "Vulkan™ provides unprecedented control to developers over generating graphics and compute workloads for a wide range of hardware, from tiny embedded processors to high-end workstation GPUs with wildly different architectures. As usual, with great power comes great responsibility, and making sure that your application runs correctly on all these possible target platforms it is crucial to follow all the rules of the API specification even if some level of violation of these rules, either intentional or accidental, seem to not cause any issues on a particular hardware and driver implementation.\n\nTraditional graphics APIs try to solve this issue by defining a set of illegal API usage conditions that are required to be caught by driver implementations and reported to the application through some sort of error reporting mechanism. The problem with this approach is that even though these errors generated in response to incorrect API usage are extremely valuable during the development of an application, checking for all of these error conditions costs significant CPU time spent in the driver that provides no value when running a released application that is known to use the API correctly. Not to mention the fact that practice reveals some driver implementations are less pedantic about certain rules established by the API specifications than others, and thus relying on testing on a particular implementation and observing no problems could still lead to portability issues when the same application is ran against other driver implementations.\n\nUnlike traditional graphics APIs, Vulkan groups possible error scenarios into two distinct buckets:\n• Validity errors are error conditions resulting from incorrect API usage, i.e. the application not respecting the API usage rules that are required in order to get well-defined behavior from the issued commands. These rules are described in the specification for all API commands and structures in text blocks titled “Valid Usage“.\n• Run-time errors are error conditions that can occur even during the execution of applications that use the API correctly, like running out of memory, or failure to present to a window that has been closed in the meantime. Run-time errors are reported in the form of result codes. The specification describes the possible result codes each command may return individually in the form of text blocks titled “Return Codes“, accompanied with language describing the situations when each particular result code is expected to be returned by driver implementations.\n\nWhile many of the Vulkan API commands do return a result code in the form of one of the constants of the enumeration, these result codes are only used to indicate run-time errors and status information about certain operations or objects, but do not report information about respecting valid usage conditions. This allows release builds of applications to run at maximum performance because the driver implementations don’t have to spend precious CPU cycles on checking for the potential violation of specification rules as that’s anyways unnecessary in case of applications that are known to use the API correctly.\n\nAs driver implementations aren’t checking valid usage conditions and expect that all inputs coming from the application to be valid according to the specification, running applications that use the API incorrectly may result in unexpected behavior, including corrupted rendering or even application crashes. Often the consequences of passing invalid parameters to an API command might only manifest when executing latter commands.\n\nWe already acknowledged that not having to check for valid API usage for release builds of applications that are known to behave correctly from the point of view of the Vulkan API specification has great benefits, but it’s still very important to be able to identify incorrect API usage during the development of an application because finding the mistake we made that results in the weird corruption we see or the mysterious crash we can’t explain is not trivial to debug without a hint about where we should look for the error.\n\nIn order to provide a solution for this, Vulkan comes with a set of validation and debug layers as part of the Vulkan SDK. At the time of writing the SDK includes almost a dozen layers dedicated for validating certain aspects of API usage and providing debugging tools to developers like an API call dumper. When any subset of these layers are enabled they insert themselves automatically into the call-chain of every Vulkan API call issued by the application to perform their job. A detailed description of the individual layers is outside of the scope of this article but curious readers can find more information here.\n\nThe benefit of validation layers compared to the approach taken by traditional APIs is that applications only have to spend time on extensive error checking when explicitly requested, during development and typically when using debug builds of the application. This fits naturally in the general pay for what you use principle of the Vulkan API. Additionally, as the official validation layers coming with the SDK are maintained centrally and work equivalently across driver implementations, this approach doesn’t suffer from the fragmentation issues often seen in the error checking behavior of traditional APIs thus developers can be confident that the same validation errors are going to be reported in all cases, indifferent of the driver implementation the application is ran against.\n\nWhat’s even better, the validation layers aren’t just looking for violations of the allowed API usage, but can also report warnings about potential incorrect or dangerous use of the API, and are even capable of reporting performance warnings that allow developers to identify places where the API is used correctly but isn’t used in the most efficient way. Examples of such potential performance warnings are binding resources that aren’t actually used or using a sub-optimal layout for an image.\n\nApplication developers willing to validate their API usage during development are going to be primarily interested in that bulks all standard validation layers in a big meta-layer. Enabling this layer ensures that all official validation layers will going to be keen on trying to catch any mistake the application makes in the use of Vulkan. In order to report the caught violations of valid API usage to the application the validation layers expose the instance extension that allows feeding the detected validation errors and warnings to application-provided callbacks. We are going to present the basic usage of this extension in this article but more information is available in the Vulkan Registry.\n\nWe recommend that all applications should enable and use the validation layers in their debug builds in order to make sure their applications are always respecting valid API usage and thus are going to be portable across the wide range of Vulkan driver implementations.\n\nThe following code snippet shows a typical C++ example of how applications should enable the layer and the extension at instance creation time in their debug builds:\n\nEditor’s Note: Based on your input I’ve replaced the use of the macro to indicate code that is meant to be built only in debug versions of the application and now the code examples refer to a custom macro called that you should replace with the debug build macro used by your project or compiler toolchain.\n\nOf course, a resilient application should first check for the presence of the used instance layers and extensions before passing them to by using the and commands, respectively. After a successful instance creation the validation layers are active for the instance and the debug report extension is available for use.\n\nAs the instance extension is not a core feature, the addresses of its entry points have to be acquired through the use of the command as shown in the code snippet below:\n\nWe’ll talk about each individual entry point of the extension separately, but first let’s take a look at how an application-provided debug report callback should look like and what behavior it should follow. The application can register any number of debug report callbacks, they only need to match the signature defined by . A sample debug report callback that simply directs all incoming debug messages to is presented below:\n\nThe parameters passed to the callback provide information about where and what type of validation event has triggered the call, like the type of the event (error, warning, performance warning, etc.), the type and handle of the object being created or manipulated by the command triggering the call, the code and text message describing the event, and there’s even a parameter to supply application-specific user data to the callback which is provided when registering the callback. By putting a breakpoint in the callback, developers can also have access to the complete callstack to more accurately determine the location of the offending API call.\n\nThe return value of the callback is a Boolean that indicates to the validation layers whether the API call that triggered the debug report callback should be aborted or not. However, developers have to be aware that in case an error is reported by one of the validation layers it’s an indication that something invalid was being attempted by the application thus any operation following the error might result in undefined behavior or even a crash. As such, it’s advised that developers stop at the first error and try to resolve that before making any assumptions about the behavior of subsequent operations. Think about validation errors in the same way like errors reported by compilers: often subsequent errors are just consequences of the first one.\n\nWhen registering our debug report callback, we can specify what type of events we want to get notification about. Typically we’re interested in errors, warnings, and performance warnings; the following code snipped registers our callback with such a configuration:\n\nAn already registered callback can then be unregistered by destroying the callback object just like any other API object using the corresponding destroy command, . Developers should make sure to unregister their debug report callbacks before destroying the instance, otherwise they going to be notified about their misbehavior through any debug report callback that’s registered to receive errors.\n\nThe last remaining entry point of the debug report extension that we didn’t discuss yet, can be used to generate debug report messages from application code. This can be useful to mark certain points of the execution of the application or to report application specific information to the same stream where the validation messages are fed.\n\nUpdate: Since version 1.0.13 of the Vulkan API specification and the Vulkan SDK device layers have been deprecated so the instructions related to enabling the validation layers at the device level have been removed accordingly.\n\nThe recommended way to validate an application is the approach presented so far, because it allows developers to enable validation based on the type of the build, as presented, based on some application setting, or through any other mechanism. Additionally, the debug report callback enables fine grained control over which validation events should be captured and how.\n\nHowever, in some cases it’s possible that modifying or rebuilding the application to enable validation programatically is not viable or convenient. This includes cases like validating release builds of applications that don’t reproduce the issue in debug builds, or validating third-party applications or libraries that we cannot rebuild because of lack of access to the source code.\n\nThere’s a solution even for situations like this, as layers can also be enabled through the environment variable . This variable accepts a list of layer names to enable separated by semicolons (Windows) or colons (Linux). The following command enables all standard validation layers on Windows:\n\nWhen enabling validation through this approach, besides setting the environment variable to activate the layers, the reporting mechanism must be configured for each layer via a settings file, otherwise the activated layers will produce no output. This settings file must be named and must be located in the working directory of the application or in the directory specified using the environment variable. A sample layer settings file is provided as part of the Vulkan SDK under the folder which will simply output all error, warning, and performance warning messages to , if used, but can be easily changed to output a different subset of the validation messages and can be redirected to files instead of console output (which may be necessary to capture the output of applications without a console). The sample settings file contains instructions about how to change the various configuration options.\n\nWhile getting familiar with the Vulkan API may seem a bit involving at the beginning, as due to its nature it has a steeper learning curve than traditional APIs, the validation layers make it much easier to catch any mistakes, and they also provide a lot of additional useful information beyond just reporting basic errors. While using the validation layers does not completely eliminate the need to test your application on multiple platforms, it minimizes the chances of any portability issues resulting from incorrect API usage.\n\nIn addition to that, the official loader and validation layers are all available open-source on Github. So in case you find any errors that aren’t currently caught by any of the validation layers then don’t hesitate: contribute!\n\nDon’t forget: validate your application before the users validate it for you!"
    },
    {
        "link": "https://reddit.com/r/vulkan/comments/jwwmza/reenabled_validation_layers_and_now_i_get_an",
        "document": "I've run into a confusing issue when using validation layers. The very first render pass I attempt to begin (vkCmdBeginRenderPass) throws an exception:\n\nWhat is rp_state? The framebuffer is an opaque vulkan handle, but it seems to be set up properly and everything runs normally with validation layers turned off.\n\nHas anyone run into this? I'm getting no relevant results searching the error."
    },
    {
        "link": "https://stackoverflow.com/questions/36438651/vklayer-param-checker-dll-access-violation",
        "document": "I have a Vulkan 1.0.5.0 program set up, using the LunarG installer, and it works without enabling any layers.\n\nWhen I try and enable either of:\n\nI get an access violation in VkLayer_param_checker.dll or VkLayer_api_dump.dll when I try to call vkCreateInstance.\n\nThey also fail if I try and load any one individually as the only layer.\n\nThe JSON files are present in the registry under ExplicitLayers, and the files themselves looks fine.\n\nI also get the message in visual studio that the dlls are loaded.\n\nThese layers worked on an older 1.0.3.1 test program, which is odd, and I'm able to enable all of the following:\n\nIs there a specific order the layers must be loaded in? I'm sure I read that somewhere but I can't find it again. Any help appreciated."
    }
]