[
    {
        "link": "https://cnvrg.io/keras-custom-loss-functions",
        "document": ""
    },
    {
        "link": "https://stackoverflow.com/questions/48373845/loading-model-with-custom-loss-keras",
        "document": "In Keras, if you need to have a custom loss with additional parameters, we can use it like mentioned on https://datascience.stackexchange.com/questions/25029/custom-loss-function-with-additional-parameter-in-keras\n\nThe above method works when I am training the model. However, once the model is trained I am having difficulty in loading the model. When I try to use the custom_objects parameter in load_model like below\n\nIs there any way to pass in the loss function as one of the custom losses in ? From what I can gather, the inner function is not in the namespace during load_model call. Is there any easier way to load the model or use a custom loss with additional parameters"
    },
    {
        "link": "https://neptune.ai/blog/keras-loss-functions",
        "document": "You’ve created a deep learning model in Keras, you prepared the data and now you are wondering which loss you should choose for your problem.\n\nWe’ll get to that in a second but first what is a loss function?\n\nIn deep learning, the loss is computed to get the gradients with respect to model weights and update those weights accordingly via backpropagation. Loss is calculated and the network is updated after every iteration until model updates don’t bring any improvement in the desired evaluation metric.\n\nSo while you keep using the same evaluation metric like f1 score or AUC on the validation set during (long parts) of your machine learning project, the loss can be changed, adjusted and modified to get the best evaluation metric performance.\n\nYou can think of the loss function just like you think about the model architecture or the optimizer and it is important to put some thought into choosing it. In this piece we’ll look at:\n• loss functions available in Keras and how to use them,\n• how you can define your own custom loss function in Keras,\n• how to add sample weighing to create observation-sensitive losses,\n• how to avoid nans in the loss,\n• how you can monitor the loss function via plotting and callbacks.\n\nLet’s get into it!\n\nIn Keras, loss functions are passed during the compile stage, as shown below.\n\nIn this example, we’re defining the loss function by creating an instance of the loss class. Using the class is advantageous because you can pass some additional parameters.\n\nIf you want to use a loss function that is built into Keras without specifying any parameters you can just use the string alias as shown below:\n\nYou might be wondering how does one decide on which loss function to use?\n\nThere are various loss functions available in Keras. Other times you might have to implement your own custom loss functions.\n\nLet’s dive into all those scenarios.\n\nWhich loss functions are available in Keras?\n\nBinary classification loss function comes into play when solving a problem involving just two classes. For example, when predicting fraud in credit card transactions, a transaction is either fraudulent or not.\n\nThe BinaryCrossentropy will calculate the cross-entropy loss between the predicted classes and the true classes. By default, the sum_over_batch_size reduction is used. This means that the loss will return the average of the per-sample losses in the batch.\n\nThe sum reduction means that the loss function will return the sum of the per-sample losses in the batch.\n\nUsing the reduction as none returns the full array of the per-sample losses.\n\nIn binary classification, the activation function used is the sigmoid activation function. It constrains the output to a number between 0 and 1.\n\nProblems involving the prediction of more than one class use different loss functions. In this section we’ll look at a couple:\n\nThe CategoricalCrossentropy also computes the cross-entropy loss between the true classes and predicted classes. The labels are given in an one_hot format.\n\nIf you have two or more classes and the labels are integers, the SparseCategoricalCrossentropy should be used.\n\nYou can also use the Poisson class to compute the poison loss. It’s a great choice if your dataset comes from a Poisson distribution for example the number of calls a call center receives per hour.\n\nThe relative entropy can be computed using the KLDivergence class. According to the official docs at PyTorch:\n\nKL divergence is a useful distance measure for continuous distributions and is often useful when performing direct regression over the space of (discretely sampled) continuous output distributions.\n\nIn a multi-class problem, the activation function used is the softmax function.\n\nIn classification problems involving imbalanced data and object detection problems, you can use the Focal Loss. The loss introduces an adjustment to the cross-entropy criterion.\n\nIt is done by altering its shape in a way that the loss allocated to well-classified examples is down-weighted. This ensures that the model is able to learn equally from minority and majority classes.\n\nThe cross-entropy loss is scaled by scaling the factors decaying at zero as the confidence in the correct class increases. The factor of scaling down weights the contribution of unchallenging samples at training time and focuses on the challenging ones.\n\nThe Generalized Intersection over Union loss from the TensorFlow add on can also be used. The Intersection over Union (IoU) is a very common metric in object detection problems. IoU is however not very efficient in problems involving non-overlapping bounding boxes.\n\nThe Generalized Intersection over Union was introduced to address this challenge that IoU is facing. It ensures that generalization is achieved by maintaining the scale-invariant property of IoU, encoding the shape properties of the compared objects into the region property, and making sure that there is a strong correlation with IoU in the event of overlapping objects.\n\nIn regression problems, you have to calculate the differences between the predicted values and the true values but as always there are many ways to do it.\n\nThe MeanSquaredError class can be used to compute the mean square of errors between the predictions and the true values.\n\nUse Mean Squared Error when you desire to have large errors penalized more than smaller ones.\n\nThe mean absolute percentage error is computed using the function below.\n\nIt is calculated as shown below.\n\nConsider using this loss when you want a loss that you can explain intuitively. People understand percentages easily. The loss is also robust to outliers.\n\nThe mean squared logarithmic error can be computed using the formula below:\n\nHere’s an implementation of the same:\n\nMean Squared Logarithmic Error penalizes underestimates more than it does overestimates. It’s a great choice when you prefer not to penalize large errors, it is, therefore, robust to outliers.\n\nIf your interest is in computing the cosine similarity between the true and predicted values, you’d use the CosineSimilarity class. It is computed as:\n\nThe result is a number between -1 and 1 . 0 indicates orthogonality while values close to -1 show that there is great similarity.\n\nThe LogCosh class computes the logarithm of the hyperbolic cosine of the prediction error.\n\nLogCosh Loss works like the mean squared error, but will not be so strongly affected by the occasional wildly incorrect prediction. — TensorFlow Docs\n\nFor regression problems that are less sensitive to outliers, the Huber loss is used.\n\nYou can also compute the triplet loss with semi-hard negative mining via TensorFlow addons. The loss encourages the positive distances between pairs of embeddings with the same labels to be less than the minimum negative distance.\n\nSometimes there is no good loss available or you need to implement some modifications. Let’s learn how to do that.\n\nA custom loss function can be created by defining a function that takes the true values and predicted values as required parameters. The function should return an array of losses. The function can then be passed at the compile stage.\n\nLet’s see how we can apply this custom loss function to an array of predicted and true values.\n\nDuring the training process, one can weigh the loss function by observations or samples. The weights can be arbitrary, but a typical choice is class weights (distribution of labels). Each observation is weighted by the fraction of the class it belongs to (reversed) so that the loss for minority class observations is more important when calculating the loss.\n\nOne of the ways to do this is to pass the class weights during the training process.\n\nThe weights are passed using a dictionary that contains the weight for each class. You can compute the weights using Scikit-learn or calculate the weights based on your own criterion.\n\nThe second way is to pass these weights at the compile stage.\n\nHow to monitor Keras loss function with neptune.ai\n\nIt is usually a good idea to monitor the loss function on the training and validation set as the model is training. Looking at those learning curves is a good indication of overfitting or other problems with model training.\n\nThere are two main options of how this can be done.\n\nThe quickest and easiest way to log and look at the losses is by simply printing them to the console.\n\nRunning the code, you can see the loss per epoch is printed directly:\n\nDespite being easy to implement, there are a few issues with this approach:\n• The logs can be easily lost.\n• It’s difficult to see progress, especially with higher numbers of epochs.\n• You might not have access to these logs when working on remote machines.\n\nUsing callbacks can be a better alternative.\n\nCallbacks are functions passed to other functions, allowing them to be executed after a defined task or event is completed.\n\nWe’ll be using neptune.ai as our experiment tracker for the metrics we track with our callback. Neptune is a versatile and highly scalable experiment tracker, allowing you to track months-long training runs and compare thousands of metrics in no time.\n\nTo get started, make an account (it’s free for personal use!) and check out the Quickstart guide, which includes information on how to connect your Google Colab environment to Neptune. Then, all you’ll have to do is create a project and your API key from the UI.\n\nAfter that, using callbacks with Neptune is simple. For example, logging your Keras loss to Neptune could look like this:\n\nHere, our callback sends metrics (like loss and accuracy) to Neptune at the end of every batch and epoch so we can visualize them easily.\n\nYou can create the monitoring callback yourself or use one of the many available Keras callbacks in the Keras library and other libraries that integrate with it—like neptune.ai, TensorBoard, and others.\n\nOnce your callback is ready, you just pass it to model.fit(…). Be sure to specify your API key and the project name before running the code.\n\nNow you can easily monitor your experiment learning curves and visualize them like this:\n\nIn this dashboard, we’re visualizing many key aspects of our model training: accuracy, loss, hyperparameters, model architecture, and even sample predictions on the test set.\n\nYou can interact with this example project directly on the Neptune web app.\n\nMost of the time, losses you log will be just some regular values, but sometimes you might get nans when working with Keras loss functions.\n\nWhen that happens, your model will not update its weights and will stop learning, so this situation needs to be avoided.\n\nThere could be many reasons for nan loss but usually, what happens is:\n• nans in the training set will lead to nans in the loss,\n• NumPy infinite in the training set will also lead to nans in the loss,\n• Using a training set that is not scaled,\n• Use of very large l2 regularizers and a learning rate above 1,\n• Use of the wrong optimizer function,\n• Large (exploding) gradients that result in a large update to network weights during training.\n\nSo in order to avoid nans in the loss, ensure that:\n• Check that your training data is properly scaled and doesn’t contain nans;\n• Check that you are using the right optimizer and that your learning rate is not too large;\n• Check whether the l2 regularization is not too large;\n• If you are facing the exploding gradient problem, you can either: re-design the network or use gradient clipping so that your gradients have a certain “maximum allowed model update”.\n\nHopefully, this article gave you some background into loss functions in Keras.\n• Implementation of your own custom loss functions,\n• How to add sample weighing to create observation-sensitive losses,\n• How you can visualize loss as your model is training.\n\nFor more information, check out the Keras Repository and the TensorFlow Loss Functions documentation."
    },
    {
        "link": "https://tensorflow.org/guide/keras/training_with_built_in_methods",
        "document": "Stay organized with collections Save and categorize content based on your preferences.\n\nThis guide covers training, evaluation, and prediction (inference) models when using built-in APIs for training & validation (such as , and ).\n\nIf you are interested in leveraging while specifying your own training step function, see the Customizing what happens in guide.\n\nIf you are interested in writing your own training & evaluation loops from scratch, see the guide \"writing a training loop from scratch\".\n\nIn general, whether you are using built-in loops or writing your own, model training & evaluation works strictly in the same way across every kind of Keras model -- Sequential models, models built with the Functional API, and models written from scratch via model subclassing.\n\nThis guide doesn't cover distributed training, which is covered in our guide to multi-GPU & distributed training.\n\nWhen passing data to the built-in training loops of a model, you should either use NumPy arrays (if your data is small and fits in memory) or objects. In the next few paragraphs, we'll use the MNIST dataset as NumPy arrays, in order to demonstrate how to use optimizers, losses, and metrics.\n\nLet's consider the following model (here, we build in with the Functional API, but it could be a Sequential model or a subclassed model as well):\n\nHere's what the typical end-to-end workflow looks like, consisting of:\n• Validation on a holdout set generated from the original training data\n\nWe'll use MNIST data for this example.\n\nWe specify the training configuration (optimizer, loss, metrics):\n\nWe call , which will train the model by slicing the data into \"batches\" of size , and repeatedly iterating over the entire dataset for a given number of .\n\nThe returned object holds a record of the loss values and metric values during training:\n\nWe evaluate the model on the test data via :\n\nNow, let's review each piece of this workflow in detail.\n\nThe method: specifying a loss, metrics, and an optimizer\n\nTo train a model with , you need to specify a loss function, an optimizer, and optionally, some metrics to monitor.\n\nYou pass these to the model as arguments to the method:\n\nThe argument should be a list -- your model can have any number of metrics.\n\nIf your model has multiple outputs, you can specify different losses and metrics for each output, and you can modulate the contribution of each output to the total loss of the model. You will find more details about this in the Passing data to multi-input, multi-output models section.\n\nNote that if you're satisfied with the default settings, in many cases the optimizer, loss, and metrics can be specified via string identifiers as a shortcut:\n\nFor later reuse, let's put our model definition and compile step in functions; we will call them several times across different examples in this guide.\n\nMany built-in optimizers, losses, and metrics are available\n\nIn general, you won't have to create your own losses, metrics, or optimizers from scratch, because what you need is likely to be already part of the Keras API:\n\nIf you need to create a custom loss, Keras provides three ways to do so.\n\nThe first method involves creating a function that accepts inputs and . The following example shows a loss function that computes the mean squared error between the real data and the predictions:\n\nIf you need a loss function that takes in parameters beside and , you can subclass the class and implement the following two methods:\n• : accept parameters to pass during the call of your loss function\n• : use the targets (y_true) and the model predictions (y_pred) to compute the model's loss\n\nLet's say you want to use mean squared error, but with an added term that will de-incentivize prediction values far from 0.5 (we assume that the categorical targets are one-hot encoded and take values between 0 and 1). This creates an incentive for the model not to be too confident, which may help reduce overfitting (we won't know if it works until we try!).\n\nHere's how you would do it:\n\nIf you need a metric that isn't part of the API, you can easily create custom metrics by subclassing the class. You will need to implement 4 methods:\n• , in which you will create state variables for your metric.\n• , which uses the targets y_true and the model predictions y_pred to update the state variables.\n• , which uses the state variables to compute the final results.\n• , which reinitializes the state of the metric.\n\nState update and results computation are kept separate (in and , respectively) because in some cases, the results computation might be very expensive and would only be done periodically.\n\nHere's a simple example showing how to implement a metric that counts how many samples were correctly classified as belonging to a given class:\n\nHandling losses and metrics that don't fit the standard signature\n\nThe overwhelming majority of losses and metrics can be computed from and , where is an output of your model -- but not all of them. For instance, a regularization loss may only require the activation of a layer (there are no targets in this case), and this activation may not be a model output.\n\nIn such cases, you can call from inside the call method of a custom layer. Losses added in this way get added to the \"main\" loss during training (the one passed to ). Here's a simple example that adds activity regularization (note that activity regularization is built-in in all Keras layers -- this layer is just for the sake of providing a concrete example):\n\nNote that when you pass losses via , it becomes possible to call without a loss function, since the model already has a loss to minimize.\n\nConsider the following layer: it takes as inputs targets & logits, and it tracks a crossentropy loss via .\n\nYou can use it in a model with two inputs (input data & targets), compiled without a argument, like this:\n\nFor more information about training multi-input models, see the section Passing data to multi-input, multi-output models.\n\nIn the first end-to-end example you saw, we used the argument to pass a tuple of NumPy arrays to the model for evaluating a validation loss and validation metrics at the end of each epoch.\n\nHere's another option: the argument allows you to automatically reserve part of your training data for validation. The argument value represents the fraction of the data to be reserved for validation, so it should be set to a number higher than 0 and lower than 1. For instance, means \"use 20% of the data for validation\", and means \"use 60% of the data for validation\".\n\nThe way the validation is computed is by taking the last x% samples of the arrays received by the call, before any shuffling.\n\nNote that you can only use when training with NumPy data.\n\nIn the past few paragraphs, you've seen how to handle losses, metrics, and optimizers, and you've seen how to use the and arguments in , when your data is passed as NumPy arrays.\n\nLet's now take a look at the case where your data comes in the form of a object.\n\nThe API is a set of utilities in TensorFlow 2.0 for loading and preprocessing data in a way that's fast and scalable.\n\nFor a complete guide about creating , see the tf.data documentation.\n\nYou can pass a instance directly to the methods , , and :\n\nNote that the Dataset is reset at the end of each epoch, so it can be reused of the next epoch.\n\nIf you want to run training only on a specific number of batches from this Dataset, you can pass the argument, which specifies how many training steps the model should run using this Dataset before moving on to the next epoch.\n\nIf you do this, the dataset is not reset at the end of each epoch, instead we just keep drawing the next batches. The dataset will eventually run out of data (unless it is an infinitely-looping dataset).\n\nYou can pass a instance as the argument in :\n\nAt the end of each epoch, the model will iterate over the validation dataset and compute the validation loss and validation metrics.\n\nIf you want to run validation only on a specific number of batches from this dataset, you can pass the argument, which specifies how many validation steps the model should run with the validation dataset before interrupting validation and moving on to the next epoch:\n\nNote that the validation dataset will be reset after each use (so that you will always be evaluating on the same samples from epoch to epoch).\n\nThe argument (generating a holdout set from the training data) is not supported when training from objects, since this feature requires the ability to index the samples of the datasets, which is not possible in general with the API.\n\nBesides NumPy arrays, eager tensors, and TensorFlow , it's possible to train a Keras model using Pandas dataframes, or from Python generators that yield batches of data & labels.\n\nIn particular, the class offers a simple interface to build Python data generators that are multiprocessing-aware and can be shuffled.\n\nIn general, we recommend that you use:\n• NumPy input data if your data is small and fits in memory\n• objects if you have large datasets and you need to do distributed training\n• objects if you have large datasets and you need to do a lot of custom Python-side processing that cannot be done in TensorFlow (e.g. if you rely on external libraries for data loading or preprocessing).\n\nis a utility that you can subclass to obtain a Python generator with two important properties:\n• It works well with multiprocessing.\n• It can be shuffled (e.g. when passing in ).\n\nThe method should return a complete batch. If you want to modify your dataset between epochs, you may implement .\n\nWith the default settings the weight of a sample is decided by its frequency in the dataset. There are two methods to weight the data, independent of sample frequency:\n\nThis is set by passing a dictionary to the argument to . This dictionary maps class indices to the weight that should be used for samples belonging to this class.\n\nThis can be used to balance classes without resampling, or to train a model that gives more importance to a particular class.\n\nFor instance, if class \"0\" is half as represented as class \"1\" in your data, you could use .\n\nHere's a NumPy example where we use class weights or sample weights to give more importance to the correct classification of class #5 (which is the digit \"5\" in the MNIST dataset).\n\nFor fine grained control, or if you are not building a classifier, you can use \"sample weights\".\n• When training from NumPy data: Pass the argument to .\n• When training from or any other sort of iterator: Yield tuples.\n\nA \"sample weights\" array is an array of numbers that specify how much weight each sample in a batch should have in computing the total loss. It is commonly used in imbalanced classification problems (the idea being to give more weight to rarely-seen classes).\n\nWhen the weights used are ones and zeros, the array can be used as a mask for the loss function (entirely discarding the contribution of certain samples to the total loss).\n\nIn the previous examples, we were considering a model with a single input (a tensor of shape ) and a single output (a prediction tensor of shape ). But what about models that have multiple inputs or outputs?\n\nConsider the following model, which has an image input of shape (that's ) and a time series input of shape (that's ). Our model will have two outputs computed from the combination of these inputs: a \"score\" (of shape ) and a probability distribution over five classes (of shape ).\n\nLet's plot this model, so you can clearly see what we're doing here (note that the shapes shown in the plot are batch shapes, rather than per-sample shapes).\n\nAt compilation time, we can specify different losses to different outputs, by passing the loss functions as a list:\n\nIf we only passed a single loss function to the model, the same loss function would be applied to every output (which is not appropriate here).\n\nSince we gave names to our output layers, we could also specify per-output losses and metrics via a dict:\n\nWe recommend the use of explicit names and dicts if you have more than 2 outputs.\n\nIt's possible to give different weights to different output-specific losses (for instance, one might wish to privilege the \"score\" loss in our example, by giving to 2x the importance of the class loss), using the argument:\n\nYou could also choose not to compute a loss for certain outputs, if these outputs are meant for prediction but not for training:\n\nPassing data to a multi-input or multi-output model in works in a similar way as specifying a loss function in compile: you can pass lists of NumPy arrays (with 1:1 mapping to the outputs that received a loss function) or dicts mapping output names to NumPy arrays.\n\nHere's the use case: similarly as what we did for NumPy arrays, the should return a tuple of dicts.\n\nCallbacks in Keras are objects that are called at different points during training (at the start of an epoch, at the end of a batch, at the end of an epoch, etc.). They can be used to implement certain behaviors, such as:\n• Doing validation at different points during training (beyond the built-in per-epoch validation)\n• Checkpointing the model at regular intervals or when it exceeds a certain accuracy threshold\n• Changing the learning rate of the model when training seems to be plateauing\n• Doing fine-tuning of the top layers when training seems to be plateauing\n• Sending email or instant message notifications when training ends or where a certain performance threshold is exceeded\n\nCallbacks can be passed as a list to your call to :\n\nMany built-in callbacks are available\n\nThere are many built-in callbacks already available in Keras, such as:\n• : Stop training when training is no longer improving the validation metrics.\n• : periodically write model logs that can be visualized in TensorBoard (more details in the section \"Visualization\").\n\nSee the callbacks documentation for the complete list.\n\nYou can create a custom callback by extending the base class . A callback has access to its associated model through the class property .\n\nMake sure to read the complete guide to writing custom callbacks.\n\nHere's a simple example saving a list of per-batch loss values during training:\n\nWhen you're training model on relatively large datasets, it's crucial to save checkpoints of your model at frequent intervals.\n\nThe easiest way to achieve this is with the callback:\n\nThe callback can be used to implement fault-tolerance: the ability to restart training from the last saved state of the model in case training gets randomly interrupted. Here's a basic example:\n\nYou call also write your own callback for saving and restoring models.\n\nFor a complete guide on serialization and saving, see the guide to saving and serializing Models.\n\nA common pattern when training deep learning models is to gradually reduce the learning as training progresses. This is generally known as \"learning rate decay\".\n\nThe learning decay schedule could be static (fixed in advance, as a function of the current epoch or the current batch index), or dynamic (responding to the current behavior of the model, in particular the validation loss).\n\nYou can easily use a static learning rate decay schedule by passing a schedule object as the argument in your optimizer:\n\nSeveral built-in schedules are available: , , , and .\n\nA dynamic learning rate schedule (for instance, decreasing the learning rate when the validation loss is no longer improving) cannot be achieved with these schedule objects, since the optimizer does not have access to validation metrics.\n\nHowever, callbacks do have access to all metrics, including validation metrics! You can thus achieve this pattern by using a callback that modifies the current learning rate on the optimizer. In fact, this is even built-in as the callback.\n\nThe best way to keep an eye on your model during training is to use TensorBoard -- a browser-based application that you can run locally that provides you with:\n• Live plots of the loss and metrics for training and evaluation\n• (optionally) Visualizations of the histograms of your layer activations\n• (optionally) 3D visualizations of the embedding spaces learned by your layers\n\nIf you have installed TensorFlow with pip, you should be able to launch TensorBoard from the command line:\n\nThe easiest way to use TensorBoard with a Keras model and the method is the callback.\n\nIn the simplest case, just specify where you want the callback to write logs, and you're good to go:\n\nFor more information, see the documentation for the callback."
    },
    {
        "link": "https://medium.com/towards-data-science/creating-custom-loss-functions-in-tensorflow-understanding-the-theory-and-practicalities-383a19e387d6",
        "document": "Creating Custom Loss Functions in TensorFlow: Understanding the Theory and Practicalities\n\nIn machine learning, the loss function is a crucial component of the training process. It measures the difference between the model’s predictions and the true output and is used to update the model’s parameters to minimize this difference. While many commonly used loss functions are built into TensorFlow, there may be situations where you need to define a custom loss function to better suit the specific requirements of your model.\n\nThis can be useful for handling imbalanced datasets, incorporating domain knowledge, and other specific use cases. In this article, we will explore the theory behind custom loss functions, the benefits of using them, and the practicalities of creating them in TensorFlow.\n\nIn machine learning, the goal of training a model is to minimize the difference between its predictions and the true output. This difference is measured by a loss function, also known as a cost function. A loss function is a scalar function that compares the predicted output of a model with its true output. The most commonly used loss functions are mean squared error, mean absolute error, and cross-entropy.\n\nHow do Loss functions drive the optimization?\n\nThe optimization algorithm uses the value of the loss function to adjust the parameters of the model so that the difference between the predicted and true output is minimized. During the training phase, the model is presented with a set of inputs and corresponding true outputs, and the parameters of the model are adjusted to minimize the loss. The process is iterative, and it stops when the loss function reaches a minimum value or when a maximum number of iterations is reached.\n\nThe Need for Custom Loss Functions\n\nWhile the built-in loss functions provided by TensorFlow are sufficient for many cases, there may be situations where a custom loss function is needed. One of the most common reasons is handling imbalanced datasets. In such cases, the data may contain a large number of examples of one class and only a few examples of another class. This can lead to a model that is highly accurate but does not perform well for the minority class. In such cases, custom loss functions that optimize for recall or precision can be used to balance the trade-off between accuracy and performance on the minority class.\n\nAnother reason to use a custom loss function is to incorporate domain knowledge into the model. For example, in some cases, the predictions of a model need to satisfy specific constraints, such as being non-negative or having a specific range. Custom loss functions can be defined to enforce these constraints. Additionally, there are also some specific research areas such as object detection, and semantic segmentation has their own specific losses like cross-entropy with mask, dice loss, focal loss, etc.\n\nTensorFlow provides several tools for creating custom loss functions, including the module. To create a custom loss function in TensorFlow, you can subclass the class and define a method. The the method should take in the predicted and true outputs and return the calculated loss. It's also possible to pass additional arguments to the custom loss function's constructor to use them in the loss calculation.\n\nIt is also possible to use functions from the TensorFlow library to create custom loss functions, such as using mathematical operations or using the module. One important point to consider when defining custom loss functions is how the differentiable, as the optimizer is going to use the gradients of the loss w.r.t the model's parameters to update the model.\n\nOne common pitfall to avoid when creating custom loss functions is to forget to properly handle the case where the inputs are batched, this means that the inputs are matrices and not single values, so the mathematical operations should work on matrix dimensions as well.\n\nIt’s also important to note that the custom loss function’s class should implement the , and methods, which is the standard way to create a subclass in Keras.\n\nLet’s start with an example\n\nHere’s an example of creating a custom loss function in TensorFlow for handling imbalanced datasets. The example is a binary classification problem where the goal is to classify data points as either class A or class B, where class A is the minority class.\n\nThe custom loss function we will create will be a weighted cross-entropy loss, which assigns a higher weight to the minority class to balance the trade-off between the accuracy and performance of the minority class.\n\nHere, we are subclassing the class and defining a the method which takes in y_true and y_pred, the true and predicted labels respectively. The method calculates the weighted cross-entropy loss by using the weight variable passed during initialization and returning the mean of loss.\n\nIn order to use this custom loss function, you can pass an instance of it to the method of your model when defining the model.\n\nHere we passed the WeightedCrossEntropy object with weight=0.8 while compiling the model which will be used as the loss function during training.\n\nIt’s important to note that the weight parameter should be set based on the relative frequencies of the minority and majority classes in the training dataset.\n\nPlease keep in mind that this is an example and you might need to adjust it to fit your specific use case, it should also be coupled with techniques such as over-sampling, under-sampling, or synthetic data generation in order to handle imbalanced data properly.\n\nHere’s an example of how to use the custom loss function we created earlier in the context of a digit classification problem using the MNIST dataset. First, we will load the MNIST dataset using TensorFlow’s built-in module and split it into training and testing sets. Next, we will define a simple model for classifying the digits in the MNIST dataset. Now, we will determine the weight for the custom loss function based on the relative frequencies of the minority and majority classes in the training dataset. In this case, the minority class is ‘0’ and the majority class is ‘1’ to ‘9’.\n\nWe then define the custom loss function and pass the weight parameter to it. Finally, we compile our model, specifying the custom loss function, optimizer and metrics and we train our model with the training data. It’s important to keep in mind that this is just one example of how to use a custom loss function in TensorFlow, and there are many other ways you could use it depending on the problem you’re trying to solve. Additionally, it’s important to evaluate the performance of the model on the test set, as well as interpret the results and compare them with other techniques to handle imbalanced datasets.\n\nCustom loss functions can be a powerful tool for improving the performance of machine learning models, particularly when dealing with imbalanced datasets or incorporating domain knowledge. While creating a custom loss function can seem daunting, TensorFlow provides several tools and libraries to make the process easier. By understanding the theory and practicalities of custom loss functions, you’ll be well-equipped to tackle any challenges that come your way.\n\nIf you enjoyed this article and want to keep learning more about this topic, I invite you to join Medium membership at this link.\n\nBy becoming a member, you’ll have access to a wider variety of high-quality content, and exclusive access to member-only stories, and you’ll be supporting independent writers and creators like myself. Plus, as a member, you’ll be able to highlight your favourite passages, save stories for later, and get personalized reading recommendations. Sign up today and let’s continue exploring this topic and others together.\n\nThank you for your support! Until next,"
    },
    {
        "link": "https://keras.io/api/metrics",
        "document": "A metric is a function that is used to judge the performance of your model.\n\nMetric functions are similar to loss functions, except that the results from evaluating a metric are not used when training the model. Note that you may use any loss function as a metric.\n\nThe method takes a argument, which is a list of metrics:\n\nMetric values are displayed during and logged to the object returned by . They are also returned by .\n\nNote that the best way to monitor your metrics during training is via TensorBoard.\n\nTo track metrics under a specific name, you can pass the argument to the metric constructor:\n\nAll built-in metrics may also be passed via their string identifier (in this case, default constructor argument values are used, including a default metric name):\n\nUnlike losses, metrics are stateful. You update their state using the method, and you query the scalar metric result using the method:\n\nThe internal state can be cleared via .\n\nHere's how you would use a metric as part of a simple custom training loop:\n\nMuch like loss functions, any callable with signature that returns an array of losses (one of sample in the input batch) can be passed to as a metric. Note that sample weighting is automatically supported for any such metric.\n\nIn this case, the scalar metric value you are tracking during training and evaluation is the average of the per-batch metric values for all batches see during a given epoch (or during a given call to ).\n\nNot all metrics can be expressed via stateless callables, because metrics are evaluated for each batch during training and evaluation, but in some cases the average of the per-batch values is not what you are interested in.\n\nLet's say that you want to compute AUC over a given evaluation dataset: the average of the per-batch AUC values isn't the same as the AUC over the entire dataset.\n\nFor such metrics, you're going to want to subclass the class, which can maintain a state across batches. It's easy:\n• Update the variables given and in"
    },
    {
        "link": "https://tensorflow.org/guide/keras/training_with_built_in_methods",
        "document": "Stay organized with collections Save and categorize content based on your preferences.\n\nThis guide covers training, evaluation, and prediction (inference) models when using built-in APIs for training & validation (such as , and ).\n\nIf you are interested in leveraging while specifying your own training step function, see the Customizing what happens in guide.\n\nIf you are interested in writing your own training & evaluation loops from scratch, see the guide \"writing a training loop from scratch\".\n\nIn general, whether you are using built-in loops or writing your own, model training & evaluation works strictly in the same way across every kind of Keras model -- Sequential models, models built with the Functional API, and models written from scratch via model subclassing.\n\nThis guide doesn't cover distributed training, which is covered in our guide to multi-GPU & distributed training.\n\nWhen passing data to the built-in training loops of a model, you should either use NumPy arrays (if your data is small and fits in memory) or objects. In the next few paragraphs, we'll use the MNIST dataset as NumPy arrays, in order to demonstrate how to use optimizers, losses, and metrics.\n\nLet's consider the following model (here, we build in with the Functional API, but it could be a Sequential model or a subclassed model as well):\n\nHere's what the typical end-to-end workflow looks like, consisting of:\n• Validation on a holdout set generated from the original training data\n\nWe'll use MNIST data for this example.\n\nWe specify the training configuration (optimizer, loss, metrics):\n\nWe call , which will train the model by slicing the data into \"batches\" of size , and repeatedly iterating over the entire dataset for a given number of .\n\nThe returned object holds a record of the loss values and metric values during training:\n\nWe evaluate the model on the test data via :\n\nNow, let's review each piece of this workflow in detail.\n\nThe method: specifying a loss, metrics, and an optimizer\n\nTo train a model with , you need to specify a loss function, an optimizer, and optionally, some metrics to monitor.\n\nYou pass these to the model as arguments to the method:\n\nThe argument should be a list -- your model can have any number of metrics.\n\nIf your model has multiple outputs, you can specify different losses and metrics for each output, and you can modulate the contribution of each output to the total loss of the model. You will find more details about this in the Passing data to multi-input, multi-output models section.\n\nNote that if you're satisfied with the default settings, in many cases the optimizer, loss, and metrics can be specified via string identifiers as a shortcut:\n\nFor later reuse, let's put our model definition and compile step in functions; we will call them several times across different examples in this guide.\n\nMany built-in optimizers, losses, and metrics are available\n\nIn general, you won't have to create your own losses, metrics, or optimizers from scratch, because what you need is likely to be already part of the Keras API:\n\nIf you need to create a custom loss, Keras provides three ways to do so.\n\nThe first method involves creating a function that accepts inputs and . The following example shows a loss function that computes the mean squared error between the real data and the predictions:\n\nIf you need a loss function that takes in parameters beside and , you can subclass the class and implement the following two methods:\n• : accept parameters to pass during the call of your loss function\n• : use the targets (y_true) and the model predictions (y_pred) to compute the model's loss\n\nLet's say you want to use mean squared error, but with an added term that will de-incentivize prediction values far from 0.5 (we assume that the categorical targets are one-hot encoded and take values between 0 and 1). This creates an incentive for the model not to be too confident, which may help reduce overfitting (we won't know if it works until we try!).\n\nHere's how you would do it:\n\nIf you need a metric that isn't part of the API, you can easily create custom metrics by subclassing the class. You will need to implement 4 methods:\n• , in which you will create state variables for your metric.\n• , which uses the targets y_true and the model predictions y_pred to update the state variables.\n• , which uses the state variables to compute the final results.\n• , which reinitializes the state of the metric.\n\nState update and results computation are kept separate (in and , respectively) because in some cases, the results computation might be very expensive and would only be done periodically.\n\nHere's a simple example showing how to implement a metric that counts how many samples were correctly classified as belonging to a given class:\n\nHandling losses and metrics that don't fit the standard signature\n\nThe overwhelming majority of losses and metrics can be computed from and , where is an output of your model -- but not all of them. For instance, a regularization loss may only require the activation of a layer (there are no targets in this case), and this activation may not be a model output.\n\nIn such cases, you can call from inside the call method of a custom layer. Losses added in this way get added to the \"main\" loss during training (the one passed to ). Here's a simple example that adds activity regularization (note that activity regularization is built-in in all Keras layers -- this layer is just for the sake of providing a concrete example):\n\nNote that when you pass losses via , it becomes possible to call without a loss function, since the model already has a loss to minimize.\n\nConsider the following layer: it takes as inputs targets & logits, and it tracks a crossentropy loss via .\n\nYou can use it in a model with two inputs (input data & targets), compiled without a argument, like this:\n\nFor more information about training multi-input models, see the section Passing data to multi-input, multi-output models.\n\nIn the first end-to-end example you saw, we used the argument to pass a tuple of NumPy arrays to the model for evaluating a validation loss and validation metrics at the end of each epoch.\n\nHere's another option: the argument allows you to automatically reserve part of your training data for validation. The argument value represents the fraction of the data to be reserved for validation, so it should be set to a number higher than 0 and lower than 1. For instance, means \"use 20% of the data for validation\", and means \"use 60% of the data for validation\".\n\nThe way the validation is computed is by taking the last x% samples of the arrays received by the call, before any shuffling.\n\nNote that you can only use when training with NumPy data.\n\nIn the past few paragraphs, you've seen how to handle losses, metrics, and optimizers, and you've seen how to use the and arguments in , when your data is passed as NumPy arrays.\n\nLet's now take a look at the case where your data comes in the form of a object.\n\nThe API is a set of utilities in TensorFlow 2.0 for loading and preprocessing data in a way that's fast and scalable.\n\nFor a complete guide about creating , see the tf.data documentation.\n\nYou can pass a instance directly to the methods , , and :\n\nNote that the Dataset is reset at the end of each epoch, so it can be reused of the next epoch.\n\nIf you want to run training only on a specific number of batches from this Dataset, you can pass the argument, which specifies how many training steps the model should run using this Dataset before moving on to the next epoch.\n\nIf you do this, the dataset is not reset at the end of each epoch, instead we just keep drawing the next batches. The dataset will eventually run out of data (unless it is an infinitely-looping dataset).\n\nYou can pass a instance as the argument in :\n\nAt the end of each epoch, the model will iterate over the validation dataset and compute the validation loss and validation metrics.\n\nIf you want to run validation only on a specific number of batches from this dataset, you can pass the argument, which specifies how many validation steps the model should run with the validation dataset before interrupting validation and moving on to the next epoch:\n\nNote that the validation dataset will be reset after each use (so that you will always be evaluating on the same samples from epoch to epoch).\n\nThe argument (generating a holdout set from the training data) is not supported when training from objects, since this feature requires the ability to index the samples of the datasets, which is not possible in general with the API.\n\nBesides NumPy arrays, eager tensors, and TensorFlow , it's possible to train a Keras model using Pandas dataframes, or from Python generators that yield batches of data & labels.\n\nIn particular, the class offers a simple interface to build Python data generators that are multiprocessing-aware and can be shuffled.\n\nIn general, we recommend that you use:\n• NumPy input data if your data is small and fits in memory\n• objects if you have large datasets and you need to do distributed training\n• objects if you have large datasets and you need to do a lot of custom Python-side processing that cannot be done in TensorFlow (e.g. if you rely on external libraries for data loading or preprocessing).\n\nis a utility that you can subclass to obtain a Python generator with two important properties:\n• It works well with multiprocessing.\n• It can be shuffled (e.g. when passing in ).\n\nThe method should return a complete batch. If you want to modify your dataset between epochs, you may implement .\n\nWith the default settings the weight of a sample is decided by its frequency in the dataset. There are two methods to weight the data, independent of sample frequency:\n\nThis is set by passing a dictionary to the argument to . This dictionary maps class indices to the weight that should be used for samples belonging to this class.\n\nThis can be used to balance classes without resampling, or to train a model that gives more importance to a particular class.\n\nFor instance, if class \"0\" is half as represented as class \"1\" in your data, you could use .\n\nHere's a NumPy example where we use class weights or sample weights to give more importance to the correct classification of class #5 (which is the digit \"5\" in the MNIST dataset).\n\nFor fine grained control, or if you are not building a classifier, you can use \"sample weights\".\n• When training from NumPy data: Pass the argument to .\n• When training from or any other sort of iterator: Yield tuples.\n\nA \"sample weights\" array is an array of numbers that specify how much weight each sample in a batch should have in computing the total loss. It is commonly used in imbalanced classification problems (the idea being to give more weight to rarely-seen classes).\n\nWhen the weights used are ones and zeros, the array can be used as a mask for the loss function (entirely discarding the contribution of certain samples to the total loss).\n\nIn the previous examples, we were considering a model with a single input (a tensor of shape ) and a single output (a prediction tensor of shape ). But what about models that have multiple inputs or outputs?\n\nConsider the following model, which has an image input of shape (that's ) and a time series input of shape (that's ). Our model will have two outputs computed from the combination of these inputs: a \"score\" (of shape ) and a probability distribution over five classes (of shape ).\n\nLet's plot this model, so you can clearly see what we're doing here (note that the shapes shown in the plot are batch shapes, rather than per-sample shapes).\n\nAt compilation time, we can specify different losses to different outputs, by passing the loss functions as a list:\n\nIf we only passed a single loss function to the model, the same loss function would be applied to every output (which is not appropriate here).\n\nSince we gave names to our output layers, we could also specify per-output losses and metrics via a dict:\n\nWe recommend the use of explicit names and dicts if you have more than 2 outputs.\n\nIt's possible to give different weights to different output-specific losses (for instance, one might wish to privilege the \"score\" loss in our example, by giving to 2x the importance of the class loss), using the argument:\n\nYou could also choose not to compute a loss for certain outputs, if these outputs are meant for prediction but not for training:\n\nPassing data to a multi-input or multi-output model in works in a similar way as specifying a loss function in compile: you can pass lists of NumPy arrays (with 1:1 mapping to the outputs that received a loss function) or dicts mapping output names to NumPy arrays.\n\nHere's the use case: similarly as what we did for NumPy arrays, the should return a tuple of dicts.\n\nCallbacks in Keras are objects that are called at different points during training (at the start of an epoch, at the end of a batch, at the end of an epoch, etc.). They can be used to implement certain behaviors, such as:\n• Doing validation at different points during training (beyond the built-in per-epoch validation)\n• Checkpointing the model at regular intervals or when it exceeds a certain accuracy threshold\n• Changing the learning rate of the model when training seems to be plateauing\n• Doing fine-tuning of the top layers when training seems to be plateauing\n• Sending email or instant message notifications when training ends or where a certain performance threshold is exceeded\n\nCallbacks can be passed as a list to your call to :\n\nMany built-in callbacks are available\n\nThere are many built-in callbacks already available in Keras, such as:\n• : Stop training when training is no longer improving the validation metrics.\n• : periodically write model logs that can be visualized in TensorBoard (more details in the section \"Visualization\").\n\nSee the callbacks documentation for the complete list.\n\nYou can create a custom callback by extending the base class . A callback has access to its associated model through the class property .\n\nMake sure to read the complete guide to writing custom callbacks.\n\nHere's a simple example saving a list of per-batch loss values during training:\n\nWhen you're training model on relatively large datasets, it's crucial to save checkpoints of your model at frequent intervals.\n\nThe easiest way to achieve this is with the callback:\n\nThe callback can be used to implement fault-tolerance: the ability to restart training from the last saved state of the model in case training gets randomly interrupted. Here's a basic example:\n\nYou call also write your own callback for saving and restoring models.\n\nFor a complete guide on serialization and saving, see the guide to saving and serializing Models.\n\nA common pattern when training deep learning models is to gradually reduce the learning as training progresses. This is generally known as \"learning rate decay\".\n\nThe learning decay schedule could be static (fixed in advance, as a function of the current epoch or the current batch index), or dynamic (responding to the current behavior of the model, in particular the validation loss).\n\nYou can easily use a static learning rate decay schedule by passing a schedule object as the argument in your optimizer:\n\nSeveral built-in schedules are available: , , , and .\n\nA dynamic learning rate schedule (for instance, decreasing the learning rate when the validation loss is no longer improving) cannot be achieved with these schedule objects, since the optimizer does not have access to validation metrics.\n\nHowever, callbacks do have access to all metrics, including validation metrics! You can thus achieve this pattern by using a callback that modifies the current learning rate on the optimizer. In fact, this is even built-in as the callback.\n\nThe best way to keep an eye on your model during training is to use TensorBoard -- a browser-based application that you can run locally that provides you with:\n• Live plots of the loss and metrics for training and evaluation\n• (optionally) Visualizations of the histograms of your layer activations\n• (optionally) 3D visualizations of the embedding spaces learned by your layers\n\nIf you have installed TensorFlow with pip, you should be able to launch TensorBoard from the command line:\n\nThe easiest way to use TensorBoard with a Keras model and the method is the callback.\n\nIn the simplest case, just specify where you want the callback to write logs, and you're good to go:\n\nFor more information, see the documentation for the callback."
    },
    {
        "link": "https://tensorflow.org/guide/keras",
        "document": "Stay organized with collections Save and categorize content based on your preferences.\n\nKeras is the high-level API of the TensorFlow platform. It provides an approachable, highly-productive interface for solving machine learning (ML) problems, with a focus on modern deep learning. Keras covers every step of the machine learning workflow, from data processing to hyperparameter tuning to deployment. It was developed with a focus on enabling fast experimentation.\n\nWith Keras, you have full access to the scalability and cross-platform capabilities of TensorFlow. You can run Keras on a TPU Pod or large clusters of GPUs, and you can export Keras models to run in the browser or on mobile devices. You can also serve Keras models via a web API.\n\nKeras is designed to reduce cognitive load by achieving the following goals:\n• Minimize the number of actions required for common use cases.\n• Follow the principle of progressive disclosure of complexity: It's easy to get started, and you can complete advanced workflows by learning as you go.\n\nWho should use Keras\n\nThe short answer is that every TensorFlow user should use the Keras APIs by default. Whether you're an engineer, a researcher, or an ML practitioner, you should start with Keras.\n\nThere are a few use cases (for example, building tools on top of TensorFlow or developing your own high-performance platform) that require the low-level TensorFlow Core APIs. But if your use case doesn't fall into one of the Core API applications, you should prefer Keras.\n\nThe core data structures of Keras are layers and models. A layer is a simple input/output transformation, and a model is a directed acyclic graph (DAG) of layers.\n\nThe class is the fundamental abstraction in Keras. A encapsulates a state (weights) and some computation (defined in the method).\n\nWeights created by layers can be trainable or non-trainable. Layers are recursively composable: If you assign a layer instance as an attribute of another layer, the outer layer will start tracking the weights created by the inner layer.\n\nYou can also use layers to handle data preprocessing tasks like normalization and text vectorization. Preprocessing layers can be included directly into a model, either during or after training, which makes the model portable.\n\nA model is an object that groups layers together and that can be trained on data.\n\nThe simplest type of model is the model, which is a linear stack of layers. For more complex architectures, you can either use the Keras functional API, which lets you build arbitrary graphs of layers, or use subclassing to write models from scratch.\n• : Trains the model for a fixed number of epochs.\n• : Returns the loss and metrics values for the model; configured via the method.\n\nThese methods give you access to the following built-in training features:\n• Callbacks. You can leverage built-in callbacks for early stopping, model checkpointing, and TensorBoard monitoring. You can also implement custom callbacks.\n• Distributed training. You can easily scale up your training to multiple GPUs, TPUs, or devices.\n• Step fusing. With the argument in , you can process multiple batches in a single call, which greatly improves device utilization on TPUs.\n\nFor a detailed overview of how to use , see the training and evaluation guide. To learn how to customize the built-in training and evaluation loops, see Customizing what happens in .\n\nKeras provides many other APIs and tools for deep learning, including:\n\nFor a full list of available APIs, see the Keras API reference. To learn more about other Keras projects and initiatives, see The Keras ecosystem.\n\nTo get started using Keras with TensorFlow, check out the following topics:\n• Making new layers and models via subclassing\n• Customizing what happens in fit()\n\nTo learn more about Keras, see the following topics at keras.io:"
    },
    {
        "link": "https://keras.io/api/losses",
        "document": "The purpose of loss functions is to compute the quantity that a model should seek to minimize during training.\n\nNote that all losses are available both via a class handle and via a function handle. The class handles enable you to pass configuration arguments to the constructor (e.g. ), and they perform reduction by default when used in a standalone way (see details below).\n\nThis is the class to subclass in order to create new custom losses.\n• reduction: Type of reduction to apply to the loss. In almost all cases this should be . Supported options are , , , or . sums the loss, and sum the loss and divide by the sample size, and sums the loss and divides by the sum of the sample weights. and perform no aggregation. Defaults to .\n• name: Optional name for the loss instance.\n• dtype: The dtype of the loss's computations. Defaults to , which means using . is a unless set to different value (via ). If a is provided, then the will be utilized.\n\nTo be implemented by subclasses:\n• : Contains the logic for loss calculation using , .\n\nA loss function is one of the two arguments required for compiling a Keras model:\n\nAll built-in loss functions may also be passed via their string identifier:\n\nLoss functions are typically created by instantiating a loss class (e.g. ). All losses are also provided as function handles (e.g. ).\n\nUsing classes enables you to pass configuration arguments at instantiation time, e.g.:\n• y_true: Ground truth values, of shape . For sparse loss functions, such as sparse categorical crossentropy, the shape should be\n• sample_weight: Optional acts as reduction weighting coefficient for the per-sample losses. If a scalar is provided, then the loss is simply scaled by the given value. If is a tensor of size , then the total loss for each sample of the batch is rescaled by the corresponding element in the vector. If the shape of is (or can be broadcasted to this shape), then each loss element of is scaled by the corresponding value of . (Note on : all loss functions reduce by 1 dimension, usually .)\n\nBy default, loss functions return one scalar loss value for each input sample in the batch dimension, e.g.\n\nHowever, loss class instances feature a constructor argument, which defaults to (i.e. average). Allowable values are \"sum_over_batch_size\", \"sum\", and \"none\":\n• \"sum_over_batch_size\" means the loss instance will return the average of the per-sample losses in the batch.\n• \"sum\" means the loss instance will return the sum of the per-sample losses in the batch.\n• \"none\" means the loss instance will return the full array of per-sample losses.\n\nNote that this is an important difference between loss functions like and default loss class instances like : the function version does not perform reduction, but by default the class instance does.\n\nWhen using , this difference is irrelevant since reduction is handled by the framework.\n\nHere's how you would use a loss class instance as part of a simple training loop:\n\nAny callable with the signature that returns an array of losses (one of sample in the input batch) can be passed to as a loss. Note that sample weighting is automatically supported for any such loss.\n\nLoss functions applied to the output of a model aren't the only way to create losses.\n\nWhen writing the method of a custom layer or a subclassed model, you may want to compute scalar quantities that you want to minimize during training (e.g. regularization losses). You can use the layer method to keep track of such loss terms.\n\nHere's an example of a layer that adds a sparsity regularization loss based on the L2 norm of the inputs:\n\nLoss values added via can be retrieved in the list property of any or (they are recursively retrieved from every underlying layer):\n\nThese losses are cleared by the top-level layer at the start of each forward pass – they don't accumulate. So always contain only the losses created during the last forward pass. You would typically use these losses by summing them before computing your gradients when writing a training loop.\n\nWhen using , such loss terms are handled automatically.\n\nWhen writing a custom training loop, you should retrieve these terms by hand from , like this:\n\nSee the documentation for more details."
    },
    {
        "link": "https://neptune.ai/blog/keras-loss-functions",
        "document": "You’ve created a deep learning model in Keras, you prepared the data and now you are wondering which loss you should choose for your problem.\n\nWe’ll get to that in a second but first what is a loss function?\n\nIn deep learning, the loss is computed to get the gradients with respect to model weights and update those weights accordingly via backpropagation. Loss is calculated and the network is updated after every iteration until model updates don’t bring any improvement in the desired evaluation metric.\n\nSo while you keep using the same evaluation metric like f1 score or AUC on the validation set during (long parts) of your machine learning project, the loss can be changed, adjusted and modified to get the best evaluation metric performance.\n\nYou can think of the loss function just like you think about the model architecture or the optimizer and it is important to put some thought into choosing it. In this piece we’ll look at:\n• loss functions available in Keras and how to use them,\n• how you can define your own custom loss function in Keras,\n• how to add sample weighing to create observation-sensitive losses,\n• how to avoid nans in the loss,\n• how you can monitor the loss function via plotting and callbacks.\n\nLet’s get into it!\n\nIn Keras, loss functions are passed during the compile stage, as shown below.\n\nIn this example, we’re defining the loss function by creating an instance of the loss class. Using the class is advantageous because you can pass some additional parameters.\n\nIf you want to use a loss function that is built into Keras without specifying any parameters you can just use the string alias as shown below:\n\nYou might be wondering how does one decide on which loss function to use?\n\nThere are various loss functions available in Keras. Other times you might have to implement your own custom loss functions.\n\nLet’s dive into all those scenarios.\n\nWhich loss functions are available in Keras?\n\nBinary classification loss function comes into play when solving a problem involving just two classes. For example, when predicting fraud in credit card transactions, a transaction is either fraudulent or not.\n\nThe BinaryCrossentropy will calculate the cross-entropy loss between the predicted classes and the true classes. By default, the sum_over_batch_size reduction is used. This means that the loss will return the average of the per-sample losses in the batch.\n\nThe sum reduction means that the loss function will return the sum of the per-sample losses in the batch.\n\nUsing the reduction as none returns the full array of the per-sample losses.\n\nIn binary classification, the activation function used is the sigmoid activation function. It constrains the output to a number between 0 and 1.\n\nProblems involving the prediction of more than one class use different loss functions. In this section we’ll look at a couple:\n\nThe CategoricalCrossentropy also computes the cross-entropy loss between the true classes and predicted classes. The labels are given in an one_hot format.\n\nIf you have two or more classes and the labels are integers, the SparseCategoricalCrossentropy should be used.\n\nYou can also use the Poisson class to compute the poison loss. It’s a great choice if your dataset comes from a Poisson distribution for example the number of calls a call center receives per hour.\n\nThe relative entropy can be computed using the KLDivergence class. According to the official docs at PyTorch:\n\nKL divergence is a useful distance measure for continuous distributions and is often useful when performing direct regression over the space of (discretely sampled) continuous output distributions.\n\nIn a multi-class problem, the activation function used is the softmax function.\n\nIn classification problems involving imbalanced data and object detection problems, you can use the Focal Loss. The loss introduces an adjustment to the cross-entropy criterion.\n\nIt is done by altering its shape in a way that the loss allocated to well-classified examples is down-weighted. This ensures that the model is able to learn equally from minority and majority classes.\n\nThe cross-entropy loss is scaled by scaling the factors decaying at zero as the confidence in the correct class increases. The factor of scaling down weights the contribution of unchallenging samples at training time and focuses on the challenging ones.\n\nThe Generalized Intersection over Union loss from the TensorFlow add on can also be used. The Intersection over Union (IoU) is a very common metric in object detection problems. IoU is however not very efficient in problems involving non-overlapping bounding boxes.\n\nThe Generalized Intersection over Union was introduced to address this challenge that IoU is facing. It ensures that generalization is achieved by maintaining the scale-invariant property of IoU, encoding the shape properties of the compared objects into the region property, and making sure that there is a strong correlation with IoU in the event of overlapping objects.\n\nIn regression problems, you have to calculate the differences between the predicted values and the true values but as always there are many ways to do it.\n\nThe MeanSquaredError class can be used to compute the mean square of errors between the predictions and the true values.\n\nUse Mean Squared Error when you desire to have large errors penalized more than smaller ones.\n\nThe mean absolute percentage error is computed using the function below.\n\nIt is calculated as shown below.\n\nConsider using this loss when you want a loss that you can explain intuitively. People understand percentages easily. The loss is also robust to outliers.\n\nThe mean squared logarithmic error can be computed using the formula below:\n\nHere’s an implementation of the same:\n\nMean Squared Logarithmic Error penalizes underestimates more than it does overestimates. It’s a great choice when you prefer not to penalize large errors, it is, therefore, robust to outliers.\n\nIf your interest is in computing the cosine similarity between the true and predicted values, you’d use the CosineSimilarity class. It is computed as:\n\nThe result is a number between -1 and 1 . 0 indicates orthogonality while values close to -1 show that there is great similarity.\n\nThe LogCosh class computes the logarithm of the hyperbolic cosine of the prediction error.\n\nLogCosh Loss works like the mean squared error, but will not be so strongly affected by the occasional wildly incorrect prediction. — TensorFlow Docs\n\nFor regression problems that are less sensitive to outliers, the Huber loss is used.\n\nYou can also compute the triplet loss with semi-hard negative mining via TensorFlow addons. The loss encourages the positive distances between pairs of embeddings with the same labels to be less than the minimum negative distance.\n\nSometimes there is no good loss available or you need to implement some modifications. Let’s learn how to do that.\n\nA custom loss function can be created by defining a function that takes the true values and predicted values as required parameters. The function should return an array of losses. The function can then be passed at the compile stage.\n\nLet’s see how we can apply this custom loss function to an array of predicted and true values.\n\nDuring the training process, one can weigh the loss function by observations or samples. The weights can be arbitrary, but a typical choice is class weights (distribution of labels). Each observation is weighted by the fraction of the class it belongs to (reversed) so that the loss for minority class observations is more important when calculating the loss.\n\nOne of the ways to do this is to pass the class weights during the training process.\n\nThe weights are passed using a dictionary that contains the weight for each class. You can compute the weights using Scikit-learn or calculate the weights based on your own criterion.\n\nThe second way is to pass these weights at the compile stage.\n\nHow to monitor Keras loss function with neptune.ai\n\nIt is usually a good idea to monitor the loss function on the training and validation set as the model is training. Looking at those learning curves is a good indication of overfitting or other problems with model training.\n\nThere are two main options of how this can be done.\n\nThe quickest and easiest way to log and look at the losses is by simply printing them to the console.\n\nRunning the code, you can see the loss per epoch is printed directly:\n\nDespite being easy to implement, there are a few issues with this approach:\n• The logs can be easily lost.\n• It’s difficult to see progress, especially with higher numbers of epochs.\n• You might not have access to these logs when working on remote machines.\n\nUsing callbacks can be a better alternative.\n\nCallbacks are functions passed to other functions, allowing them to be executed after a defined task or event is completed.\n\nWe’ll be using neptune.ai as our experiment tracker for the metrics we track with our callback. Neptune is a versatile and highly scalable experiment tracker, allowing you to track months-long training runs and compare thousands of metrics in no time.\n\nTo get started, make an account (it’s free for personal use!) and check out the Quickstart guide, which includes information on how to connect your Google Colab environment to Neptune. Then, all you’ll have to do is create a project and your API key from the UI.\n\nAfter that, using callbacks with Neptune is simple. For example, logging your Keras loss to Neptune could look like this:\n\nHere, our callback sends metrics (like loss and accuracy) to Neptune at the end of every batch and epoch so we can visualize them easily.\n\nYou can create the monitoring callback yourself or use one of the many available Keras callbacks in the Keras library and other libraries that integrate with it—like neptune.ai, TensorBoard, and others.\n\nOnce your callback is ready, you just pass it to model.fit(…). Be sure to specify your API key and the project name before running the code.\n\nNow you can easily monitor your experiment learning curves and visualize them like this:\n\nIn this dashboard, we’re visualizing many key aspects of our model training: accuracy, loss, hyperparameters, model architecture, and even sample predictions on the test set.\n\nYou can interact with this example project directly on the Neptune web app.\n\nMost of the time, losses you log will be just some regular values, but sometimes you might get nans when working with Keras loss functions.\n\nWhen that happens, your model will not update its weights and will stop learning, so this situation needs to be avoided.\n\nThere could be many reasons for nan loss but usually, what happens is:\n• nans in the training set will lead to nans in the loss,\n• NumPy infinite in the training set will also lead to nans in the loss,\n• Using a training set that is not scaled,\n• Use of very large l2 regularizers and a learning rate above 1,\n• Use of the wrong optimizer function,\n• Large (exploding) gradients that result in a large update to network weights during training.\n\nSo in order to avoid nans in the loss, ensure that:\n• Check that your training data is properly scaled and doesn’t contain nans;\n• Check that you are using the right optimizer and that your learning rate is not too large;\n• Check whether the l2 regularization is not too large;\n• If you are facing the exploding gradient problem, you can either: re-design the network or use gradient clipping so that your gradients have a certain “maximum allowed model update”.\n\nHopefully, this article gave you some background into loss functions in Keras.\n• Implementation of your own custom loss functions,\n• How to add sample weighing to create observation-sensitive losses,\n• How you can visualize loss as your model is training.\n\nFor more information, check out the Keras Repository and the TensorFlow Loss Functions documentation."
    }
]