[
    {
        "link": "https://docs.oracle.com/javase/8/docs/api/java/lang/Math.html",
        "document": ""
    },
    {
        "link": "https://stackoverflow.com/questions/25150660/how-does-java-calculates-trigonometry",
        "document": "It depends on the JVM implementation, but in OpenJDK, just calls , which is implemented with a native method that calls the sine function provided by the fdlibm library.\n\nHere's the C source code for the fdlibm sine function in OpenJDK 8:\n• k_sin.c (the function used in the implementation of )\n\nThe latter file has comments that describe the algorithm. The key point seems to be that \" is approximated by a polynomial of degree 13\". It looks like transforms the argument into an equivalent value in the range (-pi/4, +pi/4), and performs a polynomial approximation that's accurate enough within that range.\n\nNote that although the actual Java bytecode of the method just calls , the JVM may execute calls using other means besides actually calling the method. In particular, it's likely to to translate a call into the corresponding native CPU instruction (such as the x86 ). But a call to will always use the fdlibm implementation."
    },
    {
        "link": "https://stackoverflow.com/questions/64616754/java-float-trigonometric-optimization",
        "document": "I'm writing my own 3D rendering engine. Following general knowledge I am currently using floating point values as my base of operations. For the rotation matrices I however require the trigonometric functions in the java.lang.Math library, which uses double values as in and output.\n\nI was wondering if you could implement an optimized version of the trigonometric functions using floating point values, improving performance."
    },
    {
        "link": "https://docs.oracle.com/javase/8/docs/api?java/lang/Math.html",
        "document": "JavaScript is disabled on your browser.\n\nThis document is designed to be viewed using the frames feature. If you see this message, you are using a non-frame-capable web client. Link to Non-frame version."
    },
    {
        "link": "https://tutorialspoint.com/computer_graphics/computer_graphics_trigonometry.htm",
        "document": "Trigonometry plays a crucial role in computer graphics. It helps us understand and manipulate angles, distances, and positions. With trigonometry, we can utilize the idea of polar coordinates while working with viewport display, etc. In this chapter, we will see how trigonometry is used in graphics.\n\nLet's understand some basic concepts of trigonometry and learn their applications with examples.\n\nWhile working with trigonometry, angles are the most fundamental term. In graphics, we often work with angles. An angle is formed between two half-lines or directions. These half-lines come from a common origin. There are two possible angles between these lines. We need a convention to choose which one to use.\n\nOne common convention uses the smaller arc length as the angle. The sign of the angle is determined by the order of the half-lines. With this convention, all angles fall in the range $\\mathrm{[-\\pi, \\pi]}$.\n\nAngles are measured in radians or degrees. The full circle is 2 radians or 360 degrees. We can convert between these units −\n\nWe all know the trigonometric functions that are associated with right angled triangles. In a rightangle triangle with sides a, o, and h (hypotenuse), we have the Pythagorean theorem:\n\nFrom this, we define the main trigonometric functions −\n\nApart from the Cartesian coordinates, there are some other coordinates one of them is the polar coordinate. In polar coordinates, we describe a point using −\n• An angle relative to the positive x-axis (φ)\n\nBy convention, positive angles go counterclockwise from the x-axis.\n\nLet us see the properties for the trigonometric functions that are used in computer graphics.\n\nThis property is useful in animations and rotations.\n\nInverse functions are also important in graphics. Common inverse functions include −\n\nA special function, atan2(s,c), is very useful. It takes two values proportional to sin A and cos A. It returns the angle A. This function is often used to find the angle of a 2D point in polar coordinates.\n\nLet us see some key identities can simplify many graphics calculations.\n\nThese identities help when working with rotations −\n\nThese are useful for normalizing vectors −\n\nThese help when combining rotations −\n\nGraphics often involve working with triangles. These formulas are helpful −\n\nFor any triangle with sides a, b, c and opposite angles A, B, C −\n\nThis is useful for finding unknown sides or angles.\n\nFor the same triangle −\n\nThis generalizes the Pythagorean theorem to non-right triangles.\n\nThe area of a triangle can be computed from its side lengths −\n\nRotations − Rotations in 2D use sin and cos −\n\nWhere (x,y) is the original point and (x',y') is the rotated point.\n\nCircular Motion − Trigonometry is key for circular motion. For a circle with radius r −\n\nAs θ increases, the point (x,y) moves around the circle.\n\nProjections − When projecting 3D objects onto 2D screens, we use trigonometry to calculate angles and distances.\n\nLighting − Calculating light reflections and shadows involves trigonometry. The angle between a surface normal and a light ray determines the brightness.\n\nIn this chapter, we explained the role of trigonometry in graphics. We covered some of the basic concepts like angles and trigonometric functions. We discussed polar coordinates and their use in graphics.\n\nWe explored the important trigonometric identities and their applications in computer graphics. We also explained how trigonometry helps in triangle calculations. Finally, we saw how these concepts apply to rotations, circular motion, projections, and lighting in graphics. These we will see later more in detail for each of these concepts."
    },
    {
        "link": "https://scratchapixel.com/lessons/3d-basic-rendering/perspective-and-orthographic-projection-matrix/opengl-perspective-projection-matrix.html",
        "document": "In all OpenGL books and references, the perspective projection matrix used in OpenGL is defined as:\n\nWhat similarities does this matrix have with the matrix we studied in the previous chapter? It is important to remember that matrices in OpenGL are defined using a column-major order, as opposed to row-major order. In the lesson on Geometry, we explained that to transition from one order to the other, one can simply transpose the matrix. If we transpose the above matrix, we get:\n\nThis is the matrix we would use on Scratchapixel, as we use row vectors. However, in OpenGL, you would use the first matrix, as OpenGL uses column vectors by default, though this can be changed in OpenGL 4.x and modern real-time 3D graphics APIs such as Vulkan. Pay attention to the element in red (third row and fourth column). When we multiply a homogeneous point with this matrix, the point's \\(w\\) coordinate is multiplied by this element, and the value of \\(w\\) ends up being the projected point's \\(z\\) coordinate:\n\nOur mathematical expressions and equations are accurate, reflecting the correct formulas for the perspective projection matrix as used in OpenGL and its transformation upon transposition.\n\nIn summary, we understand that the matrix is correctly set up for the z-divide. Let's now examine how points are projected in OpenGL (Vulkan, Meta, Direct3D or WebGL). The principle remains the same as discussed in the previous chapter. A line is drawn from the camera's origin to the point \\(P\\) that we want to project, and the intersection of this line with the image plane determines the position of the projected point \\(P_s\\). While the setup mirrors that shown in figure 1 from the previous chapter, it's important to note that in OpenGL, the image plane is situated on the near clipping plane, as opposed to being precisely one unit away from the camera's origin.\n\nThe technique of using similar triangles, as employed in chapter 1, is applicable here as well. The triangles \\(\\Delta ABC\\) and \\(\\Delta DEF\\) are similar. Thus, we can express:\n\nBy substituting \\(AB\\) with \\(n\\) (the near clipping plane), \\(DE\\) with \\(P_z\\) (the z-coordinate of \\(P\\)), and \\(EF\\) with \\(P_y\\) (the y-coordinate of \\(P\\)), we can rewrite this equation as (equation 1):\n\nAs observed, the only difference from the equation in the previous chapter is the inclusion of \\(n\\) in the numerator. However, the principle of division by \\(P_z\\) remains unchanged (noting that since the camera is oriented along the negative z-axis, \\(P_z\\) is negative: \\(P_z < 0\\)). To maintain the y-coordinate of the projected point as positive, given that \\(P_y\\) is positive, we negate \\(P_z\\). Following the same logic, we derive the x-coordinate of the projected point with the following equation (equation 2):\n\nHaving determined the values for \\(P_s{}_x\\) and \\(P_s{}_y\\), we now need to elucidate how they correlate with the OpenGL perspective matrix. The purpose of a projection matrix is to remap the values projected onto the image plane to a unit cube (defined by minimum and maximum extents of \\((-1,-1,-1)\\) and \\((1,1,1)\\), respectively). Once the point \\(P\\) is projected onto the image plane, \\(P_s\\) is considered visible if its \\(x\\) and \\(y\\) coordinates fall within the range \\([left, right]\\) for \\(x\\) and \\([bottom, top]\\) for \\(y\\), as depicted in Figure 2. While we have previously discussed in the lesson 3D Viewing: the Pinhole Camera Model how the \\(left\\), \\(right\\), \\(bottom\\), and \\(top\\) coordinates are calculated, we will revisit this explanation in this chapter. These screen coordinates set the limits or boundaries on the image plane for visible points (all points contained in the viewing frustum and projected onto the image plane). Assuming \\(P_s{}_x\\) is visible, it can be expressed as:\n\nwhere \\(l\\) and \\(r\\) represent the left and right coordinates, respectively. Our objective is to remap \\(P_s{}_x\\) so that its final value resides within the range \\([-1,1]\\) (the dimensions of the unit cube along the \\(x\\)-axis). Reiterating the equations introduced in the previous lesson, let's start by subtracting \\(l\\) from all terms to rewrite the equation as:\n\nNormalizing the term on the right by dividing all terms of this formula by \\(r-l\\) yields:\n\nMultiplying all terms by 2 gives:\n\nSubtracting 1 from all terms results in:\n\nThis remaps the central term to the range \\([-1,1]\\), which was our goal, though the terms can be further rearranged:\n\nThese two terms are quite similar to the first two terms of the first row in the OpenGL perspective projection matrix. We are getting closer. If we replace \\(Ps_x\\) from the previous equation with equation 2, we get:\n\nWe can easily encode this equation in matrix form. If we replace the first and third coefficients of the matrix's first row with the first and second term of this formula, here is what we get:\n\nRemember, the OpenGL matrix uses column-major ordering, therefore, we will have to place the multiplication sign to the right of the matrix and the point coordinates in a column vector:\n\nAnd since \\(Ps_x\\) will be divided at the end of the process by \\(-P_z\\) when we convert \\(Ps\\) from homogeneous to Cartesian coordinates, we get:\n\nThis is the first coordinate of the projected point \\(Ps\\) computed using the OpenGL perspective matrix. The derivation is quite lengthy, and we will skip it for \\(Ps_y\\). However, if you follow the steps we used for \\(Ps_x\\), doing it yourself shouldn't be a problem. You just need to replace \\(l\\) and \\(r\\) with \\(b\\) and \\(t\\), and you end up with the following formula:\n\nWe can achieve this result with point-matrix multiplication if we replace the second and third coefficients of the matrix's second row with the first and second terms of this equation:\n\nComputing \\(Ps_y\\) using this matrix gives:\n\nand after the division by \\(-P_z\\):\n\nOur matrix works again. All that's left to do to complete it is find a way to remap the z-coordinate of the projected points to the range [-1,1]. We know that the x- and y-coordinates of \\(P\\) don't contribute to the calculation of the projected point's z-coordinate. Thus, the first and second coefficients of the matrix's third row, which would be multiplied by \\(P\\)'s x- and y-coordinates, are necessarily zero (in green). We are left with two coefficients, \\(A\\) and \\(B\\), in the matrix which are unknown (in red).\n\nIf we write the equation to compute \\(Ps_z\\) using this matrix, we get (remember that \\(Ps_z\\) is also divided by \\(Ps_w\\) when the point is converted from homogeneous to Cartesian coordinates, and that \\(P_w = 1\\)):\n\nWe need to find the values of A and B. Fortunately, we know that when \\(P_z\\) is on the near clipping plane, \\(Ps_z\\) needs to be remapped to -1, and when \\(P_z\\) is on the far clipping plane, \\(Ps_z\\) needs to be remapped to 1. Therefore, we need to replace \\(Ps_z\\) with \\(n\\) and \\(f\\) in the equation to get two new equations (note that the z-coordinate of all the points projected on the image plane is negative, but \\(n\\) and \\(f\\) are positive, therefore we will use \\(-n\\) and \\(-f\\) instead):\n\nAnd substitute B in equation 2 with this equation:\n\nNow that we have a solution for A, finding B is straightforward. We just replace A in equation 1 to find B:\n\nWe can replace the solutions we found for A and B in our matrix, and we finally get:\n\nwhich is the OpenGL perspective projection matrix.\n\nShould Z be in Range \\([-1,1]\\) or \\([0,1]\\)? This Sadly Matters\n\nWhether Z should be in the range \\([-1,1]\\) or \\([0,1]\\) is a valid question. So far, we've chosen to remap \\(z\\) to the range \\([-1,1]\\) and have provided the equations for that. Most perspective matrix code remaps Z to that range. However, many (if not most) real-time graphics APIs, such as OpenGL and Vulkan, expect the depth range to be within \\([0,1]\\). Technically, these graphics APIs allow you to define this range more or less as you like when you create your graphics pipeline. In Vulkan, you set and in the structure (which itself has a parameter where you set these depth bounds). In OpenGL, these values are set through .\n\nNow, you can achieve this in two ways. You can modify the original perspective projection matrix so that the Z-coordinate directly remaps to \\([0,1]\\).\n\nFrom which we can derive:\n\nAnother solution simply consists of using the original matrix and letting the real-time graphics API remap these values for you. This is possible in OpenGL because when points are transformed from NDC space to window space (or raster space, if you prefer), the \\(z\\) is remapped as follows:\n\nDon't worry too much about \\(x_w\\) and \\(y_w\\) here. We are only interested in \\(z_w\\) (by the way, \\(w\\) stands for window space here). In OpenGL, at this particular stage, the variables \\(n\\) and \\(f\\) are set to the and values that we spoke about earlier. So if those are 0 and 1 respectively, this is similar to \\(\\frac{1}{2} z_d + \\frac{1}{2}\\), which effectively remaps points in the range \\([-1,1]\\) to the range \\([0,1]\\).\n\nThings get a little more complicated in APIs such as Vulkan. XX\n\nThe remapping of the z-coordinate uniquely prioritizes points closer to the camera with greater numerical precision compared to points further away. As discussed in the previous chapter, this characteristic can lead to issues where the lack of numerical precision results in adjacent samples receiving identical depth values after projection onto the screen, despite having distinct z-coordinates in world space. This phenomenon, known as z-fighting, poses a challenge. Although the problem cannot be entirely eliminated—given the inherent limitations of precision in single-precision floating-point numbers—it can be mitigated by carefully adjusting the near and far clipping planes to align as closely as possible with the nearest and furthest objects visible in the scene. This rationale underlines the importance of precise clipping plane adjustments.\n\nThe Field of View and Image Aspect Ratio\n\nYou may have noticed that, so far, we haven't made any reference to the camera's field of view (FOV) and image aspect ratio. However, as mentioned in the previous chapter and the lesson on cameras (in the basic section), changing the FOV alters the extent of the scene viewed through the camera. Thus, the field of view and the image aspect ratio are somehow related to the projection process. We deliberately ignored this detail until now to stay focused on the OpenGL perspective projection matrix, which doesn't directly depend on the camera's field of view, but it does so indirectly. The construction of the matrix relies on six parameters: the left, right, bottom, and top coordinates, as well as the near and far clipping planes. The user provides the values for the near and far clipping planes, but how about the left, right, bottom, and top coordinates? What are these, where do they come from, and how do we calculate them? Observing Figures 2 and 5, you can see that these coordinates correspond to the lower-left and upper-right corners of the frustum front face, where the image of the 3D scene is projected.\n\nTo compute the top coordinate, we look at the right-angled triangle ABC. The angle subtended by AB and AC is half the FOV, and the adjacent side of the triangle is the value for the near-clipping plane. Using trigonometry, we can express this as:\n\nAnd since the bottom half of the camera is symmetrical to the upper half, we can state that:\n\nIn Figure 5, two scenarios are considered: the image can either be square or rectangular. For a square camera, it's straightforward: the left and bottom coordinates are the same, the right and top coordinates are also the same, and mirroring the bottom-left coordinates around the x- and y-axis gives the top-right coordinates. Therefore, if we compute the top coordinates, we can easily set the other three:\n\nFor a non-square camera, as shown in the right inside of figure 5, computing the coordinates becomes slightly more complicated. The bottom and top coordinates remain the same, but the left and right coordinates are scaled by the aspect ratio, defined as the image width over the image height. The general formulas for computing the left, right, and bottom coordinates are:\n\nThus, the camera's field of view and image aspect ratio are crucial in calculating the left, right, bottom, and top coordinates, which in turn are used in constructing the perspective projection matrix. This is how they indirectly influence how much of the scene is visible through the camera.\n\nTo test the OpenGL perspective projection matrix, we will reuse the code from the previous chapter. In the old fixed-function rendering pipeline, two functions, (part of the GLU library) and , were utilized to set the screen coordinates and the projection matrix. These functions are deprecated (since OpenGL 3.1) in the new programmable rendering pipeline, but we use them in this lesson to demonstrate their implementation based on what we have learned in this chapter. You can still emulate them in your CPU program if desired.\n\nSetting up the perspective projection matrix in OpenGL was achieved through a call to . This function accepted six arguments:\n\nThe implementation of this function is shown below (line 20). The function was used to set the screen coordinates, taking as arguments the angle of view, the image aspect ratio (image width over image height), and the clipping planes.\n\nIn OpenGL, the angle of view is defined as the vertical angle (hence the 'y' in the variable name). On Scratchapixel, we use the horizontal angle of view. An implementation of this function is provided below (line 8). The rest of the code remains unchanged. We first compute the screen coordinates, then the projection matrix. Next, we iterate over all the vertices of the teapot geometry, transform them from object/world space to camera space, and finally project them onto the screen using the perspective projection matrix. Remember, the matrix remaps the projected point to NDC space. Thus, as in the previous version of the code, visible points fall within the range [-1,1] in height and [-imageAspectRatio, imageAspectRatio] (or [-1,1] if the image is square) in width.\n\nWe noted in the first chapter that even if matrices are constructed differently (and appear different), they should always yield the same result: a point in 3D space should be projected to the same pixel location on the image. Comparing the results of projecting the teapot's vertices using the first matrix with those using the same camera settings (same field of view, image aspect ratio, near and far clipping planes) and the OpenGL perspective projection matrix produces identical images (see image below).\n\nThe source code of this program is available on Scratchapixel's GitHub repo."
    },
    {
        "link": "https://songho.ca/opengl/gl_projectionmatrix.html",
        "document": "Updates: The MathML version is available here.\n\nA computer monitor is a 2D surface. A 3D scene rendered by OpenGL must be projected onto the computer screen as a 2D image. GL_PROJECTION matrix is used for this projection transformation. First, it transforms all vertex data from the eye coordinates to the clip coordinates. Then, these clip coordinates are also transformed to the normalized device coordinates (NDC) by dividing with w component of the clip coordinates.\n\nTherefore, we have to keep in mind that both clipping (frustum culling) and NDC transformations are integrated into GL_PROJECTION matrix. The following sections describe how to build the projection matrix from 6 parameters; left, right, bottom, top, near and far boundary values.\n\nNote that the frustum culling (clipping) is performed in the clip coordinates, just before dividing by w . The clip coordinates, x , y and z are tested by comparing with w . If any clip coordinate is less than -w , or greater than w , then the vertex will be discarded. \n\n\n\nThen, OpenGL will reconstruct the edges of the polygon where clipping occurs.\n\nIn perspective projection, a 3D point in a truncated pyramid frustum (eye coordinates) is mapped to a cube (NDC); the range of x-coordinate from [l, r] to [-1, 1], the y-coordinate from [b, t] to [-1, 1] and the z-coordinate from [-n, -f] to [-1, 1].\n\nNote that the eye coordinates are defined in the right-handed coordinate system, but NDC uses the left-handed coordinate system. That is, the camera at the origin is looking along -Z axis in eye space, but it is looking along +Z axis in NDC. Since glFrustum() accepts only positive values of near and far distances, we need to negate them during the construction of GL_PROJECTION matrix.\n\nIn OpenGL, a 3D point in eye space is projected onto the near plane (projection plane). The following diagrams show how a point (x , y , z ) in eye space is projected to (x , y , z ) on the near plane.\n\nFrom the top view of the frustum, the x-coordinate of eye space, x is mapped to x , which is calculated by using the ratio of similar triangles; \n\n\n\nFrom the side view of the frustum, y is also calculated in a similar way; \n\n\n\nNote that both x and y depend on z ; they are inversely propotional to -z . In other words, they are both divided by -z . It is a very first clue to construct GL_PROJECTION matrix. After the eye coordinates are transformed by multiplying GL_PROJECTION matrix, the clip coordinates are still a homogeneous coordinates. It finally becomes the normalized device coordinates (NDC) by divided by the w-component of the clip coordinates. (See more details on OpenGL Transformation.) \n\n ,\n\nTherefore, we can set the w-component of the clip coordinates as -z . And, the 4th of GL_PROJECTION matrix becomes (0, 0, -1, 0). \n\n\n\nNext, we map x and y to x and y of NDC with linear relationship; [l, r] ⇒ [-1, 1] and [b, t] ⇒ [-1, 1].\n\nThen, we substitute x and y into the above equations.\n\nNote that we make both terms of each equation divisible by -z for perspective division (x /w , y /w ). And we set w to -z earlier, and the terms inside parentheses become x and y of the clip coordiantes.\n\nFrom these equations, we can find the 1st and 2nd rows of GL_PROJECTION matrix. \n\n\n\nNow, we only have the 3rd row of GL_PROJECTION matrix to solve. Finding z is a little different from others because z in eye space is always projected to -n on the near plane. But we need unique z value for the clipping and depth test. Plus, we should be able to unproject (inverse transform) it. Since we know z does not depend on x or y value, we borrow w-component to find the relationship between z and z . Therefore, we can specify the 3rd row of GL_PROJECTION matrix like this. \n\n\n\nIn eye space, w equals to 1. Therefore, the equation becomes; \n\n\n\nTo find the coefficients, A and B, we use the (z , z ) relation; (-n, -1) and (-f, 1), and put them into the above equation. \n\n\n\nTo solve the equations for A and B, rewrite eq.(1) for B; \n\n\n\nSubstitute eq.(1') to B in eq.(2), then solve for A; \n\n\n\nWe found A and B. Therefore, the relation between z and z becomes; \n\n\n\nFinally, we found all entries of GL_PROJECTION matrix. The complete projection matrix is;\n\nThis projection matrix is for a general frustum. If the viewing volume is symmetric, which is and , then it can be simplified as; \n\n\n\nBefore we move on, please take a look at the relation between z and z , eq.(3) once again. You notice it is a rational function and is non-linear relationship between z and z . It means there is very high precision at the near plane, but very little precision at the far plane. If the range [-n, -f] is getting larger, it causes a depth precision problem (z-fighting); a small change of z around the far plane does not affect on z value. The distance between n and f should be short as possible to minimize the depth buffer precision problem.\n\nThe perspective projection matrix can be simplified by setting the far plane to ∞ in the third row of the perspective matrix. \n\n\n\nTherefore, both general and symmetric perspective projection matices with infinite far plane become;\n\nNote that the infinite projection matrix still suffers from the depth precision error .\n\nIt is hard to determine 4 parameters (left, right, top, and bottom) properly with a given near and far planes for the perspective projection on a specific window dimension. You can easily derive these 4 parameters from the vertical/horizontal field of view angle and the aspect ratio, width/height. However these conversion are limited for a symmetric perspective projection matrix.\n\nConstructing GL_PROJECTION matrix for orthographic projection is much simpler than perspective mode.\n\nAll x , y and z components in eye space are linearly mapped to NDC. We just need to scale a rectangular volume to a cube, then move it to the origin. Let's find out the elements of GL_PROJECTION using linear relationship.\n\nSince w-component is not necessary for orthographic projection, the 4th row of GL_PROJECTION matrix remains as (0, 0, 0, 1). Therefore, the complete GL_PROJECTION matrix for orthographic projection is;\n\nIt can be further simplified if the viewing volume is symmetrical, and ."
    },
    {
        "link": "https://gamedev.stackexchange.com/questions/120338/what-does-a-perspective-projection-matrix-look-like-in-opengl",
        "document": "Stack Exchange network consists of 183 Q&A communities including Stack Overflow, the largest, most trusted online community for developers to learn, share their knowledge, and build their careers."
    },
    {
        "link": "https://stackoverflow.com/questions/15008997/in-opengl-what-effect-does-creating-a-perspective-projection-matrix-have-on-the",
        "document": "I've recently begun learning OpenGL and as far as the communication with the GL and shaders go, I've gained a good competence, but I'm a little unclear regarding the coordinate system.\n\nI'm using OpenGL ES 2.0, so I have to do all of the matrix management myself. I've come to understand that the following:\n• None In order to observe correct results multiply the matrices as model * view * projection (which makes perfect sense as matrix multiplication is not commutative).\n• None The model matrix represents the scale, rotation, translation, etc of the drawing primitive. Moving the primitive in 3D space involves transformations applied to this matrix.\n• None The view matrix represents the \"camera\" as many refer to it. Distance between the object and viewer as well as rotation of the eye around the object come from transformations to this matrix.\n• None Finally, the perspective matrix represents the 3D space that the scene exists in. I'm following some examples which mostly use the perspective method using the field of view and aspect ratio. This is where my confusion starts.\n\nA primitive's coordinates are given as a float in the interval +-[0, 1]. But the perspective matrix represents a 3D space from near-z to far-z (which I've seen to be 0 and 100 respectively). I'm confused as to how the primitive's coordinates map into this space. Clearly my linear algebra skills aren't as strong as I'd like them to be in this case. Can anyone clarify how these points are mapped into this space?\n\nFor instance, many examples define a cube to be at +-(.5, .5, .5). I I use a perspective martrix of near-z = 0, far-z = 100, and the aspect ratio of the entire display, would this mean that the cube is always at .5 of each of these dimensions? What I mean is, if the perspective matrix works out to go from x=-5 to x=5, does an x coordinate end up being .5(-5) = -2.5?"
    },
    {
        "link": "https://reddit.com/r/GraphicsProgramming/comments/lt133i/projection_matrix_knowing_how_to_build_from",
        "document": "My main question is - Do I need to be able to implement a projection-view matrix from scratch or is a general understanding okay?\n\nI'm pretty new - pretty familiar with programming 2D, have used 3D software, but a beginner with 3D programming. I'm working through the Advanced Android Graphics course on Coursera. Starts with implementing 2D-as-3D and has a seven minute video on Projection Matrices, then says, \"Now you do it.\" I was lost. So I watched some lectures on YouTube. The matrices look a little different. I have a graphics API book and they just give you the projection matrix function. From what I understand that's pretty common.\n\nIn general, would you say I need to be able to build the projection matrices myself or just know how to use it?"
    }
]