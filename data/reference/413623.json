[
    {
        "link": "https://dev.mysql.com/doc/refman/8.4/en/replication-encrypted-connections.html",
        "document": "To use an encrypted connection for the transfer of the binary log required during replication, both the source and the replica servers must support encrypted network connections. If either server does not support encrypted connections (because it has not been compiled or configured for them), replication through an encrypted connection is not possible.\n\nSetting up encrypted connections for replication is similar to doing so for client/server connections. You must obtain (or create) a suitable security certificate that you can use on the source, and a similar certificate (from the same certificate authority) on each replica. You must also obtain suitable key files.\n\nFor more information on setting up a server and client for encrypted connections, see Section 8.3.1, “Configuring MySQL to Use Encrypted Connections”.\n\nTo enable encrypted connections on the source, you must create or obtain suitable certificate and key files, and then add the following configuration parameters to the section of the source file, changing the file names as necessary:\n\nThe paths to the files may be relative or absolute; we recommend that you always use complete paths for this purpose.\n\nThe configuration parameters are as follows:\n\nTo enable encrypted connections on the replica, use the statement.\n• None To name the replica's certificate and SSL private key files using , add the appropriate options, like this: These options correspond to the options with the same names, as described in Command Options for Encrypted Connections. For these options to take effect, must also be set. For a replication connection, specifying a value for either of or corresponds to setting . The connection attempt succeeds only if a valid matching Certificate Authority (CA) certificate is found using the specified information.\n• None To activate host name identity verification, add the option, like this: For a replication connection, specifying corresponds to setting , as described in Command Options for Encrypted Connections. For this option to take effect, must also be set. Host name identity verification does not work with self-signed certificates.\n• None To activate certificate revocation list (CRL) checks, add the or option, as shown here: These options correspond to the options with the same names, as described in Command Options for Encrypted Connections. If they are not specified, no CRL checking takes place.\n• None To specify lists of ciphers, ciphersuites, and encryption protocols permitted by the replica for the replication connection, use the , , and options, like this:\n• None The option specifies a colon-separated list of one or more ciphers permitted by the replica for the replication connection.\n• None The option specifies a comma-separated list of the TLS encryption protocols permitted by the replica for the replication connection, in a format like that for the server system variable. The connection procedure negotiates the use of the highest TLS version that both the source and the replica permit. To be able to connect, the replica must have at least one TLS version in common with the source.\n• None The option specifies a colon-separated list of one or more ciphersuites that are permitted by the replica for the replication connection if TLSv1.3 is used for the connection. If this option is set to when TLSv1.3 is used (which is the default if you do not set the option), the ciphersuites that are enabled by default are allowed. If you set the option to an empty string, no cipher suites are allowed, and TLSv1.3 is therefore not used. The protocols, ciphers, and ciphersuites that you can specify in these lists depend on the SSL library used to compile MySQL. For information about the formats, the permitted values, and the defaults if you do not specify the options, see Section 8.3.2, “Encrypted Connection TLS Protocols and Ciphers”. You can use the option to specify any selection of ciphersuites, including only non-default ciphersuites if you want.\n• None After the source information has been updated, start the replication process on the replica, like this: You can use the statement to confirm that an encrypted connection was established successfully.\n• None Requiring encrypted connections on the replica does not ensure that the source requires encrypted connections from replicas. If you want to ensure that the source only accepts replicas that connect using encrypted connections, create a replication user account on the source using the option, then grant that user the privilege. For example: mysql> CREATE USER 'repl'@'%.example.com' IDENTIFIED BY 'password' -> REQUIRE SSL; mysql> GRANT REPLICATION SLAVE ON *.* -> TO 'repl'@'%.example.com'; If you have an existing replication user account on the source, you can add to it with this statement:"
    },
    {
        "link": "https://dev.mysql.com/doc/en/using-encrypted-connections.html",
        "document": "Several configuration parameters are available to indicate whether to use encrypted connections, and to specify the appropriate certificate and key files. This section provides general guidance about configuring the server and clients for encrypted connections:\n\nEncrypted connections also can be used in other contexts, as discussed in these additional sections:\n\nInstructions for creating any required certificate and key files are available in Section 8.3.3, “Creating SSL and RSA Certificates and Keys”.\n\nThe option enables validation of the server public key certificate file, Certificate Authority (CA) certificate files, and certificate revocation-list files at server startup: If set to , the server stops execution of the startup in case of invalid certificates. The server informs DBAs by providing valid debug messages, error messages, or both depending on the status of the certificates. This capability may be useful, for example, to avoid restarting a MySQL server that has been running so long that its SSL certificate has expired. Similarly, when you execute the statement to change the TLS context at runtime, the new server and CA certificate files are not used if validation fails. The server continues to use the old certificates in this case. For more information about changing the TLS context dynamically, see Server-Side Runtime Configuration and Monitoring for Encrypted Connections. For a connection using the server main interface:\n• None If is specified, then the server validates the respective CA certificate and gives the DBA an appropriate warning message.\n• None If is specified, then the server validates all the CA certificates in the respective folder and gives the DBA an appropriate warning message.\n• None If SSL parameters are not specified, by default the server validates the CA certificate present in the data directory and gives the DBA an appropriate warning message. For a connection using the server administrative interface:\n• None If is specified, then the server validates the respective CA certificate and gives the DBA an appropriate warning message.\n• None If is specified, then the server validates all of the CA certificates in the respective folder and gives the DBA an appropriate warning message.\n• None If administrative SSL parameters are not specified, by default the server validates the CA certificate present in the data directory and gives the DBA an appropriate warning message. For a connection using the server main interface:\n• None If is not specified, then the server validates the server certificate in default data directory.\n• None If is given, then the server validates the server certificate, taking into consideration , if specified.\n• None If a DBA sets the command-line option to validate certificates, then the server stops in case of invalid certificates and an appropriate error message is displayed to the DBA. Otherwise, the server emits warning messages to the DBA and the server starts. For a connection using the server administrative interface:\n• None If is not specified, then the server validates the server certificate in default data directory.\n• None If is given, then the server validates the server certificate, taking into consideration , if specified.\n• None If a DBA sets the command-line option to validate certificates, then the server stops in case of invalid certificates and an appropriate error message is displayed to the DBA. Otherwise, the server emits warning messages to the DBA and the server starts.\n\nFor some MySQL deployments it may be not only desirable but mandatory to use encrypted connections (for example, to satisfy regulatory requirements). This section discusses configuration settings that enable you to do this. These levels of control are available:\n• None You can configure the server to require that clients connect using encrypted connections.\n• None You can invoke individual client programs to require an encrypted connection, even if the server permits but does not require encryption.\n• None You can configure individual MySQL accounts to be usable only over encrypted connections. To require that clients connect using encrypted connections, enable the system variable. For example, put these lines in the server file: Alternatively, to set and persist the value at runtime, use this statement: sets a value for the running MySQL instance. It also saves the value, causing it to be used for subsequent server restarts. See Section 15.7.6.1, “SET Syntax for Variable Assignment”. With enabled, client connections to the server are required to use some form of secure transport, and the server permits only TCP/IP connections that use SSL, or connections that use a socket file (on Unix) or shared memory (on Windows). The server rejects nonsecure connection attempts, which fail with an error. To invoke a client program such that it requires an encrypted connection whether or not the server requires encryption, use an option value of , , or . For example: To configure a MySQL account to be usable only over encrypted connections, include a clause in the statement that creates the account, specifying in that clause the encryption characteristics you require. For example, to require an encrypted connection and the use of a valid X.509 certificate, use : For additional information about the clause, see Section 15.7.1.3, “CREATE USER Statement”. To modify existing accounts that have no encryption requirements, use the statement."
    },
    {
        "link": "https://dev.mysql.com/doc/refman/9.1/en/replication-encrypted-connections.html",
        "document": "To use an encrypted connection for the transfer of the binary log required during replication, both the source and the replica servers must support encrypted network connections. If either server does not support encrypted connections (because it has not been compiled or configured for them), replication through an encrypted connection is not possible.\n\nSetting up encrypted connections for replication is similar to doing so for client/server connections. You must obtain (or create) a suitable security certificate that you can use on the source, and a similar certificate (from the same certificate authority) on each replica. You must also obtain suitable key files.\n\nFor more information on setting up a server and client for encrypted connections, see Section 8.3.1, “Configuring MySQL to Use Encrypted Connections”.\n\nTo enable encrypted connections on the source, you must create or obtain suitable certificate and key files, and then add the following configuration parameters to the section of the source file, changing the file names as necessary:\n\nThe paths to the files may be relative or absolute; we recommend that you always use complete paths for this purpose.\n\nThe configuration parameters are as follows:\n\nTo enable encrypted connections on the replica, use the statement.\n• None To name the replica's certificate and SSL private key files using , add the appropriate options, like this: These options correspond to the options with the same names, as described in Command Options for Encrypted Connections. For these options to take effect, must also be set. For a replication connection, specifying a value for either of or corresponds to setting . The connection attempt succeeds only if a valid matching Certificate Authority (CA) certificate is found using the specified information.\n• None To activate host name identity verification, add the option, like this: For a replication connection, specifying corresponds to setting , as described in Command Options for Encrypted Connections. For this option to take effect, must also be set. Host name identity verification does not work with self-signed certificates.\n• None To activate certificate revocation list (CRL) checks, add the or option, as shown here: These options correspond to the options with the same names, as described in Command Options for Encrypted Connections. If they are not specified, no CRL checking takes place.\n• None To specify lists of ciphers, ciphersuites, and encryption protocols permitted by the replica for the replication connection, use the , , and options, like this:\n• None The option specifies a colon-separated list of one or more ciphers permitted by the replica for the replication connection.\n• None The option specifies a comma-separated list of the TLS encryption protocols permitted by the replica for the replication connection, in a format like that for the server system variable. The connection procedure negotiates the use of the highest TLS version that both the source and the replica permit. To be able to connect, the replica must have at least one TLS version in common with the source.\n• None The option specifies a colon-separated list of one or more ciphersuites that are permitted by the replica for the replication connection if TLSv1.3 is used for the connection. If this option is set to when TLSv1.3 is used (which is the default if you do not set the option), the ciphersuites that are enabled by default are allowed. If you set the option to an empty string, no cipher suites are allowed, and TLSv1.3 is therefore not used. The protocols, ciphers, and ciphersuites that you can specify in these lists depend on the SSL library used to compile MySQL. For information about the formats, the permitted values, and the defaults if you do not specify the options, see Section 8.3.2, “Encrypted Connection TLS Protocols and Ciphers”. You can use the option to specify any selection of ciphersuites, including only non-default ciphersuites if you want.\n• None After the source information has been updated, start the replication process on the replica, like this: You can use the statement to confirm that an encrypted connection was established successfully.\n• None Requiring encrypted connections on the replica does not ensure that the source requires encrypted connections from replicas. If you want to ensure that the source only accepts replicas that connect using encrypted connections, create a replication user account on the source using the option, then grant that user the privilege. For example: mysql> CREATE USER 'repl'@'%.example.com' IDENTIFIED BY 'password' -> REQUIRE SSL; mysql> GRANT REPLICATION SLAVE ON *.* -> TO 'repl'@'%.example.com'; If you have an existing replication user account on the source, you can add to it with this statement:"
    },
    {
        "link": "https://stackoverflow.com/questions/15198820/how-do-i-know-ssl-is-being-used-in-mysql-replication",
        "document": "I have successfully set up my certificates and keys and using the mysql documentation found here: http://dev.mysql.com/doc/refman/5.1/en/replication-solutions-ssl.html\n\nMy replication is working but i need a way to be sure if ssl is being used, how do i do this?"
    },
    {
        "link": "https://dev.mysql.com/doc/mysql-replication-excerpt/5.7/en/replication-encrypted-connections.html",
        "document": "To use an encrypted connection for the transfer of the binary log required during replication, both the source and the replica servers must support encrypted network connections. If either server does not support encrypted connections (because it has not been compiled or configured for them), replication through an encrypted connection is not possible.\n\nSetting up encrypted connections for replication is similar to doing so for client/server connections. You must obtain (or create) a suitable security certificate that you can use on the source, and a similar certificate (from the same certificate authority) on each replica. You must also obtain suitable key files.\n\nFor more information on setting up a server and client for encrypted connections, see Configuring MySQL to Use Encrypted Connections.\n\nTo enable encrypted connections on the source, you must create or obtain suitable certificate and key files, and then add the following configuration parameters to the source's configuration within the section of the source's file, changing the file names as necessary:\n\nThe paths to the files may be relative or absolute; we recommend that you always use complete paths for this purpose.\n\nThe configuration parameters are as follows:\n\nTo enable encrypted connections on the replica, use the statement.\n• None To name the replica's certificate and SSL private key files using , add the appropriate options, like this: These options correspond to the options with the same names, as described in Command Options for Encrypted Connections. For these options to take effect, must also be set. For a replication connection, specifying a value for either of or corresponds to setting . The connection attempt succeeds only if a valid matching Certificate Authority (CA) certificate is found using the specified information.\n• None To activate host name identity verification, add the option: This option corresponds to the option, which is deprecated as of MySQL 5.7.11 and removed in MySQL 8.0. For a replication connection, specifying corresponds to setting , as described in Command Options for Encrypted Connections. For this option to take effect, must also be set. Host name identity verification does not work with self-signed certificates.\n• None To activate certificate revocation list (CRL) checks, add the or option, as shown here: These options correspond to the options with the same names, as described in Command Options for Encrypted Connections. If they are not specified, no CRL checking takes place.\n• None To specify lists of ciphers and encryption protocols permitted by the replica for the replication connection, add the and options, like this: The option specifies the list of ciphers permitted by the replica for the replication connection, with one or more cipher names separated by colons. The option specifies the encryption protocols permitted by the replica for the replication connection. The format is like that for the system variable, with one or more comma-separated protocol versions. The protocols and ciphers that you can use in these lists depend on the SSL library used to compile MySQL. For information about the formats and permitted values, see Encrypted Connection TLS Protocols and Ciphers.\n• None After the source information has been updated, start the replication process on the replica, like this: You can use the statement to confirm that an encrypted connection was established successfully.\n• None Requiring encrypted connections on the replica does not ensure that the source requires encrypted connections from replicas. If you want to ensure that the source only accepts replicas that connect using encrypted connections, create a replication user account on the source using the option, then grant that user the privilege. For example: mysql> CREATE USER 'repl'@'%.example.com' IDENTIFIED BY 'password' -> REQUIRE SSL; mysql> GRANT REPLICATION SLAVE ON *.* -> TO 'repl'@'%.example.com'; If you have an existing replication user account on the source, you can add to it with this statement:"
    },
    {
        "link": "https://cyberciti.biz/faq/tcpdump-capture-record-protocols-port",
        "document": "How do I capture a specific protocol or port, such as 80 (HTTP) or 443 (HTTPS), using the TCPDump tool under Linux/UNIX? How do I record traffic with TCPDump and find problems later on with my network or server issues? Let’s dive into the nitty-gritty of capturing and analyzing your network traffic for trapshooting network and server issues.TCPDump is a tool for network monitoring and data acquisition. It can save lots of time and can be used for debugging network or server related problems. Tcpdump prints out a description of the contents of packets on a network interface that match the boolean expression.\n\nLet us see how you can use tcpdump to capture and record specific protocols and ports on Linux or Unix. The syntax is as follows:\n\n \n\n The main options are:\n• – State the network interface (NIC) to capture on. For example, eth0, wlan0, wifi0, enp5s0 and so on. See how to list network cards on Linux for more info.\n• – Use IP addresses instead of resolving hostname using DNS. This for speed.\n• – Write captured packets to a file. Typically you use the .pcap extension. For example, eth1.pcap.\n\nFilter Expressions allows you to captures traffic based upon various conditions such as:\n• – Use protocol such as tcp, udp, icmp.\n• – State IP address or hostname to capture traffic from to or from a host.\n• – Captures traffic to or from a specific CIDR such as 10.8.0.1/24.\n\nDisplaying and showing available network interfaces on Linux or Unix or *BSD\n\nFor TCP:\n\n \n\n The “ ” option is used to show each packet both headers and data in ASCII format instead of the default hexadecimal and ASCII dump. This improves readability in many cases. For UDP:\n\n \n\n Sample outputs:\n\n\n\nHere is how to capture ICMP protocol:Outputs:\n\nTry:\n\n \n\n OR\n\n \n\n OR\n\n \n\n For TCP/443 (TSL/SSL), try:\n\n \n\n In this example, capture HTTP TCP Port 80 Traffic to/from a specific host:\n\n \n\n For SSH port:\n\n \n\n OR\n• -x : When parsing and printing, in addition to printing the headers of each packet, print the data of each packet.\n• -X : hen parsing and printing, in addition to printing the headers of each packet, print the data of each packet (minus its link level header) in hex and ASCII. This is very handy for analysing new protocols.\n• -s 1500: Snarf snaplen bytes of data from each packet rather than the default of 68. This is useful to see lots of information.\n\nHow to capture all traffic to/from a host on multiple ports\n\nSay you want to debug and capture TCP ports 80 or Port 443 on eth3 NIC, try:\n\n\n\nHow to capture traffic and save to a file\n\nSay you want to capture all DNS traffic at port 53 and write to a file named dns_53.pacp in the current directory, try:\n\n \n\n Please be aware of the potential size of capture files if you don’t limit with -c option which tells to exit after receiving 1000 packets:\n\n \n\n In this example, capture all traffic except traffic over port 22 and save to a file named network.pcap:\n\n\n\nHow do I analyze the captured packets in a file?\n\nYou can use the tcpdump command itself. For example here is how to read from a given dump file named dns_53.pacp:\n\n \n\n Apart from that you can use the following tools:\n• tshark: A CLI (command-line) version of Wireshark for packet analysis and more.\n\nSee “How to capture Linux network packets to a file” for more info.\n\nThe tcpdump can be used to find out about attacks and other problems. Let us say your webserver facing problem everday at midnight. Enter following command into cron. It will schedule capturing of 30,000 packets and writing raw data to a file called port.80.debug.txt:\n\nNext day you can log into your box and read the /root/port.80.debug.txt file as follows::\n\n \n\n This simple technique can be used to record and debug problems later on, depending on your requirements.\n\nHow do I use the grep command or egrep command with tcpdump?\n\nThe syntax is simple:\n\n \n\n Or you can try the ngrep command (Network grep) as follows:\n\n\n\nTCPDump is an awesome packet analyzer that works on Linux, macOS, and Unix-like systems. It allows the user to intercept and display TCP/IP and other packets being transmitted or received over a network. This tool is essential for sysadmins and developers to debug networking or server issues.\n\nSee man page of the tcpdump using the man command. For example:\n\n\n\n🥺 Was this helpful? Please add a comment to show your appreciation or feedback."
    },
    {
        "link": "https://baeldung.com/linux/tcpdump-capture-ssl-handshake",
        "document": "SSL is the most common protocol for exchanging encrypted data over a TCP connection. And in order to establish an SSL connection, the two endpoints must exchange public keys, encryption algorithm, protocol version, and so on. This exchange is known as an SSL handshake.\n\nSince this is an asymmetric key-certificate exchange, there’s often a chance that the handshake will fail. For example, if the server has an expired certificate or if the client and server can’t negotiate the SSL/TLS protocol version, the handshake will fail.\n\nIn most cases, we can find the failure reason by analyzing the SSL handshake messages between the client and server. In this tutorial, we’ll study a way to capture these messages over the network.\n\nThe tcpdump command allows us to capture the TCP packets on any network interface in a Linux system.\n\nGenerally, a lot of TCP traffic flows in a typical SSL exchange. Although tcpdump is quite useful and can capture any amount of data, this usually results in large dump files, sometimes in the order of gigabytes. Such dump files are sometimes impossible to analyze. For example, it would require a lot of resources in analyzing such dumps in Wireshark.\n\nTo overcome this problem, the tcpdump command provides some filtering options. Thus, only those TCP packets that satisfy the filtering conditions are captured in the output dump.\n\nLet’s quickly go through the messages that the client and server exchange during the SSL handshake:\n• Client Hello – Originated by the client. It contains the protocol version, cipher suites supported by the client, and a secured random number.\n• Server Hello – Returned by the server in response to the Client Hello. Contains the protocol version chosen by the server, selected cipher suite from the client’s list, encryption algorithm, and other TLS version-specific extensions.\n• Server Certificate – Originated by the server. Contains the public certificate chain that the client will authenticate.\n• Certificate Request – Originated by the server. This message is only sent if the server also needs to authenticate the client, as is the case in two-way SSL.\n• Server Hello Done – Originated by the server. Indicates the end of Server Hello.\n• Client Certificate – Returned by the client in response to Client Request. Client sends its certificate chain to the server.\n• Client Key Exchange – Originated by the client. It generates a pre-master secret and encrypts it with the server’s public certificate. It then sends the master secret to exchange the encryption algorithm with the server.\n• Certificate Verify – Originated by the server. This indicates successful authentication of the client’s certificate.\n• Finished – Sent by both the client and the server to indicate successful authentication and key exchange.\n\nIf there are some SSL failures during connection establishment, analyzing the above messages is a good starting point.\n\nAlthough we’ll not discuss these messages in detail, it’s important to realize that these messages are part of the TCP data packets. Therefore, if we want to capture only these messages, we need advanced filtering options compared to the ones we studied in the last section.\n\nWith this in mind, let’s explore some of the data filtering options in tcpdump and see how we can use them to filter only SSL handshake messages.\n\nIn addition to the metadata like port or host, the tcpdump command also supports filtering on the TCP data. In other words, tcpdump allows us to match the data bytes in the packet with a filter expression. For example, we can filter packets with certain TCP flags:\n\nThis command will capture only the SYN and FIN packets and may help in analyzing the lifecycle of a TCP connection.\n\nIn the same way, we can filter SSL handshake messages if we know the structure of data bytes. From the TLS specification, we know that every message in the handshake protocol starts with a unique numerical value. For example, all handshake message contains 22, represented as 0x16 in hex, as the first data byte:\n\nSo, based on this fact, let’s see how we can filter the handshake messages.\n\nSuppose we want to analyze SSL connection establishment attempts from a client. For this, we must check the Client Hello message between the client and the server. The Client Hello messages contain 01 in the sixth data byte of the TCP packet. Thus, to filter such packets:\n\nLet’s understand the different parts of the command options:\n• tcp port 8081 – captures packets only on port 8081, assuming this is the SSL port of the application server\n• and (tcp[12] & 0xf0) – reads the 13th byte of the packet and keeps the higher 4 bits\n• && ((tcp[12] & 0xf0) >>2) – when we multiply the above by 4, it gives the TCP header size\n\nAs we can see from the SSL dump above, the TLS header precedes the TCP data packet. So, to get the first and sixth data byte, we need to calculate the TCP header size and skip matching these bytes. The second and third terms above do just that.\n\nNow, tcp[TCP header size] points to the first byte of the data in the packet. And thus the term, tcp[((tcp[12] & 0xf0) >>2)] = 0x16 checks whether this byte is equal to 22, the numerical code for SSL handshake. And, tcp[((tcp[12] & 0xf0) >>2)+5] = 0x01 will filter packets where the sixth byte is 1, representing Client Hello.\n\nSimilarly, we can capture any handshake message we discussed earlier. For example, we can use tcp[((tcp[12] & 0xf0) >>2)+5] = 0x02 for Server Hello messages.\n\nThe SSL protocol has been evolving over time. After SSLv3, the protocol was succeeded by TLS, which is mostly similar. Modern applications generally exchange messages over TLSv1.3. However, many still support TLSv1.0, TLSv1.1, and TLSv1.2 for backward compatibility.\n\nThe TLS specification assigns a unique numerical code to every TLS version:\n\nIn the SSL handshake message, the tenth and eleventh bytes of the data contain the TLS version. Therefore, a tcpdump filter can be applied:\n\nThe terms tcp[((tcp[12] & 0xf0) >>2)+9] = 0x03 and tcp[((tcp[12] & 0xf0) >>2)+10] = 0x03 check the tenth and eleventh bytes to filter all packets over TLSv1.2. This command will capture all SSL handshake packets where TLSv1.2 is exchanged.\n\nSo far, we have only captured SSL handshake messages. Once the handshake is finished, the client and server can exchange the application data. Such application data packets also contain the TLS version in the second and third data bytes:\n\nHere, we’ve added a filter to capture packets that have 17 in the first byte and 03 in the second and third bytes. This is because 17 is the numeric code for Application Data packets, and 0303 denotes TLSv1.2, as we have seen before.\n\nTo filter failures, we’ll check the first byte, which contains 15 or 21, based on the failure:\n\nThis command will capture packets where the first data byte is either 15 or 21.\n\nIn this article, we discussed tcpdump filters to match the TCP data in a packet with an expression. Using this knowledge, we can easily capture packets where data matches the filter expression.\n\nWe later used this approach to capture the SSL handshake packets by matching a unique numeric code for each message."
    },
    {
        "link": "https://hostzealot.com/blog/how-to/ssl-handshake-capture-with-tcpdump",
        "document": "SSL is by far the most common protocol protocol that is used for encrypted data transmission over TCP connections. During this procedure, both parties must exchange different kinds of information, including public keys, encryption algorithms, protocol versions, and many others. Sometimes, however, the exchange doesn’t go as it is supposed to and there is a need to detect issues and fix them. A common way to do it is by capturing SSL handshake with tchpdump. By doing this, you’ll be able to analyze in detail, what’s going on with your data transmission and take steps to solving the issues.\n\ntcpdump is a powerful command-line network analysis tool that is used for capturing and displaying the packets transmitted and received over a network interface, available on most Unix-like operating systems, including Linux and macOS. If your point is to capture SSL handshake, you should know that the tool by itself can capture vast volumes of data, which you won’t be able to analyze in a productive way. With this in mind, you’ll have to apply a series of filters that will single out the packages that have directly to do with your task. The filtering criteria include source and destination IP addresses, port numbers, and protocols.\n\nThe SSL (Secure Sockets Layer) handshake is an essential part of the SSL/TLS (Transport Layer Security) protocol that is widely used for securing communication over computer networks. Although SSL has been largely superseded by TLS the term \"SSL handshake\" is still widely used to describe the initial negotiation phase of a TLS connection. An SSL handshake consists of a series of messages that are exchanged between the client and the server, and these messages are the stages of establishing a secure and encrypted communication channel. Let’s have a look at them.\n• None The handshake begins with the client sending a ClientHello message to the server. This message consists of the client's SSL/TLS version number, a list of supported cipher suites (algorithms for encryption, key exchange, and message authentication), a list of supported compression methods, and possibly a list of supported extensions.\n• None : To give a response to the previous message, the server sends a ServerHello message to the client, containing the server's SSL/TLS version number, the cipher suite and compression method selected from the client's list, and possibly server-selected extensions.\n• None : For the sake of authentication, the server sends its certificate to the client, which contains the server’s public key, later used for key exchange by the client.\n• None : In case the server requires authentication from the side of the client, like with two-way SSL, the server sends the message to the client.\n• None : The client and the server exchange key information. This can take place in different ways. For example, the client may send a pre-master secret encrypted with the server's public key (like in the case of RSA key exchange). Alternatively, both client and server may generate keys together (like in the case of Diffie-Hellman key exchange). Based on the chosen cipher suite, this step may vary.\n• None : After the server finished sending messages to support the key exchange and server authentication, it sends the ServerHelloDone message to indicate it.\n• None : To respond to the previous message the client sends a key exchange message, including a pre-master secret that depends on the key exchange method.\n• None : In case client authentication is needed, the client may send a digitally-signed certificate verify message, allowing the server to verify the client's certificate.\n• None Finally, both the client and server exchange encrypted Finished messages, which verify that the key exchange and authentication processes were successful.\n\nSince tcpdump filters information on the packet level and cannot deal with such constructus as SSL/TLS protocols directly, you’ll have to apply filtres relying on general characteristics of handshake packets, like port numbers and packer sizes, to capture only the handshake process. Let’s have a look at approaches that you can use for this task. SSL/TLS handshakes typically occur over port 443 for HTTPS, although other ports used for securing protocols may be involved as well. In particular, to capture all traffic on the default HTTPS port 443, use: Keep in mind, that this will capture all the traffic on the port and not only the handshake messages.\n• None Capturing the beginning of the connection: Since a handshake takes place at the beginning of an SSL/TLS connection, capturing the initial packet exchanges can help single out the handshake messages. For example, you can capture SYN and SYN-ACK packets so you can see the start of TCP connections taking place before the SSL/TLS handshake. Since handshake messages, ClientHello and ServerHello, in particular, tend to have a distinctive range in sizes, this fact can theoretically be taken advantage of to filter packets based on their TCP payload size. Nevertheless, since there is a great degree of randomness to such variables, as size, this method is rather imprecise and unreliable. Wireshark is a special tool that can provide you with a more detailed analysis of the traffic you’ve captured previously with tcpdump, filtering for specific handshake messages. First, capture the traffic from the specific port, writing it to a file: Open the capture_file.pcap file with Wireshark and use its SSL/TLS filters, like ssl.handshake.type for further analysis.\n\nAlthough most modern applications use TLSv1.3 protocol for message exchange. Nevertheless, to preserve compatibility with older versions, TLSv1.0, TLSv1.1, and TLSv1.2 are supported. Each version is assigned a numerical code: Given that this information is contained in the 10th and 11th bytes of the data in the SSL handshake message, the following filter can be used:"
    },
    {
        "link": "https://docs.rackspace.com/docs/capture-packets-with-tcpdump",
        "document": "is a powerful network debugging tool that you can use to intercept and display packets on a network interface. An important feature of is the filter that enables you to display only the packets you want to see.\n\nThis example uses Ubuntu® 18.04, but the installation steps are similar for other Linux® distributions. Use the following command to install on a server running the Ubuntu operating system:\n\nBy default, captures packets on . To specify a different interface, use the command line flag. The following command captures all packets on the interface:\n\nUse the following command to listen to all UDP connections:\n\nUse the following command to capture packets for a specific port:\n\nThe preceding command returns all packets that have port as their destination or source port.\n\nSuppose you want be more specific and capture only packets with destination port 80. If you have a web server on your cloud, you can use the folloiwng command to see incoming packets.\n\nYou can also capture packets for a specific host. The following command catches packets coming only from IP address :\n\ncan take logical arguments such as or . You can use logical statements in a command. For example, the following command catches all the Secure Shell (SSH) packets going from an SSH server to a client with IP address :\n\nYou can conveniently save raw packets to a file by using the option:\n\nTo read the saved file, use the following command:\n\nSystem administrators commonly use , a powerful packet sniffer tool, to solve network problems and investigate traffic. You can use with Boolean expressions to capture the packets that you want to examine."
    },
    {
        "link": "https://last9.io/blog/mysql-monitoring-open-source-vs-commercial-tools",
        "document": "MySQL is the backbone of many applications, and keeping it running smoothly is essential. But monitoring MySQL isn’t just about tracking CPU usage or checking if the database is up.\n\nIt’s about understanding queries, indexing, slow queries, and resource utilization to ensure performance never takes a hit. This guide walks through everything you need to know to monitor MySQL effectively.\n\nMonitoring MySQL isn’t just a best practice; it’s a necessity. Without proper monitoring, databases can become bottlenecks, leading to slow applications, downtime, and frustrated users.\n• Availability & reliability – Detect failures before they cause downtime.\n\nNot all metrics are equally important—some are critical for diagnosing performance issues. Below are the essential MySQL performance metrics you should track:\n• Slow Queries – Identifies queries that exceed a predefined execution time threshold, often indicating inefficiencies in indexing or query structure.\n• Query Execution Time – Measures how long each query takes to run, helping detect bottlenecks in database performance.\n• Query Errors & Warnings – Tracks queries that fail due to syntax issues, logical errors, or other unexpected behaviors.\n• Deadlocks & Lock Waits – Highlights contention issues where multiple queries block each other, leading to performance degradation.\n• CPU Usage – High CPU consumption by MySQL may indicate inefficient queries, missing indexes, or excessive workload on the database server.\n• Memory Usage – Monitors how MySQL utilizes memory buffers and caches, which can impact performance if improperly configured.\n• Disk I/O – Tracks read/write operations on disk; excessive disk activity often suggests slow queries, inadequate indexing, or poor query optimization.\n• Connections & Threads – Observes active connections and idle threads to detect potential connection saturation or inefficient resource allocation.\n• Replication Lag – Measures the delay between the primary database and its replicas, as high lag can lead to data inconsistencies in read-replica environments.\n• Binlog Size & Events – Tracks MySQL’s binary logs, which record database changes for replication; large logs may indicate high transaction volume or inefficient logging practices.\n• Buffer Pool Hit Ratio – Evaluates how efficiently MySQL retrieves data from memory rather than disk, with a low ratio suggesting insufficient memory allocation.\n• Table Scans vs. Indexed Reads – Compares full table scans against indexed reads to determine whether queries are efficiently utilizing indexes.\n• Row Lock Contention – Identifies scenarios where multiple queries attempt to access the same rows simultaneously, leading to delays and reduced performance.\n\nMySQL includes several built-in tools and schemas that provide insights into server performance and health. These tools help diagnose issues, optimize queries, and track resource usage.\n\nMySQL provides several key commands for real-time monitoring:\n• SHOW PROCESSLIST – Displays currently running queries, making it easier to identify long-running or stalled queries that may impact performance.\n• SHOW STATUS – Provides various server status variables, including connection counts, buffer usage, and query statistics, helping to assess resource consumption and system health.\n• EXPLAIN – Analyzes query execution plans, showing how MySQL processes a query and helping to optimize indexing and query structure.\n• SHOW ENGINE INNODB STATUS – Offers detailed InnoDB metrics, including buffer pool usage, transaction activity, lock waits, and contention issues, giving a deep dive into the storage engine’s performance.\n• Performance Schema – Captures in-depth performance data, such as query execution timing, resource usage, I/O operations, and lock waits. This tool is useful for diagnosing slow queries and identifying performance bottlenecks.\n• sys Schema – Built on top of the Performance Schema, the sys Schema simplifies performance data by providing summary tables and predefined queries. It offers a more user-friendly way to assess server performance without manually analyzing raw Performance Schema data.\n\nMonitoring MySQL performance is crucial for ensuring database reliability, detecting slow queries, and optimizing overall system performance.\n\nBelow are seven of the best open-source MySQL monitoring tools, each with its own strengths and ideal use cases.\n• Query Analytics: Offers detailed analysis of slow queries and provides recommendations for optimization.\n• System Metrics: Monitors system resources like CPU, memory, disk I/O, and network usage, providing a comprehensive overview of MySQL performance.\n• User-Friendly Dashboards: Includes pre-built dashboards for MySQL performance, making it easy to spot issues.\n• Integration with MySQL, MongoDB, and PostgreSQL: Supports multiple databases, so you can monitor a mixed stack from a single platform.\n\nWhen to Use:\n\nPMM is a great choice for teams managing MySQL databases with a focus on performance optimization. It’s perfect for environments where understanding query performance, server resource usage, and database efficiency are crucial.\n\nMany users appreciate PMM’s detailed insights into query performance and its ability to help diagnose bottlenecks. However, some note that the initial setup can be complex, especially for teams without extensive experience in performance tuning.\n• MySQL Uptime Monitoring: Tracks the uptime of MySQL servers to ensure they're running smoothly.\n• Replication Health: Monitors replication lag and the health of replication channels, alerting you to any issues.\n• Queries Per Second: Keeps tabs on query throughput to gauge the load on your MySQL server.\n• Customizable Alerts: Set thresholds for metrics, so you're alerted before minor issues become major problems.\n\nWhen to Use:\n\nZabbix is ideal for environments where comprehensive monitoring is required, and MySQL is part of a larger infrastructure. It's a great tool for teams looking for an open-source option with a strong focus on uptime, replication, and query performance.\n\nUsers enjoy Zabbix for its flexibility and customizability. The downside is that some find its UI a bit dated, and configuring advanced alerts can take time. Still, it’s widely praised for its robustness and scalability, making it a popular choice for larger setups.\n• Flexible Monitoring: Prometheus collects and stores metrics, while Grafana visualizes them in customizable dashboards.\n• Time-Series Metrics: Excellent for tracking metrics over time and spotting trends.\n• Alerting: Prometheus integrates with Alertmanager to trigger alerts based on predefined thresholds.\n• Integration with Multiple Databases: Prometheus supports a wide range of databases, while Grafana can be used for monitoring MySQL along with many other systems.\n\nWhen to Use:\n\nPrometheus & Grafana are perfect for teams who need flexibility in monitoring and want to create their custom dashboards. If you’re running MySQL alongside other services and need unified monitoring, this pair is an excellent choice.\n\nPrometheus and Grafana are often praised for their customizability and visual appeal. Users love the ability to create tailored dashboards that provide deep insights into their systems. However, there is a bit of a learning curve when setting everything up, especially for users unfamiliar with Prometheus' time-series model.\n• Real-Time Monitoring: Provides real-time insights with minimal latency, so you can catch issues as they arise.\n• Low Overhead: Uses a small amount of resources to monitor systems, making it suitable for lightweight environments.\n• Pre-built Dashboards: Offers a wide variety of pre-configured dashboards for different metrics, including MySQL.\n• Instant Alerts: Configurable alerts ensure you're notified immediately if something goes wrong.\n\nWhen to Use:\n\nNetdata is ideal for teams that need real-time monitoring with minimal setup. It’s well-suited for small to medium environments where you want to quickly spot performance issues without heavy resource usage.\n\nUsers love Netdata for its low overhead and real-time insights. It’s especially appreciated for being lightweight and offering great visuals. However, some users feel that it lacks the depth of analysis seen in more comprehensive tools, and it’s not the best choice for large-scale production environments.\n• Graphical Interface: Uses RRDtool to generate detailed graphs of MySQL performance metrics.\n• Alerting & Thresholds: Allows administrators to set alerts based on predefined conditions.\n\nWhen to Use:\n\nCacti is a solid choice for teams that need a visual representation of MySQL performance trends over time. It works well for network and system monitoring beyond just MySQL.\n\nUsers appreciate Cacti’s extensive graphing capabilities but mention that it requires more manual setup than modern alternatives.\n\nWhen to Use:\n\nNagios is best suited for enterprises that require a mature and highly customizable monitoring tool.\n\nUsers praise Nagios for its reliability but note that configuration can be complex for beginners.\n• Query Optimization: Offers insights on how to fine-tune MySQL queries for better performance.\n\nWhen to Use:\n\nMySQLTuner is perfect for DBAs looking for a quick way to assess and optimize their MySQL configurations.\n\nUsers love MySQLTuner for its ease of use and instant recommendations, though it lacks real-time monitoring features.\n\nThese seven open-source MySQL monitoring tools provide different levels of insight, automation, and control, catering to various use cases. Whether you need real-time insights, historical trends, or deep query analytics, there's a tool that fits your needs.\n\ntcpdump can be used to analyze MySQL traffic at a network level, helping detect query delays without touching the database logs.\n\nMost developers look at slow queries, but locking issues can be just as bad. Performance Schema tables like events_waits_summary_by_instance can uncover hidden contention.\n\neBPF (Extended Berkeley Packet Filter) provides in-kernel monitoring of MySQL queries with minimal overhead. Tools like bpftrace allow tracing MySQL syscalls in real time.\n• Set up alerts – Monitoring is useless if you don’t get notified of issues.\n• Use dashboards – Visualizing metrics makes them easier to understand.\n• Scale wisely – If MySQL usage is growing, ensure scaling strategies are in place.\n\nModern applications involve multiple services, databases, caches, and APIs working together. When something slows down, pinpointing the root cause can feel like searching for a needle in a haystack. This is where distributed tracing comes in.\n\nDistributed tracing tracks requests as they flow through different components of an application. It captures details about each step—how long it took, where delays happened, and how different services interacted. When applied to MySQL monitoring, it helps you see how queries impact overall application performance.\n\nWhy is Distributed Tracing Important for MySQL?\n\nWhile traditional MySQL monitoring tools focus on metrics like CPU usage, query execution time, and connection stats, they often lack context. Distributed tracing fills in the gaps by showing:\n• Query Performance Across Services: Track how a single request moves from your application to MySQL and back, identifying slow database interactions.\n• Bottlenecks in the Stack: See if delays are due to MySQL itself or an issue elsewhere, like an overloaded API or a slow external dependency.\n• Correlating Database Queries with User Requests: Find out which queries are causing slow user experiences rather than just spotting slow queries in isolation.\n• Instrumentation: Adding tracing agents (like OpenTelemetry, Jaeger, or Zipkin) to your application and database. These capture traces as requests pass through.\n• Trace Context Propagation: Ensuring requests carry a unique trace ID so each step is linked across services.\n• Trace Collection and Analysis: Viewing collected traces in a dashboard to analyze MySQL query performance in the bigger picture.\n\nDistributed tracing helps track requests across multiple services, providing visibility into MySQL query performance and latency within a broader system.\n\nHere are three commonly used tools for tracing MySQL activity in distributed environments:\n• Overview: OpenTelemetry is a widely used open-source observability framework that provides tracing, metrics, and logging capabilities. It allows you to collect telemetry data across various services, including MySQL.\n• Key Features:\n• Integrates with multiple backends like Prometheus, Jaeger, and Grafana.\n• Best Use Case: Ideal for teams looking for an open and extensible observability framework that integrates with modern cloud-native applications.\n• Overview: Originally developed by Uber, Jaeger is a powerful distributed tracing system designed to monitor transactions across microservices. It helps visualize request flows and identify bottlenecks in MySQL query execution.\n• Best Use Case: Suitable for organizations that need a robust and scalable tracing solution with strong visualization capabilities for debugging MySQL performance issues.\n• Overview: Last9 offers an advanced observability platform with built-in MySQL tracing capabilities. It provides structured visibility into MySQL performance, allowing users to monitor query execution times, detect anomalies, and optimize database efficiency.\n• Best Use Case: Best for teams that require a structured, ready-to-use MySQL monitoring solution with deep tracing capabilities.\n\nHow to Secure Your MySQL Monitoring Setup\n\nMonitoring MySQL isn’t just about performance—it’s also a critical part of database security. A good monitoring setup helps detect suspicious activity, prevent unauthorized access, and ensure compliance with security best practices.\n\nHere’s how monitoring tools play a role in keeping your MySQL database secure.\n\nMonitoring tools track login attempts, failed authentications, and unusual access patterns. A spike in failed login attempts? That could indicate a brute-force attack. Unexpected access from a new location? Time to investigate.\n\nAttackers often try to exploit databases using SQL injection or other malicious queries. By monitoring executed SQL statements, you can spot unusual patterns—like a flood of DROP TABLE commands or excessive data exfiltration attempts.\n\nChanges in user roles and permissions should always raise an eyebrow. If an application suddenly gets admin-level privileges, that’s a potential red flag. Monitoring tools can alert you to privilege escalations that may indicate a security breach.\n\nWho accessed what data, and when? Good monitoring tools provide audit logs that help track changes to sensitive tables. If a user starts reading or modifying more data than usual, it might signal a data breach or internal threat.\n\nLarge data transfers or unexpected spikes in queries could indicate data exfiltration attempts. Monitoring tools help identify when a massive amount of data is being accessed or exported, so you can take action before sensitive information leaks.\n\nAre database connections encrypted? Are users connecting over SSL/TLS? Monitoring tools help enforce security best practices by flagging unencrypted connections or weak authentication methods.\n\nFor organizations that need to comply with regulations like GDPR, HIPAA, or PCI DSS, database monitoring provides essential logs and reports. These logs help prove compliance and make audits smoother.\n\nGood monitoring tools don’t just collect data—they alert you in real-time. Whether it’s an unauthorized login, a sudden data spike, or an unusual SQL query, timely alerts help security teams respond before real damage is done.\n\nPicking the right MySQL monitoring tool is about finding the one that fits your environment, your team’s needs, and your budget. Here’s what to consider:\n\n1. What Are You Monitoring?\n\nDifferent tools excel at different things. Are you keeping an eye on slow queries? Looking for replication issues? Monitoring resource usage? Make a list of what matters most for your MySQL setup so you can focus on tools that meet those needs.\n\nSome tools specialize in real-time monitoring, helping you spot issues as they happen. Others focus on long-term trends, giving you insights into performance over time. If you need both, look for a tool that provides a good mix.\n\nA powerful tool is useless if it's too complicated to use. Check the UI, dashboard customization options, and overall ease of setup. Some tools require extensive configuration, while others work right out of the box.\n\nYour monitoring tool should work well with your existing infrastructure. Consider whether it integrates with services like Prometheus, Grafana, and Last9, or alerting systems like PagerDuty and Slack.\n\nOpen-source tools like PMM (Percona Monitoring and Management) are great for flexibility and cost savings but may require more setup and maintenance. Commercial tools, on the other hand, often provide better support and advanced features but come at a price.\n\nA tool that works well for a single MySQL instance might not scale to dozens or hundreds of instances. Consider how well a tool handles growing workloads and whether it supports distributed architectures.\n\nSome tools are free, some have freemium models, and others come with hefty licensing fees. Factor in the total cost of ownership, including maintenance, support, and any required infrastructure.\n\nA strong user community can be invaluable when troubleshooting issues. Open-source tools often have active forums, while commercial tools typically offer dedicated support. Make sure help is available when you need it.\n\nWhich One Should You Choose?\n• Go Open-Source If… You have a technical team, need flexibility, and want a free solution.\n• Go Commercial If… You need enterprise-level support, automation, and a plug-and-play experience.\n\nBoth types have their place. For small projects or cost-sensitive setups, open-source tools are great. For mission-critical applications requiring scalability and dedicated support, commercial solutions offer peace of mind."
    }
]