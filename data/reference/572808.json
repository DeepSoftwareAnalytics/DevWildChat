[
    {
        "link": "https://docs.julialang.org/en/v1/manual/functions",
        "document": "In Julia, a function is an object that maps a tuple of argument values to a return value. Julia functions are not pure mathematical functions, because they can alter and be affected by the global state of the program. The basic syntax for defining functions in Julia is:\n\nThis function accepts two arguments and and returns the value of the last expression evaluated, which is .\n\nThere is a second, more terse syntax for defining a function in Julia. The traditional function declaration syntax demonstrated above is equivalent to the following compact \"assignment form\":\n\nIn the assignment form, the body of the function must be a single expression, although it can be a compound expression (see Compound Expressions). Short, simple function definitions are common in Julia. The short function syntax is accordingly quite idiomatic, considerably reducing both typing and visual noise.\n\nA function is called using the traditional parenthesis syntax:\n\nWithout parentheses, the expression refers to the function object, and can be passed around like any other value:\n\nAs with variables, Unicode can also be used for function names:\n\nJulia function arguments follow a convention sometimes called \"pass-by-sharing\", which means that values are not copied when they are passed to functions. Function arguments themselves act as new variable bindings (new \"names\" that can refer to values), much like assignments , so that the objects they refer to are identical to the passed values. Modifications to mutable values (such as s) made within a function will be visible to the caller. (This is the same behavior found in Scheme, most Lisps, Python, Ruby and Perl, among other dynamic languages.)\n\nFor example, in the function\n\nThe statement mutates the object , and hence this change will be visible in the array passed by the caller for this argument. On the other hand, the assignment changes the binding (\"name\") to refer to a new value , rather than mutating the original object referred to by , and hence does not change the corresponding argument passed by the caller. This can be seen if we call :\n\nAs a common convention in Julia (not a syntactic requirement), such a function would typically be named rather than , as a visual reminder at the call site that at least one of the arguments (often the first one) is being mutated.\n\nYou can declare the types of function arguments by appending to the argument name, as usual for Type Declarations in Julia. For example, the following function computes Fibonacci numbers recursively:\n\nand the specification means that it will only be callable when is a subtype of the abstract type.\n\nArgument-type declarations normally have no impact on performance: regardless of what argument types (if any) are declared, Julia compiles a specialized version of the function for the actual argument types passed by the caller. For example, calling will trigger the compilation of specialized version of optimized specifically for arguments, which is then re-used if or are called. (There are rare exceptions when an argument-type declaration can trigger additional compiler specializations; see: Be aware of when Julia avoids specializing.) The most common reasons to declare argument types in Julia are, instead:\n• Dispatch: As explained in Methods, you can have different versions (\"methods\") of a function for different argument types, in which case the argument types are used to determine which implementation is called for which arguments. For example, you might implement a completely different algorithm that works for any type by using Binet's formula to extend it to non-integer values.\n• Correctness: Type declarations can be useful if your function only returns correct results for certain argument types. For example, if we omitted argument types and wrote , then would silently give us the nonsensical answer .\n• Clarity: Type declarations can serve as a form of documentation about the expected arguments.\n\nHowever, it is a common mistake to overly restrict the argument types, which can unnecessarily limit the applicability of the function and prevent it from being re-used in circumstances you did not anticipate. For example, the function above works equally well for arguments (machine integers) and arbitrary-precision integers (see BigFloats and BigInts), which is especially useful because Fibonacci numbers grow exponentially rapidly and will quickly overflow any fixed-precision type like (see Overflow behavior). If we had declared our function as , however, the application to would have been prevented for no reason. In general, you should use the most general applicable abstract types for arguments, and when in doubt, omit the argument types. You can always add argument-type specifications later if they become necessary, and you don't sacrifice performance or functionality by omitting them.\n\nThe value returned by a function is the value of the last expression evaluated, which, by default, is the last expression in the body of the function definition. In the example function, , from the previous section this is the value of the expression . As an alternative, as in many other languages, the keyword causes a function to return immediately, providing an expression whose value is returned:\n\nSince function definitions can be entered into interactive sessions, it is easy to compare these definitions:\n\nOf course, in a purely linear function body like , the usage of is pointless since the expression is never evaluated and we could simply make the last expression in the function and omit the . In conjunction with other control flow, however, is of real use. Here, for example, is a function that computes the hypotenuse length of a right triangle with sides of length and , avoiding overflow:\n\nThere are three possible points of return from this function, returning the values of three different expressions, depending on the values of and . The on the last line could be omitted since it is the last expression.\n\nA return type can be specified in the function declaration using the operator. This converts the return value to the specified type.\n\nThis function will always return an regardless of the types of and . See Type Declarations for more on return types.\n\nReturn type declarations are rarely used in Julia: in general, you should instead write \"type-stable\" functions in which Julia's compiler can automatically infer the return type. For more information, see the Performance Tips chapter.\n\nFor functions that do not need to return a value (functions used only for some side effects), the Julia convention is to return the value :\n\nThis is a convention in the sense that is not a Julia keyword but only a singleton object of type . Also, you may notice that the function example above is contrived, because already returns , so that the line is redundant.\n\nThere are two possible shortened forms for the expression. On the one hand, the keyword implicitly returns , so it can be used alone. On the other hand, since functions implicitly return their last expression evaluated, can be used alone when it's the last expression. The preference for the expression as opposed to or alone is a matter of coding style.\n\nIn Julia, most operators are just functions with support for special syntax. (The exceptions are operators with special evaluation semantics like and . These operators cannot be functions since Short-Circuit Evaluation requires that their operands are not evaluated before evaluation of the operator.) Accordingly, you can also apply them using parenthesized argument lists, just as you would any other function:\n\nThe infix form is exactly equivalent to the function application form – in fact the former is parsed to produce the function call internally. This also means that you can assign and pass around operators such as and just like you would with other function values:\n\nUnder the name , the function does not support infix notation, however.\n\nA few special expressions correspond to calls to functions with non-obvious names. These are:\n\nNote that expressions similar to but with more than two consecutive also correspond to calls.\n\nFunctions in Julia are first-class objects: they can be assigned to variables, and called using the standard function call syntax from the variable they have been assigned to. They can be used as arguments, and they can be returned as values. They can also be created anonymously, without being given a name, using either of these syntaxes:\n\nEach statement creates a function taking one argument and returning the value of the polynomial at that value. Notice that the result is a generic function, but with a compiler-generated name based on consecutive numbering.\n\nThe primary use for anonymous functions is passing them to functions which take other functions as arguments. A classic example is , which applies a function to each value of an array and returns a new array containing the resulting values:\n\nThis is fine if a named function effecting the transform already exists to pass as the first argument to . Often, however, a ready-to-use, named function does not exist. In these situations, the anonymous function construct allows easy creation of a single-use function object without needing a name:\n\nAn anonymous function accepting multiple arguments can be written using the syntax .\n\nArgument-type declarations for anonymous functions work as for named functions, for example . The return type of an anonymous function cannot be specified.\n\nA zero-argument anonymous function can be written as . The idea of a function with no arguments may seem strange, but is useful in cases where a result cannot (or should not) be precomputed. For example, Julia has a zero-argument function that returns the current time in seconds, and thus is an anonymous function that returns this time rounded to the nearest integer assigned to the variable . Each time this anonymous function is called as the current time will be calculated and returned.\n\nJulia has a built-in data structure called a tuple that is closely related to function arguments and return values. A tuple is a fixed-length container that can hold any values, but cannot be modified (it is immutable). Tuples are constructed with commas and parentheses, and can be accessed via indexing:\n\nNotice that a length-1 tuple must be written with a comma, , since would just be a parenthesized value. represents the empty (length-0) tuple.\n\nThe components of tuples can optionally be named, in which case a named tuple is constructed:\n\nThe fields of named tuples can be accessed by name using dot syntax ( ) in addition to the regular indexing syntax ( or ).\n\nA comma-separated list of variables (optionally wrapped in parentheses) can appear on the left side of an assignment: the value on the right side is destructured by iterating over and assigning to each variable in turn:\n\nThe value on the right should be an iterator (see Iteration interface) at least as long as the number of variables on the left (any excess elements of the iterator are ignored).\n\nThis can be used to return multiple values from functions by returning a tuple or other iterable value. For example, the following function returns two values:\n\nIf you call it in an interactive session without assigning the return value anywhere, you will see the tuple returned:\n\nDestructuring assignment extracts each value into a variable:\n\nAnother common use is for swapping variables:\n\nIf only a subset of the elements of the iterator are required, a common convention is to assign ignored elements to a variable consisting of only underscores (which is an otherwise invalid variable name, see Allowed Variable Names):\n\nOther valid left-hand side expressions can be used as elements of the assignment list, which will call or , or recursively destructure individual elements of the iterator:\n\nIf the last symbol in the assignment list is suffixed by (known as slurping), then it will be assigned a collection or lazy iterator of the remaining elements of the right-hand side iterator:\n\nSee for details on the precise handling and customization for specific iterators.\n\nSlurping in assignments can also occur in any other position. As opposed to slurping the end of a collection however, this will always be eager.\n\nThis is implemented in terms of the function .\n\nNote that for variadic function definitions, slurping is still only allowed in final position. This does not apply to single argument destructuring though, as that does not affect method dispatch:\n\nInstead of destructuring based on iteration, the right side of assignments can also be destructured using property names. This follows the syntax for NamedTuples, and works by assigning to each variable on the left a property of the right side of the assignment with the same name using :\n\nThe destructuring feature can also be used within a function argument. If a function argument name is written as a tuple (e.g. ) instead of just a symbol, then an assignment will be inserted for you:\n\nNotice the extra set of parentheses in the definition of . Without those, would be a two-argument function, and this example would not work.\n\nSimilarly, property destructuring can also be used for function arguments:\n\nIt is often convenient to be able to write functions taking an arbitrary number of arguments. Such functions are traditionally known as \"varargs\" functions, which is short for \"variable number of arguments\". You can define a varargs function by following the last positional argument with an ellipsis:\n\nThe variables and are bound to the first two argument values as usual, and the variable is bound to an iterable collection of the zero or more values passed to after its first two arguments:\n\nIn all these cases, is bound to a tuple of the trailing values passed to .\n\nIt is possible to constrain the number of values passed as a variable argument; this will be discussed later in Parametrically-constrained Varargs methods.\n\nOn the flip side, it is often handy to \"splat\" the values contained in an iterable collection into a function call as individual arguments. To do this, one also uses but in the function call instead:\n\nIn this case a tuple of values is spliced into a varargs call precisely where the variable number of arguments go. This need not be the case, however:\n\nFurthermore, the iterable object splatted into a function call need not be a tuple:\n\nAlso, the function that arguments are splatted into need not be a varargs function (although it often is):\n\nAs you can see, if the wrong number of elements are in the splatted container, then the function call will fail, just as it would if too many arguments were given explicitly.\n\nIt is often possible to provide sensible default values for function arguments. This can save users from having to pass every argument on every call. For example, the function from module constructs a type for a given year , month and day . However, and arguments are optional and their default value is . This behavior can be expressed concisely as:\n\nObserve, that this definition calls another method of the function that takes one argument of type .\n\nWith this definition, the function can be called with either one, two or three arguments, and is automatically passed when only one or two of the arguments are specified:\n\nOptional arguments are actually just a convenient syntax for writing multiple method definitions with different numbers of arguments (see Note on Optional and keyword Arguments). This can be checked for our function example by calling the function:\n\nSome functions need a large number of arguments, or have a large number of behaviors. Remembering how to call such functions can be difficult. Keyword arguments can make these complex interfaces easier to use and extend by allowing arguments to be identified by name instead of only by position.\n\nFor example, consider a function that plots a line. This function might have many options, for controlling line style, width, color, and so on. If it accepts keyword arguments, a possible call might look like , where we have chosen to specify only line width. Notice that this serves two purposes. The call is easier to read, since we can label an argument with its meaning. It also becomes possible to pass any subset of a large number of arguments, in any order.\n\nFunctions with keyword arguments are defined using a semicolon in the signature:\n\nWhen the function is called, the semicolon is optional: one can either call or , but the former style is more common. An explicit semicolon is required only for passing varargs or computed keywords as described below.\n\nKeyword argument default values are evaluated only when necessary (when a corresponding keyword argument is not passed), and in left-to-right order. Therefore default expressions may refer to prior keyword arguments.\n\nThe types of keyword arguments can be made explicit as follows:\n\nKeyword arguments can also be used in varargs functions:\n\nExtra keyword arguments can be collected using , as in varargs functions:\n\nInside , will be an immutable key-value iterator over a named tuple. Named tuples (as well as dictionaries with keys of , and other iterators yielding two-value collections with symbol as first values) can be passed as keyword arguments using a semicolon in a call, e.g. .\n\nIf a keyword argument is not assigned a default value in the method definition, then it is required: an exception will be thrown if the caller does not assign it a value:\n\nOne can also pass expressions after a semicolon. For example, is equivalent to . This is useful in situations where the keyword name is computed at runtime.\n\nWhen a bare identifier or dot expression occurs after a semicolon, the keyword argument name is implied by the identifier or field name. For example is equivalent to and is equivalent to .\n\nThe nature of keyword arguments makes it possible to specify the same argument more than once. For example, in the call it is possible that the structure also contains a value for . In such a case the rightmost occurrence takes precedence; in this example, is certain to have the value . However, explicitly specifying the same keyword argument multiple times, for example , is not allowed and results in a syntax error.\n\nWhen optional and keyword argument default expressions are evaluated, only previous arguments are in scope. For example, given this definition:\n\nthe in refers to a in an outer scope, not the subsequent argument .\n\nPassing functions as arguments to other functions is a powerful technique, but the syntax for it is not always convenient. Such calls are especially awkward to write when the function argument requires multiple lines. As an example, consider calling on a function with several cases:\n\nJulia provides a reserved word for rewriting this code more clearly:\n\nThe syntax creates an anonymous function with argument and passes the anonymous function as the first argument to the \"outer\" function - in this example. Similarly, would create a two-argument anonymous function. Note that would create a one-argument anonymous function, whose argument is a tuple to be deconstructed. A plain would declare that what follows is an anonymous function of the form .\n\nHow these arguments are initialized depends on the \"outer\" function; here, will sequentially set to , , , calling the anonymous function on each, just as would happen in the syntax .\n\nThis syntax makes it easier to use functions to effectively extend the language, since calls look like normal code blocks. There are many possible uses quite different from , such as managing system state. For example, there is a version of that runs code ensuring that the opened file is eventually closed:\n\nThis is accomplished by the following definition:\n\nHere, first opens the file for writing and then passes the resulting output stream to the anonymous function you defined in the block. After your function exits, will make sure that the stream is properly closed, regardless of whether your function exited normally or threw an exception. (The construct will be described in Control Flow.)\n\nWith the block syntax, it helps to check the documentation or implementation to know how the arguments of the user function are initialized.\n\nA block, like any other inner function, can \"capture\" variables from its enclosing scope. For example, the variable in the above example of is captured from the outer scope. Captured variables can create performance challenges as discussed in performance tips.\n\nFunctions in Julia can be combined by composing or piping (chaining) them together.\n\nFunction composition is when you combine functions together and apply the resulting composition to arguments. You use the function composition operator ( ) to compose the functions, so is the same as .\n\nYou can type the composition operator at the REPL and suitably-configured editors using .\n\nFor example, the and functions can be composed like this:\n\nThis adds the numbers first, then finds the square root of the result.\n\nThe next example composes three functions and maps the result over an array of strings:\n\nFunction chaining (sometimes called \"piping\" or \"using a pipe\" to send data to a subsequent function) is when you apply a function to the previous function's output:\n\nHere, the total produced by is passed to the function. The equivalent composition would be:\n\nThe pipe operator can also be used with broadcasting, as , to provide a useful combination of the chaining/piping and dot vectorization syntax (described below).\n\nWhen combining pipes with anonymous functions, parentheses must be used if subsequent pipes are not to be parsed as part of the anonymous function's body. Compare:\n\nIn technical-computing languages, it is common to have \"vectorized\" versions of functions, which simply apply a given function to each element of an array to yield a new array via . This kind of syntax is convenient for data processing, but in other languages vectorization is also often required for performance: if loops are slow, the \"vectorized\" version of a function can call fast library code written in a low-level language. In Julia, vectorized functions are not required for performance, and indeed it is often beneficial to write your own loops (see Performance Tips), but they can still be convenient. Therefore, any Julia function can be applied elementwise to any array (or other collection) with the syntax . For example, can be applied to all elements in the vector like so:\n\nOf course, you can omit the dot if you write a specialized \"vector\" method of , e.g. via , and this is just as efficient as . The advantage of the syntax is that which functions are vectorizable need not be decided upon in advance by the library writer.\n\nMore generally, is actually equivalent to , which allows you to operate on multiple arrays (even of different shapes), or a mix of arrays and scalars (see Broadcasting). For example, if you have , then will return a new array consisting of for each in , and will return a new vector consisting of for each index (throwing an exception if the vectors have different length).\n\nKeyword arguments are not broadcasted over, but are simply passed through to each call of the function. For example, is equivalent to .\n\nMoreover, nested calls are fused into a single loop. For example, is equivalent to , similar to : there is only a single loop over , and a single array is allocated for the result. [In contrast, in a typical \"vectorized\" language would first allocate one temporary array for , and then compute in a separate loop, allocating a second array.] This loop fusion is not a compiler optimization that may or may not occur, it is a syntactic guarantee whenever nested calls are encountered. Technically, the fusion stops as soon as a \"non-dot\" function call is encountered; for example, in the and loops cannot be merged because of the intervening function.\n\nFinally, the maximum efficiency is typically achieved when the output array of a vectorized operation is pre-allocated, so that repeated calls do not allocate new arrays over and over again for the results (see Pre-allocating outputs). A convenient syntax for this is , which is equivalent to except that, as above, the loop is fused with any nested \"dot\" calls. For example, is equivalent to , overwriting with in-place. If the left-hand side is an array-indexing expression, e.g. , then it translates to on a , e.g. , so that the left-hand side is updated in-place.\n\nSince adding dots to many operations and function calls in an expression can be tedious and lead to code that is difficult to read, the macro is provided to convert every function call, operation, and assignment in an expression into the \"dotted\" version.\n\nBinary (or unary) operators like are handled with the same mechanism: they are equivalent to calls and are fused with other nested \"dot\" calls. etcetera is equivalent to and results in a fused in-place assignment; see also dot operators.\n\nYou can also combine dot operations with function chaining using , as in this example:\n\nAll functions in the fused broadcast are always called for every element of the result. Thus will add a mask of independent and identically sampled random values to each element of the array , but will add the same random sample to each element. In cases where the fused computation is constant along one or more axes of the broadcast iteration, it may be possible to leverage a space-time tradeoff and allocate intermediate values to reduce the number of computations. See more at performance tips.\n\nWe should mention here that this is far from a complete picture of defining functions. Julia has a sophisticated type system and allows multiple dispatch on argument types. None of the examples given here provide any type annotations on their arguments, meaning that they are applicable to all types of arguments. The type system is described in Types and defining a function in terms of methods chosen by multiple dispatch on run-time argument types is described in Methods."
    },
    {
        "link": "https://docs.julialang.org/en/v1/manual/methods",
        "document": "Recall from Functions that a function is an object that maps a tuple of arguments to a return value, or throws an exception if no appropriate value can be returned. It is common for the same conceptual function or operation to be implemented quite differently for different types of arguments: adding two integers is very different from adding two floating-point numbers, both of which are distinct from adding an integer to a floating-point number. Despite their implementation differences, these operations all fall under the general concept of \"addition\". Accordingly, in Julia, these behaviors all belong to a single object: the function.\n\nTo facilitate using many different implementations of the same concept smoothly, functions need not be defined all at once, but can rather be defined piecewise by providing specific behaviors for certain combinations of argument types and counts. A definition of one possible behavior for a function is called a method. Thus far, we have presented only examples of functions defined with a single method, applicable to all types of arguments. However, the signatures of method definitions can be annotated to indicate the types of arguments in addition to their number, and more than a single method definition may be provided. When a function is applied to a particular tuple of arguments, the most specific method applicable to those arguments is applied. Thus, the overall behavior of a function is a patchwork of the behaviors of its various method definitions. If the patchwork is well designed, even though the implementations of the methods may be quite different, the outward behavior of the function will appear seamless and consistent.\n\nThe choice of which method to execute when a function is applied is called dispatch. Julia allows the dispatch process to choose which of a function's methods to call based on the number of arguments given, and on the types of all of the function's arguments. This is different than traditional object-oriented languages, where dispatch occurs based only on the first argument, which often has a special argument syntax, and is sometimes implied rather than explicitly written as an argument. Using all of a function's arguments to choose which method should be invoked, rather than just the first, is known as multiple dispatch. Multiple dispatch is particularly useful for mathematical code, where it makes little sense to artificially deem the operations to \"belong\" to one argument more than any of the others: does the addition operation in belong to any more than it does to ? The implementation of a mathematical operator generally depends on the types of all of its arguments. Even beyond mathematical operations, however, multiple dispatch ends up being a powerful and convenient paradigm for structuring and organizing programs.\n\nUntil now, we have, in our examples, defined only functions with a single method having unconstrained argument types. Such functions behave just like they would in traditional dynamically typed languages. Nevertheless, we have used multiple dispatch and methods almost continually without being aware of it: all of Julia's standard functions and operators, like the aforementioned function, have many methods defining their behavior over various possible combinations of argument type and count.\n\nWhen defining a function, one can optionally constrain the types of parameters it is applicable to, using the type-assertion operator, introduced in the section on Composite Types:\n\nThis function definition applies only to calls where and are both values of type :\n\nApplying it to any other types of arguments will result in a :\n\nAs you can see, the arguments must be precisely of type . Other numeric types, such as integers or 32-bit floating-point values, are not automatically converted to 64-bit floating-point, nor are strings parsed as numbers. Because is a concrete type and concrete types cannot be subclassed in Julia, such a definition can only be applied to arguments that are exactly of type . It may often be useful, however, to write more general methods where the declared parameter types are abstract:\n\nThis method definition applies to any pair of arguments that are instances of . They need not be of the same type, so long as they are each numeric values. The problem of handling disparate numeric types is delegated to the arithmetic operations in the expression .\n\nTo define a function with multiple methods, one simply defines the function multiple times, with different numbers and types of arguments. The first method definition for a function creates the function object, and subsequent method definitions add new methods to the existing function object. The most specific method definition matching the number and types of the arguments will be executed when the function is applied. Thus, the two method definitions above, taken together, define the behavior for over all pairs of instances of the abstract type – but with a different behavior specific to pairs of values. If one of the arguments is a 64-bit float but the other one is not, then the method cannot be called and the more general method must be used:\n\nThe definition is only used in the first case, while the definition is used in the others. No automatic casting or conversion of function arguments is ever performed: all conversion in Julia is non-magical and completely explicit. Conversion and Promotion, however, shows how clever application of sufficiently advanced technology can be indistinguishable from magic.\n\nFor non-numeric values, and for fewer or more than two arguments, the function remains undefined, and applying it will still result in a :\n\nYou can easily see which methods exist for a function by entering the function object itself in an interactive session:\n\nThis output tells us that is a function object with two methods. To find out what the signatures of those methods are, use the function:\n\nwhich shows that has two methods, one taking two arguments and one taking arguments of type . It also indicates the file and line number where the methods were defined: because these methods were defined at the REPL, we get the apparent line number .\n\nIn the absence of a type declaration with , the type of a method parameter is by default, meaning that it is unconstrained since all values in Julia are instances of the abstract type . Thus, we can define a catch-all method for like so:\n\nThis catch-all is less specific than any other possible method definition for a pair of parameter values, so it will only be called on pairs of arguments to which no other method definition applies.\n\nNote that in the signature of the third method, there is no type specified for the arguments and . This is a shortened way of expressing .\n\nAlthough it seems a simple concept, multiple dispatch on the types of values is perhaps the single most powerful and central feature of the Julia language. Core operations typically have dozens of methods:\n\nMultiple dispatch together with the flexible parametric type system give Julia its ability to abstractly express high-level algorithms decoupled from implementation details.\n\nWhen you create multiple methods of the same function, this is sometimes called \"specialization.\" In this case, you're specializing the function by adding additional methods to it: each new method is a new specialization of the function. As shown above, these specializations are returned by .\n\nThere's another kind of specialization that occurs without programmer intervention: Julia's compiler can automatically specialize the method for the specific argument types used. Such specializations are not listed by , as this doesn't create new s, but tools like allow you to inspect such specializations.\n\nFor example, if you create a method\n\nyou've given the function one new method (possibly its only method), and that method takes any pair of number inputs. But if you then execute\n\nJulia will compile twice, once for and again for . The point of compiling twice is performance: the methods that get called for (which uses) vary depending on the specific types of and , and by compiling different specializations Julia can do all the method lookup ahead of time. This allows the program to run much more quickly, since it does not have to bother with method lookup while it is running. Julia's automatic specialization allows you to write generic algorithms and expect that the compiler will generate efficient, specialized code to handle each case you need.\n\nIn cases where the number of potential specializations might be effectively unlimited, Julia may avoid this default specialization. See Be aware of when Julia avoids specializing for more information.\n\nIt is possible to define a set of function methods such that there is no unique most specific method applicable to some combinations of arguments:\n\nHere the call could be handled by either the or the method. The order in which the methods are defined does not matter and neither is more specific than the other. In such cases, Julia raises a rather than arbitrarily picking a method. You can avoid method ambiguities by specifying an appropriate method for the intersection case:\n\nIt is recommended that the disambiguating method be defined first, since otherwise the ambiguity exists, if transiently, until the more specific method is defined.\n\nIn more complex cases, resolving method ambiguities involves a certain element of design; this topic is explored further below.\n\nMethod definitions can optionally have type parameters qualifying the signature:\n\nThe first method applies whenever both arguments are of the same concrete type, regardless of what type that is, while the second method acts as a catch-all, covering all other cases. Thus, overall, this defines a boolean function that checks whether its two arguments are of the same type:\n\nSuch definitions correspond to methods whose type signatures are types (see UnionAll Types).\n\nThis kind of definition of function behavior by dispatch is quite common – idiomatic, even – in Julia. Method type parameters are not restricted to being used as the types of arguments: they can be used anywhere a value would be in the signature of the function or body of the function. Here's an example where the method type parameter is used as the type parameter to the parametric type in the method signature:\n\nThe type parameter in this example ensures that the added element is a subtype of the existing eltype of the vector . The keyword introduces a list of those constraints after the method signature definition. This works the same for one-line definitions, as seen above, and must appear before the return type declaration, if present, as illustrated below:\n\nIf the type of the appended element does not match the element type of the vector it is appended to, a is raised. In the following example, the method's type parameter is used as the return value:\n\nJust as you can put subtype constraints on type parameters in type declarations (see Parametric Types), you can also constrain type parameters of methods:\n\nThe function behaves much like the function defined above, but is only defined for pairs of numbers.\n\nParametric methods allow the same syntax as expressions used to write types (see UnionAll Types). If there is only a single parameter, the enclosing curly braces (in ) can be omitted, but are often preferred for clarity. Multiple parameters can be separated with commas, e.g. , or written using nested , e.g. .\n\nWhen redefining a method or adding new methods, it is important to realize that these changes don't take effect immediately. This is key to Julia's ability to statically infer and compile code to run fast, without the usual JIT tricks and overhead. Indeed, any new method definition won't be visible to the current runtime environment, including Tasks and Threads (and any previously defined functions). Let's start with an example to see what this means:\n\nIn this example, observe that the new definition for has been created, but can't be immediately called. The new global is immediately visible to the function, so you could write (without parentheses). But neither you, nor any of your callers, nor the functions they call, or etc. can call this new method definition!\n\nBut there's an exception: future calls to from the REPL work as expected, being able to both see and call the new definition of .\n\nHowever, future calls to will continue to see the definition of as it was at the previous statement at the REPL, and thus before that call to .\n\nYou may want to try this for yourself to see how it works.\n\nThe implementation of this behavior is a \"world age counter\". This monotonically increasing value tracks each method definition operation. This allows describing \"the set of method definitions visible to a given runtime environment\" as a single number, or \"world age\". It also allows comparing the methods available in two worlds just by comparing their ordinal value. In the example above, we see that the \"current world\" (in which the method exists), is one greater than the task-local \"runtime world\" that was fixed when the execution of started.\n\nSometimes it is necessary to get around this (for example, if you are implementing the above REPL). Fortunately, there is an easy solution: call the function using :\n\nFinally, let's take a look at some more complex examples where this rule comes into play. Define a function , which initially has one method:\n\nStart some other operations that use :\n\nNow we add some new methods to :\n\nWhile complex dispatch logic is not required for performance or usability, sometimes it can be the best way to express some algorithm. Here are a few common design patterns that come up sometimes when using dispatch in this way.\n\nHere is a correct code template for returning the element-type of any arbitrary subtype of that has well-defined element type:\n\nusing so-called triangular dispatch. Note that types, for example , do not match the above method. The implementation of in adds a fallback method to for such cases.\n\nOne common mistake is to try and get the element-type by using introspection:\n\nHowever, it is not hard to construct cases where this will fail:\n\nHere we have created a type which has no parameters, but where the element-type is still fully specified, with equal to !\n\nAnother mistake is to try to walk up the type hierarchy using :\n\nWhile this works for declared types, it fails for types without supertypes:\n\nWhen building generic code, there is often a need for constructing a similar object with some change made to the layout of the type, also necessitating a change of the type parameters. For instance, you might have some sort of abstract array with an arbitrary element type and want to write your computation on it with a specific element type. We must implement a method for each subtype that describes how to compute this type transform. There is no general transform of one subtype into another subtype with a different parameter.\n\nThe subtypes of typically implement two methods to achieve this: A method to convert the input array to a subtype of a specific abstract type; and a method to make a new uninitialized array with a specific element type. Sample implementations of these can be found in Julia Base. Here is a basic example usage of them, guaranteeing that and are of the same type:\n\nAs an extension of this, in cases where the algorithm needs a copy of the input array, is insufficient as the return value may alias the original input. Combining (to make the output array) and (to fill it with the input data) is a generic way to express the requirement for a mutable copy of the input argument:\n\nIn order to dispatch a multi-level parametric argument list, often it is best to separate each level of dispatch into distinct functions. This may sound similar in approach to single-dispatch, but as we shall see below, it is still more flexible.\n\nFor example, trying to dispatch on the element-type of an array will often run into ambiguous situations. Instead, commonly code will dispatch first on the container type, then recurse down to a more specific method based on eltype. In most cases, the algorithms lend themselves conveniently to this hierarchical approach, while in other cases, this rigor must be resolved manually. This dispatching branching can be observed, for example, in the logic to sum two matrices:\n\nA natural extension to the iterated dispatch above is to add a layer to method selection that allows to dispatch on sets of types which are independent from the sets defined by the type hierarchy. We could construct such a set by writing out a of the types in question, but then this set would not be extensible as -types cannot be altered after creation. However, such an extensible set can be programmed with a design pattern often referred to as a \"Holy-trait\".\n\nThis pattern is implemented by defining a generic function which computes a different singleton value (or type) for each trait-set to which the function arguments may belong to. If this function is pure there is no impact on performance compared to normal dispatch.\n\nThe example in the previous section glossed over the implementation details of and , which both operate in terms of these traits. When iterating over a matrix, such as in the implementation of , one important question is what order to use to traverse the data. When subtypes implement the trait, other functions such as can dispatch on this information to pick the best algorithm (see Abstract Array Interface). This means that each subtype does not need to implement a custom version of , since the generic definitions + trait classes will enable the system to select the fastest version. Here is a toy implementation of illustrating the trait-based dispatch:\n\nThis trait-based approach is also present in the mechanism employed by the scalar . It uses , which returns the optimal common type to compute the operation given the two types of the operands. This makes it possible to reduce the problem of implementing every function for every pair of possible type arguments, to the much smaller problem of implementing a conversion operation from each type to a common type, plus a table of preferred pair-wise promotion rules.\n\nThe discussion of trait-based promotion provides a transition into our next design pattern: computing the output element type for a matrix operation.\n\nFor implementing primitive operations, such as addition, we use the function to compute the desired output type. (As before, we saw this at work in the call in the call to ).\n\nFor more complex functions on matrices, it may be necessary to compute the expected return type for a more complex sequence of operations. This is often performed by the following steps:\n• Write a small function that expresses the set of operations performed by the kernel of the algorithm.\n• Compute the element type of the result matrix as , where is computed from applied to each input array.\n• Build the output matrix as , where are the desired dimensions of the output array.\n\nFor a more specific example, a generic square-matrix multiply pseudo-code might look like:\n\nOne way to significantly cut down on compile-times and testing complexity is to isolate the logic for converting to the desired type and the computation. This lets the compiler specialize and inline the conversion logic independent from the rest of the body of the larger kernel.\n\nThis is a common pattern seen when converting from a larger class of types to the one specific argument type that is actually supported by the algorithm:\n\nFunction parameters can also be used to constrain the number of arguments that may be supplied to a \"varargs\" function (Varargs Functions). The notation is used to indicate such a constraint. For example:\n\nMore usefully, it is possible to constrain varargs methods by a parameter. For example:\n\nwould be called only when the number of matches the dimensionality of the array.\n\nWhen only the type of supplied arguments needs to be constrained can be equivalently written as . For instance is a shorthand for .\n\nAs mentioned briefly in Functions, optional arguments are implemented as syntax for multiple method definitions. For example, this definition:\n\ntranslates to the following three methods:\n\nThis means that calling is equivalent to calling . In this case the result is , because invokes the first method of above. However, this need not always be the case. If you define a fourth method that is more specialized for integers:\n\nthen the result of both and is . In other words, optional arguments are tied to a function, not to any specific method of that function. It depends on the types of the optional arguments which method is invoked. When optional arguments are defined in terms of a global variable, the type of the optional argument may even change at run-time.\n\nKeyword arguments behave quite differently from ordinary positional arguments. In particular, they do not participate in method dispatch. Methods are dispatched based only on positional arguments, with keyword arguments processed after the matching method is identified.\n\nMethods are associated with types, so it is possible to make any arbitrary Julia object \"callable\" by adding methods to its type. (Such \"callable\" objects are sometimes called \"functors.\")\n\nFor example, you can define a type that stores the coefficients of a polynomial, but behaves like a function evaluating the polynomial:\n\nNotice that the function is specified by type instead of by name. As with normal functions there is a terse syntax form. In the function body, will refer to the object that was called. A can be used as follows:\n\nThis mechanism is also the key to how type constructors and closures (inner functions that refer to their surrounding environment) work in Julia.\n\nOccasionally it is useful to introduce a generic function without yet adding methods. This can be used to separate interface definitions from implementations. It might also be done for the purpose of documentation or code readability. The syntax for this is an empty block without a tuple of arguments:\n\nMethod design and the avoidance of ambiguities\n\nJulia's method polymorphism is one of its most powerful features, yet exploiting this power can pose design challenges. In particular, in more complex method hierarchies it is not uncommon for ambiguities to arise.\n\nAbove, it was pointed out that one can resolve ambiguities like\n\nThis is often the right strategy; however, there are circumstances where following this advice mindlessly can be counterproductive. In particular, the more methods a generic function has, the more possibilities there are for ambiguities. When your method hierarchies get more complicated than this simple example, it can be worth your while to think carefully about alternative strategies.\n\nBelow we discuss particular challenges and some alternative ways to resolve such issues.\n\n(and ) arguments present special challenges. For example,\n\nare ambiguous because of the possibility that : there are no elements to determine whether the or variant should be called. To resolve the ambiguity, one approach is define a method for the empty tuple:\n\nAlternatively, for all methods but one you can insist that there is at least one element in the tuple:\n\nWhen you might be tempted to dispatch on two or more arguments, consider whether a \"wrapper\" function might make for a simpler design. For example, instead of writing multiple variants:\n\nyou might consider defining\n\nwhere converts the argument to type . This is a very specific example of the more general principle of orthogonal design, in which separate concepts are assigned to separate methods. Here, will most likely need a fallback definition\n\nA related strategy exploits to bring and to a common type:\n\nOne risk with this design is the possibility that if there is no suitable promotion method converting and to the same type, the second method will recurse on itself infinitely and trigger a stack overflow.\n\nDispatch on one argument at a time\n\nIf you need to dispatch on multiple arguments, and there are many fallbacks with too many combinations to make it practical to define all possible variants, then consider introducing a \"name cascade\" where (for example) you dispatch on the first argument and then call an internal method:\n\nThen the internal methods and can dispatch on without concern about ambiguities with each other with respect to .\n\nBe aware that this strategy has at least one major disadvantage: in many cases, it is not possible for users to further customize the behavior of by defining further specializations of your exported function . Instead, they have to define specializations for your internal methods and , and this blurs the lines between exported and internal methods.\n\nWhere possible, try to avoid defining methods that dispatch on specific element types of abstract containers. For example,\n\ngenerates ambiguities for anyone who defines a method\n\nThe best approach is to avoid defining either of these methods: instead, rely on a generic method and make sure this method is implemented with generic calls (like and ) that do the right thing for each container type and element type separately. This is just a more complex variant of the advice to orthogonalize your methods.\n\nWhen this approach is not possible, it may be worth starting a discussion with other developers about resolving the ambiguity; just because one method was defined first does not necessarily mean that it can't be modified or eliminated. As a last resort, one developer can define the \"band-aid\" method\n\nthat resolves the ambiguity by brute force.\n\nIf you are defining a method \"cascade\" that supplies defaults, be careful about dropping any arguments that correspond to potential defaults. For example, suppose you're writing a digital filtering algorithm and you have a method that handles the edges of the signal by applying padding:\n\nThis will run afoul of a method that supplies default padding:\n\nTogether, these two methods generate an infinite recursion with constantly growing bigger.\n\nThe better design would be to define your call hierarchy like this:\n\nis supplied in the same argument position as any other kind of padding, so it keeps the dispatch hierarchy well organized and with reduced likelihood of ambiguities. Moreover, it extends the \"public\" interface: a user who wants to control the padding explicitly can call the variant directly.\n\nYou can define methods within a local scope, for example\n\nHowever, you should not define local methods conditionally or subject to control flow, as in\n\nas it is not clear what function will end up getting defined. In the future, it might be an error to define local methods in this manner.\n\nFor cases like this use anonymous functions instead:"
    },
    {
        "link": "https://scls.gitbooks.io/ljthw/content/_chapters/11-ex8.html",
        "document": ""
    },
    {
        "link": "https://media.readthedocs.org/pdf/julia-wf/stable/julia-wf.pdf",
        "document": ""
    },
    {
        "link": "http://julia-ylwu.readthedocs.org/en/latest/manual/functions.html",
        "document": "In Julia, a function is an object that maps a tuple of argument values to a return value. Julia functions are not pure mathematical functions, in the sense that functions can alter and be affected by the global state of the program. The basic syntax for defining functions in Julia is:\n\nThis syntax is similar to MATLAB, but there are some significant differences:\n• In MATLAB, this definition must be saved in a file, named , whereas in Julia, this expression can appear anywhere, including in an interactive session.\n• In MATLAB, the closing is optional, being implied by the end of the file. In Julia, the terminating is required.\n• In MATLAB, this function would print the value but would not return any value, whereas in Julia, the last expression evaluated is a function’s return value.\n• Expression values are never printed automatically except in interactive sessions. Semicolons are only required to separate expressions on the same line.\n\nIn general, while the function definition syntax is reminiscent of MATLAB, the similarity is largely superficial. Therefore, rather than continually comparing the two, in what follows, we will simply describe the behavior of functions in Julia directly.\n\nThere is a second, more terse syntax for defining a function in Julia. The traditional function declaration syntax demonstrated above is equivalent to the following compact “assignment form”:\n\nIn the assignment form, the body of the function must be a single expression, although it can be a compound expression (see Compound Expressions). Short, simple function definitions are common in Julia. The short function syntax is accordingly quite idiomatic, considerably reducing both typing and visual noise.\n\nA function is called using the traditional parenthesis syntax:\n\nWithout parentheses, the expression refers to the function object, and can be passed around like any value:\n\nThere are two other ways that functions can be applied: using special operator syntax for certain function names (see Operators Are Functions below), or with the function:\n\nThe function applies its first argument — a function object — to its remaining arguments.\n\nThe value returned by a function is the value of the last expression evaluated, which, by default, is the last expression in the body of the function definition. In the example function, , from the previous section this is the value of the expression . As in C and most other imperative or functional languages, the keyword causes a function to return immediately, providing an expression whose value is returned: Since functions definitions can be entered into interactive sessions, it is easy to compare these definitions: Of course, in a purely linear function body like , the usage of is pointless since the expression is never evaluated and we could simply make the last expression in the function and omit the . In conjunction with other control flow, however, is of real use. Here, for example, is a function that computes the hypotenuse length of a right triangle with sides of length x and y, avoiding overflow: There are three possible points of return from this function, returning the values of three different expressions, depending on the values of x and y. The on the last line could be omitted since it is the last expression.\n\nIn Julia, most operators are just functions with support for special syntax. The exceptions are operators with special evaluation semantics like and . These operators cannot be functions since short-circuit evaluation (see Short-Circuit Evaluation) requires that their operands are not evaluated before evaluation of the operator. Accordingly, you can also apply them using parenthesized argument lists, just as you would any other function: The infix form is exactly equivalent to the function application form — in fact the former is parsed to produce the function call internally. This also means that you can assign and pass around operators such as and just like you would with other function values: Under the name , the function does not support infix notation, however.\n\nFunctions in Julia are first-class objects: they can be assigned to variables, called using the standard function call syntax from the variable they have been assigned to. They can be used as arguments, and they can be returned as values. They can also be created anonymously, without giving them a name: This creates an unnamed function taking one argument and returning the value of the polynomial x^2 + 2x - 1 at that value. The primary use for anonymous functions is passing them to functions which take other functions as arguments. A classic example is the function, which applies a function to each value of an array and returns a new array containing the resulting values: This is fine if a named function effecting the transform one wants already exists to pass as the first argument to . Often, however, a ready-to-use, named function does not exist. In these situations, the anonymous function construct allows easy creation of a single-use function object without needing a name: An anonymous function accepting multiple arguments can be written using the syntax . A zero-argument anonymous function is written as . The idea of a function with no arguments may seem strange, but is useful for “delaying” a computation. In this usage, a block of code is wrapped in a zero-argument function, which is later invoked by calling it as .\n\nIn Julia, one returns a tuple of values to simulate returning multiple values. However, tuples can be created and destructured without needing parentheses, thereby providing an illusion that multiple values are being returned, rather than a single tuple value. For example, the following function returns a pair of values: If you call it in an interactive session without assigning the return value anywhere, you will see the tuple returned: A typical usage of such a pair of return values, however, extracts each value into a variable. Julia supports simple tuple “destructuring” that facilitates this: You can also return multiple values via an explicit usage of the keyword: This has the exact same effect as the previous definition of .\n\nIt is often convenient to be able to write functions taking an arbitrary number of arguments. Such functions are traditionally known as “varargs” functions, which is short for “variable number of arguments”. You can define a varargs function by following the last argument with an ellipsis: The variables and are bound to the first two argument values as usual, and the variable is bound to an iterable collection of the zero or more values passed to after its first two arguments: In all these cases, is bound to a tuple of the trailing values passed to . On the flip side, it is often handy to “splice” the values contained in an iterable collection into a function call as individual arguments. To do this, one also uses but in the function call instead: In this case a tuple of values is spliced into a varargs call precisely where the variable number of arguments go. This need not be the case, however: Furthermore, the iterable object spliced into a function call need not be a tuple: Also, the function that arguments are spliced into need not be a varargs function (although it often is): As you can see, if the wrong number of elements are in the spliced container, then the function call will fail, just as it would if too many arguments were given explicitly.\n\nPassing functions as arguments to other functions is a powerful technique, but the syntax for it is not always convenient. Such calls are especially awkward to write when the function argument requires multiple lines. As an example, consider calling on a function with several cases: Julia provides a reserved word for rewriting this code more clearly: The syntax creates an anonymous function with argument and passes it as the first argument to . This syntax makes it easier to use functions to effectively extend the language, since calls look like normal code blocks. There are many possible uses quite different from , such as managing system state. For example, the standard library provides a function for running code in a given directory, and switching back to the previous directory when the code finishes or aborts. There is also a definition of that runs code ensuring that the opened file is eventually closed. We can combine these functions to safely write a file in a certain directory: The function argument to takes no arguments; it is just a block of code. The function argument to receives a handle to the opened file."
    },
    {
        "link": "https://docs.julialang.org/en/v1/manual/arrays",
        "document": "Julia, like most technical computing languages, provides a first-class array implementation. Most technical computing languages pay a lot of attention to their array implementation at the expense of other containers. Julia does not treat arrays in any special way. The array library is implemented almost completely in Julia itself, and derives its performance from the compiler, just like any other code written in Julia. As such, it's also possible to define custom array types by inheriting from . See the manual section on the AbstractArray interface for more details on implementing a custom array type.\n\nAn array is a collection of objects stored in a multi-dimensional grid. Zero-dimensional arrays are allowed, see this FAQ entry. In the most general case, an array may contain objects of type . For most computational purposes, arrays should contain objects of a more specific type, such as or .\n\nIn general, unlike many other technical computing languages, Julia does not expect programs to be written in a vectorized style for performance. Julia's compiler uses type inference and generates optimized code for scalar array indexing, allowing programs to be written in a style that is convenient and readable, without sacrificing performance, and using less memory at times.\n\nIn Julia, all arguments to functions are passed by sharing (i.e. by pointers). Some technical computing languages pass arrays by value, and while this prevents accidental modification by callees of a value in the caller, it makes avoiding unwanted copying of arrays difficult. By convention, a function name ending with a indicates that it will mutate or destroy the value of one or more of its arguments (compare, for example, and ). Callees must make explicit copies to ensure that they don't modify inputs that they don't intend to change. Many non-mutating functions are implemented by calling a function of the same name with an added at the end on an explicit copy of the input, and returning that copy.\n\nMany functions for constructing and initializing arrays are provided. In the following list of such functions, calls with a argument can either take a single tuple of dimension sizes or a series of dimension sizes passed as a variable number of arguments. Most of these functions also accept a first input , which is the element type of the array. If the type is omitted it will default to .\n\nTo see the various ways we can pass dimensions to these functions, consider the following examples:\n\nHere, is a and the first argument — the element type — is optional, defaulting to .\n\nArrays can also be directly constructed with square braces; the syntax creates a one-dimensional array (i.e., a vector) containing the comma-separated arguments as its elements. The element type ( ) of the resulting array is automatically determined by the types of the arguments inside the braces. If all the arguments are the same type, then that is its . If they all have a common promotion type then they get converted to that type using and that type is the array's . Otherwise, a heterogeneous array that can hold anything — a — is constructed; this includes the literal where no arguments are given. Array literal can be typed with the syntax where is a type.\n\nIf the arguments inside the square brackets are separated by single semicolons ( ) or newlines instead of commas, then their contents are vertically concatenated together instead of the arguments being used as elements themselves.\n\nSimilarly, if the arguments are separated by tabs or spaces or double semicolons, then their contents are horizontally concatenated together.\n\nSingle semicolons (or newlines) and spaces (or tabs) can be combined to concatenate both horizontally and vertically at the same time.\n\nSpaces (and tabs) have a higher precedence than semicolons, performing any horizontal concatenations first and then concatenating the result. Using double semicolons for the horizontal concatenation, on the other hand, performs any vertical concatenations before horizontally concatenating the result.\n\nJust as and concatenate in the first and second dimension, using more semicolons extends this same general scheme. The number of semicolons in the separator specifies the particular dimension, so concatenates in the third dimension, in the 4th, and so on. Fewer semicolons take precedence, so the lower dimensions are generally concatenated first.\n\nLike before, spaces (and tabs) for horizontal concatenation have a higher precedence than any number of semicolons. Thus, higher-dimensional arrays can also be written by specifying their rows first, with their elements textually arranged in a manner similar to their layout:\n\nAlthough they both mean concatenation in the second dimension, spaces (or tabs) and cannot appear in the same array expression unless the double semicolon is simply serving as a \"line continuation\" character. This allows a single horizontal concatenation to span multiple lines (without the line break being interpreted as a vertical concatenation).\n\nTerminating semicolons may also be used to add trailing length 1 dimensions.\n\nMore generally, concatenation can be accomplished through the function. These syntaxes are shorthands for function calls that themselves are convenience functions:\n\nAn array with a specific element type can be constructed using the syntax . This will construct a 1-d array with element type , initialized to contain elements , , , etc. For example, constructs a heterogeneous array that can contain any values.\n\nConcatenation syntax can similarly be prefixed with a type to specify the element type of the result.\n\nComprehensions provide a general and powerful way to construct arrays. Comprehension syntax is similar to set construction notation in mathematics:\n\nThe meaning of this form is that is evaluated with the variables , , etc. taking on each value in their given list of values. Values can be specified as any iterable object, but will commonly be ranges like or , or explicit arrays of values like . The result is an N-d dense array with dimensions that are the concatenation of the dimensions of the variable ranges , , etc. and each evaluation returns a scalar.\n\nThe following example computes a weighted average of the current element and its left and right neighbor along a 1-d grid. :\n\nThe resulting array type depends on the types of the computed elements just like array literals do. In order to control the type explicitly, a type can be prepended to the comprehension. For example, we could have requested the result in single precision by writing:\n\nComprehensions can also be written without the enclosing square brackets, producing an object known as a generator. This object can be iterated to produce values on demand, instead of allocating an array and storing them in advance (see Iteration). For example, the following expression sums a series without allocating memory:\n\nWhen writing a generator expression with multiple dimensions inside an argument list, parentheses are needed to separate the generator from subsequent arguments:\n\nAll comma-separated expressions after are interpreted as ranges. Adding parentheses lets us add a third argument to :\n\nGenerators are implemented via inner functions. Just like inner functions used elsewhere in the language, variables from the enclosing scope can be \"captured\" in the inner function. For example, captures the three variables , and from the enclosing scope. Captured variables can present performance challenges; see performance tips.\n\nRanges in generators and comprehensions can depend on previous ranges by writing multiple keywords:\n\nIn such cases, the result is always 1-d.\n\nGenerated values can be filtered using the keyword:\n\nThe general syntax for indexing into an n-dimensional array is:\n\nwhere each may be a scalar integer, an array of integers, or any other supported index. This includes ( ) to select all indices within the entire dimension, ranges of the form or to select contiguous or strided subsections, and arrays of booleans to select elements at their indices.\n\nIf all the indices are scalars, then the result is a single element from the array . Otherwise, is an array with the same number of dimensions as the sum of the dimensionalities of all the indices.\n\nIf all indices are vectors, for example, then the shape of would be , with location of containing the value .\n\nNote how the size of the resulting array is different in the last two cases.\n\nIf is changed to a two-dimensional matrix, then becomes an -dimensional array of shape . The matrix adds a dimension.\n\nThe location contains the value at . All dimensions indexed with scalars are dropped. For example, if is an array of indices, then the result of is an array with size . Its th element is populated by .\n\nAs a special part of this syntax, the keyword may be used to represent the last index of each dimension within the indexing brackets, as determined by the size of the innermost array being indexed. Indexing syntax without the keyword is equivalent to a call to :\n\nThe general syntax for assigning values in an n-dimensional array is:\n\nwhere each may be a scalar integer, an array of integers, or any other supported index. This includes ( ) to select all indices within the entire dimension, ranges of the form or to select contiguous or strided subsections, and arrays of booleans to select elements at their indices.\n\nIf all indices are integers, then the value in location of is overwritten with the value of , ing to the of if necessary.\n\nIf any index is itself an array, then the right hand side must also be an array with the same shape as the result of indexing or a vector with the same number of elements. The value in location of is overwritten with the value , converting if necessary. The element-wise assignment operator may be used to broadcast across the selected locations:\n\nJust as in Indexing, the keyword may be used to represent the last index of each dimension within the indexing brackets, as determined by the size of the array being assigned into. Indexed assignment syntax without the keyword is equivalent to a call to :\n\nIn the expression , each may be a scalar index, an array of scalar indices, or an object that represents an array of scalar indices and can be converted to such by :\n• A scalar index. By default this includes:\n• s, which behave like an -tuple of integers spanning multiple dimensions (see below for more details)\n• An array of scalar indices. This includes:\n• Empty arrays like , which select no elements e.g. (not to be confused with )\n• Ranges like or , which select contiguous or strided subsections from to (inclusive)\n• Any custom array of scalar indices that is a subtype of\n• Arrays of (see below for more details)\n• An object that represents an array of scalar indices and can be converted to such by . By default this includes:\n\nThe special object represents a scalar index that behaves like an -tuple of integers spanning multiple dimensions. For example:\n\nConsidered alone, this may seem relatively trivial; simply gathers multiple integers together into one object that represents a single multidimensional index. When combined with other indexing forms and iterators that yield es, however, this can produce very elegant and efficient code. See Iteration below, and for some more advanced examples, see this blog post on multidimensional algorithms and iteration.\n\nArrays of are also supported. They represent a collection of scalar indices that each span dimensions, enabling a form of indexing that is sometimes referred to as pointwise indexing. For example, it enables accessing the diagonal elements from the first \"page\" of from above:\n\nThis can be expressed much more simply with dot broadcasting and by combining it with a normal integer index (instead of extracting the first from as a separate step). It can even be combined with a to extract both diagonals from the two pages at the same time:\n\nOften referred to as logical indexing or indexing with a logical mask, indexing by a boolean array selects elements at the indices where its values are . Indexing by a boolean vector is effectively the same as indexing by the vector of integers that is returned by . Similarly, indexing by a -dimensional boolean array is effectively the same as indexing by the vector of s where its values are . A logical index must be a array of the same shape as the dimension(s) it indexes into, or it must be the only index provided and match the shape of the one-dimensional reshaped view of the array it indexes into. It is generally more efficient to use boolean arrays as indices directly instead of first calling .\n\nThe ordinary way to index into an -dimensional array is to use exactly indices; each index selects the position(s) in its particular dimension. For example, in the three-dimensional array , will select the number in the second row of the third column in the first \"page\" of the array. This is often referred to as cartesian indexing.\n\nWhen exactly one index is provided, that index no longer represents a location in a particular dimension of the array. Instead, it selects the th element using the column-major iteration order that linearly spans the entire array. This is known as linear indexing. It essentially treats the array as though it had been reshaped into a one-dimensional vector with .\n\nA linear index into the array can be converted to a for cartesian indexing with (see ), and a set of cartesian indices can be converted to a linear index with (see ).\n\nIt's important to note that there's a very large asymmetry in the performance of these conversions. Converting a linear index to a set of cartesian indices requires dividing and taking the remainder, whereas going the other way is just multiplies and adds. In modern processors, integer division can be 10-50 times slower than multiplication. While some arrays — like itself — are implemented using a linear chunk of memory and directly use a linear index in their implementations, other arrays — like — need the full set of cartesian indices to do their lookup (see to introspect which is which).\n\nIn addition to linear indexing, an -dimensional array may be indexed with fewer or more than indices in certain situations.\n\nIndices may be omitted if the trailing dimensions that are not indexed into are all length one. In other words, trailing indices can be omitted only if there is only one possible value that those omitted indices could be for an in-bounds indexing expression. For example, a four-dimensional array with size may be indexed with only three indices as the dimension that gets skipped (the fourth dimension) has length one. Note that linear indexing takes precedence over this rule.\n\nWhen omitting all indices with , this semantic provides a simple idiom to retrieve the only element in an array and simultaneously ensure that there was only one element.\n\nSimilarly, more than indices may be provided if all the indices beyond the dimensionality of the array are (or more generally are the first and only element of where is that particular dimension number). This allows vectors to be indexed like one-column matrices, for example:\n\nThe recommended ways to iterate over a whole array are\n\nThe first construct is used when you need the value, but not index, of each element. In the second construct, will be an if is an array type with fast linear indexing; otherwise, it will be a :\n\nIf you write a custom type, you can specify that it has fast linear indexing using\n\nThis setting will cause iteration over a to use integers. If you don't specify this trait, the default value is used.\n\nThe following operators are supported for arrays:\n\nTo enable convenient vectorization of mathematical and other operations, Julia provides the dot syntax , e.g. or , for elementwise operations over arrays or mixtures of arrays and scalars (a Broadcasting operation); these have the additional advantage of \"fusing\" into a single loop when combined with other dot calls, e.g. .\n\nAlso, every binary operator supports a dot version that can be applied to arrays (and combinations of arrays and scalars) in such fused broadcasting operations, e.g. .\n\nNote that comparisons such as operate on whole arrays, giving a single boolean answer. Use dot operators like for elementwise comparisons. (For comparison operations like , only the elementwise version is applicable to arrays.)\n\nAlso notice the difference between , which s elementwise over and , and , which finds the largest value within . The same relationship holds for and .\n\nIt is sometimes useful to perform element-by-element binary operations on arrays of different sizes, such as adding a vector to each column of a matrix. An inefficient way to do this would be to replicate the vector to the size of the matrix:\n\nThis is wasteful when dimensions get large, so Julia provides , which expands singleton dimensions in array arguments to match the corresponding dimension in the other array without using extra memory, and applies the given function elementwise:\n\nDotted operators such as and are equivalent to calls (except that they fuse, as described above). There is also a function to specify an explicit destination (which can also be accessed in a fusing fashion by assignment). In fact, is equivalent to , providing a convenient syntax to broadcast any function (dot syntax). Nested \"dot calls\" (including calls to etcetera) automatically fuse into a single call.\n\nAdditionally, is not limited to arrays (see the function documentation); it also handles scalars, tuples and other collections. By default, only some argument types are considered scalars, including (but not limited to) s, s, s, s, s and some common singletons like and . All other arguments are iterated over or indexed into elementwise.\n\nSometimes, you want a container (like an array) that would normally participate in broadcast to be \"protected\" from broadcast's behavior of iterating over all of its elements. By placing it inside another container (like a single element ) broadcast will treat it as a single value.\n\nThe base array type in Julia is the abstract type . It is parameterized by the number of dimensions and the element type . and are aliases for the 1-d and 2-d cases. Operations on objects are defined using higher level operators and functions, in a way that is independent of the underlying storage. These operations generally work correctly as a fallback for any specific array implementation.\n\nThe type includes anything vaguely array-like, and implementations of it might be quite different from conventional arrays. For example, elements might be computed on request rather than stored. However, any concrete type should generally implement at least (returning an tuple), and ; mutable arrays should also implement . It is recommended that these operations have nearly constant time complexity, as otherwise some array functions may be unexpectedly slow. Concrete types should also typically provide a method, which is used to allocate a similar array for and other out-of-place operations. No matter how an is represented internally, is the type of object returned by integer indexing ( , when is not empty) and should be the length of the tuple returned by . For more details on defining custom implementations, see the array interface guide in the interfaces chapter.\n\nis an abstract subtype of intended to include all arrays where elements are stored contiguously in column-major order (see additional notes in Performance Tips). The type is a specific instance of ; and are aliases for the 1-d and 2-d cases. Very few operations are implemented specifically for beyond those that are required for all s; much of the array library is implemented in a generic manner that allows all custom arrays to behave similarly.\n\nis a specialization of that performs indexing by sharing memory with the original array rather than by copying it. A is created with the function, which is called the same way as (with an array and a series of index arguments). The result of looks the same as the result of , except the data is left in place. stores the input index vectors in a object, which can later be used to index the original array indirectly. By putting the macro in front of an expression or block of code, any slice in that expression will be converted to create a view instead.\n\ns are space-efficient \"packed\" boolean arrays, which store one bit per boolean value. They can be used similarly to arrays (which store one byte per boolean value), and can be converted to/from the latter via and , respectively.\n\nAn array is \"strided\" if it is stored in memory with well-defined spacings (strides) between its elements. A strided array with a supported element type may be passed to an external (non-Julia) library like BLAS or LAPACK by simply passing its and the stride for each dimension. The is the distance between elements along dimension . For example, the builtin returned by has its elements arranged contiguously in column major order. This means that the stride of the first dimension — the spacing between elements in the same column — is :\n\nThe stride of the second dimension is the spacing between elements in the same row, skipping as many elements as there are in a single column ( ). Similarly, jumping between the two \"pages\" (in the third dimension) requires skipping elements. The of this array is the tuple of these three numbers together:\n\nIn this particular case, the number of elements skipped in memory matches the number of linear indices skipped. This is only the case for contiguous arrays like (and other subtypes) and is not true in general. Views with range indices are a good example of non-contiguous strided arrays; consider . This view refers to the same memory as but is skipping and re-arranging some of its elements. The stride of the first dimension of is because we're only selecting every third row from our original array:\n\nThis view is similarly selecting every other column from our original — and thus it needs to skip the equivalent of two five-element columns when moving between indices in the second dimension:\n\nThe third dimension is interesting because its order is reversed! Thus to get from the first \"page\" to the second one it must go backwards in memory, and so its stride in this dimension is negative!\n\nThis means that the for is actually pointing into the middle of 's memory block, and it refers to elements both backwards and forwards in memory. See the interface guide for strided arrays for more details on defining your own strided arrays. and are convenient aliases for many of the builtin array types that are considered strided arrays, allowing them to dispatch to select specialized implementations that call highly tuned and optimized BLAS and LAPACK functions using just the pointer and strides.\n\nIt is worth emphasizing that strides are about offsets in memory rather than indexing. If you are looking to convert between linear (single-index) indexing and cartesian (multi-index) indexing, see and ."
    },
    {
        "link": "https://discourse.julialang.org/t/creating-multidimensional-arrays/85630",
        "document": "Hey everyone, i am fairly new to Julia and i am feeling like taking crazy pills. I am coming from numpy/tensorflow and all i want to do is to create a test array with size (1,3) and tile it in the first dimension by 300, so that i have an array of size (300,3).\n\n In numpy i would do it somewhat like this: if i try to do the same with julia but my brain is melting and nothing makes sense. I cannot even seem to create a multidimensional array with this line: because for some reason the size(a) gives (1,), Why doesn’t it look recursivly into its elements and puts together a multidimensional array automatically? It doesn’t even do this when i specify its type as Array as in example b. So the first question is, what is the most consistent/nicest way of putting together multidimensional arrays explicitly? The tiling also makes my brain hurt: both give the SAME result, but maybe i just missunderstood the ; operator. I eventually got it to work with But that does look pretty hacky. Is there another way that does not need to use permutedims, especially since it seemed to crash my kernel a few times, when i was low on RAM? All of this seems kinda weird and not really made for multidimensional arrays like numpy or tensorflow is. Am i simply missing a big package here that handles this more like numpy, or is this just the way it is in julia? I know that i can use numpy in julia via python, but i want to write GPU kernels eventually, and i do not think parallelization will work seemlessly with python numpy arrays. Hope you can clear up some of my missconceptions.\n\nTake a look at the docs that were linked. But for a short answer, or are both valid ways of creating a 1x3 array. The semicolons approach is more general in that it can create arrays of arbitrary dimensions and can be used to create 1x1 arrays ( or will create a 1 array but will create a 1x1). To elaborate, a indicates that the contents should be concatenated along the first dimension, along the second, along the third, etc.\n\nBe very careful when using , it only creates one array and copies the same one to multiple locations. Editing one of the values will affect them all. Go far back enough in my activity and you’ll find that this caused a huge bug in my code. Edit: It’s a nuanced case, I think it’s fine here because the elements of the array are bitstypes, but arrays of arrays will cause issues when used with repeat: Summing a vector of vectors in a non-allocating way In any case, be aware of this: julia> x = repeat([[0,0]],3) 3-element Vector{Vector{Int64}}: [0, 0] [0, 0] [0, 0] julia> x[1][1] = 1 1 julia> x 3-element Vector{Vector{Int64}}: [1, 0] [1, 0] [1, 0] use a comprehension probably: julia> x = [ [0,0] for _ in 1:3 ] 3-element Vector{Vector{Int64}}: [0, 0] [0, 0] [0, 0] julia> x[1][1] = 1 1 julia> x 3-element Vector{Vector{Int64}}: [1, 0] [0, 0] [0, 0]\n\nWhy doesn’t it look recursivly into its elements and puts together a multidimensional array automatically? Because then how would one be able to distinguish between multi-dimensional arrays and actual arrays of arrays? They are really not the same thing. As for what you are trying, you can do this: But I suspect that there is something wasteful going on here. By creating an array with many equal rows, you are using up memory without actually storing more information. Do you really need this?\n\nAll of this seems kinda weird and not really made for multidimensional arrays like numpy or tensorflow is. Am i simply missing a big package here that handles this more like numpy, or is this just the way it is in julia? Julia has far simpler and more natural syntax and handling of arrays of all dimensions than numpy, available in the Base language, no need for any packages. The arrays also work for absolutely all and any types, not limited to some built-in types. But you need to learn how that syntax works, and that is actually quite close to Matlab (arrays are one of the relatively few areas where Matlab is superior to Python). I suggest that you start by looking at the manual on arrays here: Single- and multi-dimensional Arrays · The Julia Language Do remember a few key things: is the general, overarching definition. A is an (a one-dimensional one), a is also an (a two-dimensional one), etc. It therefore does not make sense trying to convert a vector to an array, it already is an array. Also, you don’t need or want type definitions when creating arrays, just use the literal syntaxes: for , or for . And then some new syntax for higher dimensions (see manual).\n\nThat is the best solution for my problem so far. Thanks. I guess i could go without the tiling for now, but i want to have a bundle of rays with the same origin for a simple path tracer that i want to eventually place on the GPU as a Julia test project. For now its just simpler to have the origins and the directions be in the same dimensionality. Also even without the project, i want to know how to handle multi-dim arrs as good as possible."
    },
    {
        "link": "https://stackoverflow.com/questions/58414230/how-convert-between-different-kinds-of-multidimensional-arrays-in-julia",
        "document": "Others have have given replies that help solve your problem, so I'd rather just go through your example and try to explain what is going on. You seem pretty frustrated, which is not uncommon when learning a new language, but most of your complaints seem to be because Julia is being consistent.\n\nHere you are creating a 10x10 array, where each element is a 1x2 matrix. That's what you are asking for, it's not Julia being difficult or obscure, it's just being consistent and straightforward.\n\nYou have a 2D array, so you cannot index into it with 3 indices.\n\nYou have a 10x10 array and try to reshape it into a 100x2 array. The new array would have 200 elements, which is twice as much as the original, so this cannot work.\n\nHere you reshape it into a 100x1 array, that's fine.\n\nAnd now you are asking for the first (and only) column of the new, reshaped . So, naturally, you get all the data. Notice that is now a 1D array, not a 100x1 2D array.\n\nYou are asking for the second column of a 100x1 array.\n\nturns into 1D vector with 100 elements, and then you ask for the first element of that. Seems to me to be expected behaviour.\n\nYes, this doesn't work, and it's not unreasonable to expect that it might, but this is a possible future feature. Perhaps you are looking for , which reads the first element from each element of . Similarly, reads the last element from each element of .\n\nThis is not valid syntax. The dot syntax only works on functions and operators.\n\nNot sure what you want to happen here. Transpose returns a lazy datatype for performance reasons. It's pretty neat.\n\nAs far as I recall, you have changed into a 100x1 array, so cannot work."
    },
    {
        "link": "https://stackoverflow.com/questions/53243831/how-to-have-multidimensional-array-with-different-length-in-julia",
        "document": "I need to make a sequence of an array with different length by reading a dataset. I need to call each of them in a loop so probably I need some sort of indexing in order to call them. For example, how can I create the following sequence:"
    },
    {
        "link": "https://gensoft.pasteur.fr/docs/julia/1.4.1/manual/arrays.html",
        "document": "Julia, like most technical computing languages, provides a first-class array implementation. Most technical computing languages pay a lot of attention to their array implementation at the expense of other containers. Julia does not treat arrays in any special way. The array library is implemented almost completely in Julia itself, and derives its performance from the compiler, just like any other code written in Julia. As such, it's also possible to define custom array types by inheriting from . See the manual section on the AbstractArray interface for more details on implementing a custom array type.\n\nAn array is a collection of objects stored in a multi-dimensional grid. In the most general case, an array may contain objects of type . For most computational purposes, arrays should contain objects of a more specific type, such as or .\n\nIn general, unlike many other technical computing languages, Julia does not expect programs to be written in a vectorized style for performance. Julia's compiler uses type inference and generates optimized code for scalar array indexing, allowing programs to be written in a style that is convenient and readable, without sacrificing performance, and using less memory at times.\n\nIn Julia, all arguments to functions are passed by sharing (i.e. by pointers). Some technical computing languages pass arrays by value, and while this prevents accidental modification by callees of a value in the caller, it makes avoiding unwanted copying of arrays difficult. By convention, a function name ending with a indicates that it will mutate or destroy the value of one or more of its arguments (compare, for example, and ). Callees must make explicit copies to ensure that they don't modify inputs that they don't intend to change. Many non- mutating functions are implemented by calling a function of the same name with an added at the end on an explicit copy of the input, and returning that copy.\n\nMany functions for constructing and initializing arrays are provided. In the following list of such functions, calls with a argument can either take a single tuple of dimension sizes or a series of dimension sizes passed as a variable number of arguments. Most of these functions also accept a first input , which is the element type of the array. If the type is omitted it will default to .\n\nTo see the various ways we can pass dimensions to these functions, consider the following examples:\n\nHere, is a and the first argument — the element type — is optional, defaulting to .\n\nArrays can also be directly constructed with square braces; the syntax creates a one dimensional array (i.e., a vector) containing the comma-separated arguments as its elements. The element type ( ) of the resulting array is automatically determined by the types of the arguments inside the braces. If all the arguments are the same type, then that is its . If they all have a common promotion type then they get converted to that type using and that type is the array's . Otherwise, a heterogeneous array that can hold anything — a — is constructed; this includes the literal where no arguments are given.\n\nIf the arguments inside the square brackets are separated by semicolons ( ) or newlines instead of commas, then their contents are vertically concatenated together instead of the arguments being used as elements themselves.\n\nSimilarly, if the arguments are separated by tabs or spaces, then their contents are horizontally concatenated together.\n\nUsing semicolons (or newlines) and spaces (or tabs) can be combined to concatenate both horizontally and vertically at the same time.\n\nMore generally, concatenation can be accomplished through the function. These syntaxes are shorthands for function calls that themselves are convenience functions:\n\nAn array with a specific element type can be constructed using the syntax . This will construct a 1-d array with element type , initialized to contain elements , , , etc. For example, constructs a heterogeneous array that can contain any values.\n\nConcatenation syntax can similarly be prefixed with a type to specify the element type of the result.\n\nComprehensions provide a general and powerful way to construct arrays. Comprehension syntax is similar to set construction notation in mathematics:\n\nThe meaning of this form is that is evaluated with the variables , , etc. taking on each value in their given list of values. Values can be specified as any iterable object, but will commonly be ranges like or , or explicit arrays of values like . The result is an N-d dense array with dimensions that are the concatenation of the dimensions of the variable ranges , , etc. and each evaluation returns a scalar.\n\nThe following example computes a weighted average of the current element and its left and right neighbor along a 1-d grid. :\n\nThe resulting array type depends on the types of the computed elements just like array literals do. In order to control the type explicitly, a type can be prepended to the comprehension. For example, we could have requested the result in single precision by writing:\n\nComprehensions can also be written without the enclosing square brackets, producing an object known as a generator. This object can be iterated to produce values on demand, instead of allocating an array and storing them in advance (see Iteration). For example, the following expression sums a series without allocating memory:\n\nWhen writing a generator expression with multiple dimensions inside an argument list, parentheses are needed to separate the generator from subsequent arguments:\n\nAll comma-separated expressions after are interpreted as ranges. Adding parentheses lets us add a third argument to :\n\nGenerators are implemented via inner functions. Just like inner functions used elsewhere in the language, variables from the enclosing scope can be \"captured\" in the inner function. For example, captures the three variables , and from the enclosing scope. Captured variables can present performance challenges; see performance tips.\n\nRanges in generators and comprehensions can depend on previous ranges by writing multiple keywords:\n\nIn such cases, the result is always 1-d.\n\nGenerated values can be filtered using the keyword:\n\nThe general syntax for indexing into an n-dimensional array is:\n\nwhere each may be a scalar integer, an array of integers, or any other supported index. This includes ( ) to select all indices within the entire dimension, ranges of the form or to select contiguous or strided subsections, and arrays of booleans to select elements at their indices.\n\nIf all the indices are scalars, then the result is a single element from the array . Otherwise, is an array with the same number of dimensions as the sum of the dimensionalities of all the indices.\n\nIf all indices are vectors, for example, then the shape of would be , with location of containing the value .\n\nNote how the size of the resulting array is different in the last two cases.\n\nIf is changed to a two-dimensional matrix, then becomes an -dimensional array of shape . The matrix adds a dimension.\n\nThe location contains the value at . All dimensions indexed with scalars are dropped. For example, if is an array of indices, then the result of is an array with size . Its th element is populated by .\n\nAs a special part of this syntax, the keyword may be used to represent the last index of each dimension within the indexing brackets, as determined by the size of the innermost array being indexed. Indexing syntax without the keyword is equivalent to a call to :\n\nThe general syntax for assigning values in an n-dimensional array is:\n\nwhere each may be a scalar integer, an array of integers, or any other supported index. This includes ( ) to select all indices within the entire dimension, ranges of the form or to select contiguous or strided subsections, and arrays of booleans to select elements at their indices.\n\nIf all indices are integers, then the value in location of is overwritten with the value of , ing to the of if necessary.\n\nIf any index selects more than one location, then the right hand side must be an array with the same shape as the result of indexing or a vector with the same number of elements. The value in location of is overwritten with the value , converting if necessary. The element-wise assignment operator may be used to broadcast across the selected locations:\n\nJust as in Indexing, the keyword may be used to represent the last index of each dimension within the indexing brackets, as determined by the size of the array being assigned into. Indexed assignment syntax without the keyword is equivalent to a call to :\n\nIn the expression , each may be a scalar index, an array of scalar indices, or an object that represents an array of scalar indices and can be converted to such by :\n• A scalar index. By default this includes:\n• s, which behave like an -tuple of integers spanning multiple dimensions (see below for more details)\n• An array of scalar indices. This includes:\n• Empty arrays like , which select no elements\n• Ranges like or , which select contiguous or strided subsections from to (inclusive)\n• Any custom array of scalar indices that is a subtype of\n• Arrays of (see below for more details)\n• An object that represents an array of scalar indices and can be converted to such by . By default this includes:\n\nThe special object represents a scalar index that behaves like an -tuple of integers spanning multiple dimensions. For example:\n\nConsidered alone, this may seem relatively trivial; simply gathers multiple integers together into one object that represents a single multidimensional index. When combined with other indexing forms and iterators that yield es, however, this can produce very elegant and efficient code. See Iteration below, and for some more advanced examples, see this blog post on multidimensional algorithms and iteration.\n\nArrays of are also supported. They represent a collection of scalar indices that each span dimensions, enabling a form of indexing that is sometimes referred to as pointwise indexing. For example, it enables accessing the diagonal elements from the first \"page\" of from above:\n\nThis can be expressed much more simply with dot broadcasting and by combining it with a normal integer index (instead of extracting the first from as a separate step). It can even be combined with a to extract both diagonals from the two pages at the same time:\n\nOften referred to as logical indexing or indexing with a logical mask, indexing by a boolean array selects elements at the indices where its values are . Indexing by a boolean vector is effectively the same as indexing by the vector of integers that is returned by . Similarly, indexing by a -dimensional boolean array is effectively the same as indexing by the vector of s where its values are . A logical index must be a vector of the same length as the dimension it indexes into, or it must be the only index provided and match the size and dimensionality of the array it indexes into. It is generally more efficient to use boolean arrays as indices directly instead of first calling .\n\nThe ordinary way to index into an -dimensional array is to use exactly indices; each index selects the position(s) in its particular dimension. For example, in the three-dimensional array , will select the number in the second row of the third column in the first \"page\" of the array. This is often referred to as cartesian indexing.\n\nWhen exactly one index is provided, that index no longer represents a location in a particular dimension of the array. Instead, it selects the th element using the column-major iteration order that linearly spans the entire array. This is known as linear indexing. It essentially treats the array as though it had been reshaped into a one-dimensional vector with .\n\nA linear index into the array can be converted to a for cartesian indexing with (see ), and a set of cartesian indices can be converted to a linear index with (see ).\n\nIt's important to note that there's a very large assymmetry in the performance of these conversions. Converting a linear index to a set of cartesian indices requires dividing and taking the remainder, whereas going the other way is just multiplies and adds. In modern processors, integer division can be 10-50 times slower than multiplication. While some arrays — like itself — are implemented using a linear chunk of memory and directly use a linear index in their implementations, other arrays — like — need the full set of cartesian indices to do their lookup (see to introspect which is which). As such, when iterating over an entire array, it's much better to iterate over instead of . Not only will the former be much faster in cases where is , but it will also support OffsetArrays, too.\n\nIn addition to linear indexing, an -dimensional array may be indexed with fewer or more than indices in certain situations.\n\nIndices may be omitted if the trailing dimensions that are not indexed into are all length one. In other words, trailing indices can be omitted only if there is only one possible value that those omitted indices could be for an in-bounds indexing expression. For example, a four-dimensional array with size may be indexed with only three indices as the dimension that gets skipped (the fourth dimension) has length one. Note that linear indexing takes precedence over this rule.\n\nWhen omitting all indices with , this semantic provides a simple idiom to retrieve the only element in an array and simultaneously ensure that there was only one element.\n\nSimilarly, more than indices may be provided if all the indices beyond the dimensionality of the array are (or more generally are the first and only element of where is that particular dimension number). This allows vectors to be indexed like one-column matrices, for example:\n\nThe recommended ways to iterate over a whole array are\n\nThe first construct is used when you need the value, but not index, of each element. In the second construct, will be an if is an array type with fast linear indexing; otherwise, it will be a :\n\nIn contrast with , iterating with provides an efficient way to iterate over any array type.\n\nIf you write a custom type, you can specify that it has fast linear indexing using\n\nThis setting will cause iteration over a to use integers. If you don't specify this trait, the default value is used.\n\nThe following operators are supported for arrays:\n\nTo enable convenient vectorization of mathematical and other operations, Julia provides the dot syntax , e.g. or , for elementwise operations over arrays or mixtures of arrays and scalars (a Broadcasting operation); these have the additional advantage of \"fusing\" into a single loop when combined with other dot calls, e.g. .\n\nAlso, every binary operator supports a dot version that can be applied to arrays (and combinations of arrays and scalars) in such fused broadcasting operations, e.g. .\n\nNote that comparisons such as operate on whole arrays, giving a single boolean answer. Use dot operators like for elementwise comparisons. (For comparison operations like , only the elementwise version is applicable to arrays.)\n\nAlso notice the difference between , which s elementwise over and , and , which finds the largest value within . The same relationship holds for and .\n\nIt is sometimes useful to perform element-by-element binary operations on arrays of different sizes, such as adding a vector to each column of a matrix. An inefficient way to do this would be to replicate the vector to the size of the matrix:\n\nThis is wasteful when dimensions get large, so Julia provides , which expands singleton dimensions in array arguments to match the corresponding dimension in the other array without using extra memory, and applies the given function elementwise:\n\nDotted operators such as and are equivalent to calls (except that they fuse, as described below). There is also a function to specify an explicit destination (which can also be accessed in a fusing fashion by assignment). In fact, is equivalent to , providing a convenient syntax to broadcast any function (dot syntax). Nested \"dot calls\" (including calls to etcetera) automatically fuse into a single call.\n\nAdditionally, is not limited to arrays (see the function documentation); it also handles scalars, tuples and other collections. By default, only some argument types are considered scalars, including (but not limited to) s, s, s, s, s and some common singletons like and . All other arguments are iterated over or indexed into elementwise.\n\nThe base array type in Julia is the abstract type . It is parameterized by the number of dimensions and the element type . and are aliases for the 1-d and 2-d cases. Operations on objects are defined using higher level operators and functions, in a way that is independent of the underlying storage. These operations generally work correctly as a fallback for any specific array implementation.\n\nThe type includes anything vaguely array-like, and implementations of it might be quite different from conventional arrays. For example, elements might be computed on request rather than stored. However, any concrete type should generally implement at least (returning an tuple), and ; mutable arrays should also implement . It is recommended that these operations have nearly constant time complexity, or technically Õ(1) complexity, as otherwise some array functions may be unexpectedly slow. Concrete types should also typically provide a method, which is used to allocate a similar array for and other out-of-place operations. No matter how an is represented internally, is the type of object returned by integer indexing ( , when is not empty) and should be the length of the tuple returned by . For more details on defining custom implementations, see the array interface guide in the interfaces chapter.\n\nis an abstract subtype of intended to include all arrays where elements are stored contiguously in column-major order (see additional notes in Performance Tips). The type is a specific instance of ; and are aliases for the 1-d and 2-d cases. Very few operations are implemented specifically for beyond those that are required for all s; much of the array library is implemented in a generic manner that allows all custom arrays to behave similarly.\n\nis a specialization of that performs indexing by sharing memory with the original array rather than by copying it. A is created with the function, which is called the same way as (with an array and a series of index arguments). The result of looks the same as the result of , except the data is left in place. stores the input index vectors in a object, which can later be used to index the original array indirectly. By putting the macro in front of an expression or block of code, any slice in that expression will be converted to create a view instead.\n\ns are space-efficient \"packed\" boolean arrays, which store one bit per boolean value. They can be used similarly to arrays (which store one byte per boolean value), and can be converted to/from the latter via and , respectively.\n\nA \"strided\" array is stored in memory with elements laid out in regular offsets such that an instance with a supported element type can be passed to external C and Fortran functions that expect this memory layout. Strided arrays must define a method that returns a tuple of \"strides\" for each dimension; a provided method accesses the th element within this tuple. Increasing the index of dimension by should increase the index of by . If a pointer conversion method is provided, the memory layout must correspond in the same way to these strides. is a very specific example of a strided array where the elements are arranged contiguously, thus it provides its subtypes with the appropriate definition of . More concrete examples can be found within the interface guide for strided arrays. and are convenient aliases for many of the builtin array types that are considered strided arrays, allowing them to dispatch to select specialized implementations that call highly tuned and optimized BLAS and LAPACK functions using just the pointer and strides.\n\nThe following example computes the QR decomposition of a small section of a larger array, without creating any temporaries, and by calling the appropriate LAPACK function with the right leading dimension size and stride parameters."
    }
]