[
    {
        "link": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html",
        "document": ""
    },
    {
        "link": "https://pandas.pydata.org/pandas-docs/version/1.4.1/reference/frame.html",
        "document": "Access a single value for a row/column pair by integer position. Access a group of rows and columns by label(s) or a boolean array. Insert column into DataFrame at specified location. Get the 'info axis' (see Indexing for more). Get item from object for given key (ex: DataFrame column). Whether each element in the DataFrame is contained in values. Replace values where the condition is False. Replace values where the condition is True. Query the columns of a DataFrame with a boolean expression. For more information on , , , and , see the indexing documentation.\n\nGet Addition of dataframe and other, element-wise (binary operator ). Get Subtraction of dataframe and other, element-wise (binary operator ). Get Multiplication of dataframe and other, element-wise (binary operator ). Get Floating division of dataframe and other, element-wise (binary operator ). Get Floating division of dataframe and other, element-wise (binary operator ). Get Integer division of dataframe and other, element-wise (binary operator ). Get Modulo of dataframe and other, element-wise (binary operator ). Get Exponential power of dataframe and other, element-wise (binary operator ). Compute the matrix multiplication between the DataFrame and other. Get Addition of dataframe and other, element-wise (binary operator ). Get Subtraction of dataframe and other, element-wise (binary operator ). Get Multiplication of dataframe and other, element-wise (binary operator ). Get Floating division of dataframe and other, element-wise (binary operator ). Get Floating division of dataframe and other, element-wise (binary operator ). Get Integer division of dataframe and other, element-wise (binary operator ). Get Modulo of dataframe and other, element-wise (binary operator ). Get Exponential power of dataframe and other, element-wise (binary operator ). Get Less than of dataframe and other, element-wise (binary operator ). Get Greater than of dataframe and other, element-wise (binary operator ). Get Less than or equal to of dataframe and other, element-wise (binary operator ). Get Greater than or equal to of dataframe and other, element-wise (binary operator ). Get Not equal to of dataframe and other, element-wise (binary operator ). Get Equal to of dataframe and other, element-wise (binary operator ). Update null elements with value in the same location in .\n\nReturn a Series/DataFrame with absolute numeric value of each element. Return whether all elements are True, potentially over an axis. Return whether any element is True, potentially over an axis. Count non-NA cells for each column or row. Return the mean absolute deviation of the values over the requested axis. Return the maximum of the values over the requested axis. Return the mean of the values over the requested axis. Return the median of the values over the requested axis. Return the minimum of the values over the requested axis. Get the mode(s) of each element along the selected axis. Percentage change between the current and a prior element. Return the product of the values over the requested axis. Return the product of the values over the requested axis. Return values at the given quantile over requested axis. Return unbiased standard error of the mean over requested axis. Return the sum of the values over the requested axis. Count number of distinct elements in specified axis. Return a Series containing counts of unique rows in the DataFrame.\n\nAlign two objects on their axes with the specified join method. Select values at particular time of day (e.g., 9:30AM). Select values between particular times of the day (e.g., 9:00-9:30 AM). Drop specified labels from rows or columns. Test whether two objects contain the same elements. Subset the dataframe rows or columns according to the specified index labels. Return index of first occurrence of maximum over requested axis. Return index of first occurrence of minimum over requested axis. Conform Series/DataFrame to new index with optional filling logic. Return an object with matching indices as other object. Set the name of the axis for the index or columns. Reset the index, or a level of it. Return a random sample of items from an axis of object. Return the elements in the given positional indices along an axis. Truncate a Series or DataFrame before and after some index value.\n\nSort by the values along either axis. Sort object by labels (along an axis). Return the first rows ordered by in descending order. Return the first rows ordered by in ascending order. Stack the prescribed level(s) from columns to index. Transform each element of a list-like to a row, replicating index values. Return an xarray object from the pandas object.\n\nReturn the last row(s) without any NaNs before . Shift index by desired number of periods with an optional time . (DEPRECATED) Shift the time index, using the index's frequency if available. Return index for first non-NA value or None, if no non-NA value is found. Return index for last non-NA value or None, if no non-NA value is found. Cast to DatetimeIndex of timestamps, at beginning of period. Localize tz-naive index of a Series or DataFrame to target time zone.\n\nFlags refer to attributes of the pandas object. Properties of the dataset (like the date is was recorded, the URL it was accessed from, etc.) should be stored in ."
    },
    {
        "link": "https://stackoverflow.com/questions/13784192/creating-an-empty-pandas-dataframe-and-then-filling-it",
        "document": "Most answers here will tell you how to create an empty DataFrame and fill it out, but no one will tell you that it is a bad thing to do.\n\nHere is my advice: Accumulate data in a list, not a DataFrame.\n\nUse a list to collect your data, then initialise a DataFrame when you are ready. Either a list-of-lists or list-of-dicts format will work, accepts both.\n\nconverts the list of rows (where each row is a scalar value) into a DataFrame. If your function yields s instead, call .\n• None It is always cheaper to append to a list and create a DataFrame in one go than it is to create an empty DataFrame (or one of NaNs) and append to it over and over again.\n• None Lists also take up less memory and are a much lighter data structure to work with, append, and remove (if needed).\n• None are automatically inferred (rather than assigning to all of them).\n• None A is automatically created for your data, instead of you having to take care to assign the correct index to the row you are appending at each iteration.\n\nIf you aren't convinced yet, this is also mentioned in the documentation:\n\nwas deprecated in version 1.4 and removed from the pandas API entirely in version 2.0. See also this github issue that originally proposed its deprecation.\n\nHere is the biggest mistake I've seen from beginners:\n\nMemory is re-allocated for every or operation you have. Couple this with a loop and you have a quadratic complexity operation.\n\nThe other mistake associated with is that users tend to forget append is not an in-place function, so the result must be assigned back. You also have to worry about the dtypes:\n\nDealing with object columns is never a good thing, because pandas cannot vectorize operations on those columns. You will need to call the method to fix it:\n\nI have also seen used to append to a DataFrame that was created empty:\n\nAs before, you have not pre-allocated the amount of memory you need each time, so the memory is re-grown each time you create a new row. It's just as bad as , and even more ugly.\n\nAnd then, there's creating a DataFrame of NaNs, and all the caveats associated therewith.\n\nIt creates a DataFrame of columns, like the others.\n\nAppending still has all the issues as the methods above.\n\nThe Proof is in the Pudding\n\nTiming these methods is the fastest way to see just how much they differ in terms of their memory and utility."
    },
    {
        "link": "https://pandas.pydata.org/pandas-docs/version/1.4/pandas.pdf",
        "document": ""
    },
    {
        "link": "https://pandas.pydata.org/pandas-docs/version/1.4/reference/frame.html",
        "document": "Access a single value for a row/column pair by integer position. Access a group of rows and columns by label(s) or a boolean array. Insert column into DataFrame at specified location. Get the 'info axis' (see Indexing for more). Get item from object for given key (ex: DataFrame column). Whether each element in the DataFrame is contained in values. Replace values where the condition is False. Replace values where the condition is True. Query the columns of a DataFrame with a boolean expression. For more information on , , , and , see the indexing documentation.\n\nGet Addition of dataframe and other, element-wise (binary operator ). Get Subtraction of dataframe and other, element-wise (binary operator ). Get Multiplication of dataframe and other, element-wise (binary operator ). Get Floating division of dataframe and other, element-wise (binary operator ). Get Floating division of dataframe and other, element-wise (binary operator ). Get Integer division of dataframe and other, element-wise (binary operator ). Get Modulo of dataframe and other, element-wise (binary operator ). Get Exponential power of dataframe and other, element-wise (binary operator ). Compute the matrix multiplication between the DataFrame and other. Get Addition of dataframe and other, element-wise (binary operator ). Get Subtraction of dataframe and other, element-wise (binary operator ). Get Multiplication of dataframe and other, element-wise (binary operator ). Get Floating division of dataframe and other, element-wise (binary operator ). Get Floating division of dataframe and other, element-wise (binary operator ). Get Integer division of dataframe and other, element-wise (binary operator ). Get Modulo of dataframe and other, element-wise (binary operator ). Get Exponential power of dataframe and other, element-wise (binary operator ). Get Less than of dataframe and other, element-wise (binary operator ). Get Greater than of dataframe and other, element-wise (binary operator ). Get Less than or equal to of dataframe and other, element-wise (binary operator ). Get Greater than or equal to of dataframe and other, element-wise (binary operator ). Get Not equal to of dataframe and other, element-wise (binary operator ). Get Equal to of dataframe and other, element-wise (binary operator ). Update null elements with value in the same location in .\n\nReturn a Series/DataFrame with absolute numeric value of each element. Return whether all elements are True, potentially over an axis. Return whether any element is True, potentially over an axis. Count non-NA cells for each column or row. Return the mean absolute deviation of the values over the requested axis. Return the maximum of the values over the requested axis. Return the mean of the values over the requested axis. Return the median of the values over the requested axis. Return the minimum of the values over the requested axis. Get the mode(s) of each element along the selected axis. Percentage change between the current and a prior element. Return the product of the values over the requested axis. Return the product of the values over the requested axis. Return values at the given quantile over requested axis. Return unbiased standard error of the mean over requested axis. Return the sum of the values over the requested axis. Count number of distinct elements in specified axis. Return a Series containing counts of unique rows in the DataFrame.\n\nAlign two objects on their axes with the specified join method. Select values at particular time of day (e.g., 9:30AM). Select values between particular times of the day (e.g., 9:00-9:30 AM). Drop specified labels from rows or columns. Test whether two objects contain the same elements. Subset the dataframe rows or columns according to the specified index labels. Return index of first occurrence of maximum over requested axis. Return index of first occurrence of minimum over requested axis. Conform Series/DataFrame to new index with optional filling logic. Return an object with matching indices as other object. Set the name of the axis for the index or columns. Reset the index, or a level of it. Return a random sample of items from an axis of object. Return the elements in the given positional indices along an axis. Truncate a Series or DataFrame before and after some index value.\n\nSort by the values along either axis. Sort object by labels (along an axis). Return the first rows ordered by in descending order. Return the first rows ordered by in ascending order. Stack the prescribed level(s) from columns to index. Transform each element of a list-like to a row, replicating index values. Return an xarray object from the pandas object.\n\nReturn the last row(s) without any NaNs before . Shift index by desired number of periods with an optional time . (DEPRECATED) Shift the time index, using the index's frequency if available. Return index for first non-NA value or None, if no non-NA value is found. Return index for last non-NA value or None, if no non-NA value is found. Cast to DatetimeIndex of timestamps, at beginning of period. Localize tz-naive index of a Series or DataFrame to target time zone.\n\nFlags refer to attributes of the pandas object. Properties of the dataset (like the date is was recorded, the URL it was accessed from, etc.) should be stored in ."
    },
    {
        "link": "https://pandas.pydata.org/pandas-docs/version/1.4/reference/api/pandas.concat.html",
        "document": "Concatenate pandas objects along a particular axis with optional set logic along the other axes.\n\nCan also add a layer of hierarchical indexing on the concatenation axis, which may be useful if the labels are the same (or overlapping) on the passed axis number.\n\nobjs a sequence or mapping of Series or DataFrame objects If a mapping is passed, the sorted keys will be used as the argument, unless it is passed, in which case the values will be selected (see below). Any None objects will be dropped silently unless they are all None in which case a ValueError will be raised. The axis to concatenate along. How to handle indexes on other axis (or axes). If True, do not use the index values along the concatenation axis. The resulting axis will be labeled 0, …, n - 1. This is useful if you are concatenating objects where the concatenation axis does not have meaningful indexing information. Note the index values on the other axes are still respected in the join. If multiple levels passed, should contain tuples. Construct hierarchical index using the passed keys as the outermost level. Specific levels (unique values) to use for constructing a MultiIndex. Otherwise they will be inferred from the keys. Names for the levels in the resulting hierarchical index. Check whether the new concatenated axis contains duplicates. This can be very expensive relative to the actual data concatenation. Sort non-concatenation axis if it is not already aligned when is ‘outer’. This has no effect when , which already preserves the order of the non-concatenation axis. Changed in version 1.0.0: Changed to not sort by default. If False, do not copy data unnecessarily. When concatenating all along the index (axis=0), a is returned. When contains at least one , a is returned. When concatenating along the columns (axis=1), a is returned.\n\nThe keys, levels, and names arguments are all optional.\n\nA walkthrough of how this method fits in with other tools for combining pandas objects can be found here.\n\nClear the existing index and reset it in the result by setting the option to .\n\nAdd a hierarchical index at the outermost level of the data with the option.\n\nLabel the index keys you create with the option.\n\nCombine objects with overlapping columns and return everything. Columns outside the intersection will be filled with values.\n\nCombine objects with overlapping columns and return only those that are shared by passing to the keyword argument.\n\nCombine objects horizontally along the x axis by passing in .\n\nPrevent the result from including duplicate index values with the option."
    },
    {
        "link": "https://pandas.pydata.org/docs/reference/api/pandas.concat.html",
        "document": "Allows optional set logic along the other axes.\n\nCan also add a layer of hierarchical indexing on the concatenation axis, which may be useful if the labels are the same (or overlapping) on the passed axis number.\n\nobjs a sequence or mapping of Series or DataFrame objects If a mapping is passed, the sorted keys will be used as the argument, unless it is passed, in which case the values will be selected (see below). Any None objects will be dropped silently unless they are all None in which case a ValueError will be raised. The axis to concatenate along. How to handle indexes on other axis (or axes). If True, do not use the index values along the concatenation axis. The resulting axis will be labeled 0, …, n - 1. This is useful if you are concatenating objects where the concatenation axis does not have meaningful indexing information. Note the index values on the other axes are still respected in the join. If multiple levels passed, should contain tuples. Construct hierarchical index using the passed keys as the outermost level. Specific levels (unique values) to use for constructing a MultiIndex. Otherwise they will be inferred from the keys. Names for the levels in the resulting hierarchical index. Check whether the new concatenated axis contains duplicates. This can be very expensive relative to the actual data concatenation. Sort non-concatenation axis if it is not already aligned. One exception to this is when the non-concatentation axis is a DatetimeIndex and join=’outer’ and the axis is not already aligned. In that case, the non-concatenation axis is always sorted lexicographically. If False, do not copy data unnecessarily. When concatenating all along the index (axis=0), a is returned. When contains at least one , a is returned. When concatenating along the columns (axis=1), a is returned.\n\nThe keys, levels, and names arguments are all optional.\n\nA walkthrough of how this method fits in with other tools for combining pandas objects can be found here.\n\nIt is not recommended to build DataFrames by adding single rows in a for loop. Build a list of rows and make a DataFrame in a single concat.\n\nClear the existing index and reset it in the result by setting the option to .\n\nAdd a hierarchical index at the outermost level of the data with the option.\n\nLabel the index keys you create with the option.\n\nCombine objects with overlapping columns and return everything. Columns outside the intersection will be filled with values.\n\nCombine objects with overlapping columns and return only those that are shared by passing to the keyword argument.\n\nCombine objects horizontally along the x axis by passing in .\n\nPrevent the result from including duplicate index values with the option.\n\nAppend a single row to the end of a object."
    },
    {
        "link": "https://stackoverflow.com/questions/71565413/adding-a-dictionary-to-a-row-in-a-pandas-dataframe-using-concat-in-pandas-1-4",
        "document": "After updating to pandas 1.4, I now receive the following warning when using frame.append to append a dictionary to a Pandas DataFrame.\n\nBelow is the code. This still works, though I would like to resolve the warning.\n\nI have updated the code to the below, which kicks a different warning:\n\n2 questions: Is the first warning wrong? What is the pandas 1.4 way to achieve this? Thanks."
    },
    {
        "link": "https://stackoverflow.com/questions/72084338/how-to-concat-pandas-series-and-dataframe",
        "document": "I would like to concat the Pandas Series into my Dataframe. My code works fine with Pandas append function, however, it seems that append will not be used in the future and I am not able to figure out how to solve it with pd.concat.\n\nHere is my code snippet:\n\nWith inside , it shows ValueError: Length of values (3) does not match length of index (4) ."
    },
    {
        "link": "https://pandas.pydata.org/pandas-docs/version/1.4/user_guide/merging.html",
        "document": "pandas provides various facilities for easily combining together Series or DataFrame with various kinds of set logic for the indexes and relational algebra functionality in the case of join / merge-type operations.\n\nIn addition, pandas also provides utilities to compare two Series or DataFrame and summarize their differences.\n\nThe function (in the main pandas namespace) does all of the heavy lifting of performing concatenation operations along an axis while performing optional set logic (union or intersection) of the indexes (if any) on the other axes. Note that I say “if any” because there is only a single possible axis of concatenation for Series. Before diving into all of the details of and what it can do, here is a simple example: Like its sibling function on ndarrays, , takes a list or dict of homogeneously-typed objects and concatenates them with some configurable handling of “what to do with the other axes”:\n• None : a sequence or mapping of Series or DataFrame objects. If a dict is passed, the sorted keys will be used as the argument, unless it is passed, in which case the values will be selected (see below). Any None objects will be dropped silently unless they are all None in which case a ValueError will be raised.\n• None : {0, 1, …}, default 0. The axis to concatenate along.\n• None : {‘inner’, ‘outer’}, default ‘outer’. How to handle indexes on other axis(es). Outer for union and inner for intersection.\n• None : boolean, default False. If True, do not use the index values on the concatenation axis. The resulting axis will be labeled 0, …, n - 1. This is useful if you are concatenating objects where the concatenation axis does not have meaningful indexing information. Note the index values on the other axes are still respected in the join.\n• None : sequence, default None. Construct hierarchical index using the passed keys as the outermost level. If multiple levels passed, should contain tuples.\n• None : list of sequences, default None. Specific levels (unique values) to use for constructing a MultiIndex. Otherwise they will be inferred from the keys.\n• None : list, default None. Names for the levels in the resulting hierarchical index.\n• None : boolean, default False. Check whether the new concatenated axis contains duplicates. This can be very expensive relative to the actual data concatenation.\n• None : boolean, default True. If False, do not copy data unnecessarily. Without a little bit of context many of these arguments don’t make much sense. Let’s revisit the above example. Suppose we wanted to associate specific keys with each of the pieces of the chopped up DataFrame. We can do this using the argument: As you can see (if you’ve read the rest of the documentation), the resulting object’s index has a hierarchical index. This means that we can now select out each chunk by key: It’s not a stretch to see how this can be very useful. More detail on this functionality below. It is worth noting that (and therefore ) makes a full copy of the data, and that constantly reusing this function can create a significant performance hit. If you need to use the operation over several datasets, use a list comprehension. When concatenating DataFrames with named axes, pandas will attempt to preserve these index/column names whenever possible. In the case where all inputs share a common name, this name will be assigned to the result. When the input names do not all agree, the result will be unnamed. The same is true for , but the logic is applied separately on a level-by-level basis. Set logic on the other axes¶ When gluing together multiple DataFrames, you have a choice of how to handle the other axes (other than the one being concatenated). This can be done in the following two ways:\n• None Take the union of them all, . This is the default option as it results in zero information loss. Here is an example of each of these methods. First, the default behavior: Here is the same thing with : Lastly, suppose we just wanted to reuse the exact index from the original DataFrame: Similarly, we could index before the concatenation: For objects which don’t have a meaningful index, you may wish to append them and ignore the fact that they may have overlapping indexes. To do this, use the argument: You can concatenate a mix of and objects. The will be transformed to with the column name as the name of the . Since we’re concatenating a to a , we could have achieved the same result with . To concatenate an arbitrary number of pandas objects ( or ), use . If unnamed are passed they will be numbered consecutively. Passing will drop all name references. A fairly common use of the argument is to override the column names when creating a new based on existing . Notice how the default behaviour consists on letting the resulting inherit the parent ’ name, when these existed. Through the argument we can override the existing column names. Let’s consider a variation of the very first example presented: You can also pass a dict to in which case the dict keys will be used for the argument (unless other keys are specified): The MultiIndex created has levels that are constructed from the passed keys and the index of the pieces: If you wish to specify other levels (as will occasionally be the case), you can do so using the argument: This is fairly esoteric, but it is actually necessary for implementing things like GroupBy where the order of a categorical variable is meaningful. If you have a series that you want to append as a single row to a , you can convert the row into a and use You should use with this method to instruct DataFrame to discard its index. If you wish to preserve the index, you should construct an appropriately-indexed DataFrame and append or concatenate those objects.\n\npandas has full-featured, high performance in-memory join operations idiomatically very similar to relational databases like SQL. These methods perform significantly better (in some cases well over an order of magnitude better) than other open source implementations (like in R). The reason for this is careful algorithmic design and the internal layout of the data in . See the cookbook for some advanced strategies. Users who are familiar with SQL but new to pandas might be interested in a comparison with SQL. pandas provides a single function, , as the entry point for all standard database join operations between or named objects:\n• None : Column or index level names to join on. Must be found in both the left and right DataFrame and/or Series objects. If not passed and and are , the intersection of the columns in the DataFrames and/or Series will be inferred to be the join keys.\n• None : Columns or index levels from the left DataFrame or Series to use as keys. Can either be column names, index level names, or arrays with length equal to the length of the DataFrame or Series.\n• None : Columns or index levels from the right DataFrame or Series to use as keys. Can either be column names, index level names, or arrays with length equal to the length of the DataFrame or Series.\n• None : If , use the index (row labels) from the left DataFrame or Series as its join key(s). In the case of a DataFrame or Series with a MultiIndex (hierarchical), the number of levels must match the number of join keys from the right DataFrame or Series.\n• None : Same usage as for the right DataFrame or Series\n• None : One of , , , , . Defaults to . See below for more detailed description of each method.\n• None : Sort the result DataFrame by the join keys in lexicographical order. Defaults to , setting to will improve performance substantially in many cases.\n• None : A tuple of string suffixes to apply to overlapping columns. Defaults to .\n• None : Always copy data (default ) from the passed DataFrame or named Series objects, even when reindexing is not necessary. Cannot be avoided in many cases but may improve performance / memory usage. The cases where copying can be avoided are somewhat pathological but this option is provided nonetheless.\n• None : Add a column to the output DataFrame called with information on the source of each row. is Categorical-type and takes on a value of for observations whose merge key only appears in DataFrame or Series, for observations whose merge key only appears in DataFrame or Series, and if the observation’s merge key is found in both.\n• None : string, default None. If specified, checks if merge is of specified type.\n• None “one_to_one” or “1:1”: checks if merge keys are unique in both left and right datasets.\n• None “one_to_many” or “1:m”: checks if merge keys are unique in left dataset.\n• None “many_to_one” or “m:1”: checks if merge keys are unique in right dataset.\n• None “many_to_many” or “m:m”: allowed, but does not result in checks. Support for specifying index levels as the , , and parameters was added in version 0.23.0. Support for merging named objects was added in version 0.24.0. The return type will be the same as . If is a or named and is a subclass of , the return type will still be . is a function in the pandas namespace, and it is also available as a instance method , with the calling being implicitly considered the left object in the join. The related method, uses internally for the index-on-index (by default) and column(s)-on-index join. If you are joining on index only, you may wish to use to save yourself some typing. Experienced users of relational databases like SQL will be familiar with the terminology used to describe join operations between two SQL-table like structures ( objects). There are several cases to consider which are very important to understand:\n• None one-to-one joins: for example when joining two objects on their indexes (which must contain unique values).\n• None many-to-one joins: for example when joining an index (unique) to one or more columns in a different . When joining columns on columns (potentially a many-to-many join), any indexes on the passed objects will be discarded. It is worth spending some time understanding the result of the many-to-many join case. In SQL / standard relational algebra, if a key combination appears more than once in both tables, the resulting table will have the Cartesian product of the associated data. Here is a very basic example with one unique key combination: Here is a more complicated example with multiple join keys. Only the keys appearing in and are present (the intersection), since by default. The argument to specifies how to determine which keys are to be included in the resulting table. If a key combination does not appear in either the left or right tables, the values in the joined table will be . Here is a summary of the options and their SQL equivalent names: Use keys from left frame only Use keys from right frame only Use union of keys from both frames Use intersection of keys from both frames Create the cartesian product of rows of both frames You can merge a mult-indexed Series and a DataFrame, if the names of the MultiIndex correspond to the columns from the DataFrame. Transform the Series to a DataFrame using before merging, as shown in the following example. Here is another example with duplicate join keys in DataFrames: Joining / merging on duplicate keys can cause a returned frame that is the multiplication of the row dimensions, which may result in memory overflow. It is the user’ s responsibility to manage duplicate values in keys before joining large DataFrames. Users can use the argument to automatically check whether there are unexpected duplicates in their merge keys. Key uniqueness is checked before merge operations and so should protect against memory overflows. Checking key uniqueness is also a good way to ensure user data structures are as expected. In the following example, there are duplicate values of in the right . As this is not a one-to-one merge – as specified in the argument – an exception will be raised. MergeError: Merge keys are not unique in right dataset; not a one-to-one merge If the user is aware of the duplicates in the right but wants to ensure there are no duplicates in the left DataFrame, one can use the argument instead, which will not raise an exception. accepts the argument . If , a Categorical-type column called will be added to the output object that takes on values: The argument will also accept string arguments, in which case the indicator function will use the value of the passed string as the name for the indicator column. Merging will preserve the dtype of the join keys. We are able to preserve the join keys: Of course if you have missing values that are introduced, then the resulting dtype will be upcast. Merging will preserve dtypes of the mergands. See also the section on categoricals. The category dtypes must be exactly the same, meaning the same categories and the ordered attribute. Otherwise the result will coerce to the categories’ dtype. Merging on dtypes that are the same can be quite performant compared to dtype merging. is a convenient method for combining the columns of two potentially differently-indexed into a single result . Here is a very basic example: The same as above, but with . The data alignment here is on the indexes (row labels). This same behavior can be achieved using plus additional arguments instructing it to use the indexes: takes an optional argument which may be a column or multiple column names, which specifies that the passed is to be aligned on that column in the . These two function calls are completely equivalent: Obviously you can choose whichever form you find more convenient. For many-to-one joins (where one of the ’s is already indexed by the join key), using may be more convenient. Here is a simple example: To join on multiple keys, the passed DataFrame must have a : Now this can be joined by passing the two key column names: The default for is to perform a left join (essentially a “VLOOKUP” operation, for Excel users), which uses only the keys found in the calling DataFrame. Other join types, for example inner join, can be just as easily performed: As you can see, this drops any rows where there was no match. You can join a singly-indexed with a level of a MultiIndexed . The level will match on the name of the index of the singly-indexed frame against a level name of the MultiIndexed frame. This is equivalent but less verbose and more memory efficient / faster than this. This is supported in a limited way, provided that the index for the right argument is completely used in the join, and is a subset of the indices in the left argument, as in this example: If that condition is not satisfied, a join with two multi-indexes can be done using the following code. Merging on a combination of columns and index levels¶ Strings passed as the , , and parameters may refer to either column names or index level names. This enables merging instances on a combination of index levels and columns without resetting indexes. When DataFrames are merged on a string that matches an index level in both frames, the index level is preserved as an index level in the resulting DataFrame. When DataFrames are merged using only some of the levels of a , the extra levels will be dropped from the resulting merge. In order to preserve those levels, use on those level names to move those levels to columns prior to doing the merge. If a string matches both a column name and an index level name, then a warning is issued and the column takes precedence. This will result in an ambiguity error in a future version. The merge argument takes a tuple of list of strings to append to overlapping column names in the input s to disambiguate the result columns: has and arguments which behave similarly. A list or tuple of can also be passed to to join them together on their indexes. Merging together values within Series or DataFrame columns¶ Another fairly common situation is to have two like-indexed (or similarly indexed) or objects and wanting to “patch” values in one object from values for matching indices in the other. Here is an example: For this, use the method: Note that this method only takes values from the right if they are missing in the left . A related method, , alters non-NA values in place:\n\nA function allows combining time series and other ordered data. In particular it has an optional keyword to fill/interpolate missing data: A is similar to an ordered left-join except that we match on nearest key rather than equal keys. For each row in the , we select the last row in the whose key is less than the left’s key. Both DataFrames must be sorted by the key. Optionally an asof merge can perform a group-wise merge. This matches the key equally, in addition to the nearest match on the key. For example; we might have and and we want to merge them. By default we are taking the asof of the quotes. We only asof within between the quote time and the trade time. We only asof within between the quote time and the trade time and we exclude exact matches on time. Note that though we exclude the exact matches (of the quotes), prior quotes do propagate to that point in time.\n\nThe and methods allow you to compare two DataFrame or Series, respectively, and summarize their differences. This feature was added in V1.1.0. For example, you might want to compare two and stack their differences side by side. By default, if two corresponding values are equal, they will be shown as . Furthermore, if all values in an entire row / column, the row / column will be omitted from the result. The remaining differences will be aligned on columns. If you wish, you may choose to stack the differences on rows. If you wish to keep all original rows and columns, set argument to . self other self other self other You may also keep all the original values even if they are equal. self other self other self other"
    }
]