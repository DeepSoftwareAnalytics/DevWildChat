[
    {
        "link": "https://community.khronos.org/t/glrotatef/17660",
        "document": "There are a few things about openGL and rotations and translations that you should know and maybe hard to grasp at first.\n\nFirst all openGL operations start at 0,0,0 as the axis point.\n\nglRotate( Angle of rotation(0-360), X, Y, Z) Where XYZ is what axis to rotate, 0 = No-rotation, 1 = rotation per Angle.\n\n The rotation is done around 0,0,0 as the axis, so if your object is not draw with 0,0,0 being is center then it rotates with an offset.\n\nLet’s say you have a cube it has one corner as 0,0,0 and the far corner is 1,1,1. In order to rotate the cube around it’s center we must move it’s center to 0,0,0.\n\nglRotate(angle, 1, 0, 0); // Rotate around X axis\n\n glTranslate(-0.5, -0.5, -0.5); // Move cubes center from 0.5,0.5,0.5 to 0.0, 0.0, 0.0;\n\n Draw_cube();\n\nNow also remember openGL does operations work in reverse, so that the glTranslate is done frist even though we called it last.\n\nSo what happens is the cube has it center translated to 0,0,0, then we rotated around it’s center.\n\nOriginally posted by badwhorsey:\n\n [b]So does that mean I don’t need the actual coordinates, do I just need to pick the axis to rotate on by setting it to 1?"
    },
    {
        "link": "https://learn.microsoft.com/en-us/windows/win32/opengl/glrotatef",
        "document": "The glRotatef function multiplies the current matrix by a rotation matrix.\n\nThis function does not return a value.\n\nThe following error code can be retrieved by the glGetError function.\n\nThe glRotatef function computes a matrix that performs a counterclockwise rotation of angle degrees about the vector from the origin through the point (x, y, z).\n\nThe current matrix (see glMatrixMode) is multiplied by this rotation matrix, with the product replacing the current matrix. That is, if M is the current matrix and R is the translation matrix, then M is replaced with M R.\n\nIf the matrix mode is either GL_MODELVIEW or GL_PROJECTION, all objects drawn after glRotatef is called are rotated. Use glPushMatrix and glPopMatrix to save and restore the unrotated coordinate system.\n\nThe following functions retrieve information related to glRotatef:"
    },
    {
        "link": "https://stackoverflow.com/questions/3515059/how-to-rotate-a-specific-object-in-opengl",
        "document": "I have some objects on the screen and would like to rotate only one of them. I tried using the glRotatef(...) function but turns out glRotatef(...) rotates all my objects (rotates the camera, maybe?). How can I rotate only one?"
    },
    {
        "link": "https://community.khronos.org/t/glrotatef/14062",
        "document": "when i use the following to rotate it works:\n\n glRotatef(45.0, 0.0, 0.0, 1.0); however, when i rotate in any of the other axies, nothing. ie the following doesn’t do anything:\n\n glRotatef(0.0, 0.0, 45.0, 1.0),\n\nOriginally posted by simmosn:\n\n however, when i rotate in any of the other axies, nothing. ie the following doesn’t do anything:\n\n glRotatef(0.0, 0.0, 45.0, 1.0), The first argument specifies how many degree you want to rotate around an axis. The following three argument specifiy the x, y, z axis to rotate, respectively. In that statement, you’re rotating the y and z axis 0 degrees. Thats why you don’t see any change. Also, the last three parameters are clamped to the range of [0, 1].\n\nyour error is this i think : the first parameter is the angle, the others are the axis on wich you want to rotate. if u want to rotate set the axis to 1.0\n\nthanks for your help. i was being a bit thick, but all part of the learning process\n\nHello,\n\n I need to rotate in y axis from +15 degree to -15 degree\n\n how to do that\n\n gl.glRotatef(mAngleY, 0, 1, 0);"
    },
    {
        "link": "https://www3.ntu.edu.sg/home/ehchua/programming/opengl/CG_Introduction.html",
        "document": "An Introduction on OpenGL with 2D Graphics\n\nTo set up OpenGL, depending on your programming platform, read:\n• How to write OpenGL programs in C/C++.\n• How to write OpenGL programs in Java: JOGL or LWJGL.\n• How to write OpenGL|ES programs in Android.\n\nExample 1: Setting Up OpenGL and GLUT ( )\n\nMake sure that you can run the \" \" described in \"How to write OpenGL programs in C/C++\", reproduced below:\n\nThe header \" \" is needed for the Windows platform only.\n\nWe also included the GLUT header, which is guaranteed to include \" \" (for GL Utility) and \" \" (for Core OpenGL).\n\nThe rest of the program will be explained in due course.\n\nOpenGL (Open Graphics Library) is a cross-platform, hardware-accelerated, language-independent, industrial standard API for producing 3D (including 2D) graphics. Modern computers have dedicated GPU (Graphics Processing Unit) with its own memory to speed up graphics rendering. OpenGL is the software interface to graphics hardware. In other words, OpenGL graphic rendering commands issued by your applications could be directed to the graphic hardware and accelerated.\n\nWe use 3 sets of libraries in our OpenGL programs:\n• : consists of hundreds of commands, which begin with a prefix \" \" (e.g., , , , ). The Core OpenGL models an object via a set of geometric primitives such as point, line and polygon.\n• : built on-top of the core OpenGL to provide important utilities (such as setting camera view and projection) and more building models (such as qradric surfaces and polygon tessellation). GLU commands start with a prefix \" \" (e.g., , ).\n• : OpenGL is designed to be independent of the windowing system or operating system. GLUT is needed to interact with the Operating System (such as creating a window, handling key and mouse inputs); it also provides more building models (such as sphere and torus). GLUT commands start with a prefix of \" \" (e.g., , ). GLUT is platform independent, which is built on top of platform-specific OpenGL extension such as GLX for X Window System, WGL for Microsoft Window, and AGL, CGL or Cocoa for Mac OS.\n\n Quoting from the opengl.org: \"GLUT is designed for constructing small to medium sized OpenGL programs. While GLUT is well-suited to learning OpenGL and developing simple OpenGL applications, GLUT is not a full-featured toolkit so large applications requiring sophisticated user interfaces are better off using native window system toolkits. GLUT is simple, easy, and small.\"\n\n Alternative of GLUT includes SDL, ....\n• : \"GLEW is a cross-platform open-source C/C++ extension loading library. GLEW provides efficient run-time mechanisms for determining which OpenGL extensions are supported on the target platform.\" Source and pre-build binary available at http://glew.sourceforge.net/. A standalone utility called \" \" (under the \" \" directory) can be used to produce the list of OpenGL functions supported by your graphics system.\n\nTry building and runnng this OpenGL C/C++ program:\n\nThe expected output and the coordinates are as follows. Take note that 4 shapes have pure color, and 2 shapes have color blending from their vertices.\n\nI shall explain the program in the following sections.\n\nOpenGL operates as a state machine, and maintain a set of state variables (such as the foreground color, background color, and many more). In a state machine, once the value of a state variable is set, the value persists until a new value is given.\n\nFor example, we set the \"clearing\" (background) color to black once in . We use this setting to clear the window in the repeatedly ( is called back whenever there is a window re-paint request) - the clearing color is not changed in the entire program.\n\nAnother example: If we use function to set the current foreground color to \"red\", then \"red\" will be used for all the subsequent vertices, until we use another function to change the foreground color.\n\nIn a state machine, everything shall remain until you explicitly change it!\n• begins with lowercase (for core OpenGL), (for OpenGL Utility) or (for OpenGL Utility Toolkit).\n• followed by the purpose of the function, in camel case (initial-capitalized), e.g., to specify the drawing color, to define the position of a vertex.\n• followed by specifications for the parameters, e.g., takes three parameters. takes two parameters. \n\n (This is needed as C Language does not support function overloading. Different versions of the function need to be written for different parameter lists.)\n\nThe convention can be expressed as follows:\n\nThe function may take 2, 3, or 4 parameters, in type of ( ), ( ), ( ) or ( ). The ' ' (for vector) denotes that the parameters are kept in an array of 2, 3, or 4 elements, and pass into the function as an array pointer.\n• Floating-point numbers: (32-bit), (64-bit), and (between 0.0 and 1.0).\n• (unsigned char with 0 for false and non-0 for true).\n\nThe OpenGL types are defined via in \" \" as follows:\n\nOpenGL's constants begins with \" \", \" \" or \" \", in uppercase separated with underscores, e.g., .\n\nThe is meant for carrying out one-time OpenGL initialization tasks, such as setting the clearing color. is invoked once (and only once) in .\n\nThe function is known as a callback event handler. An event handler provides the response to a particular event (such as key-press, mouse-click, window-paint). The function is meant to be the handler for window-paint event. The OpenGL graphics system calls back in response to a window-paint request to re-paint the window (e.g., window first appears, window is restored after minimized, and window is resized). Callback means that the function is invoked by the system, instead of called by the your program.\n\nThe runs when the window first appears and once per subsequent re-paint request. Observe that we included OpenGL graphics rendering code inside the function, so as to re-draw the entire window when the window first appears and upon each re-paint request.\n\nGLUT provides high-level utilities to simplify OpenGL programming, especially in interacting with the Operating System (such as creating a window, handling key and mouse inputs). The following GLUT functions were used in the above program:\n• : initializes GLUT, must be called before other GL/GLUT functions. It takes the same arguments as the .\n• : creates a window with the given title.\n• : specifies the initial window width and height, in pixels.\n• : positions the top-left corner of the initial window at (x, y). The coordinates (x, y), in term of pixels, is measured in window coordinates, i.e., origin (0, 0) is at the top-left corner of the screen; x-axis pointing right and y-axis pointing down.\n• : registers the callback function (or event handler) for handling window-paint event. The OpenGL graphic system calls back this handler when it receives a window re-paint request. In the example, we register the function as the handler.\n• : enters the infinite event-processing loop, i.e, put the OpenGL graphics system to wait for events (such as re-paint), and trigger respective event handlers (such as ).\n\nIn the function of the example:\n\nWe initialize the GLUT and create a window with a title, an initial size and position.\n\nWe register function as the callback handler for window-paint event. That is, runs when the window first appears and whenever there is a request to re-paint the window.\n\nWe call the to perform all the one-time initialization operations. In this example, we set the clearing (background) color once, and use it repeatably in the function.\n\nWe then put the program into the event-handling loop, awaiting for events (such as window-paint request) to trigger off the respective event handlers (such as ).\n\nWe use function to set the foreground color, and function to set the background (or clearing) color.\n• Color is typically specified in in the range and .\n• Color can be specified using RGB (Red-Green-Blue) or RGBA (Red-Green-Blue-Alpha) components. The 'A' (or alpha) specifies the transparency (or opacity) index, with value of 1 denotes opaque (non-transparent and cannot see-thru) and value of 0 denotes total transparent. We shall discuss alpha later.\n\nIn the above example, we set the background color via in , with R=0, G=0, B=0 (black) and A=1 (opaque and cannot see through).\n\nIn , we set the vertex color via for subsequent vertices. For example, R=1, G=0, B=0 (red).\n\nIn OpenGL, an object is made up of geometric primitives such as triangle, quad, line segment and point. A primitive is made up of one or more vertices. OpenGL supports the following primitives:\n\nA geometric primitive is defined by specifying its vertices via function, enclosed within a pair and .\n\nspecifies the type of geometric object, such as , , , , and . For types that end with ' ', you can define multiple objects of the same type in each / pair. For example, for , each set of three 's defines a triangle.\n\nThe vertices are usually specified in precision. It is because integer is not suitable for trigonometric operations (needed to carry out transformations such as rotation). Precision of is sufficient for carrying out intermediate operations, and render the objects finally into pixels on screen (with resolution of says 800x600, integral precision). precision is often not necessary.\n\nIn the above example:\n\nWe set the color to red (R=1, G=0, B=0). All subsequent vertices will have the color of red. Take note that in OpenGL, color (and many properties) is applied to vertices rather than primitive shapes. The color of the a primitive shape is interpolated from its vertices.\n\nWe similarly define a second quad in green.\n\nFor the third quad (as follows), the vertices have different color. The color of the quad surface is interpolated from its vertices, resulting in a shades of white to dark gray, as shown in the output.\n\nThe following diagram shows the OpenGL 2D Coordinate System, which corresponds to the everyday 2D Cartesian coordinates with origin located at the bottom-left corner.\n\nThe default OpenGL 2D clipping-area (i.e., what is captured by the camera) is an orthographic view with x and y in the range of -1.0 and 1.0, i.e., a 2x2 square with centered at the origin. This clipping-area is mapped to the viewport on the screen. Viewport is measured in pixels.\n\nStudy the above example to convince yourself that the 2D shapes created are positioned correctly on the screen.\n\nTry dragging the corner of the window to make it bigger or smaller. Observe that all the shapes are distorted.\n\nWe can handle the re-sizing of window via a callback handler , which can be programmed to adjust the OpenGL clipping-area according to the window's aspect ratio.\n\nClipping Area: Clipping area refers to the area that can be seen (i.e., captured by the camera), measured in OpenGL coordinates.\n\nThe function can be used to set the clipping area of 2D orthographic view. Objects outside the clipping area will be clipped away and cannot be seen.\n\nTo set the clipping area, we need to issue a series of commands as follows: we first select the so-called projection matrix for operation, and reset the projection matrix to identity. We then choose the 2D orthographic view with the desired clipping area, via .\n\nViewport: Viewport refers to the display area on the window (screen), which is measured in pixels in screen coordinates (excluding the title bar).\n\nThe clipping area is mapped to the viewport. We can use function to configure the viewport.\n\nSuppose the the clipping area's (left, right, bottom, top) is (-1.0, 1.0, -1.0, 1.0) (in OpenGL coordinates) and the viewport's (xTopLeft, xTopRight, width, height) is (0, 0, 640, 480) (in screen coordinates in pixels), then the bottom-left corner (-1.0, -1.0) maps to (0, 0) in the viewport, the top-right corner (1.0, 1.0) maps to (639, 479). It is obvious that if the aspect ratios for the clipping area and the viewport are not the same, the shapes will be distorted.\n\nTake note that in the earlier example, the windows' size of 320x320 has a square shape, with a aspect ratio consistent with the default 2x2 squarish clipping-area.\n\nA function, which is called back when the window first appears and whenever the window is re-sized, can be used to ensure consistent aspect ratio between clipping-area and viewport, as shown in the above example. The graphics sub-system passes the window's width and height, in pixels, into the .\n\nWe compute the aspect ratio of the new re-sized window, given its new and provided by the graphics sub-system to the callback function .\n\nWe set the viewport to cover the entire new re-sized window, in pixels. \n\n Try setting the viewport to cover only a quarter (lower-right qradrant) of the window via .\n\nWe set the aspect ratio of the clipping area to match the viewport. To set the clipping area, we first choose the operate on the projection matrix via . OpenGL has two matrices, a projection matrix (which deals with camera projection such as setting the clipping area) and a model-view matrix (for transforming the objects from their local spaces to the common world space). We reset the projection matrix via .\n\nFinally, we invoke to set the clipping area with an aspect ratio matching the viewport. The shorter side has the range from -1 to +1, as illustrated below:\n\nWe need to register the callback handler with GLUT via in the as follows:\n\nIn the above function, we specify the initial window size to , which is non-squarish. Try re-sizing the window and observe the changes.\n\nNote that the runs at least once when the window first appears. It is then called back whenever the window is re-shaped. On the other hand, the runs once (and only once); and the runs in response to window re-paint request (e.g., after the window is re-sized).\n\nIn the above sample, we positioned each of the shapes by defining their vertices with respective to the same origin (called world space). It took me quite a while to figure out the absolute coordinates of these vertices.\n\nInstead, we could position each of the shapes by defining their vertices with respective to their own center (called model space or local space). We can then use translation and/or rotation to position the shapes at the desired locations in the world space, as shown in the following revised function.\n\nTranslation and rotation are parts of so-called model transform, which transform from the objects from the local space (or model space) to the common world space. To carry out model transform, we set the matrix mode to mode-view matrix ( ) and reset the matrix. (Recall that in the previous example, we set the matrix mode to projection matrix ( ) to set the clipping area.)\n\nOpenGL is operating as a state machine. That is, once a state is set, the value of the state persists until it is changed. In other words, once the coordinates are translated or rotated, all the subsequent operations will be based on this coordinates.\n\nTranslation is done via function:\n\nTake note that function must be placed outside the / , where as can be placed inside / .\n\nRotation is done via function:\n\nTake note that the rotational angle is measured in degrees (instead of radians) in OpenGL.\n\nIn the above example, we translate within the x-y plane (z=0) and rotate about the z-axis (which is normal to the x-y plane).\n\nTo perform animation (e.g., rotating the shapes), you could register an callback handler with GLUT, via command. The graphic system will call back the function when there is no other event to be processed.\n\nIn the function, you could issue command to post a window re-paint request, which in turn will activate function.\n\nTake note that the above is equivalent to registering as the function.\n\nDouble buffering uses two display buffers to smoothen animation. The next screen is prepared in a back buffer, while the current screen is held in a front buffer. Once the preparation is done, you can use command to swap the front and back buffers.\n\nTo use double buffering, you need to make two changes:\n• In the , include this line before creating the window:\n• In the function, replace with , which swap the front and back buffers.\n\nDouble buffering should be used in animation. For static display, single buffering is sufficient. (Many graphics hardware always double buffered, so it is hard to see the differences.)\n\nThe following program rotates all the shapes created in our previous example using idle function with double buffering.\n\nIn the above example, instead of accumulating all the translations and undoing the rotations, we use to save the current state, perform transformations, and restore the saved state via . (In the above example, we can also use to reset the matrix before the next transformations.)\n\nWe define a global variable called to keep track of the rotational angle of all the shapes. We will later use to rotate all the shapes to this angle.\n\nAt the end of each refresh (in ), we update the rotational angle of all the shapes.\n\nInstead of which flushes the framebuffer for display immediately, we enable double buffering and use to swap the front- and back-buffer during the VSync for smoother display.\n\nWe define an function, which posts a re-paint request and invoke , if there is no event outstanding. We register this function in via .\n\nWhen double buffering is enabled, synchronizes with the screen refresh interval (VSync). That is, the buffers will be swapped at the same time when the monitor is putting up a new frame. As the result, function, at best, refreshes the animation at the same rate as the refresh rate of the monitor (60Hz for LCD/LED monitor). It may operates at half the monitor refresh rate (if the computations takes more than 1 refresh interval), one-third, one-fourth, and so on, because it need to wait for the VSync.\n\nWith , we have no control to the refresh interval. We could register a function with GLUT via . The function will be called back at the specified fixed interval.\n\nThe following modifications rotate all the shapes created in the earlier example counter-clockwise by 2 degree per 30 milliseconds.\n\nWe replace the function by a function, which post a re-paint request to invoke , after the timer expired.\n\nIn , we register the function, and activate the immediately (with initial timer = 0).\n• : requests a display with the specified mode, such as color mode ( , , ), single/double buffering ( , ), enable depth ( ), joined with a bit ' '.\n\nThis example shows a ball bouncing inside the window. Take note that circle is not a primitive geometric shape in OpenGL. This example uses to compose a circle.\n\nWe can register callback functions to handle keyboard inputs for normal and special keys, respectively.\n• : registers callback handler for special key (such as arrow keys and function keys).\n\nExample 8: Switching between Full-Screen and Windowed-mode ( )\n\nFor the bouncing ball program, the following special-key handler toggles between full-screen and windowed modes using F1 key.\n\n[TODO] Using to draw a Circle is inefficient (due to the compute-intensive and functions). Try using GLU's quadric.\n\nFor the bouncing ball program, the following key and special-key handlers provide exits with ESC (27), increase/decrease y speed with up-/down-arrow key, increase/decrease x speed with left-/right-arrow key, increase/decrease ball's radius with PageUp/PageDown key.\n\nSimilarly, we can register callback function to handle mouse-click and mouse-motion.\n• : registers callback handler for mouse motion (when the mouse is clicked and moved).\n\nFor the bouncing ball program, the following mouse handler pause the movement with left-mouse click, and resume with right-mouse click."
    },
    {
        "link": "https://learn.microsoft.com/en-us/windows/win32/opengl/gltranslatef",
        "document": "The glTranslatef function multiplies the current matrix by a translation matrix.\n\nThis function does not return a value.\n\nThe glTranslatef function produces the translation specified by (x, y, z). The translation vector is used to compute a 4x4 translation matrix:\n\nThe current matrix (see glMatrixMode) is multiplied by this translation matrix, with the product replacing the current matrix. That is, if M is the current matrix and T is the translation matrix, then M is replaced with M T.\n\nIf the matrix mode is either GL_MODELVIEW or GL_PROJECTION, all objects drawn after glTranslatef is called are translated. Use glPushMatrix and glPopMatrix to save and restore the untranslated coordinate system.\n\nThe following functions retrieve information related to glTranslated and glTranslatef:"
    },
    {
        "link": "https://www3.ntu.edu.sg/home/ehchua/programming/opengl/CG_Introduction.html",
        "document": "An Introduction on OpenGL with 2D Graphics\n\nTo set up OpenGL, depending on your programming platform, read:\n• How to write OpenGL programs in C/C++.\n• How to write OpenGL programs in Java: JOGL or LWJGL.\n• How to write OpenGL|ES programs in Android.\n\nExample 1: Setting Up OpenGL and GLUT ( )\n\nMake sure that you can run the \" \" described in \"How to write OpenGL programs in C/C++\", reproduced below:\n\nThe header \" \" is needed for the Windows platform only.\n\nWe also included the GLUT header, which is guaranteed to include \" \" (for GL Utility) and \" \" (for Core OpenGL).\n\nThe rest of the program will be explained in due course.\n\nOpenGL (Open Graphics Library) is a cross-platform, hardware-accelerated, language-independent, industrial standard API for producing 3D (including 2D) graphics. Modern computers have dedicated GPU (Graphics Processing Unit) with its own memory to speed up graphics rendering. OpenGL is the software interface to graphics hardware. In other words, OpenGL graphic rendering commands issued by your applications could be directed to the graphic hardware and accelerated.\n\nWe use 3 sets of libraries in our OpenGL programs:\n• : consists of hundreds of commands, which begin with a prefix \" \" (e.g., , , , ). The Core OpenGL models an object via a set of geometric primitives such as point, line and polygon.\n• : built on-top of the core OpenGL to provide important utilities (such as setting camera view and projection) and more building models (such as qradric surfaces and polygon tessellation). GLU commands start with a prefix \" \" (e.g., , ).\n• : OpenGL is designed to be independent of the windowing system or operating system. GLUT is needed to interact with the Operating System (such as creating a window, handling key and mouse inputs); it also provides more building models (such as sphere and torus). GLUT commands start with a prefix of \" \" (e.g., , ). GLUT is platform independent, which is built on top of platform-specific OpenGL extension such as GLX for X Window System, WGL for Microsoft Window, and AGL, CGL or Cocoa for Mac OS.\n\n Quoting from the opengl.org: \"GLUT is designed for constructing small to medium sized OpenGL programs. While GLUT is well-suited to learning OpenGL and developing simple OpenGL applications, GLUT is not a full-featured toolkit so large applications requiring sophisticated user interfaces are better off using native window system toolkits. GLUT is simple, easy, and small.\"\n\n Alternative of GLUT includes SDL, ....\n• : \"GLEW is a cross-platform open-source C/C++ extension loading library. GLEW provides efficient run-time mechanisms for determining which OpenGL extensions are supported on the target platform.\" Source and pre-build binary available at http://glew.sourceforge.net/. A standalone utility called \" \" (under the \" \" directory) can be used to produce the list of OpenGL functions supported by your graphics system.\n\nTry building and runnng this OpenGL C/C++ program:\n\nThe expected output and the coordinates are as follows. Take note that 4 shapes have pure color, and 2 shapes have color blending from their vertices.\n\nI shall explain the program in the following sections.\n\nOpenGL operates as a state machine, and maintain a set of state variables (such as the foreground color, background color, and many more). In a state machine, once the value of a state variable is set, the value persists until a new value is given.\n\nFor example, we set the \"clearing\" (background) color to black once in . We use this setting to clear the window in the repeatedly ( is called back whenever there is a window re-paint request) - the clearing color is not changed in the entire program.\n\nAnother example: If we use function to set the current foreground color to \"red\", then \"red\" will be used for all the subsequent vertices, until we use another function to change the foreground color.\n\nIn a state machine, everything shall remain until you explicitly change it!\n• begins with lowercase (for core OpenGL), (for OpenGL Utility) or (for OpenGL Utility Toolkit).\n• followed by the purpose of the function, in camel case (initial-capitalized), e.g., to specify the drawing color, to define the position of a vertex.\n• followed by specifications for the parameters, e.g., takes three parameters. takes two parameters. \n\n (This is needed as C Language does not support function overloading. Different versions of the function need to be written for different parameter lists.)\n\nThe convention can be expressed as follows:\n\nThe function may take 2, 3, or 4 parameters, in type of ( ), ( ), ( ) or ( ). The ' ' (for vector) denotes that the parameters are kept in an array of 2, 3, or 4 elements, and pass into the function as an array pointer.\n• Floating-point numbers: (32-bit), (64-bit), and (between 0.0 and 1.0).\n• (unsigned char with 0 for false and non-0 for true).\n\nThe OpenGL types are defined via in \" \" as follows:\n\nOpenGL's constants begins with \" \", \" \" or \" \", in uppercase separated with underscores, e.g., .\n\nThe is meant for carrying out one-time OpenGL initialization tasks, such as setting the clearing color. is invoked once (and only once) in .\n\nThe function is known as a callback event handler. An event handler provides the response to a particular event (such as key-press, mouse-click, window-paint). The function is meant to be the handler for window-paint event. The OpenGL graphics system calls back in response to a window-paint request to re-paint the window (e.g., window first appears, window is restored after minimized, and window is resized). Callback means that the function is invoked by the system, instead of called by the your program.\n\nThe runs when the window first appears and once per subsequent re-paint request. Observe that we included OpenGL graphics rendering code inside the function, so as to re-draw the entire window when the window first appears and upon each re-paint request.\n\nGLUT provides high-level utilities to simplify OpenGL programming, especially in interacting with the Operating System (such as creating a window, handling key and mouse inputs). The following GLUT functions were used in the above program:\n• : initializes GLUT, must be called before other GL/GLUT functions. It takes the same arguments as the .\n• : creates a window with the given title.\n• : specifies the initial window width and height, in pixels.\n• : positions the top-left corner of the initial window at (x, y). The coordinates (x, y), in term of pixels, is measured in window coordinates, i.e., origin (0, 0) is at the top-left corner of the screen; x-axis pointing right and y-axis pointing down.\n• : registers the callback function (or event handler) for handling window-paint event. The OpenGL graphic system calls back this handler when it receives a window re-paint request. In the example, we register the function as the handler.\n• : enters the infinite event-processing loop, i.e, put the OpenGL graphics system to wait for events (such as re-paint), and trigger respective event handlers (such as ).\n\nIn the function of the example:\n\nWe initialize the GLUT and create a window with a title, an initial size and position.\n\nWe register function as the callback handler for window-paint event. That is, runs when the window first appears and whenever there is a request to re-paint the window.\n\nWe call the to perform all the one-time initialization operations. In this example, we set the clearing (background) color once, and use it repeatably in the function.\n\nWe then put the program into the event-handling loop, awaiting for events (such as window-paint request) to trigger off the respective event handlers (such as ).\n\nWe use function to set the foreground color, and function to set the background (or clearing) color.\n• Color is typically specified in in the range and .\n• Color can be specified using RGB (Red-Green-Blue) or RGBA (Red-Green-Blue-Alpha) components. The 'A' (or alpha) specifies the transparency (or opacity) index, with value of 1 denotes opaque (non-transparent and cannot see-thru) and value of 0 denotes total transparent. We shall discuss alpha later.\n\nIn the above example, we set the background color via in , with R=0, G=0, B=0 (black) and A=1 (opaque and cannot see through).\n\nIn , we set the vertex color via for subsequent vertices. For example, R=1, G=0, B=0 (red).\n\nIn OpenGL, an object is made up of geometric primitives such as triangle, quad, line segment and point. A primitive is made up of one or more vertices. OpenGL supports the following primitives:\n\nA geometric primitive is defined by specifying its vertices via function, enclosed within a pair and .\n\nspecifies the type of geometric object, such as , , , , and . For types that end with ' ', you can define multiple objects of the same type in each / pair. For example, for , each set of three 's defines a triangle.\n\nThe vertices are usually specified in precision. It is because integer is not suitable for trigonometric operations (needed to carry out transformations such as rotation). Precision of is sufficient for carrying out intermediate operations, and render the objects finally into pixels on screen (with resolution of says 800x600, integral precision). precision is often not necessary.\n\nIn the above example:\n\nWe set the color to red (R=1, G=0, B=0). All subsequent vertices will have the color of red. Take note that in OpenGL, color (and many properties) is applied to vertices rather than primitive shapes. The color of the a primitive shape is interpolated from its vertices.\n\nWe similarly define a second quad in green.\n\nFor the third quad (as follows), the vertices have different color. The color of the quad surface is interpolated from its vertices, resulting in a shades of white to dark gray, as shown in the output.\n\nThe following diagram shows the OpenGL 2D Coordinate System, which corresponds to the everyday 2D Cartesian coordinates with origin located at the bottom-left corner.\n\nThe default OpenGL 2D clipping-area (i.e., what is captured by the camera) is an orthographic view with x and y in the range of -1.0 and 1.0, i.e., a 2x2 square with centered at the origin. This clipping-area is mapped to the viewport on the screen. Viewport is measured in pixels.\n\nStudy the above example to convince yourself that the 2D shapes created are positioned correctly on the screen.\n\nTry dragging the corner of the window to make it bigger or smaller. Observe that all the shapes are distorted.\n\nWe can handle the re-sizing of window via a callback handler , which can be programmed to adjust the OpenGL clipping-area according to the window's aspect ratio.\n\nClipping Area: Clipping area refers to the area that can be seen (i.e., captured by the camera), measured in OpenGL coordinates.\n\nThe function can be used to set the clipping area of 2D orthographic view. Objects outside the clipping area will be clipped away and cannot be seen.\n\nTo set the clipping area, we need to issue a series of commands as follows: we first select the so-called projection matrix for operation, and reset the projection matrix to identity. We then choose the 2D orthographic view with the desired clipping area, via .\n\nViewport: Viewport refers to the display area on the window (screen), which is measured in pixels in screen coordinates (excluding the title bar).\n\nThe clipping area is mapped to the viewport. We can use function to configure the viewport.\n\nSuppose the the clipping area's (left, right, bottom, top) is (-1.0, 1.0, -1.0, 1.0) (in OpenGL coordinates) and the viewport's (xTopLeft, xTopRight, width, height) is (0, 0, 640, 480) (in screen coordinates in pixels), then the bottom-left corner (-1.0, -1.0) maps to (0, 0) in the viewport, the top-right corner (1.0, 1.0) maps to (639, 479). It is obvious that if the aspect ratios for the clipping area and the viewport are not the same, the shapes will be distorted.\n\nTake note that in the earlier example, the windows' size of 320x320 has a square shape, with a aspect ratio consistent with the default 2x2 squarish clipping-area.\n\nA function, which is called back when the window first appears and whenever the window is re-sized, can be used to ensure consistent aspect ratio between clipping-area and viewport, as shown in the above example. The graphics sub-system passes the window's width and height, in pixels, into the .\n\nWe compute the aspect ratio of the new re-sized window, given its new and provided by the graphics sub-system to the callback function .\n\nWe set the viewport to cover the entire new re-sized window, in pixels. \n\n Try setting the viewport to cover only a quarter (lower-right qradrant) of the window via .\n\nWe set the aspect ratio of the clipping area to match the viewport. To set the clipping area, we first choose the operate on the projection matrix via . OpenGL has two matrices, a projection matrix (which deals with camera projection such as setting the clipping area) and a model-view matrix (for transforming the objects from their local spaces to the common world space). We reset the projection matrix via .\n\nFinally, we invoke to set the clipping area with an aspect ratio matching the viewport. The shorter side has the range from -1 to +1, as illustrated below:\n\nWe need to register the callback handler with GLUT via in the as follows:\n\nIn the above function, we specify the initial window size to , which is non-squarish. Try re-sizing the window and observe the changes.\n\nNote that the runs at least once when the window first appears. It is then called back whenever the window is re-shaped. On the other hand, the runs once (and only once); and the runs in response to window re-paint request (e.g., after the window is re-sized).\n\nIn the above sample, we positioned each of the shapes by defining their vertices with respective to the same origin (called world space). It took me quite a while to figure out the absolute coordinates of these vertices.\n\nInstead, we could position each of the shapes by defining their vertices with respective to their own center (called model space or local space). We can then use translation and/or rotation to position the shapes at the desired locations in the world space, as shown in the following revised function.\n\nTranslation and rotation are parts of so-called model transform, which transform from the objects from the local space (or model space) to the common world space. To carry out model transform, we set the matrix mode to mode-view matrix ( ) and reset the matrix. (Recall that in the previous example, we set the matrix mode to projection matrix ( ) to set the clipping area.)\n\nOpenGL is operating as a state machine. That is, once a state is set, the value of the state persists until it is changed. In other words, once the coordinates are translated or rotated, all the subsequent operations will be based on this coordinates.\n\nTranslation is done via function:\n\nTake note that function must be placed outside the / , where as can be placed inside / .\n\nRotation is done via function:\n\nTake note that the rotational angle is measured in degrees (instead of radians) in OpenGL.\n\nIn the above example, we translate within the x-y plane (z=0) and rotate about the z-axis (which is normal to the x-y plane).\n\nTo perform animation (e.g., rotating the shapes), you could register an callback handler with GLUT, via command. The graphic system will call back the function when there is no other event to be processed.\n\nIn the function, you could issue command to post a window re-paint request, which in turn will activate function.\n\nTake note that the above is equivalent to registering as the function.\n\nDouble buffering uses two display buffers to smoothen animation. The next screen is prepared in a back buffer, while the current screen is held in a front buffer. Once the preparation is done, you can use command to swap the front and back buffers.\n\nTo use double buffering, you need to make two changes:\n• In the , include this line before creating the window:\n• In the function, replace with , which swap the front and back buffers.\n\nDouble buffering should be used in animation. For static display, single buffering is sufficient. (Many graphics hardware always double buffered, so it is hard to see the differences.)\n\nThe following program rotates all the shapes created in our previous example using idle function with double buffering.\n\nIn the above example, instead of accumulating all the translations and undoing the rotations, we use to save the current state, perform transformations, and restore the saved state via . (In the above example, we can also use to reset the matrix before the next transformations.)\n\nWe define a global variable called to keep track of the rotational angle of all the shapes. We will later use to rotate all the shapes to this angle.\n\nAt the end of each refresh (in ), we update the rotational angle of all the shapes.\n\nInstead of which flushes the framebuffer for display immediately, we enable double buffering and use to swap the front- and back-buffer during the VSync for smoother display.\n\nWe define an function, which posts a re-paint request and invoke , if there is no event outstanding. We register this function in via .\n\nWhen double buffering is enabled, synchronizes with the screen refresh interval (VSync). That is, the buffers will be swapped at the same time when the monitor is putting up a new frame. As the result, function, at best, refreshes the animation at the same rate as the refresh rate of the monitor (60Hz for LCD/LED monitor). It may operates at half the monitor refresh rate (if the computations takes more than 1 refresh interval), one-third, one-fourth, and so on, because it need to wait for the VSync.\n\nWith , we have no control to the refresh interval. We could register a function with GLUT via . The function will be called back at the specified fixed interval.\n\nThe following modifications rotate all the shapes created in the earlier example counter-clockwise by 2 degree per 30 milliseconds.\n\nWe replace the function by a function, which post a re-paint request to invoke , after the timer expired.\n\nIn , we register the function, and activate the immediately (with initial timer = 0).\n• : requests a display with the specified mode, such as color mode ( , , ), single/double buffering ( , ), enable depth ( ), joined with a bit ' '.\n\nThis example shows a ball bouncing inside the window. Take note that circle is not a primitive geometric shape in OpenGL. This example uses to compose a circle.\n\nWe can register callback functions to handle keyboard inputs for normal and special keys, respectively.\n• : registers callback handler for special key (such as arrow keys and function keys).\n\nExample 8: Switching between Full-Screen and Windowed-mode ( )\n\nFor the bouncing ball program, the following special-key handler toggles between full-screen and windowed modes using F1 key.\n\n[TODO] Using to draw a Circle is inefficient (due to the compute-intensive and functions). Try using GLU's quadric.\n\nFor the bouncing ball program, the following key and special-key handlers provide exits with ESC (27), increase/decrease y speed with up-/down-arrow key, increase/decrease x speed with left-/right-arrow key, increase/decrease ball's radius with PageUp/PageDown key.\n\nSimilarly, we can register callback function to handle mouse-click and mouse-motion.\n• : registers callback handler for mouse motion (when the mouse is clicked and moved).\n\nFor the bouncing ball program, the following mouse handler pause the movement with left-mouse click, and resume with right-mouse click."
    },
    {
        "link": "https://quora.com/What-exactly-does-glTranslatef-x-y-z-in-OpenGL-do",
        "document": "Something went wrong. Wait a moment and try again."
    },
    {
        "link": "https://khronos.org/opengl/wiki/Viewing_and_Transformations",
        "document": "How does the camera work in OpenGL?\n\nAs far as OpenGL is concerned, there is no camera. More specifically, the camera is always located at the eye space coordinate (0.0, 0.0, 0.0). To give the appearance of moving the camera, your OpenGL application must move the scene with the inverse of the camera transformation by placing it on the MODELVIEW matrix. This is commonly referred to as the viewing transformation.\n\nIn practice this is mathematically equivalent to a camera transformation but more efficient because model transformations and camera transformations are concatenated to a single matrix. As a result though, certain operations must be performed when the camera and only the camera is on the MODELVIEW matrix. For example to position a light source in world space it most be positioned while the viewing transformation and only the viewing transformation is applied to the MODELVIEW matrix.\n\nHow can I move my eye, or camera, in my scene?\n\nOpenGL doesn't provide an interface to do this using a camera model. However, the GLU library provides the gluLookAt() function, which takes an eye position, a position to look at, and an up vector, all in object space coordinates. This function computes the inverse camera transform according to its parameters and multiplies it onto the current matrix stack.\n\nWhere should my camera go, the ModelView or Projection matrix?\n\nThe GL_PROJECTION matrix should contain only the projection transformation calls it needs to transform eye space coordinates into clip coordinates.\n\nThe GL_MODELVIEW matrix, as its name implies, should contain modeling and viewing transformations, which transform object space coordinates into eye space coordinates. Remember to place the camera transformations on the GL_MODELVIEW matrix and never on the GL_PROJECTION matrix.\n\nThink of the projection matrix as describing the attributes of your camera, such as field of view, focal length, fish eye lens, etc. Think of the ModelView matrix as where you stand with the camera and the direction you point it.\n\nThe game dev FAQ has good information on these two matrices.\n\nRead Steve Baker's article on projection abuse. This article is highly recommended and well-written. It's helped several new OpenGL programmers.\n\nA simple method for zooming is to use a uniform scale on the ModelView matrix. However, this often results in clipping by the zNear and zFar clipping planes if the model is scaled too large.\n\nA better method is to restrict the width and height of the view volume in the Projection matrix.\n\nFor example, your program might maintain a zoom factor based on user input, which is a floating-point number. When set to a value of 1.0, no zooming takes place. Larger values result in greater zooming or a more restricted field of view, while smaller values cause the opposite to occur. Code to create this effect might look like:\n\nInstead of gluPerspective(), your application might use glFrustum(). This gets tricky, because the left, right, bottom, and top parameters, along with the zNear plane distance, also affect the field of view. Assuming you desire to keep a constant zNear plane distance (a reasonable assumption), glFrustum() code might look like this:\n\nGiven the current ModelView matrix, how can I determine the object-space location of the camera?\n\nThe \"camera\" or viewpoint is at (0., 0., 0.) in eye space. When you turn this into a vector [0 0 0 1] and multiply it by the inverse of the ModelView matrix, the resulting vector is the object-space location of the camera.\n\nOpenGL doesn't let you inquire (through a glGet* routine) the inverse of the ModelView matrix. You'll need to compute the inverse with your own code.\n\nHow do I make the camera \"orbit\" around a point in my scene?\n\nYou can simulate an orbit by translating/rotating the scene/object and leaving your camera in the same place. For example, to orbit an object placed somewhere on the Y axis, while continuously looking at the origin, you might do this:\n\nIf you insist on physically orbiting the camera position, you'll need to transform the current camera position vector before using it in your viewing transformations.\n\nIn either event, I recommend you investigate gluLookAt() (if you aren't using this routine already).\n\nHow can I automatically calculate a view that displays my entire model? (I know the bounding sphere and up vector.)\n\nThe following is from a posting by Dave Shreiner on setting up a basic viewing system:\n\nFirst, compute a bounding sphere for all objects in your scene. This should provide you with two bits of information: the center of the sphere (let ( c.x, c.y, c.z ) be that point) and its diameter (call it \"diam\").\n\nNext, choose a value for the zNear clipping plane. General guidelines are to choose something larger than, but close to 1.0. So, let's say you set\n\nStructure your matrix calls in this order (for an Orthographic projection):\n\nThis approach should center your objects in the middle of the window and stretch them to fit (i.e., its assuming that you're using a window with aspect ratio = 1.0). If your window isn't square, compute left, right, bottom, and top, as above, and put in the following logic before the call to glOrtho():\n\nThe above code should position the objects in your scene appropriately. If you intend to manipulate (i.e. rotate, etc.), you need to add a viewing transform to it.\n\nA typical viewing transform will go on the ModelView matrix and might look like this:\n\nThis is usually caused by incorrect transformations.\n\nAssuming you are using gluPerspective() on the Projection matrix stack with zNear and zFar as the third and fourth parameters, you need to set gluLookAt on the ModelView matrix stack, and pass parameters so your geometry falls between zNear and zFar.\n\nIt's usually best to experiment with a simple piece of code when you're trying to understand viewing transformations. Let's say you are trying to look at a unit sphere centered on the origin. You'll want to set up your transformations as follows:\n\nIt's important to note how the Projection and ModelView transforms work together.\n\nIn this example, the Projection transform sets up a 50.0-degree field of view with trigonometric functions to add a zoom factor sub-parameter, with an aspect ratio and zoom factor of 1.0. The zNear clipping plane is 3.0 units in front of the eye, and the zFar clipping plane is 7.0 units in front of the eye. This leaves a Z volume distance of 4.0 units, ample room for a unit sphere.\n\nThe ModelView transform sets the eye position at (0.0, 0.0, 5.0), and the look-at point is the origin in the center of our unit sphere. Note that the eye position is 5.0 units away from the look at point. This is important, because a distance of 5.0 units in front of the eye is in the middle of the Z volume that the Projection transform defines. If the gluLookAt() call had placed the eye at (0.0, 0.0, 1.0), it would produce a distance of 1.0 to the origin. This isn't long enough to include the sphere in the view volume, and it would be clipped by the zNear clipping plane.\n\nSimilarly, if you place the eye at (0.0, 0.0, 10.0), the distance of 10.0 to the look at point will result in the unit sphere being 10.0 units away from the eye and far behind the zFar clipping plane placed at 7.0 units.\n\nIf this has confused you, read up on transformations in the OpenGL red book or OpenGL Specification. After you understand object coordinate space, eye coordinate space, and clip coordinate space, the above should become clear. Also, experiment with small test programs. If you're having trouble getting the correct transforms in your main application project, it can be educational to write a small piece of code that tries to reproduce the problem with simpler geometry.\n\nHow do I get a specified point (XYZ) to appear at the center of the scene?\n\ngluLookAt() is the easiest way to do this. Simply set the X, Y, and Z values of your point as the fourth, fifth, and sixth parameters to gluLookAt().\n\nI put my gluLookAt() call on my Projection matrix and now fog, lighting, and texture mapping don't work correctly. What happened?\n\nOften this is caused by placing the transformation on the wrong matrix, look at question 3 for an explanation of this problem. However occasionally, and in particular for lighting, this can be caused because the lights were positioned when the wrong matrix is on the MODELVIEW matrix stack. When a light is positioned in eye space, i.e. relative to the eye, it should be positioned when an identity matrix is on the MODELVIEW stack. When a light is positioned in the world it should be positioned when the viewing matrix is on the MODELVIEW stack. When the light is positioned relative to an object under transformation it should be positioned when that object's model matrix has been multiplied with the viewing matrix on the MODELVIEW stack, remembering that it will have to be positioned before anything lit by it is rendered. If any light moves relative to the eye between frames it must be repositioned each frame using the appropriate matrix.\n\nStereo viewing is accomplished by presenting a different image to the left and right eyes of the viewer. These images must be appropriate for the viewers relationship to the display they are looking at, much moreso than a mono 3D image. In addition the method used is tied closely to the display technology being used. Some graphics systems and display devices support stereo viewing in hardware and support features like left and right framebuffers in addition to the front and back buffers of conventional double buffered systems. Other systems support stereo correctly when two viewports are created in specific screen regions and specific video mode is used to send these to the screen. In conjunction with these modes a viewer often wears glasses either shuttered or polarized to select the displayed image appropriate to each eye. However even without these graphics features a developer can generate stereo views using features like color filtering where colored filters select an image based on red or blue filters and draw left and right eye images to red and blue framebuffer components for example, or even more simply just have multiple systems or graphics cards (or even a single card) generate two entirely separate video signals, for which a separate left and right eye image is drawn. The video is then sent to the appropriate eye either using a display employing polarizing filters or a head mounted display or some other custom display operating on similar principals.\n\nFrom an OpenGL perspective, the requirements of stereo rendering are to use the appropriate setup to render to left and right eyes (be it color masks, separate contexts or different viewports) and then match the geometry of the OpenGL projection to the relationship of the viewer's left and right eyes with the display. The final OpenGL requirement is that the position of the eyes in the 'virtual' world must be given a pupil separation on the modelview stack, this separation would of course be a translation in eye space, but could be calculated in other equivalent ways.\n\nI can't get transformations to work. Where can I learn more about matrices?\n\nA thorough explanation of basic matrix math and linear algebra is beyond the scope of this FAQ. These concepts are taught in high school math classes in the United States.\n\nIf you understand the basics, but just get confused (a common problem even for the experienced!), read through Steve Baker's review of matrix concepts and his article on Euler angles.\n\nFor programming purposes, OpenGL matrices are 16-value arrays with base vectors laid out contiguously in memory. The translation components occupy the 13th, 14th, and 15th elements of the 16-element matrix.\n\nColumn-major versus row-major is purely a notational convention. Note that post-multiplying with column-major matrices produces the same result as pre-multiplying with row-major matrices. The OpenGL Specification and the OpenGL Reference Manual both use column-major notation. You can use any notation, as long as it's clearly stated.\n\nSadly, the use of column-major format in the spec and blue book has resulted in endless confusion in the OpenGL programming community. Column-major notation suggests that matrices are not laid out in memory as a programmer would expect.\n\nA summary of Usenet postings on the subject can be found here.\n\nThe short answer: Anything you want them to be.\n\nDepending on the contents of your geometry database, it may be convenient for your application to treat one OpenGL coordinate unit as being equal to one millimeter or one parsec or anything in between (or larger or smaller).\n\nOpenGL also lets you specify your geometry with coordinates of differing values. For example, you may find it convenient to model an airplane's controls in centimeters, its fuselage in meters, and a world to fly around in kilometers. OpenGL's ModelView matrix can then scale these different coordinate systems into the same eye coordinate space.\n\nIt's the application's responsibility to ensure that the Projection and ModelView matrices are constructed to provide an image that keeps the viewer at an appropriate distance, with an appropriate field of view, and keeps the zNear and zFar clipping planes at an appropriate range. An application that displays molecules in micron scale, for example, would probably not want to place the viewer at a distance of 10 feet with a 60 degree field of view.\n\nHow are coordinates transformed? What are the different coordinate spaces?\n\nObject Coordinates are transformed by the ModelView matrix to produce Eye Coordinates.\n\nEye Coordinates are transformed by the Projection matrix to produce Clip Coordinates.\n\nClip Coordinate X, Y, and Z are divided by Clip Coordinate W to produce Normalized Device Coordinates.\n\nNormalized Device Coordinates are scaled and translated by the viewport parameters to produce Window Coordinates.\n\nObject coordinates are the raw coordinates you submit to OpenGL with a call to glVertex*() or glVertexPointer(). They represent the coordinates of your object or other geometry you want to render.\n\nMany programmers use a World Coordinate system. Objects are often modeled in one coordinate system, then scaled, translated, and rotated into the world you're constructing. World Coordinates result from transforming Object Coordinates by the modelling transforms stored in the ModelView matrix. However, OpenGL has no concept of World Coordinates. World Coordinates are purely an application construct.\n\nEye Coordinates result from transforming Object Coordinates by the ModelView matrix. The ModelView matrix contains both modelling and viewing transformations that place the viewer at the origin with the view direction aligned with the negative Z axis.\n\nClip Coordinates result from transforming Eye Coordinates by the Projection matrix. Clip Coordinate space ranges from -Wc to Wc in all three axes, where Wc is the Clip Coordinate W value. OpenGL clips all coordinates outside this range.\n\nPerspective division performed on the Clip Coordinates produces Normalized Device Coordinates, ranging from -1 to 1 in all three axes.\n\nWindow Coordinates result from scaling and translating Normalized Device Coordinates by the viewport. The parameters to glViewport() and glDepthRange() control this transformation. With the viewport, you can map the Normalized Device Coordinate cube to any location in your window and depth buffer.\n\nFor more information, see the OpenGL Specification, Figure 2.6.\n\nHow do I transform only one object in my scene or give each object its own transform?\n\nOpenGL provides matrix stacks specifically for this purpose. In this case, use the ModelView matrix stack.\n\nA typical OpenGL application first sets the matrix mode with a call to glMatrixMode(GL_MODELVIEW) and loads a viewing transform, perhaps with a call to gluLookAt(). More information is available on gluLookAt().\n\nThen the code renders each object in the scene with its own transformation by wrapping the rendering with calls to glPushMatrix() and glPopMatrix(). For example:\n\nThe above code renders a cylinder rotated 90 degrees around the X-axis. The ModelView matrix is restored to its previous value after the glPopMatrix() call. Similar call sequences can render subsequent objects in the scene.\n\nHow do I draw 2D controls over my 3D rendering?\n\nThe basic strategy is to set up a 2D projection for drawing controls. You can do this either on top of your 3D rendering or in overlay planes. If you do so on top of a 3D rendering, you'll need to redraw the controls at the end of every frame (immediately before swapping buffers). If you draw into the overlay planes, you only need to redraw the controls if you're updating them.\n\nTo set up a 2D projection, you need to change the Projection matrix. Normally, it's convenient to set up the projection so one world coordinate unit is equal to one screen pixel, as follows:\n\ngluOrtho2D() sets up a Z range of -1 to 1, so you need to use one of the glVertex2*() functions to ensure your geometry isn't clipped by the zNear or zFar clipping planes.\n\nNormally, the ModelView matrix is set to the identity when drawing 2D controls, though you may find it convenient to do otherwise (for example, you can draw repeated controls with interleaved translation matrices).\n\nIf exact pixelization is required, you might want to put a small translation in the ModelView matrix, as shown below:\n\nIf you're drawing on top of a 3D-depth buffered image, you'll need to somehow disable depth testing while drawing your 2D geometry. You can do this by calling glDisable(GL_DEPTH_TEST) or glDepthFunc (GL_ALWAYS). Depending on your application, you might also simply clear the depth buffer before starting the 2D rendering. Finally, drawing all 2D geometry with a minimum Z coordinate is also a solution.\n\nAfter the 2D projection is established as above, you can render normal OpenGL primitives to the screen, specifying their coordinates with XY pixel addresses (using OpenGL-centric screen coordinates, with (0,0) in the lower left).\n\nHow do I bypass OpenGL matrix transformations and send 2D coordinates directly for rasterization?\n\nThere isn't a mode switch to disable OpenGL matrix transformations. However, if you set either or both matrices to the identity with a glLoadIdentity() call, typical OpenGL implementations are intelligent enough to know that an identity transformation is a no-op and will act accordingly.\n\nMore detailed information on using OpenGL as a rasterization-only API is in the OpenGL Game Developer’s FAQ.\n\nWhat are the pros and cons of using absolute versus relative coordinates?\n\nSome OpenGL applications may need to render the same object in multiple locations in a single scene. OpenGL lets you do this two ways:\n• Use “absolute coordinates\". Maintain multiple copies of each object, each with its own unique set of vertices. You don't need to change the ModelView matrix to render the object at the desired location.\n• Use “relative coordinates\". Keep only one copy of the object, and render it multiple times by pushing the ModelView matrix stack, setting the desired transform, sending the geometry, and popping the stack. Repeat these steps for each object.\n\nIn general, frequent changes to state, such as to the ModelView matrix, can negatively impact your application’s performance. OpenGL can process your geometry faster if you don't wrap each individual primitive in a lot of changes to the ModelView matrix.\n\nHowever, sometimes you need to weigh this against the memory savings of replicating geometry. Let's say you define a doorknob with high approximation, such as 200 or 300 triangles, and you're modeling a house with 50 doors in it, all of which have the same doorknob. It's probably preferable to use a single doorknob display list, with multiple unique transform matrices, rather than use absolute coordinates with 10-15K triangles in memory.\n\nAs with many computing issues, it's a trade-off between processing time and memory that you'll need to make on a case-by-case basis.\n\nHow can I draw more than one view of the same scene?\n\nYou can draw two views into the same window by using the glViewport() call. Set glViewport() to the area that you want the first view, set your scene’s view, and render. Then set glViewport() to the area for the second view, again set your scene’s view, and render.\n\nYou need to be aware that some operations don't pay attention to the glViewport, such as SwapBuffers and glClear(). SwapBuffers always swaps the entire window. However, you can restrain glClear() to a rectangular window by using the scissor rectangle.\n\nYour application might only allow different views in separate windows. If so, you need to perform a MakeCurrent operation between the two renderings. If the two windows share a context, you need to change the scene’s view as described above. This might not be necessary if your application uses separate contexts for each window.\n\nHow do I transform my objects around a fixed coordinate system rather than the object's local coordinate system?\n\nIf you rotate an object around its Y-axis, you'll find that the X- and Z-axes rotate with the object. A subsequent rotation around one of these axes rotates around the newly transformed axis and not the original axis. It's often desirable to perform transformations in a fixed coordinate system rather than the object’s local coordinate system.\n\nThe OpenGL Game Developer’s FAQ contains information on using quaternions to store rotations, which may be useful in solving this problem.\n\nThe root cause of the problem is that OpenGL matrix operations postmultiply onto the matrix stack, thus causing transformations to occur in object space. To affect screen space transformations, you need to premultiply. OpenGL doesn't provide a mode switch for the order of matrix multiplication, so you need to premultiply by hand. An application might implement this by retrieving the current matrix after each frame. The application multiplies new transformations for the next frame on top of an identity matrix and multiplies the accumulated current transformations (from the last frame) onto those transformations using glMultMatrix().\n\nYou need to be aware that retrieving the ModelView matrix once per frame might have a detrimental impact on your application’s performance. However, you need to benchmark this operation, because the performance will vary from one implementation to the next.\n\nWhat are the pros and cons of using glFrustum() versus gluPerspective()? Why would I want to use one over the other?\n\nglFrustum() and gluPerspective() both produce perspective projection matrices that you can use to transform from eye coordinate space to clip coordinate space. The primary difference between the two is that glFrustum() is more general and allows off-axis projections, while gluPerspective() only produces symmetrical (on-axis) projections. Indeed, you can use glFrustum() to implement gluPerspective(). However, aside from the layering of function calls that is a natural part of the GLU interface, there is no performance advantage to using matrices generated by glFrustum() over gluPerspective().\n\nSince glFrustum() is more general than gluPerspective(), you can use it in cases when gluPerspective() can't be used. Some examples include projection shadows, tiled renderings, and stereo views.\n\nTiled rendering uses multiple off-axis projections to render different sections of a scene. The results are assembled into one large image array to produce the final image. This is often necessary when the desired dimensions of the final rendering exceed the OpenGL implementation's maximum viewport size.\n\nIn a stereo view, two renderings of the same scene are done with the view location slightly shifted. Since the view axis is right between the “eyes”, each view must use a slightly off-axis projection to either side to achieve correct visual results.\n\nHow can I make a call to glFrustum() that matches my call to gluPerspective()?\n\nThe field of view (fov) of your glFrustum() call is:\n\nSince bottom == -top for the symmetrical projection that gluPerspective() produces, then:\n\nNote: fov must be in radians for the above formula to work with the C math library. If you have computer your fov in degrees (as in the call to gluPerspective()), then calculate top as follows:\n\nThe left and right parameters are simply functions of the top, bottom, and aspect:\n\nThe OpenGL Reference Manual (where do I get this?) shows the matrices produced by both functions.\n\nThis question usually means, \"How do I draw a quad that fills the entire OpenGL viewport?\" There are many ways to do this.\n\nThe most straightforward method is to set the desired color, set both the Projection and ModelView matrices to the identity, and call glRectf() or draw an equivalent GL_QUADS primitive. Your rectangle or quad's Z value should be in the range of –1.0 to 1.0, with –1.0 mapping to the zNear clipping plane, and 1.0 to the zFar clipping plane.\n\nAs an example, here's how to draw a full-screen quad at the zNear clipping plane:\n\nYour application might want the quad to have a maximum Z value, in which case 1 should be used for the Z value instead of -1.\n\nWhen painting a full-screen quad, it might be useful to mask off some buffers so that only specified buffers are touched. For example, you might mask off the color buffer and set the depth function to GL_ALWAYS, so only the depth buffer is painted. Also, you can set masks to allow the stencil buffer to be set or any combination of buffers.\n\nHow can I find the screen coordinates for a given object-space coordinate?\n\nYou can use the GLU library gluProject() utility routine if you only need to find it for a few vertices. For a large number of coordinates, it can be more efficient to use the Feedback mechanism.\n\nTo use gluProject(), you'll need to provide the ModelView matrix, projection matrix, viewport, and input object space coordinates. Screen space coordinates are returned for X, Y, and Z, with Z being normalized (0 <= Z <= 1).\n\nHow can I find the object-space coordinates for a pixel on the screen?\n\nThe GLU library provides the gluUnProject() function for this purpose.\n\nYou'll need to read the depth buffer to obtain the input screen coordinate Z value at the X,Y location of interest. This can be coded as follows:\n\nNote that x and y are OpenGL-centric with (0,0) in the lower-left corner.\n\nYou'll need to provide the screen space X, Y, and Z values as input to gluUnProject() with the ModelView matrix, Projection matrix, and viewport that were current at the time the specific pixel of interest was rendered.\n\nHow do I find the coordinates of a vertex transformed only by the ModelView matrix?\n\nIt's often useful to obtain the eye coordinate space value of a vertex (i.e., the object space vertex transformed by the ModelView matrix). You can obtain this by retrieving the current ModelView matrix and performing simple vector / matrix multiplication.\n\nHow do I get the active MODELVIEW or PROJECTION matrices?\n\nHow do I calculate the object-space distance from the viewer to a given point?\n\nTransform the point into eye-coordinate space by multiplying it by the ModelView matrix. Then simply calculate its distance from the origin. (If this doesn't work, you may have incorrectly placed the view transform on the Projection matrix stack.)\n\nAs with any OpenGL call, you must have a context current with a window or drawable in order for glGet*() function calls to work.\n\nHow do I keep my aspect ratio correct after a window resize?\n\nIt depends on how you are setting your projection matrix. In any case, you'll need to know the new dimensions (width and height) of your window. How to obtain these depends on which platform you're using. In GLUT, for example, the dimensions are passed as parameters to the reshape function callback.\n\nThe following assumes you're maintaining a viewport that's the same size as your window. If you are not, substitute viewportWidth and viewportHeight for windowWidth and windowHeight.\n\nIf you're using gluPerspective() to set your Projection matrix, the second parameter controls the aspect ratio in which can be implemented into the first parameter using trigonometric math to re-calculate the FOV changing the aspect direction to extend vertically instead of horizontal as it follows:\n\nFor best results, you might want to use conditional aspect to switch direction if it goes below a specified ratio:\n\nWhen your program catches a window resize, you'll need to change your Projection matrix as follows:\n\nIf you're using glFrustum(), the aspect ratio varies with the width of the view volume to the height of the view volume. You might maintain a 1:1 aspect ratio with the following window resize code:\n\nglOrtho() and gluOrtho2D() are similar to glFrustum().\n\nOpenGL doesn't have a mode switch to change from right- to left-handed coordinates. However, you can easily obtain a left-handed coordinate system by multiplying a negative Z scale onto the ModelView matrix. For example:\n\nHow can I transform an object so that it points at or follows another object or point in my scene?\n\nYou need to construct a matrix that transforms from your object's local coordinate system into a coordinate system that faces in the desired direction. See this example code to see how this type of matrix is created.\n\nIf you merely want to render an object so that it always faces the viewer, you might consider simply rendering it in eye-coordinate space with the ModelView matrix set to the identity.\n\nHow can I transform an object with a given yaw, pitch, and roll?\n\nThe upper left 3x3 portion of a transformation matrix is composed of the new X, Y, and Z axes of the post-transformation coordinate space.\n\nIf the new transform is a roll, compute new local Y and X axes by rotating them \"roll\" degrees around the local Z axis. Do similar calculations if the transform is a pitch or yaw. Then simply construct your transformation matrix by inserting the new local X, Y, and Z axes into the upper left 3x3 portion of an identity matrix. This matrix can be passed as a parameter to glMultMatrix().\n\nFurther rotations should be computed around the new local axes. This will inevitably require rotation about an arbitrary axis, which can be confusing to inexperienced 3D programmers. This is a basic concept in linear algebra.\n\nMany programmers apply all three transformations -- yaw, pitch, and roll -- at once as successive glRotate() calls about the X, Y, and Z axes. This has the disadvantage of creating gimbal lock, in which the result depends on the order of glRotate() calls.\n\nRender your scene twice, once as it is reflected in the mirror, then once from the normal (non-reflected) view. Example code demonstrates this technique.\n\nFor axis-aligned mirrors, such as a mirror on the YZ plane, the reflected scene can be rendered with a simple scale and translate. Scale by -1.0 in the axis corresponding to the mirror's normal, and translate by twice the mirror's distance from the origin. Rendering the scene with these transforms in place will yield the scene reflected in the mirror. Use the matrix stack to restore the view transform to its previous value.\n\nNext, clear the depth buffer with a call to glClear(GL_DEPTH_BUFFER_BIT). Then render the mirror. For a perfectly reflecting mirror, render into the depth buffer only. Real mirrors are not perfect reflectors, as they absorb some light. To create this effect, use blending to render a black mirror with an alpha of 0.05. glBlendFunc(GL_SRC_ALPHA,GL_ONE_MINUS_SRC_ALPHA) is a good blending function for this purpose.\n\nFinally, render the non-reflected scene. Since the entire reflected scene exists in the color buffer, and not just the portion of the reflected scene in the mirror, you will need to touch all pixels to overwrite areas of the reflected scene that should not be visible.\n\nHow can I do my own perspective scaling?\n\nOpenGL multiplies your coordinates by the ModelView matrix, then by the Projection matrix to get clip coordinates. It then performs the perspective divide to obtain normalized device coordinates. It's the perspective division step that creates a perspective rendering, with geometry in the distance appearing smaller than the geometry in the foreground. The perspective division stage is accomplished by dividing your XYZ clipping coordinate values by the clipping coordinate W value, such as:\n\nTo do your own perspective correction, you need to obtain the clipping coordinate W value. The feedback buffer provides homogenous coordinates with XYZ in device coordinates and W in clip coordinates. You might also glGetFloatv(GL_CURRENT_RASTER_POSITION,…) and the W value will again be in clipping coordinates, while XYZ are in device coordinates."
    },
    {
        "link": "https://campar.in.tum.de/twiki/pub/Chair/TeachingWs10CPP/OpenGL_TransformationsViewingLight.pdf",
        "document": ""
    },
    {
        "link": "https://learn.microsoft.com/en-us/windows/win32/opengl/glscalef",
        "document": "The glScaled and glScalef functions multiply the current matrix by a general scaling matrix.\n\nThis function does not return a value.\n\nThe following error code can be retrieved by the glGetError function.\n\nThe glScalef function produces a general scaling along the x, y, and z axes. The three arguments indicate the desired scale factors along each of the three axes. The resulting matrix appears in the following image.\n\nThe current matrix (see glMatrixMode) is multiplied by this scale matrix, with the product replacing the current matrix. That is, if M is the current matrix and S is the scale matrix, then M is replaced with M S.\n\nIf the matrix mode is either GL_MODELVIEW or GL_PROJECTION, all objects drawn after glScalef is called are scaled. Use glPushMatrix and glPopMatrix to save and restore the unscaled coordinate system.\n\nIf scale factors other than 1.0 are applied to the modelview matrix and lighting is enabled, automatic normalization of normals should probably also be enabled (glEnable and glDisable with argument GL_NORMALIZE).\n\nThe following functions retrieve information related to glScalef:"
    },
    {
        "link": "https://community.khronos.org/t/scaling-one-object/30934",
        "document": "I have a scene with several lights,walls,floors, etc and several objects. I would like to scale just one of the objects (which is made of several pieces) uniformly along the 3 axes, but without affecting any of the remaining objects in the scene and without changing the position where the object is located\n\n Where should I put the glscalef instruction? Do I need to push and pop before appliying it?"
    },
    {
        "link": "https://stackoverflow.com/questions/35397631/how-to-simply-scale-an-object-in-opengl",
        "document": "With your current coordiantes and transformations, your object is just off the screen.\n\nWhen setting all transformation matrices to identity, you are directly drawing in clip space. And if you do never use an input value other than 1 ( will always set to 1), clip space equals normalized device space. In normalized device space, the viewing volume is defined as the cube [-1,1] along all dimensions.\n\nHowever, by applying , you scale the object by 2, with the center beeing the origin. As a result, the visible part of the scene is everything in the range [-0.5,0.5] in object space coordinates, and your object is completely outside of that range.\n\nIf you want to scale on a single object, you should first translate it to the center, and apply the scale afterwards. The following sequence of transformations should make your object visible:\n\nAlso note that all of that is deprecated in modern GL. You are relying on the fixed function pipeline with the integrated matrix stack, immediate mode (Begin/End) rendering, primitive type, which is all removed from modern core profiles of OpenGL. If you are starting with GL nowadyays, I strongly recommend learning the new way."
    },
    {
        "link": "https://stackoverflow.com/questions/36635824/how-to-scale-a-model-in-opengl",
        "document": "Scaling is one of the three transformations you can do to the model matrix, along with translating and rotating.\n\nThe model matrix is one of the three matrices that transforms vertices to pixels on your screen, along with the view and projection matrices.\n\nSince the type of scaling you want only applies to the model matrix, we'll skip the other two for now. I do however recommend reading up on all three and how they interact as they are essential to OpenGL.\n\nBefore we begin I suggest picking up a library such as GLM as it will do a lot of the heavy lifting for us. From here on I will use GLM syntax to keep things concise.\n\nFirst let's store our scale in a 3d vector:\n\nNow we need a basic model matrix with no transformations:\n\nNow we can apply the scale to our model matrix:\n\nNow we've got a matrix that can be applied to any set of vertices and scale them by 10 in all three dimensions.\n\nNext we need to get this information to the shader. Just like how glVertexAttribPointer tells the shader where to find vertex attributes, we're going to use glUniform to send our matrix:\n\nHere we're querying the shader for the location of the \"model\" uniform. Then we're submitting 1 uniform matrix (our ) to that location.\n\nFinally we need to use that matrix in the shader. Here is a super simple vertex shader that does what we need:\n\nNormally we'd pass the normal and uv information along to the fragment shader but I am omitting that for now to keep things simple.\n\nThat is it. Hopefully this gets you where you're trying to go.\n\nOn a side note, the function is deprecated in GL3 and newer. I like using docs.gl as a reference since it differentiates between versions.\n\nThe code I posted above was just the source for a vertex shader, which is only one part of a greater shader program. A shader program can have a vertex shader, geometry shader, and fragment shader. For now though we'll just focus on the two required ones; vertex and fragment shaders.\n\nFirst put the vertex shader code above into a file named . Loading a file is outside the scope of this answer so I'll just assume you have a function called that takes a single argument, the filename.\n\nNext we have to build the fragment shader. Put the following code into another file called :\n\nThis fragment shader will make every fragment it processes the color green. Now let's compile it just like we did the vertex shader:\n\nNow we've got two compiled shaders. It is time to link them together into a shader program:\n\nYou'll want to do all of this prior to calling as it needs to communicate with the shader program you've built.\n\nI recommend using the following function after every GL function call when trying to troubleshoot a problem:\n\nOpenGL is a complicated state machine and you'll want to know as soon as something isn't right."
    },
    {
        "link": "https://community.khronos.org/t/looking-for-glscalef-examples/25145",
        "document": "I guess I am looking more for some Web sites that would show the before and after. Do you know of any? Right now, I am getting a black screen when I try to add a line like you mentioned (except I have 0 in last arg). I comment out and my drawing returns. I am trying to expand it.\n\nglScale just multiplies the following X,Y and Z coordinates by the amount specified in the glScale command. Thats one of the simplest commands in OpenGL, why dont you just RTFM first?\n\nI’ll continue to post on here since I still can’t expand even with the last arg as 1 and hope that DOH! goes away Given that the following is within a display routine, what am I doing incorrectly?\n\nUnfortunately, that’s not really an option. I am already provided with a main function containing: prior to the call to the display routine and need to maintain this “format”\n\nPerhaps you can start by saying what you don’t understand with DOH!'s post? Or parhaps you can start by saying what you don’t understand from TFM ?\n\nAccording to the site you’ve linked, I really should have got an GL_INVALID_OPERATION error for the code I posted above but I didn’t. I wonder why. Anyways, is it mandatory then for me to use the push and pop around the scaling to see the effect? I need to maintain the code from the main function that I posted above in resolving this problem.\n\nAccording to the site you’ve linked, I really should have got an GL_INVALID_OPERATION error for the code I posted above but I didn’t. I wonder why. Assuming you got your error reading code correct, it’s most likely a driver bug. Anyways, is it mandatory then for me to use the push and pop around the scaling to see the effect? You could do that. You could also rescale by the inverse: Either way will be fine. Using push/pop, or reloading hte matrix would ensure that you don’t run into precision problems by continuously rescaling.\n\nThe code in your outer loop is setting the projection matrix, you are scaling the modelview matrix, and you don’t clear it out, so every frame, you are going to be scaling again. (OpenGL is a state machine, the state of the modelview matrix won’t change unless you change it.) So, frame 1, you scale by 13,13. Frame 2, you will now be scaling 1313, 1313. Frame 3, 131313, 131313, etc… as you can see, you will quickly be scaling this up. Edit: I guess your code never set the matrix mode to GL_MODELVIEW like it should have so you are scaling the GL_PROJECTION matrix, which in itself is usually a no no. [This message has been edited by Deiussum (edited 09-04-2003).]\n\nThe code you gave didn’t show anywhere where you were checking for errors. To get errors, you need to actually check for them using glGetError(). The compiler won’t help you with this, and no exceptions will be thrown."
    }
]