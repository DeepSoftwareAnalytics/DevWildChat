[
    {
        "link": "https://docs.python.org/3/library/socket.html",
        "document": "This module provides access to the BSD socket interface. It is available on all modern Unix systems, Windows, MacOS, and probably additional platforms.\n\nThe Python interface is a straightforward transliteration of the Unix system call and library interface for sockets to Python’s object-oriented style: the function returns a socket object whose methods implement the various socket system calls. Parameter types are somewhat higher-level than in the C interface: as with and operations on Python files, buffer allocation on receive operations is automatic, and buffer length is implicit on send operations.\n\nDepending on the system and the build options, various socket families are supported by this module. The address format required by a particular socket object is automatically selected based on the address family specified when the socket object was created. Socket addresses are represented as follows:\n• None The address of an socket bound to a file system node is represented as a string, using the file system encoding and the error handler (see PEP 383). An address in Linux’s abstract namespace is returned as a bytes-like object with an initial null byte; note that sockets in this namespace can communicate with normal file system sockets, so programs intended to run on Linux may need to deal with both types of address. A string or bytes-like object can be used for either type of address when passing it as an argument. Changed in version 3.3: Previously, socket paths were assumed to use UTF-8 encoding. Changed in version 3.5: Writable bytes-like object is now accepted.\n• None A pair is used for the address family, where host is a string representing either a hostname in internet domain notation like or an IPv4 address like , and port is an integer.\n• None For IPv4 addresses, two special forms are accepted instead of a host address: represents , which is used to bind to all interfaces, and the string represents . This behavior is not compatible with IPv6, therefore, you may want to avoid these if you intend to support IPv6 with your Python programs.\n• None For address family, a four-tuple is used, where flowinfo and scope_id represent the and members in in C. For module methods, flowinfo and scope_id can be omitted just for backward compatibility. Note, however, omission of scope_id can cause problems in manipulating scoped IPv6 addresses. Changed in version 3.7: For multicast addresses (with scope_id meaningful) address may not contain (or ) part. This information is superfluous and may be safely omitted (recommended).\n• None Linux-only support for TIPC is available using the address family. TIPC is an open, non-IP based networked protocol designed for use in clustered computer environments. Addresses are represented by a tuple, and the fields depend on the address type. The general tuple form is , where:\n• None addr_type is one of , , or .\n• None scope is one of , , and .\n• None If addr_type is , then v1 is the server type, v2 is the port identifier, and v3 should be 0. If addr_type is , then v1 is the server type, v2 is the lower port number, and v3 is the upper port number. If addr_type is , then v1 is the node, v2 is the reference, and v3 should be set to 0.\n• None A tuple is used for the address family, where interface is a string representing a network interface name like . The network interface name can be used to receive packets from all network interfaces of this family.\n• None protocol require a tuple where both additional parameters are unsigned long integer that represent a CAN identifier (standard or extended).\n• None protocol require a tuple where additional parameters are 64-bit unsigned integer representing the ECU name, a 32-bit unsigned integer representing the Parameter Group Number (PGN), and an 8-bit integer representing the address.\n• None A string or a tuple is used for the protocol of the family. The string is the name of a kernel control using a dynamically assigned ID. The tuple can be used if ID and unit number of the kernel control are known or if a registered ID is used.\n• None supports the following protocols and address formats:\n• None accepts where is the Bluetooth address as a string and is an integer.\n• None accepts where is the Bluetooth address as a string and is an integer.\n• None accepts where is either an integer or a string with the Bluetooth address of the interface. (This depends on your OS; NetBSD and DragonFlyBSD expect a Bluetooth address while everything else expects an integer.)\n• None accepts where is a object containing the Bluetooth address in a string format. (ex. ) This protocol is not supported under FreeBSD.\n• None is a Linux-only socket based interface to Kernel cryptography. An algorithm socket is configured with a tuple of two to four elements , where:\n• None type is the algorithm type as string, e.g. , , or .\n• None name is the algorithm name and operation mode as string, e.g. , , or .\n• None allows communication between virtual machines and their hosts. The sockets are represented as a tuple where the context ID or CID and port are integers.\n• None is a low-level interface directly to network devices. The addresses are represented by the tuple where:\n• None ifname - String specifying the device name.\n• None proto - The Ethernet protocol number. May be to capture all protocols, one of the ETHERTYPE_* constants or any other Ethernet protocol number.\n• \n• None (the default) - Packet addressed to the local host.\n• None - Packet to some other host that has been caught by a device driver in promiscuous mode.\n• None - Packet originating from the local host that is looped back to a packet socket.\n• None addr - Optional bytes-like object specifying the hardware physical address, whose interpretation depends on the device.\n• None is a Linux-only socket based interface for communicating with services running on co-processors in Qualcomm platforms. The address family is represented as a tuple where the node and port are non-negative integers.\n• None is a variant of UDP which allows you to specify what portion of a packet is covered with the checksum. It adds two socket options that you can change. will change what portion of outgoing packets are covered by the checksum and will filter out packets which cover too little of their data. In both cases should be in . Such a socket should be constructed with for IPv4 or for IPv6.\n• None is a Windows-only socket based interface for communicating with Hyper-V hosts and guests. The address family is represented as a tuple where the and are UUID strings. The is the virtual machine identifier or a set of known VMID values if the target is not a specific virtual machine. Known VMID constants defined on are:\n• None - Used to bind on itself and accept connections from all partitions.\n• None - Used to bind on itself and accept connection from child partitions.\n• None - Used as a target to itself.\n• None - When used as a bind accepts connection from the parent partition. When used as an address target it will connect to the parent partition. The is the service identifier of the registered service. If you use a hostname in the host portion of IPv4/v6 socket address, the program may show a nondeterministic behavior, as Python uses the first address returned from the DNS resolution. The socket address will be resolved differently into an actual IPv4/v6 address, depending on the results from DNS resolution and/or the host configuration. For deterministic behavior use a numeric address in host portion. All errors raise exceptions. The normal exceptions for invalid argument types and out-of-memory conditions can be raised. Errors related to socket or address semantics raise or one of its subclasses. Non-blocking mode is supported through . A generalization of this based on timeouts is supported through .\n\nHere are four minimal example programs using the TCP/IP protocol: a server that echoes all data that it receives back (servicing only one client), and a client using it. Note that a server must perform the sequence , , , (possibly repeating the to service more than one client), while a client only needs the sequence , . Also note that the server does not / on the socket it is listening on but on the new socket returned by . The first two examples support IPv4 only. # Symbolic name meaning all available interfaces # The same port as used by the server The next two examples are identical to the above two, but support both IPv4 and IPv6. The server side will listen to the first address family available (it should listen to both instead). On most of IPv6-ready systems, IPv6 will take precedence and the server may not accept IPv4 traffic. The client side will try to connect to all the addresses returned as a result of the name resolution, and sends traffic to the first one connected successfully. # Symbolic name meaning all available interfaces # The same port as used by the server The next example shows how to write a very simple network sniffer with raw sockets on Windows. The example requires administrator privileges to modify the interface: # create a raw socket and bind it to the public interface The next example shows how to use the socket interface to communicate to a CAN network using the raw socket protocol. To use CAN with the broadcast manager protocol instead, open a socket with: After binding ( ) or connecting ( ) the socket, you can use the and operations (and their counterparts) on the socket object as usual. This last example might require special privileges: # CAN frame packing/unpacking (see 'struct can_frame' in <linux/can.h>) # create a raw socket and bind it to the 'vcan0' interface Running an example several times with too small delay between executions, could lead to this error: This is because the previous execution has left the socket in a state, and can’t be immediately reused. There is a flag to set, in order to prevent this, : the flag tells the kernel to reuse a local socket in state, without waiting for its natural timeout to expire. For an introduction to socket programming (in C), see the following papers:\n• None An Advanced 4.3BSD Interprocess Communication Tutorial, by Samuel J. Leffler et al, both in the UNIX Programmer’s Manual, Supplementary Documents 1 (sections PS1:7 and PS1:8). The platform-specific reference material for the various socket-related system calls are also a valuable source of information on the details of socket semantics. For Unix, refer to the manual pages; for Windows, see the WinSock (or Winsock 2) specification. For IPv6-ready APIs, readers may want to refer to RFC 3493 titled Basic Socket Interface Extensions for IPv6."
    },
    {
        "link": "https://docs.python.org/3/howto/sockets.html",
        "document": "I’m only going to talk about INET (i.e. IPv4) sockets, but they account for at least 99% of the sockets in use. And I’ll only talk about STREAM (i.e. TCP) sockets - unless you really know what you’re doing (in which case this HOWTO isn’t for you!), you’ll get better behavior and performance from a STREAM socket than anything else. I will try to clear up the mystery of what a socket is, as well as some hints on how to work with blocking and non-blocking sockets. But I’ll start by talking about blocking sockets. You’ll need to know how they work before dealing with non-blocking sockets. Part of the trouble with understanding these things is that “socket” can mean a number of subtly different things, depending on context. So first, let’s make a distinction between a “client” socket - an endpoint of a conversation, and a “server” socket, which is more like a switchboard operator. The client application (your browser, for example) uses “client” sockets exclusively; the web server it’s talking to uses both “server” sockets and “client” sockets. Of the various forms of , sockets are by far the most popular. On any given platform, there are likely to be other forms of IPC that are faster, but for cross-platform communication, sockets are about the only game in town. They were invented in Berkeley as part of the BSD flavor of Unix. They spread like wildfire with the internet. With good reason — the combination of sockets with INET makes talking to arbitrary machines around the world unbelievably easy (at least compared to other schemes).\n\nRoughly speaking, when you clicked on the link that brought you to this page, your browser did something like the following: # now connect to the web server on port 80 - the normal http port When the completes, the socket can be used to send in a request for the text of the page. The same socket will read the reply, and then be destroyed. That’s right, destroyed. Client sockets are normally only used for one exchange (or a small set of sequential exchanges). What happens in the web server is a bit more complex. First, the web server creates a “server socket”: # bind the socket to a public host, and a well-known port A couple things to notice: we used so that the socket would be visible to the outside world. If we had used or we would still have a “server” socket, but one that was only visible within the same machine. specifies that the socket is reachable by any address the machine happens to have. A second thing to note: low number ports are usually reserved for “well known” services (HTTP, SNMP etc). If you’re playing around, use a nice high number (4 digits). Finally, the argument to tells the socket library that we want it to queue up as many as 5 connect requests (the normal max) before refusing outside connections. If the rest of the code is written properly, that should be plenty. Now that we have a “server” socket, listening on port 80, we can enter the mainloop of the web server: # now do something with the clientsocket # in this case, we'll pretend this is a threaded server There’s actually 3 general ways in which this loop could work - dispatching a thread to handle , create a new process to handle , or restructure this app to use non-blocking sockets, and multiplex between our “server” socket and any active s using . More about that later. The important thing to understand now is this: this is all a “server” socket does. It doesn’t send any data. It doesn’t receive any data. It just produces “client” sockets. Each is created in response to some other “client” socket doing a to the host and port we’re bound to. As soon as we’ve created that , we go back to listening for more connections. The two “clients” are free to chat it up - they are using some dynamically allocated port which will be recycled when the conversation ends. If you need fast IPC between two processes on one machine, you should look into pipes or shared memory. If you do decide to use AF_INET sockets, bind the “server” socket to . On most platforms, this will take a shortcut around a couple of layers of network code and be quite a bit faster.\n\nThe first thing to note, is that the web browser’s “client” socket and the web server’s “client” socket are identical beasts. That is, this is a “peer to peer” conversation. Or to put it another way, as the designer, you will have to decide what the rules of etiquette are for a conversation. Normally, the ing socket starts the conversation, by sending in a request, or perhaps a signon. But that’s a design decision - it’s not a rule of sockets. Now there are two sets of verbs to use for communication. You can use and , or you can transform your client socket into a file-like beast and use and . The latter is the way Java presents its sockets. I’m not going to talk about it here, except to warn you that you need to use on sockets. These are buffered “files”, and a common mistake is to something, and then for a reply. Without a in there, you may wait forever for the reply, because the request may still be in your output buffer. Now we come to the major stumbling block of sockets - and operate on the network buffers. They do not necessarily handle all the bytes you hand them (or expect from them), because their major focus is handling the network buffers. In general, they return when the associated network buffers have been filled ( ) or emptied ( ). They then tell you how many bytes they handled. It is your responsibility to call them again until your message has been completely dealt with. When a returns 0 bytes, it means the other side has closed (or is in the process of closing) the connection. You will not receive any more data on this connection. Ever. You may be able to send data successfully; I’ll talk more about this later. A protocol like HTTP uses a socket for only one transfer. The client sends a request, then reads a reply. That’s it. The socket is discarded. This means that a client can detect the end of the reply by receiving 0 bytes. But if you plan to reuse your socket for further transfers, you need to realize that there is no on a socket. I repeat: if a socket or returns after handling 0 bytes, the connection has been broken. If the connection has not been broken, you may wait on a forever, because the socket will not tell you that there’s nothing more to read (for now). Now if you think about that a bit, you’ll come to realize a fundamental truth of sockets: messages must either be fixed length (yuck), or be delimited (shrug), or indicate how long they are (much better), or end by shutting down the connection. The choice is entirely yours, (but some ways are righter than others). Assuming you don’t want to end the connection, the simplest solution is a fixed length message: The sending code here is usable for almost any messaging scheme - in Python you send strings, and you can use to determine its length (even if it has embedded characters). It’s mostly the receiving code that gets more complex. (And in C, it’s not much worse, except you can’t use if the message has embedded s.) The easiest enhancement is to make the first character of the message an indicator of message type, and have the type determine the length. Now you have two s - the first to get (at least) that first character so you can look up the length, and the second in a loop to get the rest. If you decide to go the delimited route, you’ll be receiving in some arbitrary chunk size, (4096 or 8192 is frequently a good match for network buffer sizes), and scanning what you’ve received for a delimiter. One complication to be aware of: if your conversational protocol allows multiple messages to be sent back to back (without some kind of reply), and you pass an arbitrary chunk size, you may end up reading the start of a following message. You’ll need to put that aside and hold onto it, until it’s needed. Prefixing the message with its length (say, as 5 numeric characters) gets more complex, because (believe it or not), you may not get all 5 characters in one . In playing around, you’ll get away with it; but in high network loads, your code will very quickly break unless you use two loops - the first to determine the length, the second to get the data part of the message. Nasty. This is also when you’ll discover that does not always manage to get rid of everything in one pass. And despite having read this, you will eventually get bit by it! In the interests of space, building your character, (and preserving my competitive position), these enhancements are left as an exercise for the reader. Lets move on to cleaning up. It is perfectly possible to send binary data over a socket. The major problem is that not all machines use the same formats for binary data. For example, network byte order is big-endian, with the most significant byte first, so a 16 bit integer with the value would be the two hex bytes . However, most common processors (x86/AMD64, ARM, RISC-V), are little-endian, with the least significant byte first - that same would be . Socket libraries have calls for converting 16 and 32 bit integers - where “n” means network and “h” means host, “s” means short and “l” means long. Where network order is host order, these do nothing, but where the machine is byte-reversed, these swap the bytes around appropriately. In these days of 64-bit machines, the ASCII representation of binary data is frequently smaller than the binary representation. That’s because a surprising amount of the time, most integers have the value 0, or maybe 1. The string would be two bytes, while a full 64-bit integer would be 8. Of course, this doesn’t fit well with fixed-length messages. Decisions, decisions.\n\nStrictly speaking, you’re supposed to use on a socket before you it. The is an advisory to the socket at the other end. Depending on the argument you pass it, it can mean “I’m not going to send anymore, but I’ll still listen”, or “I’m not listening, good riddance!”. Most socket libraries, however, are so used to programmers neglecting to use this piece of etiquette that normally a is the same as . So in most situations, an explicit is not needed. One way to use effectively is in an HTTP-like exchange. The client sends a request and then does a . This tells the server “This client is done sending, but can still receive.” The server can detect “EOF” by a receive of 0 bytes. It can assume it has the complete request. The server sends a reply. If the completes successfully then, indeed, the client was still receiving. Python takes the automatic shutdown a step further, and says that when a socket is garbage collected, it will automatically do a if it’s needed. But relying on this is a very bad habit. If your socket just disappears without doing a , the socket at the other end may hang indefinitely, thinking you’re just being slow. Please your sockets when you’re done. Probably the worst thing about using blocking sockets is what happens when the other side comes down hard (without doing a ). Your socket is likely to hang. TCP is a reliable protocol, and it will wait a long, long time before giving up on a connection. If you’re using threads, the entire thread is essentially dead. There’s not much you can do about it. As long as you aren’t doing something dumb, like holding a lock while doing a blocking read, the thread isn’t really consuming much in the way of resources. Do not try to kill the thread - part of the reason that threads are more efficient than processes is that they avoid the overhead associated with the automatic recycling of resources. In other words, if you do manage to kill the thread, your whole process is likely to be screwed up.\n\nIf you’ve understood the preceding, you already know most of what you need to know about the mechanics of using sockets. You’ll still use the same calls, in much the same ways. It’s just that, if you do it right, your app will be almost inside-out. In Python, you use to make it non-blocking. In C, it’s more complex, (for one thing, you’ll need to choose between the BSD flavor and the almost indistinguishable POSIX flavor , which is completely different from ), but it’s the exact same idea. You do this after creating the socket, but before using it. (Actually, if you’re nuts, you can switch back and forth.) The major mechanical difference is that , , and can return without having done anything. You have (of course) a number of choices. You can check return code and error codes and generally drive yourself crazy. If you don’t believe me, try it sometime. Your app will grow large, buggy and suck CPU. So let’s skip the brain-dead solutions and do it right. In C, coding is fairly complex. In Python, it’s a piece of cake, but it’s close enough to the C version that if you understand in Python, you’ll have little trouble with it in C: You pass three lists: the first contains all sockets that you might want to try reading; the second all the sockets you might want to try writing to, and the last (normally left empty) those that you want to check for errors. You should note that a socket can go into more than one list. The call is blocking, but you can give it a timeout. This is generally a sensible thing to do - give it a nice long timeout (say a minute) unless you have good reason to do otherwise. In return, you will get three lists. They contain the sockets that are actually readable, writable and in error. Each of these lists is a subset (possibly empty) of the corresponding list you passed in. If a socket is in the output readable list, you can be as-close-to-certain-as-we-ever-get-in-this-business that a on that socket will return something. Same idea for the writable list. You’ll be able to send something. Maybe not all you want to, but something is better than nothing. (Actually, any reasonably healthy socket will return as writable - it just means outbound network buffer space is available.) If you have a “server” socket, put it in the potential_readers list. If it comes out in the readable list, your will (almost certainly) work. If you have created a new socket to to someone else, put it in the potential_writers list. If it shows up in the writable list, you have a decent chance that it has connected. Actually, can be handy even with blocking sockets. It’s one way of determining whether you will block - the socket returns as readable when there’s something in the buffers. However, this still doesn’t help with the problem of determining whether the other end is done, or just busy with something else. Portability alert: On Unix, works both with the sockets and files. Don’t try this on Windows. On Windows, works with sockets only. Also note that in C, many of the more advanced socket options are done differently on Windows. In fact, on Windows I usually use threads (which work very, very well) with my sockets."
    },
    {
        "link": "https://realpython.com/python-sockets",
        "document": "Socket programming is essential for network communication, enabling data exchange across different devices. In Python, sockets allow for inter-process communication (IPC) over networks. This tutorial provides a comprehensive guide on creating socket servers and clients, handling multiple connections, and managing errors in Python’s module.\n\nBy the end of this tutorial, you’ll understand that:\n• A socket in Python is an endpoint for sending or receiving data across a network using the socket API.\n• Socket programming in Python involves using sockets to establish communication between a server and clients over a network.\n• A simple echo server in Python can be created using sockets to listen for client connections and echo back received messages.\n• Handling multiple clients with Python sockets can be achieved using non-blocking sockets and the module for concurrent connections.\n• Connection errors in socket programs in Python can be managed by implementing error handling and using exceptions like .\n\nAlong the way, you’ll learn about the main functions and methods in Python’s module that let you write your own client-server applications based on TCP sockets. You’ll learn how to reliably send messages and data between endpoints and handle multiple connections simultaneously.\n\nNetworking and sockets are large subjects. Literal volumes have been written about them. If you’re new to sockets or networking, it’s completely normal if you feel overwhelmed with all of the terms and pieces. To get the most out of this tutorial, it’s best to download the source code and have it on hand for reference while reading:\n\nNow that you’ve gotten an overview of the socket API and how the client and server communicate, you’re ready to create your first client and server. You’ll begin with a simple implementation. The server will simply echo whatever it receives back to the client. Here’s the source code of the server: # Port to listen on (non-privileged ports are > 1023) Don’t worry about understanding everything above right now. There’s a lot going on in these few lines of code. This is just a starting point so you can see a basic server in action. Note: There’s a reference section at the end of this tutorial that has more information and links to additional resources. You’ll also find these and other useful links throughout the tutorial. Okay, so what exactly is happening in the API call? creates a socket object that supports the context manager type, so you can use it in a statement. There’s no need to call : # Use the socket object without calling s.close(). The arguments passed to are constants used to specify the address family and socket type. is the Internet address family for IPv4. is the socket type for TCP, the protocol that will be used to transport messages in the network. The method is used to associate the socket with a specific network interface and port number: The values passed to depend on the address family of the socket. In this example, you’re using (IPv4). So it expects a two-tuple: . can be a hostname, IP address, or empty string. If an IP address is used, should be an IPv4-formatted address string. The IP address is the standard IPv4 address for the loopback interface, so only processes on the host will be able to connect to the server. If you pass an empty string, the server will accept connections on all available IPv4 interfaces. represents the TCP port number to accept connections on from clients. It should be an integer from to , as is reserved. Some systems may require superuser privileges if the port number is less than . Here’s a note on using hostnames with : If you use a hostname in the host portion of IPv4/v6 socket address, the program may show a non-deterministic behavior, as Python uses the first address returned from the DNS resolution. The socket address will be resolved differently into an actual IPv4/v6 address, depending on the results from DNS resolution and/or the host configuration. For deterministic behavior use a numeric address in host portion. (Source) You’ll learn more about this later, in Using Hostnames. For now, just understand that when using a hostname, you could see different results depending on what’s returned from the name resolution process. These results could be anything. The first time you run your application, you might get the address . The next time, you get a different address, . The third time, you could get , and so on. In the server example, enables a server to accept connections. It makes the server a listening socket: The method has a parameter. It specifies the number of unaccepted connections that the system will allow before refusing new connections. Starting in Python 3.5, it’s optional. If not specified, a default value is chosen. If your server receives a lot of connection requests simultaneously, increasing the value may help by setting the maximum length of the queue for pending connections. The maximum value is system dependent. For example, on Linux, see . The method blocks execution and waits for an incoming connection. When a client connects, it returns a new socket object representing the connection and a tuple holding the address of the client. The tuple will contain for IPv4 connections or for IPv6. See Socket Address Families in the reference section for details on the tuple values. One thing that’s imperative to understand is that you now have a new socket object from . This is important because it’s the socket that you’ll use to communicate with the client. It’s distinct from the listening socket that the server is using to accept new connections: After provides the client socket object , an infinite loop is used to loop over blocking calls to . This reads whatever data the client sends and echoes it back using . If returns an empty object, , that signals that the client closed the connection and the loop is terminated. The statement is used with to automatically close the socket at the end of the block. Now, it’s time to look at the client’s source code: # The port used by the server In comparison to the server, the client is pretty simple. It creates a socket object, uses to connect to the server and calls to send its message. Lastly, it calls to read the server’s reply and then prints it. In this section, you’ll run the client and server to see how they behave and inspect what’s happening. Note: If you’re having trouble getting the examples or your own code to run from the command line, read How Do I Make My Own Command-Line Commands Using Python? or How to Run Your Python Scripts. If you’re on Windows, check the Python Windows FAQ. Open a terminal or command prompt, navigate to the directory that contains your scripts, ensure that you have Python 3.6 or above installed and on your path, then run the server: Your terminal will appear to hang. That’s because the server is blocked, or suspended, on : It’s waiting for a client connection. Now, open another terminal window or command prompt and run the client: In the server window, you should notice something like this: In the output above, the server printed the tuple returned from . This is the client’s IP address and TCP port number. The port number, , will most likely be different when you run it on your machine. To see the current state of sockets on your host, use . It’s available by default on macOS, Linux, and Windows. Here’s the netstat output from macOS after starting the server: Notice that is . If had used instead of , netstat would show this: is , which means all available host interfaces that support the address family will be used to accept incoming connections. In this example, was used (IPv4) in the call to . You can see this in the column: . The output above is trimmed to show the echo server only. You’ll likely see much more output, depending on the system you’re running it on. The things to notice are the columns , , and . In the last example above, netstat shows that the echo server is using an IPv4 TCP socket ( ), on port 65432 on all interfaces ( ), and it’s in the listening state ( ). Another way to access this, along with additional helpful information, is to use (list open files). It’s available by default on macOS and can be installed on Linux using your package manager, if it’s not already: gives you the , (process ID), and (user ID) of open Internet sockets when used with the option. Above is the echo server process. and have a lot of options available and differ depending on the OS that you’re running them on. Check the page or documentation for both. They’re definitely worth spending a little time with and getting to know. You’ll be rewarded. On macOS and Linux, use and . For Windows, use . Here’s a common error that you’ll encounter when a connection attempt is made to a port with no listening socket: Either the specified port number is wrong or the server isn’t running. Or maybe there’s a firewall in the path that’s blocking the connection, which can be easy to forget about. You may also see the error . Get a firewall rule added that allows the client to connect to the TCP port! There’s a list of common errors in the reference section.\n\nThe echo server definitely has its limitations. The biggest one is that it serves only one client and then exits. The echo client has this limitation too, but there’s an additional problem. When the client uses , it’s possible that it will return only one byte, from : The argument of used above is the maximum amount of data to be received at once. It doesn’t mean that will return bytes. The method also behaves this way. It returns the number of bytes sent, which may be less than the size of the data passed in. You’re responsible for checking this and calling as many times as needed to send all of the data: Applications are responsible for checking that all data has been sent; if only some of the data was transmitted, the application needs to attempt delivery of the remaining data. (Source) In the example above, you avoided having to do this by using : Unlike send(), this method continues to send data from bytes until either all data has been sent or an error occurs. is returned on success. (Source) You have two problems at this point:\n• How do you handle multiple connections concurrently?\n• You need to call and until all data is sent or received. What can you do? There are many approaches to concurrency. A popular approach is to use Asynchronous I/O. was introduced into the standard library in Python 3.4. The traditional choice is to use threads. The trouble with concurrency is it’s hard to get right. There are many subtleties to consider and guard against. All it takes is for one of these to manifest itself and your application may suddenly fail in not-so-subtle ways. This isn’t meant to scare you away from learning and using concurrent programming. If your application needs to scale, it’s a necessity if you want to use more than one processor or one core. However, for this tutorial, you’ll use something that’s even more traditional than threads and easier to reason about. You’re going to use the granddaddy of system calls: . The method allows you to check for I/O completion on more than one socket. So you can call to see which sockets have I/O ready for reading and/or writing. But this is Python, so there’s more. You’re going to use the selectors module in the standard library so that the most efficient implementation is used, regardless of the operating system you happen to be running on: This module allows high-level and efficient I/O multiplexing, built upon the select module primitives. Users are encouraged to use this module instead, unless they want precise control over the OS-level primitives used. (Source) Still, by using , you’re not able to run concurrently. That said, depending on your workload, this approach may still be plenty fast. It depends on what your application needs to do when it services a request, and the number of clients it needs to support. uses single-threaded cooperative multitasking and an event loop to manage tasks. With , you’ll be writing your own version of an event loop, albeit more simply and synchronously. When using multiple threads, even though you have concurrency, you currently have to use the GIL (Global Interpreter Lock) with CPython and PyPy. This effectively limits the amount of work you can do in parallel anyway. This is all to say that using may be a perfectly fine choice. Don’t feel like you have to use , threads, or the latest asynchronous library. Typically, in a network application, your application is I/O bound anyway: it could be waiting on the local network, for endpoints on the other side of the network, for disk writes, and so forth. If you’re getting requests from clients that initiate CPU bound work, look at the concurrent.futures module. It contains the class ProcessPoolExecutor, which uses a pool of processes to execute calls asynchronously. If you use multiple processes, the operating system is able to schedule your Python code to run in parallel on multiple processors or cores, without the GIL. For ideas and inspiration, see the PyCon talk John Reese - Thinking Outside the GIL with AsyncIO and Multiprocessing - PyCon 2018. In the next section, you’ll look at examples of a server and client that address these problems. They use to handle multiple connections simultaneously and call and as many times as needed.\n\nIn the next two sections, you’ll create a server and client that handles multiple connections using a object created from the selectors module. First, turn your attention to the multi-connection server. The first part sets up the listening socket: The biggest difference between this server and the echo server is the call to to configure the socket in non-blocking mode. Calls made to this socket will no longer block. When it’s used with , as you’ll see below, you can wait for events on one or more sockets and then read and write data when it’s ready. registers the socket to be monitored with for the events that you’re interested in. For the listening socket, you want read events: . To store whatever arbitrary data you’d like along with the socket, you’ll use . It’s returned when returns. You’ll use to keep track of what’s been sent and received on the socket. blocks until there are sockets ready for I/O. It returns a list of tuples, one for each socket. Each tuple contains a and a . The is a SelectorKey that contains a attribute. is the socket object, and is an event mask of the operations that are ready. If is , then you know it’s from the listening socket and you need to accept the connection. You’ll call your own function to get the new socket object and register it with the selector. You’ll look at that in a moment. If is not , then you know it’s a client socket that’s already been accepted, and you need to service it. is then called with and as arguments, and that’s everything you need to operate on the socket. Here’s what your function does: # Should be ready to read Because the listening socket was registered for the event , it should be ready to read. You call and then call to put the socket in non-blocking mode. Remember, this is the main objective in this version of the server because you don’t want it to block. If it blocks, then the entire server is stalled until it returns. That means other sockets are left waiting even though the server isn’t actively working. This is the dreaded “hang” state that you don’t want your server to be in. Next, you create an object to hold the data that you want included along with the socket using a . Because you want to know when the client connection is ready for reading and writing, both of those events are set with the bitwise OR operator: # Should be ready to read The mask, socket, and data objects are then passed to . Now take a look at to see how a client connection is handled when it’s ready: # Should be ready to read # Should be ready to write This is the heart of the simple multi-connection server. is the returned from that contains the socket object ( ) and data object. contains the events that are ready. If the socket is ready for reading, then will evaluate to , so is called. Any data that’s read is appended to so that it can be sent later. Note the block to check if no data is received: # Should be ready to read # Should be ready to write If no data is received, this means that the client has closed their socket, so the server should too. But don’t forget to call before closing, so it’s no longer monitored by . When the socket is ready for writing, which should always be the case for a healthy socket, any received data stored in is echoed to the client using . The bytes sent are then removed from the send buffer: # Should be ready to write The method returns the number of bytes sent. This number can then be used with slice notation on the buffer to discard the bytes sent. Now take a look at the multi-connection client, . It’s very similar to the server, but instead of listening for connections, it starts by initiating connections via : is read from the command-line and is the number of connections to create to the server. Just like the server, each socket is set to non-blocking mode. You use instead of because would immediately raise a exception. The method initially returns an error indicator, , instead of raising an exception that would interfere with the connection in progress. Once the connection is completed, the socket is ready for reading and writing and is returned by . After the socket is set up, the data you want to store with the socket is created using . The messages that the client will send to the server are copied using because each connection will call and modify the list. Everything needed to keep track of what the client needs to send, has sent, and has received, including the total number of bytes in the messages, is stored in the object . Check out the changes made from the server’s for the client’s version: def service_connection(key, mask): sock = key.fileobj data = key.data if mask & selectors.EVENT_READ: recv_data = sock.recv(1024) # Should be ready to read if recv_data: + if not recv_data or data.recv_total == data.msg_total: sel.unregister(sock) sock.close() if mask & selectors.EVENT_WRITE: + if not data.outb and data.messages: if data.outb: sent = sock.send(data.outb) # Should be ready to write data.outb = data.outb[sent:] It’s fundamentally the same but for one important difference. The client keeps track of the number of bytes it’s received from the server so that it can close its side of the connection. When the server detects this, it closes its side of the connection too. By doing this, the server depends on the client being well-behaved: the server expects the client to close its side of the connection when it’s done sending messages. If the client doesn’t close, the server will leave the connection open. In a real application, you may want to guard against this in your server by implementing a timeout to prevent client connections from accumulating if they don’t send a request after a certain amount of time. Now it’s time to run and . They both use command-line arguments. You can run them without arguments to see the options. For the server, pass and numbers: For the client, also pass the number of connections to create to the server, : Below is the server output when listening on the loopback interface on port 65432: python multiconn-server.py .0.0.1 Echoing b'Message 1 from client.Message 2 from client.' to ('127.0.0.1', 61354) Echoing b'Message 1 from client.Message 2 from client.' to ('127.0.0.1', 61355) Below is the client output when it creates two connections to the server above: python multiconn-client.py .0.0.1 Received b'Message 1 from client.Message 2 from client.' from connection 1 Received b'Message 1 from client.Message 2 from client.' from connection 2 Great! Now you’ve run the multi-connection client and server. In the next section, you’ll take this example even further.\n\nThe multi-connection client and server example is definitely an improvement compared with where you started. However, now you can take one more step and address the shortcomings of the previous example in a final implementation: the application client and server. You want a client and server that handle errors appropriately so that other connections aren’t affected. Obviously, your client or server shouldn’t come crashing down in a ball of fury if an exception isn’t caught. This is something you haven’t had to worry about until now, because the examples have intentionally left out error handling for brevity and clarity. Now that you’re familiar with the basic API, non-blocking sockets, and , you can add some error handling and address the elephant in the room, which the examples have kept hidden from you behind that large curtain over there. Remember that custom class that was mentioned way back in the introduction? That’s what you’re going to explore next. All errors raise exceptions. The normal exceptions for invalid argument types and out-of-memory conditions can be raised; starting from Python 3.3, errors related to socket or address semantics raise or one of its subclasses. (Source) So, one thing you need to do is catch . Another important consideration in relation to errors is timeouts. You’ll see them discussed in many places in the documentation. Timeouts happen and are a so-called normal error. Hosts and routers are rebooted, switch ports go bad, cables go bad, cables get unplugged, you name it. You should be prepared for these and other errors, handling them in your code. What about the elephant in the room? As hinted by the socket type , when using TCP, you’re reading from a continuous stream of bytes. It’s like reading from a file on disk, but instead you’re reading bytes from the network. However, unlike reading a file, there’s no . In other words, you can’t reposition the socket pointer, if there was one, and move around the data. When bytes arrive at your socket, there are network buffers involved. Once you’ve read them, they need to be saved somewhere, or else you will have dropped them. Calling again reads the next stream of bytes available from the socket. You’ll be reading from the socket in chunks. So, you need to call and save the data in a buffer until you’ve read enough bytes to have a complete message that makes sense to your application. It’s up to you to define and keep track of where the message boundaries are. As far as the TCP socket is concerned, it’s just sending and receiving raw bytes to and from the network. It knows nothing about what those raw bytes mean. This is why you need to define an application-layer protocol. What’s an application-layer protocol? Put simply, your application will send and receive messages. The format of these messages are your application’s protocol. In other words, the length and format that you choose for these messages define the semantics and behavior of your application. This is directly related to what you learned in the previous paragraph regarding reading bytes from the socket. When you’re reading bytes with , you need to keep up with how many bytes were read, and figure out where the message boundaries are. How can you do this? One way is to always send fixed-length messages. If they’re always the same size, then it’s easy. When you’ve read that number of bytes into a buffer, then you know you have one complete message. However, using fixed-length messages is inefficient for small messages where you’d need to use padding to fill them out. Also, you’re still left with the problem of what to do about data that doesn’t fit into one message. In this tutorial, you’ll learn a generic approach, one that’s used by many protocols, including HTTP. You’ll prefix messages with a header that includes the content length as well as any other fields you need. By doing this, you’ll only need to keep up with the header. Once you’ve read the header, you can process it to determine the length of the message’s content. With the content length, you can then read that number of bytes to consume it. You’ll implement this by creating a custom class that can send and receive messages that contain text or binary data. You can improve and extend this class for your own applications. The most important thing is that you’ll be able to see an example of how this is done. Before you get started, there’s something you need to know regarding sockets and bytes. As you learned earlier, when sending and receiving data via sockets, you’re sending and receiving raw bytes. If you receive data and want to use it in a context where it’s interpreted as multiple bytes, for example a 4-byte integer, you’ll need to take into account that it could be in a format that’s not native to your machine’s CPU. The client or server on the other end could have a CPU that uses a different byte order than your own. If this is the case, then you’ll need to convert it to your host’s native byte order before using it. This byte order is referred to as a CPU’s endianness. See Byte Endianness in the reference section for details. You’ll avoid this issue by taking advantage of Unicode for your message header and using the encoding UTF-8. Since UTF-8 uses an 8-bit encoding, there are no byte ordering issues. You can find an explanation in Python’s Encodings and Unicode documentation. Note that this applies to the text header only. You’ll use an explicit type and encoding defined in the header for the content that’s being sent, the message payload. This will allow you to transfer any data that you’d like (text or binary), in any format. You can easily determine the byte order of your machine by using . For example, you could see something like this: If you run this in a virtual machine that emulates a big-endian CPU (PowerPC), then something like this happens: In this example application, your application-layer protocol defines the header as Unicode text with a UTF-8 encoding. For the actual content in the message, the message payload, you’ll still have to swap the byte order manually if needed. This will depend on your application and whether or not it needs to process multi-byte binary data from a machine with a different endianness. You can help your client or server implement binary support by adding additional headers and using them to pass parameters, similar to HTTP. Don’t worry if this doesn’t make sense yet. In the next section, you’ll see how all of this works and fits together. Now you’ll fully define the protocol header. The protocol header is: The required headers, or sub-headers, in the protocol header’s dictionary are as follows: The byte order of the machine (uses ). This may not be required for your application. The length of the content in bytes. The type of content in the payload, for example, or . The encoding used by the content, for example, for Unicode text or for binary data. These headers inform the receiver about the content in the payload of the message. This allows you to send arbitrary data while providing enough information so that the content can be decoded and interpreted correctly by the receiver. Because the headers are in a dictionary, it’s easy to add additional headers by inserting key-value pairs as needed. There’s still a bit of a problem. You have a variable-length header, which is nice and flexible, but how do you know the length of the header when reading it with ? When you previously learned about using and message boundaries, you also learned that fixed-length headers can be inefficient. That’s true, but you’re going to use a small, 2-byte, fixed-length header to prefix the JSON header that contains its length. You can think of this as a hybrid approach to sending messages. In effect, you’re bootstrapping the message receive process by sending the length of the header first. This makes it easy for your receiver to deconstruct the message. To give you a better idea of the message format, check out a message in its entirety: A message starts with a fixed-length header of two bytes, which is an integer in network byte order. This is the length of the next header, the variable-length JSON header. Once you’ve read two bytes with , then you know you can process the two bytes as an integer and then read that number of bytes before decoding the UTF-8 JSON header. The JSON header contains a dictionary of additional headers. One of those is , which is the number of bytes of the message’s content (not including the JSON header). Once you’ve called and read bytes, then you’ve reached a message boundary, meaning you’ve read an entire message. Finally, the payoff! In this section, you’ll study the class and see how it’s used with when read and write events happen on the socket. This example application reflects what types of messages a client and server could reasonably use. You’re far beyond toy echo clients and servers at this point! To keep things simple and still demonstrate how things would work in a real application, this example uses an application protocol that implements a basic search feature. The client sends a search request and the server does a lookup for a match. If the request sent by the client isn’t recognized as a search, the server assumes it’s a binary request and returns a binary response. After reading the following sections, running the examples, and experimenting with the code, you’ll see how things work. You can then use the class as a starting point and modify it for your own use. The application is not that far off from the client and server example. The event loop code stays the same in and . What you’re going to do is move the message code into a class named and add methods to support reading, writing, and processing of the headers and content. This is a great example for using a class. As you learned before and you’ll see below, working with sockets involves keeping state. By using a class, you keep all of the state, data, and code bundled together in an organized unit. An instance of the class is created for each socket in the client and server when a connection is started or accepted. The class is mostly the same for both the client and the server for the wrapper and utility methods. They start with an underscore, like . These methods simplify working with the class. They help other methods by allowing them to stay shorter and support the DRY principle. The server’s class works in essentially the same way as the client’s and vice-versa. The difference is that the client initiates the connection and sends a request message, followed by processing the server’s response message. Conversely, the server waits for a connection, processes the client’s request message, and then sends a response message. With that, you should have a high-level overview of the individual components and their roles within the application. Understanding how the class works can be a challenge because there’s an aspect of its design that might not be immediately obvious. Why? Managing state. After a object is created, it’s associated with a socket that’s monitored for events using : # Should be ready to read The key idea here is that each object is created when a new connection is accepted. It’s associated with a socket and registered with a selector to monitor for incoming events. This setup allows the server to handle multiple connections concurrently, ensuring that messages can be read as soon as they’re available. Note: Some of the code examples in this section are from the server’s main script and class, but this section and discussion applies equally to the client as well. You’ll be alerted when the client’s version differs. When events are ready on the socket, they’re returned by . You can then get a reference back to the message object using the attribute on the object and call a method in : Looking at the event loop above, you’ll see that is in the driver’s seat. It’s blocking, waiting at the top of the loop for events. It’s responsible for waking up when read and write events are ready to be processed on the socket. Which means, indirectly, it’s also responsible for calling the method . That’s why is the entry point. Here’s what the method does: That’s good: is simple. It can only do two things: call and . This is where managing state comes in. If another method depended on state variables having a certain value, then they would only be called from and . This keeps the logic as simple as possible as events come in on the socket for processing. You might be tempted to use a mix of some methods that check the current state variables and, depending on their value, call other methods to process data outside or . In the end, this would likely prove too complex to manage and keep up with. You should definitely modify the class to suit your own needs so that it works best for you. But, you’ll probably have the best results if you keep the state checks and the calls to methods that depend on that state to the and methods if possible. Now look at . This is the server’s version, but the client’s is the same. It just uses a different method name, instead of : The method is called first. It calls to read data from the socket and store it in a receive buffer. Remember that when is called, all of the data that makes up a complete message may not have arrived yet. may need to be called again. This is why there are state checks for each part of the message before the appropriate method to process it is called. Before a method processes its part of the message, it first checks to make sure enough bytes have been read into the receive buffer. If they have, it processes its respective bytes, removes them from the buffer and writes its output to a variable that’s used by the next processing stage. Because there are three components to a message, there are three state checks and method calls: Next, check out . This is the server’s version: The method checks first for a . If one exists and a response hasn’t been created, is called. The method sets the state variable and writes the response to the send buffer. The method calls if there’s data in the send buffer. Remember that when is called, all of the data in the send buffer may not have been queued for transmission. The network buffers for the socket may be full, and may need to be called again. This is why there are state checks. The method should only be called once, but it’s expected that will need to be called multiple times. The client version of is similar: # Set selector to listen for read events, we're done writing. Because the client initiates a connection to the server and sends a request first, the state variable is checked. If a request hasn’t been queued, it calls . The method creates the request and writes it to the send buffer. It also sets the state variable so that it’s only called once. Just like for the server, calls if there’s data in the send buffer. The notable difference in the client’s version of is the last check to see if the request has been queued. This will be explained more in the section Client Main Script, but the reason for this is to tell to stop monitoring the socket for write events. If the request has been queued and the send buffer is empty, then you’re done writing and you’re only interested in read events. There’s no reason to be notified that the socket is writable. To wrap up this section, consider this thought: the main purpose of this section was to explain that is calling into the class via the method and to describe how state is managed. This is important because will be called many times over the life of the connection. Therefore, make sure that any methods that should only be called once are either checking a state variable themselves, or the state variable set by the method is checked by the caller. In the server’s main script , arguments are read from the command line that specify the interface and port to listen on: For example, to listen on the loopback interface on port , enter: Use an empty string for to listen on all interfaces. After creating the socket, a call is made to with the option : # Avoid bind() exception: OSError: [Errno 48] Address already in use Setting this socket option avoids the error Address already in use . You’ll see this when starting the server on a port that has connections in the TIME_WAIT state. For example, if the server actively closed a connection, it’ll remain in the state for two minutes or more, depending on the operating system. If you try to start the server again before the state expires, then you’ll get an exception of Address already in use . This is a safeguard to make sure that any delayed packets in the network aren’t delivered to the wrong application. The event loop catches any errors so that the server can stay up and continue to run: When a client connection is accepted, a object is created: # Should be ready to read The object is associated with the socket in the call to and is initially set to be monitored for read events only. Once the request has been read, you’ll modify it to listen for write events only. An advantage of taking this approach in the server is that in most cases, when a socket is healthy and there are no network issues, it’ll always be writable. If you told to also monitor , then the event loop would immediately wake up and notify you that this is the case. However, at this point, there’s no reason to wake up and call on the socket. There’s no response to send, because a request hasn’t been processed yet. This would consume and waste valuable CPU cycles. In the section Message Entry Point, you learned how the object was called into action when socket events were ready via . Now you’ll learn what happens as data is read on the socket and a component, or piece, of the message is ready to be processed by the server. The server’s message class is in , which is part of the source code you downloaded earlier. You can also download the code by clicking the link below: Get Your Code: Click here to get the free sample code you’ll use to learn about socket programming in Python. The methods appear in the class in the order in which processing takes place for a message. When the server has read at least two bytes, the fixed-length header can be processed: The fixed-length header is a 2-byte integer in network, or big-endian, byte order. It contains the length of the JSON header. You’ll use to read the value, decode it, and store it in . After processing the piece of the message it’s responsible for, removes it from the receive buffer. Just like with the fixed-length header, when there’s enough data in the receive buffer to contain the JSON header, it can be processed as well: The method is called to decode and deserialize the JSON header into a dictionary. Because the JSON header is defined as Unicode with a UTF-8 encoding, is hardcoded in the call. The result is saved to . After processing the piece of the message that it’s responsible for, removes it from the receive buffer. Next is the actual content, or payload, of the message. It’s described by the JSON header in . When bytes are available in the receive buffer, the request can be processed: # Set selector to listen for write events, we're done reading. After saving the message content to the variable, removes it from the receive buffer. Then, if the content type is JSON, decodes and deserializes it. If it’s not, this example application assumes that it’s a binary request and simply prints the content type. The last thing does is modify the selector to monitor write events only. In the server’s main script, , the socket is initially set to monitor read events only. Now that the request has been fully processed, you’re no longer interested in reading. A response can now be created and written to the socket. When the socket is writable, is called from : A response is created by calling other methods, depending on the content type. In this example application, a simple dictionary lookup is done for JSON requests when . For your own applications, you can define other methods that get called here. After creating the response message, the state variable is set so that doesn’t call again. Finally, the response is appended to the send buffer. This is seen by and sent via . One tricky bit to figure out is how to close the connection after the response is written. You can put the call to in the method : # Should be ready to write # Close when the buffer is drained. The response has been sent. Although it’s somewhat hidden, this is an acceptable trade-off given that the class only handles one message per connection. After the response is written, there’s nothing left for the server to do. It’s completed its work. In the client’s main script, , arguments are read from the command line and used to create requests and start connections to the server: After creating a dictionary representing the request from the command-line arguments, the host, port, and request dictionary are passed to : A socket is created for the server connection, as well as a object using the dictionary. Like for the server, the object is associated with the socket in the call to . However, for the client, the socket is initially set to be monitored for both read and write events. Once the request has been written, you’ll modify it to listen for read events only. This approach gives you the same advantage as the server: not wasting CPU cycles. After the request has been sent, you’re no longer interested in write events, so there’s no reason to wake up and process them. In the section Message Entry Point, you learned how the message object was called into action when socket events were ready via . Now you’ll learn what happens after data is read and written on the socket and a message is ready to be processed by the client. The client’s message class is in , which is part of the source code you downloaded earlier. You can also download the code by clicking the link below: Get Your Code: Click here to get the free sample code you’ll use to learn about socket programming in Python. The methods appear in the class in the order in which processing takes place for a message. The first task for the client is to queue the request: The dictionaries used to create the request, depending on what was passed on the command line, are in the client’s main script, . The request dictionary is passed as an argument to the class when a object is created. The request message is created and appended to the send buffer, which is then seen by and sent via . The state variable is set so that isn’t called again. After the request has been sent, the client waits for a response from the server. The methods for reading and processing a message in the client are the same as for the server. As response data is read from the socket, the header methods are called: and . The difference is in the naming of the final methods and the fact that they’re processing a response, not creating one: , , and . Last, but certainly not least, is the final call for : # Close when response has been processed Okay. You can now wrap the message class up. To conclude your learning about the class, it’s worth mentioning a couple of things that are important to notice with a few of the supporting methods. Any exceptions raised by the class are caught by the main script in the clause inside the event loop: # Check for a socket being monitored to continue. This is a really important line, for more than one reason! Not only does it make sure that the socket is closed, but also removes the socket from being monitored by . This greatly simplifies the code in the class and reduces complexity. If there’s an exception or you explicitly raise one yourself, you know will take care of the cleanup. The methods and also contain something interesting: # Should be ready to read The method has one too. These lines are important because they catch a temporary error and skip over it using . The temporary error is when the socket would block, for example if it’s waiting on the network or the other end of the connection, also known as its peer. By catching and skipping over the exception with , will eventually trigger a new call, and you’ll get another chance to read or write the data. After all of this hard work, it’s time to have some fun and run some searches! In these examples, you’ll run the server so that it listens on all interfaces by passing an empty string for the argument. This will allow you to run the client and connect from a virtual machine that’s on another network. It emulates a big-endian PowerPC machine. Now run the client and enter a search. See if you can find him: You might notice that the terminal is running a shell that’s using a text encoding of Unicode (UTF-8), so the output above prints nicely with emojis. Now see if you can find the puppies: Notice the byte string sent over the network for the request in the line. It’s easier to see if you look for the bytes printed in hex that represent the puppy emoji: . If your terminal is using Unicode with the encoding UTF-8, you’ll be able to enter the emoji for the search. This demonstrates that you’re sending raw bytes over the network and they need to be decoded by the receiver to be interpreted correctly. This is why you went to all of the trouble to create a header that contains the content type and encoding. Here’s the server output from both client connections above: python app-server.py Sending b'\\x00g{\"byteorder\": \"little\", \"content-type\": \"text/json\", \"content-encoding\": \"utf-8\", \"content-length\": 43}{\"result\": \"Follow the white rabbit. \\xf0\\x9f\\x90\\xb0\"}' to ('10.0.2.2', 55340) Look at the line to see the bytes that were written to the client’s socket. This is the server’s response message. You can also test sending binary requests to the server if the argument is anything other than : Because the request’s is not , the server treats it as a custom binary type and doesn’t perform JSON decoding. It simply prints the and returns the first ten bytes to the client: python app-server.py Sending b'\\x00\\x7f{\"byteorder\": \"little\", \"content-type\": \"binary/custom-server-binary-type\", \"content-encoding\": \"binary\", \"content-length\": 37}First 10 bytes of request: binary\\xf0\\x9f\\x98\\x83' to ('10.0.2.2', 55320) If everything is working as expected, you’re all set! However, if you run into any issues along the way, don’t worry. Here’s some guidance to help you get back on track.\n\nInevitably, something won’t work, and you’ll be wondering what to do. Don’t worry, it happens to everyone. Hopefully, with the help of this tutorial, your debugger, and your favorite search engine, you’ll be able to get going again with the source code part. If not, your first stop should be Python’s socket module documentation. Make sure you read all of the documentation for each function or method you’re calling. Also, read through the Reference section below for ideas. In particular, check the Errors section. Sometimes, it’s not all about the source code. The source code might be correct, and it’s just the other host, the client, or server. Or it could be the network. Maybe a router, firewall, or some other networking device is playing man-in-the-middle. For these types of issues, additional tools are essential. Below are a few tools and utilities that might help or at least provide some clues. will check if a host is alive and connected to the network by sending an ICMP echo request. It communicates directly with the operating system’s TCP/IP protocol stack, so it works independently from any application running on the host. Below is an example of running ping on macOS: Note the statistics at the end of the output. This can be helpful when you’re trying to discover intermittent connectivity problems. For example, is there any packet loss? How much latency is there? You can check the round-trip times. If there’s a firewall between you and the other host, a ping’s echo request may not be allowed. Some firewall administrators implement policies that enforce this. The idea is that they don’t want their hosts to be discoverable. If this is the case and you have firewall rules added to allow the hosts to communicate, then make sure that the rules also allow ICMP to pass between them. ICMP is the protocol used by , but it’s also the protocol TCP and other lower-level protocols use to communicate error messages. If you’re experiencing strange behavior or slow connections, this could be the reason. ICMP messages are identified by type and code. To give you an idea of the important information they carry, here are a few: See the article Path MTU Discovery for information regarding fragmentation and ICMP messages. This is an example of something that can cause strange behavior. In the section Viewing Socket State, you learned how can be used to display information about sockets and their current state. This utility is available on macOS, Linux, and Windows. That section didn’t mention the columns and in the example output. These columns will show you the number of bytes that are held in network buffers that are queued for transmission or receipt, but for some reason haven’t been read or written by the remote or local application. In other words, the bytes are waiting in network buffers in the operating system’s queues. One reason could be that the application is CPU bound or is otherwise unable to call or and process the bytes. Or there could be network issues affecting communications, like congestion or failing network hardware or cabling. To demonstrate this and see how much data you can send before seeing an error, you can try out a test client that connects to a test server and repeatedly calls . The test server never calls . It just accepts the connection. This causes the network buffers on the server to fill, which eventually raises an error on the client. Then run the client to see what the error is: Here’s output from while the client and server are still running, with the client printing out the error message above multiple times: The first entry is the server ( has port 65432): The second entry is the client ( has port 65432): The client sure was trying to write bytes, but the server wasn’t reading them. This caused the server’s network buffer queue to fill on the receive side and the client’s network buffer queue to fill on the send side. If you work with Windows, there’s a suite of utilities that you should definitely check out if you haven’t already: Windows Sysinternals. One of them is . TCPView is a graphical for Windows. In addition to addresses, port numbers, and socket state, it’ll show you running totals for the number of packets and bytes sent and received: Like with the Unix utility , you also get the process name and ID. Check the menus for other display options. Sometimes you need to see what’s happening on the wire. Forget about what the application log says or what the value is that’s being returned from a library call. You want to see what’s actually being sent or received on the network. Just like with debuggers, when you need to see it, there’s no substitute. Wireshark is a network protocol analyzer and traffic capture application that runs on macOS, Linux, and Windows, among others. There’s a GUI version named and also a terminal, text-based version named . Running a traffic capture is a great way to watch how an application behaves on the network and gather evidence about what it sends and receives, and how often and how much. You’ll also be able to see when a client or server closes or aborts a connection or stops responding. This information can be extremely helpful when you’re troubleshooting. There are many good tutorials and other resources on the web that will walk you through the basics of using Wireshark and TShark. Here’s an example of a traffic capture using Wireshark on the loopback interface: Here’s the same example shown above using : Next up, you’ll get more references to support your socket programming journey!\n\nYou can use this section as a general reference with additional information and links to external resources about networking and sockets. First, you may want to check out the Python official documentation: For further reading, consider exploring online tutorials and guides that provide practical examples and in-depth explanations of socket programming concepts. The following is from Python’s module documentation: All errors raise exceptions. The normal exceptions for invalid argument types and out-of-memory conditions can be raised; starting from Python 3.3, errors related to socket or address semantics raise or one of its subclasses. (Source) Here are some common errors you’ll probably encounter when working with sockets: Resource temporarily unavailable. For example, in non-blocking mode, when calling and the peer is busy and not reading, the send queue (network buffer) is full. Or there are issues with the network. Hopefully this is a temporary condition. Address already in use. Make sure that there’s not another process running that’s using the same port number and that your server is setting the socket option : . Connection reset by peer. The remote process crashed or did not close its socket properly, also known as an unclean shutdown. Or there’s a firewall or other device in the network path that’s missing rules or misbehaving. Operation timed out. No response from peer. Connection refused. No application listening on specified port. It’s good to familiarize yourself with these common socket errors, as understanding them can help you diagnose and troubleshoot network issues more effectively. and represent the address and protocol families used for the first argument to . APIs that use an address expect it to be in a certain format, depending on whether the socket was created with or : is a string with a hostname like or an IPv4 address like . is an integer. is a string with a hostname like or an IPv6 address like . is an integer. and represent the and members in the C struct . Note the excerpt below from Python’s socket module documentation regarding the value of the address tuple: For IPv4 addresses, two special forms are accepted instead of a host address: the empty string represents , and the string represents . This behavior is not compatible with IPv6, therefore, you may want to avoid these if you intend to support IPv6 with your Python programs. (Source) See Python’s Socket families documentation for more information. This tutorial uses IPv4 sockets, but if your network supports it, try testing and using IPv6 if possible. One way to support this easily is by using the function . It translates the and arguments into a sequence of five-tuples that contains all of the necessary arguments for creating a socket connected to that service. Note: will understand and interpret passed-in IPv6 addresses and hostnames that resolve to IPv6 addresses, in addition to IPv4. The following example returns address information for a TCP connection to on port : Results may differ on your system if IPv6 isn’t enabled. The values returned above can be used by passing them to and . There’s a client and server example in the Example section of Python’s socket module documentation. For context, this section applies mostly to using hostnames with and , or , when you intend to use the loopback interface, localhost. However, it also applies any time you’re using a hostname and there’s an expectation of it resolving to a certain address and having a special meaning to your application that affects its behavior or assumptions. This is in contrast to the typical scenario of a client using a hostname to connect to a server that’s resolved by DNS, like www.example.com. The following is from Python’s module documentation: If you use a hostname in the host portion of IPv4/v6 socket address, the program may show a non-deterministic behavior, as Python uses the first address returned from the DNS resolution. The socket address will be resolved differently into an actual IPv4/v6 address, depending on the results from DNS resolution and/or the host configuration. For deterministic behavior use a numeric address in host portion. (Source) The standard convention for the name “localhost” is for it to resolve to or , the loopback interface. This will more than likely be the case for you on your system, but maybe not. It depends on how your system is configured for name resolution. As with all things IT, there are always exceptions, and there are no guarantees that using the name “localhost” will connect to the loopback interface. For example, on Linux, see , the Name Service Switch configuration file. Another place to check on macOS and Linux is the file . On Windows, see . The file contains a static table of name-to-address mappings in a simple text format. DNS is another piece of the puzzle altogether. Interestingly enough, as of June 2018, there’s an RFC draft Let ‘localhost’ be localhost that discusses the conventions, assumptions, and security around using the name “localhost.” What’s important to understand is that when you use hostnames in your application, the returned addresses could literally be anything. Don’t make assumptions regarding a name if you have a security-sensitive application. Depending on your application and environment, this may or may not be a concern for you. Note: Security precautions and best practices still apply, even if your application isn’t explicitly security-sensitive. If your application accesses the network, it should be secured and maintained. This means, at a minimum:\n• System software updates and security patches are applied regularly, including Python. Are you using any third-party libraries? If so, make sure those are checked and updated too.\n• If possible, use a dedicated or host-based firewall to restrict connections to trusted systems only.\n• What DNS servers are configured? Do you trust them and their administrators?\n• Make sure that request data is sanitized and validated as much as possible prior to calling other code that processes it. Use fuzz tests for this and run them regularly. Regardless of whether or not you’re using hostnames, if your application needs to support secure connections through encryption and authentication, then you’ll probably want to look into using TLS. This is its own separate topic and beyond the scope of this tutorial. See Python’s ssl module documentation to get started. This is the same protocol that your web browser uses to connect securely to web sites. With interfaces, IP addresses, and name resolution to consider, there are many variables. What should you do? Here are some recommendations that you can use if you don’t have a network application review process: Use an IP address, such as or . Use an IP address, such as . To support more than one interface, use an empty string for all interfaces/addresses. See the security note above. Use an IP address, such as or . Use an IP address for consistency and non-reliance on name resolution. For the typical case, use a hostname. See the security note above. For clients or servers, if you need to authenticate the host that you’re connecting to, look into using TLS. A socket function or method that temporarily suspends your application is a blocking call. For example, , , , and block, meaning they don’t return immediately. Blocking calls have to wait on system calls (I/O) to complete before they can return a value. So you, the caller, are blocked until they’re done or a timeout or other error occurs. Blocking socket calls can be set to non-blocking mode so they return immediately. If you do this, then you’ll need to at least refactor or redesign your application to handle the socket operation when it’s ready. Because the call returns immediately, data may not be ready. The callee is waiting on the network and hasn’t had time to complete its work. If this is the case, then the current status is the value . Non-blocking mode is supported with .setblocking(). By default, sockets are always created in blocking mode. See Notes on socket timeouts for a description of the three modes. An interesting thing to note with TCP is that it’s completely legal for the client or server to close their side of the connection while the other side remains open. This is referred to as a “half-open” connection. It’s the application’s decision whether or not this is desirable. In general, it’s not. In this state, the side that has closed their end of the connection can no longer send data. They can only receive it. This approach isn’t necessarily recommended, but as an example, HTTP uses a header named “Connection” that’s used to standardize how applications should close or persist open connections. For details, see section 6.3 in RFC 7230, Hypertext Transfer Protocol (HTTP/1.1): Message Syntax and Routing. When designing and writing your application and its application-layer protocol, it’s a good idea to go ahead and work out how you expect connections to be closed. Sometimes this is obvious and simple, or it’s something that can take some initial prototyping and testing. It depends on the application and how the message loop is processed with its expected data. Just make sure that sockets are always closed in a timely manner after they complete their work. See Wikipedia’s article on endianness for details on how different CPUs store byte orderings in memory. When interpreting individual bytes, this isn’t a problem. However, when you’re handling multiple bytes that are read and processed as a single value, for example a 4-byte integer, the byte order needs to be reversed if you’re communicating with a machine that uses a different endianness. Byte order is also important for text strings that are represented as multi-byte sequences, like Unicode. Unless you’re always using true, strict ASCII and control the client and server implementations, you’re probably better off using Unicode with an encoding like UTF-8 or one that supports a byte order mark (BOM). It’s important to explicitly define the encoding used in your application-layer protocol. You can do this by mandating that all text is UTF-8 or using a “content-encoding” header that specifies the encoding. This prevents your application from having to detect the encoding, which you should avoid if possible. This becomes problematic when there is data involved that’s stored in files or a database and there’s no metadata available that specifies its encoding. When the data is transferred to another endpoint, it’ll have to try to detect the encoding. For a discussion, see Wikipedia’s Unicode article, which references RFC 3629: UTF-8, a transformation format of ISO 10646: However RFC 3629, the UTF-8 standard, recommends that byte order marks be forbidden in protocols using UTF-8, but discusses the cases where this may not be possible. In addition, the large restriction on possible patterns in UTF-8 (for instance there cannot be any lone bytes with the high bit set) means that it should be possible to distinguish UTF-8 from other character encodings without relying on the BOM. (Source) The takeaway from this is to always store the encoding used for data that’s handled by your application if it can vary. In other words, try to somehow store the encoding as metadata if it’s not always UTF-8 or some other encoding with a BOM. Then you can send that encoding in a header along with the data to tell the receiver what it is. The byte ordering used in TCP/IP is big-endian and is referred to as network order. Network order is used to represent integers in lower layers of the protocol stack, like IP addresses and port numbers. Python’s socket module includes functions that convert integers to and from network and host byte order: Convert 32-bit positive integers from network to host byte order. On machines where the host byte order is the same as network byte order, this is a no-op; otherwise, it performs a 4-byte swap operation. Convert 16-bit positive integers from network to host byte order. On machines where the host byte order is the same as network byte order, this is a no-op; otherwise, it performs a 2-byte swap operation. Convert 32-bit positive integers from host to network byte order. On machines where the host byte order is the same as network byte order, this is a no-op; otherwise, it performs a 4-byte swap operation. Convert 16-bit positive integers from host to network byte order. On machines where the host byte order is the same as network byte order, this is a no-op; otherwise, it performs a 2-byte swap operation. You can also use the module to pack and unpack binary data using format strings: The format string specifies that your data is packed as an unsigned short (2 bytes) in big-endian byte order, which is suitable for network transmission. Then, you use the same format specifier to unpack the binary data back into a Python integer."
    },
    {
        "link": "https://datacamp.com/tutorial/a-complete-guide-to-socket-programming-in-python",
        "document": "Connecting devices to exchange information is what networking is all about. Sockets are an essential part of effective network communication as they are the underlying concept used to transmit messages between devices over local or global networks and different processes on the same machine. They provide a low-level interface that allows for fine-grained control over the traffic that is to be sent or received.\n\nThis low-level nature makes it possible to create very performant communication channels (or custom protocols) for specific use cases with low overhead that may be present in traditional protocols, which are built on top of socket communication.\n\nThis is what makes sockets exceptionally useful in real-time client-server applications that depend on instant message exchange or operate with huge amounts of data.\n\nIn this article, we will cover the basics of socket programming and provide a step-by-step guide to creating socket-based client and server applications using Python. So without further ado, let's dive right in!\n\nNetworking enables communication and information sharing of any kind.\n\nIt is a process of connecting two or more devices to allow them to exchange information. A collection of such interconnected devices is called a network.\n\nThere are a lot of networks that we can observe in our physical world: airline or powerline networks or cities interconnected with one another via highways are some good examples.\n\nIn much the same way, there are numerous networks in information technology; the most prominent and well-known of which is the internet, the global network of networks that connects myriad devices and the one that you are probably using right now to read this article.\n\nThe internet contains many more networks, which differ by scale or other properties, within itself: for example, local area networks (LANs), which typically link computers located in close proximity to one another. Machines in companies or other institutions (banks, universities, etc.) or even your home devices connected to a router comprise such a network.\n\nThere are also bigger or smaller types of networks like PANs (personal area network) which can simply be your smartphone connected to a laptop via Bluetooth, MANs (metropolitan area network), which can interconnect devices in the entire city, and WANs (wide area network), which can cover entire countries or the whole world. And yes, the biggest WAN network is the internet itself.\n\nIt goes without saying that computer networks can be very complex and consist of many elements. One of the most basic and crucial primitives is a communication protocol.\n\nCommunication protocols specify the rules of how and in what format information should be sent and received. These protocols are assembled into a hierarchy to manage the various tasks involved in network communication.\n\nIn other words, some protocols handle how hardware receives, sends, or routes packets, while others are more high-level and are concerned, for example, with application-level communication etc.\n\nSome commonly used and widely well-known network communication protocols include:\n\nAn example of a link layer protocol, meaning it sits very close to the hardware and is responsible for physically sending data from one device to another in a wireless environment.\n\nIP is a network layer protocol mainly responsible for routing packets and IP addressing.\n\nA reliable, connection-oriented protocol that provides full duplex communication and ensures data integrity and delivery. This is a transport layer protocol, which manages connections, detects errors, and controls information flow.\n\nA protocol from the same protocol suite as TCP. The main difference is that UDP is a more simple, fast, but unreliable connectionless protocol that does not perform any delivery checks and follows the paradigm of “fire-and-forget.” As TCP, UPD is also located on the transport layer.\n\nAn application layer protocol and the most commonly used protocol for browser-to-server communication on the web, used to serve websites in particular. It goes without saying that this article that you are reading right now was also served via HTTP. HTTP protocol builds on top of TCP and manages and transfers information relevant to web applications like headers, which are used to transfer metadata and cookies, different HTTP methods (GET, POST, DELETE, UPDATE) etc.\n\nAnother example of an application-level protocol used for devices with limited processing power and battery life, operating in unreliable network conditions (for example, gas sensors on a mining site or simply a smart light bulb in your house). MQTT is a standard messaging protocol used in IoT (Internet of Things). It is both lightweight and simple to use, designed with built-in retransmission mechanisms for enhanced reliability. If you're interested in using this protocol with Python, you can read this Python MQTT guide that provides an in-depth overview of the Paho MQTT client.\n\nAn important observation is that all the abovementioned protocols use sockets under the hood but add their own logic and data processing on top. This is due to sockets being a low-level interface for any network communications in modern devices as we will discuss in the next section.\n\nOf course, there are a lot of other important concepts and terms used in the context of networks. Here is a quick run-down on some of the most prominent ones that may arise in the rest of the tutorial:\n• Packet: a standard unit of data transmission in a computer network (one could colloquially compare it to the term “message”).\n• IP address: a numerical identifier that uniquely identifies a device on the network. An example of an IP address is: 192.168.0.0\n• Ports: a numerical identifier that uniquely identifies a process that is running on a device and handles particular network communications: for example, it serves your website over HTTP. While an IP address identifies the device, a port identifies the application (every application is a process or consists of processes). Some well-known port examples are: port 80, which is conventionally used by server applications to manage HTTP traffic, and port 443 for HTTPS (secure HTTP).\n• Gateway: a special kind of network node (device) which serves as an access point from one network to another. These networks may even use different protocols, so some protocol translation might be necessary to be performed by the gateway. An example of a gateway can be a router which connects a home local network to the Internet.\n\nA socket is an interface (gate) for communication between different processes located on the same or different machines. In the latter case, we speak about network sockets.\n\nNetwork sockets abstract away connection management. You can think of them as connection handlers. In Unix systems, in particular, sockets are simply files that support the same write-read operations but send all the data over the network.\n\nWhen a socket is in listening or connecting state, it is always bound to a combination of an IP address plus a port number which identifies the host (machine/device) and the process.\n\nSockets can listen for incoming connections or perform outbound connections themselves. When a connection is established, the listening socket (server socket) gets additionally bound to the IP and the port of the connecting side.\n\nOr alternatively, a new socket which is now bound to two pairs of IP addresses and port numbers of a listener and a requestor is created. This way, two connected sockets on different machines can identify one another and share a single connection for data transmission without blocking the listening socket that in the meantime continues listening for other connections.\n\nIn case of the connecting socket (client socket), it gets implicitly bound to the ip address of the device and a random accessible port number upon connection initiation. Then, upon connection establishment, a binding to the other communication side’s IP and port happens in much the same way as for a listening socket but without creating a new socket.\n\nSockets in the context of networks\n\nIn this tutorial, we are concerned not with socket implementation but with what sockets mean in the context of networks.\n\nOne can say that a socket is a connection endpoint (traffic destination) which is on one side associated with the host machine's IP address and the port number of the application for which the socket was created, and on the other, it is associated to the IP address and the port of the application running on another machine to which the connection is established.\n\nWhen we talk about socket programming, we instantiate socket objects in our code and perform operations on them (listen, connect, receive, send etc.). In this context, sockets are simply special objects we create in our program that have special methods for working with network connections and traffic.\n\nUnder the hood those methods call your operating system kernel, or more specifically, the network stack, which is a special part of the kernel responsible for managing network operations.\n\nNow, it’s also important to mention that sockets often appear in the context of client-server communication.\n\nThe idea is simple: sockets relate to connections; they are connection handlers. On the web, whenever you want to send or receive some data, you initiate a connection (which is being initiated through the interface called sockets).\n\nNow, either you or the party you are trying to connect to acts as a server and another party as a client. While a server serves data to clients, clients proactively connect and request data from a server. A server listens via a listening socket for new connections, establishes them, gets the client’s requests, and communicates the requested data in its response to the client.\n\nOn the other hand, a client creates a socket using the IP address and port of the server it wishes to connect to, initiates a connection, communicates its request to the server, and receives data in response. This seamless exchange of information between the client and server sockets forms the backbone of various network applications.\n\nThe fact that sockets form a backbone also means that there are various protocols built and used on top of them. Very common ones are UDP and TCP, which we have briefly talked about already. Sockets that use one of these transport protocols are called UDP or TCP sockets.\n\nApart from network sockets, there are also other types. For example, IPC (Inter Process Communication) sockets. IPC sockets are meant to transfer data between processes on the same machine, whereas network sockets can do the same across the network.\n\nThe good thing about IPC sockets is that they avoid a lot of the overhead of constructing packets and resolving the routes to send the data. Since in the context of IPC sender and receiver are local processes, communication via IPC sockets typically has lower latency.\n\nA good example of IPC sockets are Unix-sockets which are, as with everything in Unix, just files on the filesystem. They are not identified by the IP address and port but rather by the file path on the filesystem.\n\nNote that you can just as well use network sockets for inter-process communications if both server and receiver are on localhost (i.e., have an IP address 127.0.0.1).\n\nOf course, on the one hand, this adds additional latency because of the overhead associated with processing your data by the network stack, but on the other hand, this allows us not to worry about the underlying operating system, as network sockets are present and work on all systems as opposed to IPC sockets which are specific to a given OS or OS-family.\n\nFor socket programming in Python, we use the official built-in Python socket library consisting of functions, constants, and classes that are used to create, manage and work with sockets. Some commonly used functions of this library include:\n• bind(): Associates the socket to a specific address and port.\n• listen(): Starts listening for incoming connections on the socket.\n• accept(): Accepts a connection from a client and returns a new socket for communication.\n\nLet’s take a look at socket programming with a practical example written in Python. Here, our goal is to connect two applications and make them communicate with one another. We will be using Python socket library to create a server socket application that will communicate and exchange information with a client across a network.\n\nNote, however, that for educational purposes, our example is simplified, and the applications will be running locally and not talk over the actual network - we will use a loopback localhost address to connect the client to the server.\n\nThis means that both client and server will run on the same machine and the client will be initiating a connection to the same machine it is running on, albeit to a different process that represents the server.\n\nAlternatively, you could have your applications on two different devices and have them both connected to the same Wi-Fi router, which would form a local area network. Then the client running on one device could connect to the server running on a different machine.\n\nIn this case, however, you would need to know the IP addresses that your router assigned to your devices and use them instead of localhost (127.0.0.1) loopback IP address (to see IP addresses, use terminal command for Unix-like systems or - for Windows). After you obtain the IP addresses of your applications, you can change them in the code accordingly, and the example will still work.\n\nAnyway, we are going to start with our example. You will, of course, need to have Python installed if you want to follow along.\n\nLet’s start with creating a socket server (Python TCP server, in particular, since it will be working with TCP sockets, as we will see), which will exchange messages with clients. To clarify the terminology, while technically any server is a socket server, since sockets are always used under the hood to initiate network connections, we use the phrase “socket server” because our example explicitly makes use of socket programming.\n\nSo, follow the steps below:\n• Import the module in your Python script.\n• Add a function called . We will be adding most of our code there. When you add your code to the function, don’t forget to properly indent it:\n\nAs a next step, in , create a socket object using the function.\n\nThe first argument ( ) specifies the IP address family for IPv4 (other options include: for IPv6 family and for Unix-sockets)\n\nThe second argument ( indicates that we are using a TCP socket.\n\nIn case of using TCP, the operating system will create a reliable connection with in-order data delivery, error discovery and retransmission, and flow control. You will not have to think about implementing all those details.\n\nThere is also an option for specifying a UDP socket: . This will create a socket which implements all the features of UDP under the hood.\n\nIn case you want to go more low-level than that and build your own transport layer protocol on top of the TCP/IP network layer protocol used by sockets, you can use value for the second argument. In this case the operating system will not handle any higher level protocol features for you and you will have to implement all the headers, connection confirmation and retransmission functionalities yourself if you need them. There are also other values that you can read about in the documentation.\n\nDefine the hostname or server IP and port to indicate the address which the server will be reachable from and where it will listen for incoming connections. In this example, the server is listening on the local machine - this is defined by the variable set to (also called localhost).\n\nThe variable is set to , which is the port number that the server application will be identified by by the operating system (It is recommended to use values above 1023 for your port numbers to avoid collisions with ports used by system processes).\n\nPrepare the socket to receive connections by binding it to the IP address and port which we have defined before.\n\nSet up a listening state in the server socket using the function to be able to receive incoming client connections.\n\nThis function accepts an argument called which specifies the maximum number of queued unaccepted connections. In this example, we use the value for this argument. This means that only a single client can interact with the server. A connection attempt of any client performed while the server is working with another client will be refused.\n\nIf you specify a value that is bigger than , say , it tells the operating system how many clients can be put into the queue before the method is called on them.\n\nOnce is called a client is removed from the queue and is no longer counted towards this limit. This may become clearer once you see further parts of the code, but what this parameter essentially does can be illustrated as follows: once your listening server receives the connection request it will add this client to the queue and proceed to accepting it’s request. If before the server was able to internally call on the first client, it receives a connection request from a second client, it will push this second client to the same queue provided that there is enough space in it. The size of exactly this queue is controlled by the backlog argument. As soon as the server accepts the first client, this client is removed from the queue and the server starts communicating with it. The second client is still left in the queue, waiting for the server to get free and accept the connection.\n\nIf you omit the backlog argument, it will be set to your system’s default (under Unix, you can typically view this default in the file).\n\nNext, wait and accept incoming client connections. The method stalls the execution thread until a client connects. Then it returns a tuple pair of , where address is a tuple of the client's IP address and port, and is a new socket object which shares a connection with the client and can be used to communicate with it.\n\ncreates a new socket to communicate with the client instead of binding the listening socket (called in our example) to the client's address and using it for the communication, because the listening socket needs to listen to further connections from other clients, otherwise it would be blocked. Of course, in our case, we only ever handle a single client and refuse all the other connections while doing so, but this will be more relevant once we get to the multithreaded server example.\n\nAs soon as a connection with the client has been established (after calling the method), we initiate an infinite loop to communicate. In this loop, we perform a call to the method of the object. This method receives the specified number of bytes from the client - in our case 1024.\n\n1024 bytes is just a common convention for the size of the payload, as it’s a power of two which is potentially better for optimization purposes than some other arbitrary value. You are free to change this value however you like though.\n\nSince the data received from the client into the variable is in raw binary form, we transformed it from a sequence of bytes into a string using the function.\n\nThen we have an if statement, which breaks out of the communication loop in case we receive a message. This means that as soon as our server gets a string in request, it sends the confirmation back to the client and terminates its connection with it. Otherwise, we print the received message to the console. Confirmation in our case is just sending a string to the client.\n\nNote that the method that we use on the string in the if statement, simply converts it to lowercase. This way we don’t care whether the string was originally written using uppercase or lowercase characters.\n\nNow we should handle the normal response of the server to the client (that is when the client doesn’t wish to close the connection). Inside the while loop, right after , add the following lines, which will convert a response string ( in our case) to bytes and send it to the client. This way whenever server receives a message from the client which is not , it will send out the string in response:\n\nOnce we break out from the infinite while loop, the communication with the client is complete, so we close the client socket using the method to release system resources. We also close the server socket using the same method, which effectively shuts down our server. In a real world scenario, we would of course probably want our server to continue listening to other clients and not shut down after communicating with just a single one, but don’t worry, we will get to another example further below.\n\nFor now, add the following lines after the infinite while loop:\n\nNote: don’t forget to call the function at the end of your file. Simply use the following line of code:\n\nHere is the complete source code:\n\nNote that in order not to convolute and complicate this basic example, we omitted the error handling. You would of course want to add try-except blocks and make sure that you always close the sockets in the clause. Continue reading and we will see a more advanced example.\n\nAfter setting up your server, the next step is to set up a client that will connect and send requests to your server. So, let’s start with the steps below:\n• Define the function where we will place all our code:\n\nNext, use the function to create a TCP socket object which serves as the client's point of contact with the server.\n\nSpecify the IP address and port of the server to be able to connect to it. These should match the ip address and port that you set in before.\n\nEstablish a connection with the server using the method on the client socket object. Note that we did not bind the client socket to any IP address or port. This is normal for the client, because will automatically choose a free port and pick up an IP address that provides the best route to the server from the system’s network interfaces ( in our case) and bind the client socket to those.\n\nAfter having established a connection, we start an infinite communication loop to send multiple messages to the server. We get input from the user using Python’s built-in function, then encode it into bytes and trim to be 1024 bytes at max. After that we send the message to the server using .\n\nOnce the server receives a message from the client, it responds to it. Now, in our client code, we want to receive the server's response. For that, in the communication loop, we use the method to read 1024 bytes at most. Then we convert the response from bytes into a string using and then check if it is equal to the value . If this is the case, we break out of the loop which as we later see, will terminate the client’s connection. Otherwise, we print the server’s response into the console.\n\nFinally, after the while loop, close the client socket connection using the method. This ensures that resources are properly released and the connection is terminated (i.e. when we receive the message and break out of the while loop).\n\nNote: Again, don’t forget to call the function, which we have implemented above, at the end of the file as follows:\n\nHere is the complete code:\n\nTo test the the server and client implementation that we wrote above, perform the following:\n• In one terminal window, navigate to the directory where the file is located and run the following command to start the server:\n\nThis will bind the server socket to the localhost address (127.0.0.1) on port 8000 and start listening for incoming connections.\n• In the other terminal, navigate to the directory where the file is located and run the following command to start the client:\n\nThis will prompt for user input. You can then type in your message and press Enter. This will transfer your input to the server and display it in its terminal window. The server will send its response to the client and the latter will ask you for the input again. This will continue until you send the string to the server.\n\nWe have seen how a server responds to requests from a single client in the previous example, however, in many practical situations, numerous clients may need to connect to a single server at once. This is where multithreading comes in. Multithreading is used in situations where you need to handle several tasks (e.g. execute multiple functions) concurrently (at the same time).\n\nThe idea is to spawn a thread which is an independent set of instructions that can be handled by the processor. Threads are much more lightweight than the processes because they actually live within a process itself and you don’t have to allocate a lot of resources for themselves.\n\nNote that multithreading in Python is limited. Standard Python implementation (CPython) cannot run threads truly in parallel. Only a single thread is allowed to execute at a time due to the global interpreter lock (GIL). This is, however, a separate topic, which we are not going to discuss. For the sake of our example, using limited CPython threads is enough and gets the point across. In a real-world scenario, however, if you are going to use Python, you should look into asynchronous programming. We are not going to talk about it now, because it is again a separate topic and it usually abstracts away some low-level socket operations which we specifically focus on in this article.\n\nLet's look at the example below on how multithreading may be added to your server to handle a large number of clients. Note that this time we will also add some basic error handling using the try-except-finally blocks. To get started, follow the steps below:\n\nIn your python file, import the and modules to be able to work with both sockets and threads:\n\nDefine the function which will, as in the example above, create a server socket, bind it and listen to the incoming connections. Then call in an infinite while loop. This will always keep listening for new connections. After gets an incoming connection and returns, create a thread using constructor. This thread will execute the function which we are going to define later, and pass and to it as arguments ( tuple holds an IP address and a port of the connected client). After the thread is created, we call on it to begin its execution.\n\nRemember that call is blocking, so on the first iteration of the while loop, when we reach the line with , we halt and wait for a client connection without executing anything else. As soon as the client connects, method returns, and we continue the execution: spawn a thread, which will handle said client and go to the next iteration where we will again halt at the call waiting for another client to connect.\n\nAt the end of the function, we have some error handling which ensures that the server socket is always closed in case something unexpected happens.\n\nNote that the server in our example will only be stopped in case an unexpected error occurs. Otherwise, it will listen for the clients indefinitely, and you will have to kill the terminal if you want to stop it.\n\nNow, above the function, define another one called . This function will be the one executing in a separate thread for every client’s connection. It receives the client's socket object and the tuple as arguments.\n\nInside this function, we do the same as we did in a single threaded example plus some error handling: we start a loop to get messages from the client using .\n\nThen we check if we got a close message. If so, we respond with the string and close the connection by breaking out of the loop. Otherwise, we print out the client’s request string into the console and proceed to the next loop iteration to receive the next client’s message.\n\nAt the end of this function, we have some error handling for unexpected cases ( clause), and also a clause where we release using . This clause will always be executed no matter what, which ensures that the client socket is always properly released.\n\nWhen returns, the thread which executes it, will also be automatically released.\n\nNote: Don’t forget to call the function at the end of your file.\n\nNow, let's put the complete multithreading server code together:\n\nNote: In a real-world code, to prevent possible problems like race situations or data inconsistencies while dealing with multithreaded servers, it's vital to take thread safety and synchronization techniques into consideration. In our simple example this is, however, not a problem.\n\nNow that we have a server implementation able to handle multiple clients concurrently, we could use the same client implementation as seen above in the first basic examples to initiate connection, or we could update it slightly and add some error handling. Below you can find the code, which is identical to the previous client example with an addition of try-except blocks:\n\nIf you want to test the multi-client implementation, open several terminal windows for clients and one for the server. First start the server with . After that start a couple clients using . In the server terminal windows you will see how new clients get connected to the server. You can now proceed with sending messages from different clients by entering text into the respective terminals and all of them will be handled and printed to the console on the server side.\n\nWhile every network application uses sockets created by the OS under the hood, there are numerous systems that heavily rely on socket programming specifically, either for certain special use cases or to improve the performance. But how exactly is socket programming useful in the context of data science? Well, it definitely plays a meaningful role, whenever there is a need to receive or send huge amounts of data fast. Hence, socket programming is mainly used for data collection and real-time processing, distributed computing, and inter-process communication. But let's have a closer look at some particular applications in the field of data science.\n\nSockets are widely used to collect real-time data from different sources for further processing, forwarding to a database or to an analytics pipeline etc. For example, a socket can be used to instantly receive data from a financial system or social media API for subsequent processing by data scientists.\n\nData scientists may use socket connectivity to distribute the processing and computation of huge data sets across multiple machines. Socket programming is commonly used in Apache Spark and other distributed computing frameworks for communication between the nodes.\n\nSocket programming can be used when serving machine learning models to the users, allowing for instantaneous delivery of predictions and suggestions. In order to facilitate real-time decision-making, data scientists may use performant socket-based server applications that take in large amounts of data, process it using trained models to provide predictions, and then rapidly return the findings to the client.\n\nSockets can be used for IPC, which allows different processes running on the same machine to communicate with each other and exchange data. This is useful in data science to distribute complex and resource intensive computations across multiple processes. In fact, Python’s subprocessing library is often used for this purpose: it spawns several processes to utilize multiple processor cores and increase application performance when performing heavy calculations. Communication between such processes may be implemented via IPC sockets.\n\nSocket programming allows for real-time communication and collaboration among data scientists. In order to facilitate effective collaboration and knowledge sharing, socket-based chat apps or collaborative data analysis platforms are used.\n\nIt’s worth saying that in many of the above applications, data scientists might not be directly involved in working with sockets. They would typically use libraries, frameworks, and systems that abstract away all the low-level details of socket programming. However, under the hood all such solutions are based on socket communication and utilize socket programming.\n\nBecause sockets are a low-level concept of managing connections, developers working with them have to implement all the required infrastructure around to create robust and reliable applications. This of course comes with a lot of challenges. However, there are some best practices and general guidelines one may follow to overcome these issues. Below are some of the most often encountered problems with socket programming, along with some general tips:\n\nWorking with many connections at a time; managing multiple clients, and ensuring efficient handling of concurrent requests can certainly be challenging and non-trivial. It requires careful resource management and coordination to avoid bottlenecks\n• Keep track of active connections using data structures like lists or dictionaries. Or use advanced techniques like connection pooling which also help with scalability.\n• Use threading or asynchronous programming techniques to handle multiple client connections at the same time.\n\nDealing with errors, such as connection failures, timeouts, and data transmission issues, is crucial. Handling these errors and providing appropriate feedback to the clients can be challenging, especially when doing low-level socket programming.\n• Use try-except-finally blocks to catch and handle specific types of errors.\n• Provide informative error messages and consider employing logging to aid in troubleshooting.\n\nEnsuring optimal performance and minimizing latency are key concerns when dealing with high-volume data streams or real-time applications.\n• Optimize your code for performance by minimizing unnecessary data processing and network overhead.\n• Consider load balancing techniques to distribute client requests across multiple server instances.\n\nSecuring socket-based communication and implementing proper authentication mechanisms can be difficult. Ensuring data privacy, preventing unauthorized access, and protecting against malicious activities require careful consideration and implementation of secure protocols.\n• Utilize SSL/TLS security protocols to ensure secure data transmission by encrypting the information.\n• Ensure client identity by implementing secure authentication methods like token-based authentication, public-key cryptography, or username/password.\n• Ensure that confidential data, such as passwords or API keys, are safeguarded and encrypted or ideally not stored at all (only their hashes if needed).\n\nDealing with network interruptions, fluctuating bandwidth, and unreliable connections can pose challenges. Maintaining a stable connection, handling disconnections gracefully, and implementing reconnection mechanisms are essential for robust networked applications.\n• Use keep-alive messages to detect inactive or dropped connections.\n• Implement exponential backoff reconnection logic to establish a connection again if it's lost.\n\nLast but not the least mention is code maintainability. Because of the low-level nature of socket programming, developers find themselves writing more code. This might quickly turn into an unmaintainable spaghetti code, so it’s essential to organize and structure it as early as possible and spend extra effort on planning your code’s architecture.\n• Break up your code into classes or functions which ideally shouldn’t be too long.\n• Write unit tests early on by mocking your client and server implementations\n• Consider using more high-level libraries to deal with connections unless you absolutely must use socket programming.\n\nSockets are an integral part of all network applications. In this article, we have looked into socket programming in Python. Here are the key points to remember:\n• Sockets are interfaces that abstract away connection management.\n• Sockets enable communication between different processes (usually a client and a server) locally or over a network.\n• In Python, working with sockets is done through the library, which among the rest, provides a socket object with various methods like , , , .\n• Socket programming has various applications useful in data science, including data collection, inter-process communication, and distributed computing.\n\nWith socket programming skills, developers can create efficient, real-time network applications. By mastering the concepts and best practices, they can harness the full potential of socket programming to develop reliable and scalable solutions.\n\nHowever, socket programming is a very low-level technique, which is difficult to use because application engineers have to take every little detail of application communication into account.\n\nNowadays, we very often do not need to work with sockets directly as they are typically handled by the higher level libraries and frameworks, unless there is a need to really squeeze the performance out of the application or scale it.\n\nHowever, understanding sockets and having some insights into how things work under the hood leads to a better overall awareness as a developer or a data scientist and is always a good idea.\n\nTo learn more about Python’s role in network analysis, check out our Intermediate Network Analysis in Python course. You can also follow our Python Programming skill track to improve your Python programming skills."
    },
    {
        "link": "https://python-socketio.readthedocs.io",
        "document": "This projects implements Socket.IO clients and servers that can run standalone or integrated with a variety of Python web frameworks."
    },
    {
        "link": "https://docs.python.org/3/library/sqlite3.html",
        "document": "SQLite is a C library that provides a lightweight disk-based database that doesn’t require a separate server process and allows accessing the database using a nonstandard variant of the SQL query language. Some applications can use SQLite for internal data storage. It’s also possible to prototype an application using SQLite and then port the code to a larger database such as PostgreSQL or Oracle.\n\nThe module was written by Gerhard Häring. It provides an SQL interface compliant with the DB-API 2.0 specification described by PEP 249, and requires SQLite 3.15.2 or newer.\n• None Tutorial teaches how to use the module.\n• None Reference describes the classes and functions this module defines.\n\nHow to use placeholders to bind values in SQL queries¶ SQL operations usually need to use values from Python variables. However, beware of using Python’s string operations to assemble queries, as they are vulnerable to SQL injection attacks. For example, an attacker can simply close the single quote and inject to select all rows: # Never do this -- insecure! SELECT * FROM stocks WHERE symbol = '' OR TRUE; --' Instead, use the DB-API’s parameter substitution. To insert a variable into a query string, use a placeholder in the string, and substitute the actual values into the query by providing them as a of values to the second argument of the cursor’s method. An SQL statement may use one of two kinds of placeholders: question marks (qmark style) or named placeholders (named style). For the qmark style, parameters must be a sequence whose length must match the number of placeholders, or a is raised. For the named style, parameters must be an instance of a (or a subclass), which must contain keys for all named parameters; any extra items are ignored. Here’s an example of both styles: # This is the named style used with executemany(): # This is the qmark style used in a SELECT query: PEP 249 numeric placeholders are not supported. If used, they will be interpreted as named placeholders. How to adapt custom Python types to SQLite values¶ SQLite supports only a limited set of data types natively. To store custom Python types in SQLite databases, adapt them to one of the Python types SQLite natively understands. There are two ways to adapt Python objects to SQLite types: letting your object adapt itself, or using an adapter callable. The latter will take precedence above the former. For a library that exports a custom type, it may make sense to enable that type to adapt itself. As an application developer, it may make more sense to take direct control by registering custom adapter functions. Suppose we have a class that represents a pair of coordinates, and , in a Cartesian coordinate system. The coordinate pair will be stored as a text string in the database, using a semicolon to separate the coordinates. This can be implemented by adding a method which returns the adapted value. The object passed to protocol will be of type . The other possibility is to create a function that converts the Python object to an SQLite-compatible type. This function can then be registered using . How to convert SQLite values to custom Python types¶ Writing an adapter lets you convert from custom Python types to SQLite values. To be able to convert from SQLite values to custom Python types, we use converters. Let’s go back to the class. We stored the x and y coordinates separated via semicolons as strings in SQLite. First, we’ll define a converter function that accepts the string as a parameter and constructs a object from it. Converter functions are always passed a object, no matter the underlying SQLite data type. We now need to tell when it should convert a given SQLite value. This is done when connecting to a database, using the detect_types parameter of . There are three options:\n• None Both: set detect_types to . Column names take precedence over declared types. The following example illustrates the implicit and explicit approaches: This section shows recipes for common adapters and converters. How to use connection shortcut methods¶ Using the , , and methods of the class, your code can be written more concisely because you don’t have to create the (often superfluous) objects explicitly. Instead, the objects are created implicitly and these shortcut methods return the cursor objects. This way, you can execute a statement and iterate over it directly using only a single call on the object. # close() is not a shortcut method and it's not called automatically; # the connection object should be closed manually How to use the connection context manager¶ A object can be used as a context manager that automatically commits or rolls back open transactions when leaving the body of the context manager. If the body of the statement finishes without exceptions, the transaction is committed. If this commit fails, or if the body of the statement raises an uncaught exception, the transaction is rolled back. If is , a new transaction is implicitly opened after committing or rolling back. If there is no open transaction upon leaving the body of the statement, or if is , the context manager does nothing. The context manager neither implicitly opens a new transaction nor closes the connection. If you need a closing context manager, consider using . # con.rollback() is called after the with block finishes with an exception, # the exception is still raised and must be caught # Connection object used as context manager only commits or rollbacks transactions, # so the connection object should be closed manually How to work with SQLite URIs¶\n• None Do not implicitly create a new database file if it does not already exist; will raise if unable to create a new file: More information about this feature, including a list of parameters, can be found in the SQLite URI documentation. How to create and use row factories¶ By default, represents each row as a . If a does not suit your needs, you can use the class or a custom . While exists as an attribute both on the and the , it is recommended to set , so all cursors created from the connection will use the same row factory. provides indexed and case-insensitive named access to columns, with minimal memory overhead and performance impact over a . To use as a row factory, assign it to the attribute: \"SELECT 'Earth' AS name, 6378 AS radius\" The clause can be omitted in the statement, as in the above example. In such cases, SQLite returns a single row with columns defined by expressions, e.g. literals, with the given aliases . You can create a custom that returns each row as a , with column names mapped to values: Using it, queries now return a instead of a : can be used as follows: With some adjustments, the above recipe can be adapted to use a , or any other custom class, instead of a . By default, uses to adapt SQLite values with the data type. This works well for UTF-8 encoded text, but it might fail for other encodings and invalid UTF-8. You can use a custom to handle such cases. Because of SQLite’s flexible typing, it is not uncommon to encounter table columns with the data type containing non-UTF-8 encodings, or even arbitrary data. To demonstrate, let’s assume we have a database with ISO-8859-2 (Latin-2) encoded text, for example a table of Czech-English dictionary entries. Assuming we now have a instance connected to this database, we can decode the Latin-2 encoded text using this : For invalid UTF-8 or arbitrary data in stored in table columns, you can use the following technique, borrowed from the Unicode HOWTO: The module API does not support strings containing surrogates."
    },
    {
        "link": "https://docs.python.org/3.9/library/sqlite3.html",
        "document": "SQLite is a C library that provides a lightweight disk-based database that doesn’t require a separate server process and allows accessing the database using a nonstandard variant of the SQL query language. Some applications can use SQLite for internal data storage. It’s also possible to prototype an application using SQLite and then port the code to a larger database such as PostgreSQL or Oracle.\n\nThe sqlite3 module was written by Gerhard Häring. It provides an SQL interface compliant with the DB-API 2.0 specification described by PEP 249.\n\nTo use the module, start by creating a object that represents the database. Here the data will be stored in the file:\n\nThe special path name can be provided to create a temporary database in RAM.\n\nOnce a has been established, create a object and call its method to perform SQL commands:\n\nThe saved data is persistent: it can be reloaded in a subsequent session even after restarting the Python interpreter:\n\nTo retrieve data after executing a SELECT statement, either treat the cursor as an iterator, call the cursor’s method to retrieve a single matching row, or call to get a list of the matching rows.\n\nThis example uses the iterator form:\n\nSQL operations usually need to use values from Python variables. However, beware of using Python’s string operations to assemble queries, as they are vulnerable to SQL injection attacks (see the xkcd webcomic for a humorous example of what can go wrong):\n\nInstead, use the DB-API’s parameter substitution. To insert a variable into a query string, use a placeholder in the string, and substitute the actual values into the query by providing them as a of values to the second argument of the cursor’s method. An SQL statement may use one of two kinds of placeholders: question marks (qmark style) or named placeholders (named style). For the qmark style, must be a sequence. For the named style, it can be either a sequence or instance. The length of the sequence must match the number of placeholders, or a is raised. If a is given, it must contain keys for all named parameters. Any extra items are ignored. Here’s an example of both styles:\n\nString constant stating the supported DB-API level. Required by the DB-API. Hard-coded to . String constant stating the type of parameter marker formatting expected by the module. Required by the DB-API. Hard-coded to . The module supports both and DB-API parameter styles, because that is what the underlying SQLite library supports. However, the DB-API does not allow multiple values for the attribute. The version number of this module, as a string. This is not the version of the SQLite library. The version number of this module, as a tuple of integers. This is not the version of the SQLite library. The version number of the run-time SQLite library, as a string. The version number of the run-time SQLite library, as a tuple of integers. Integer constant required by the DB-API, stating the level of thread safety the module supports. Currently hard-coded to , meaning “Threads may share the module, but not connections.” However, this may not always be true. You can check the underlying SQLite library’s compile-time threaded mode using the following query: Note that the SQLITE_THREADSAFE levels do not match the DB-API 2.0 levels. This constant is meant to be used with the detect_types parameter of the function. Setting it makes the module parse the declared type for each column it returns. It will parse out the first word of the declared type, i. e. for “integer primary key”, it will parse out “integer”, or for “number(10)” it will parse out “number”. Then for that column, it will look into the converters dictionary and use the converter function registered for that type there. This constant is meant to be used with the detect_types parameter of the function. Setting this makes the SQLite interface parse the column name for each column it returns. It will look for a string formed [mytype] in there, and then decide that ‘mytype’ is the type of the column. It will try to find an entry of ‘mytype’ in the converters dictionary and then use the converter function found there to return the value. The column name found in does not include the type, i. e. if you use something like in your SQL, then we will parse out everything until the first for the column name and strip the preceding space: the column name would simply be “Expiration date”. Opens a connection to the SQLite database file database. By default returns a object, unless a custom factory is given. database is a path-like object giving the pathname (absolute or relative to the current working directory) of the database file to be opened. You can use to open a database connection to a database that resides in RAM instead of on disk. When a database is accessed by multiple connections, and one of the processes modifies the database, the SQLite database is locked until that transaction is committed. The timeout parameter specifies how long the connection should wait for the lock to go away until raising an exception. The default for the timeout parameter is 5.0 (five seconds). For the isolation_level parameter, please see the property of objects. SQLite natively supports only the types TEXT, INTEGER, REAL, BLOB and NULL. If you want to use other types you must add support for them yourself. The detect_types parameter and the using custom converters registered with the module-level function allow you to easily do that. detect_types defaults to 0 (i. e. off, no type detection), you can set it to any combination of and to turn type detection on. Due to SQLite behaviour, types can’t be detected for generated fields (for example ), even when detect_types parameter is set. In such case, the returned type is . By default, check_same_thread is and only the creating thread may use the connection. If set , the returned connection may be shared across multiple threads. When using multiple threads with the same connection writing operations should be serialized by the user to avoid data corruption. By default, the module uses its class for the connect call. You can, however, subclass the class and make use your class instead by providing your class for the factory parameter. Consult the section SQLite and Python types of this manual for details. The module internally uses a statement cache to avoid SQL parsing overhead. If you want to explicitly set the number of statements that are cached for the connection, you can set the cached_statements parameter. The currently implemented default is to cache 100 statements. If uri is , database is interpreted as a with a file path and an optional query string. The scheme part must be . The path can be a relative or absolute file path. The query string allows us to pass parameters to SQLite. Some useful URI tricks include: # Don't implicitly create a new database file if it does not already exist. # Will raise sqlite3.OperationalError if unable to open a database file. More information about this feature, including a list of recognized parameters, can be found in the SQLite URI documentation. Changed in version 3.7: database can now also be a path-like object, not only a string. Registers a callable to convert a bytestring from the database into a custom Python type. The callable will be invoked for all database values that are of the type typename. Confer the parameter detect_types of the function for how the type detection works. Note that typename and the name of the type in your query are matched in case-insensitive manner. Registers a callable to convert the custom Python type type into one of SQLite’s supported types. The callable callable accepts as single parameter the Python value, and must return a value of the following types: int, float, str or bytes. Returns if the string sql contains one or more complete SQL statements terminated by semicolons. It does not verify that the SQL is syntactically correct, only that there are no unclosed string literals and the statement is terminated by a semicolon. This can be used to build a shell for SQLite, as in the following example: \"Enter your SQL commands to execute in sqlite3.\" By default you will not get any tracebacks in user-defined functions, aggregates, converters, authorizer callbacks etc. If you want to debug them, you can call this function with flag set to . Afterwards, you will get tracebacks from callbacks on . Use to disable the feature again.\n\nAn SQLite database connection has the following attributes and methods: Get or set the current default isolation level. for autocommit mode or one of “DEFERRED”, “IMMEDIATE” or “EXCLUSIVE”. See section Controlling Transactions for a more detailed explanation. if a transaction is active (there are uncommitted changes), otherwise. Read-only attribute. The cursor method accepts a single optional parameter factory. If supplied, this must be a callable returning an instance of or its subclasses. This method commits the current transaction. If you don’t call this method, anything you did since the last call to is not visible from other database connections. If you wonder why you don’t see the data you’ve written to the database, please check you didn’t forget to call this method. This method rolls back any changes to the database since the last call to . This closes the database connection. Note that this does not automatically call . If you just close your database connection without calling first, your changes will be lost! Create a new object and call on it with the given sql and parameters. Return the new cursor object. Create a new object and call on it with the given sql and parameters. Return the new cursor object. Create a new object and call on it with the given sql_script. Return the new cursor object. Creates a user-defined function that you can later use from within SQL statements under the function name name. num_params is the number of parameters the function accepts (if num_params is -1, the function may take any number of arguments), and func is a Python callable that is called as the SQL function. If deterministic is true, the created function is marked as deterministic, which allows SQLite to perform additional optimizations. This flag is supported by SQLite 3.8.3 or higher, will be raised if used with older versions. The function can return any of the types supported by SQLite: bytes, str, int, float and . Changed in version 3.8: The deterministic parameter was added. The aggregate class must implement a method, which accepts the number of parameters num_params (if num_params is -1, the function may take any number of arguments), and a method which will return the final result of the aggregate. The method can return any of the types supported by SQLite: bytes, str, int, float and . Creates a collation with the specified name and callable. The callable will be passed two string arguments. It should return -1 if the first is ordered lower than the second, 0 if they are ordered equal and 1 if the first is ordered higher than the second. Note that this controls sorting (ORDER BY in SQL) so your comparisons don’t affect other SQL operations. Note that the callable will get its parameters as Python bytestrings, which will normally be encoded in UTF-8. The following example shows a custom collation that sorts “the wrong way”: To remove a collation, call with as callable: You can call this method from a different thread to abort any queries that might be executing on the connection. The query will then abort and the caller will get an exception. This routine registers a callback. The callback is invoked for each attempt to access a column of a table in the database. The callback should return if access is allowed, if the entire SQL statement should be aborted with an error and if the column should be treated as a NULL value. These constants are available in the module. The first argument to the callback signifies what kind of operation is to be authorized. The second and third argument will be arguments or depending on the first argument. The 4th argument is the name of the database (“main”, “temp”, etc.) if applicable. The 5th argument is the name of the inner-most trigger or view that is responsible for the access attempt or if this access attempt is directly from input SQL code. Please consult the SQLite documentation about the possible values for the first argument and the meaning of the second and third argument depending on the first one. All necessary constants are available in the module. This routine registers a callback. The callback is invoked for every n instructions of the SQLite virtual machine. This is useful if you want to get called from SQLite during long-running operations, for example to update a GUI. If you want to clear any previously installed progress handler, call the method with for handler. Returning a non-zero value from the handler function will terminate the currently executing query and cause it to raise an exception. Registers trace_callback to be called for each SQL statement that is actually executed by the SQLite backend. The only argument passed to the callback is the statement (as ) that is being executed. The return value of the callback is ignored. Note that the backend does not only run statements passed to the methods. Other sources include the transaction management of the sqlite3 module and the execution of triggers defined in the current database. Passing as trace_callback will disable the trace callback. Exceptions raised in the trace callback are not propagated. As a development and debugging aid, use to enable printing tracebacks from exceptions raised in the trace callback. This routine allows/disallows the SQLite engine to load SQLite extensions from shared libraries. SQLite extensions can define new functions, aggregates or whole new virtual table implementations. One well-known extension is the fulltext-search extension distributed with SQLite. Loadable extensions are disabled by default. See . # alternatively you can load the extension using an API call: \"select rowid, name, ingredients from recipe where name match 'pie'\" This routine loads an SQLite extension from a shared library. You have to enable extension loading with before you can use this routine. Loadable extensions are disabled by default. See . You can change this attribute to a callable that accepts the cursor and the original row as a tuple and will return the real result row. This way, you can implement more advanced ways of returning results, such as returning an object that can also access columns by name. If returning a tuple doesn’t suffice and you want name-based access to columns, you should consider setting to the highly-optimized type. provides both index-based and case-insensitive name-based access to columns with almost no memory overhead. It will probably be better than your own custom dictionary-based approach or even a db_row based solution. Using this attribute you can control what objects are returned for the data type. By default, this attribute is set to and the module will return objects for . If you want to return instead, you can set it to . You can also set it to any other callable that accepts a single bytestring parameter and returns the resulting object. See the following example code for illustration: # by default, rows are returned as str # but we can make sqlite3 always return bytestrings ... # the bytestrings will be encoded in UTF-8, unless you stored garbage in the # we can also implement a custom text_factory ... # here we implement one that appends \"foo\" to all strings Returns the total number of database rows that have been modified, inserted, or deleted since the database connection was opened. Returns an iterator to dump the database in an SQL text format. Useful when saving an in-memory database for later restoration. This function provides the same capabilities as the command in the sqlite3 shell. This method makes a backup of an SQLite database even while it’s being accessed by other clients, or concurrently by the same connection. The copy will be written into the mandatory argument target, that must be another instance. By default, or when pages is either or a negative integer, the entire database is copied in a single step; otherwise the method performs a loop copying up to pages pages at a time. If progress is specified, it must either be or a callable object that will be executed at each iteration with three integer arguments, respectively the status of the last iteration, the remaining number of pages still to be copied and the total number of pages. The name argument specifies the database name that will be copied: it must be a string containing either , the default, to indicate the main database, to indicate the temporary database or the name specified after the keyword in an statement for an attached database. The sleep argument specifies the number of seconds to sleep by between successive attempts to backup remaining pages, can be specified either as an integer or a floating point value. Example 1, copy an existing database into another: Example 2, copy an existing database into a transient copy:\n\nA instance has the following attributes and methods. Executes an SQL statement. Values may be bound to the statement using placeholders. will only execute a single SQL statement. If you try to execute more than one statement with it, it will raise a . Use if you want to execute multiple SQL statements with one call. Executes a parameterized SQL command against all parameter sequences or mappings found in the sequence seq_of_parameters. The module also allows using an iterator yielding parameters instead of a sequence. This is a nonstandard convenience method for executing multiple SQL statements at once. It issues a statement first, then executes the SQL script it gets as a parameter. This method disregards ; any transaction control must be added to sql_script. sql_script can be an instance of . Fetches the next row of a query result set, returning a single sequence, or when no more data is available. Fetches the next set of rows of a query result, returning a list. An empty list is returned when no more rows are available. The number of rows to fetch per call is specified by the size parameter. If it is not given, the cursor’s arraysize determines the number of rows to be fetched. The method should try to fetch as many rows as indicated by the size parameter. If this is not possible due to the specified number of rows not being available, fewer rows may be returned. Note there are performance considerations involved with the size parameter. For optimal performance, it is usually best to use the arraysize attribute. If the size parameter is used, then it is best for it to retain the same value from one call to the next. Fetches all (remaining) rows of a query result, returning a list. Note that the cursor’s arraysize attribute can affect the performance of this operation. An empty list is returned when no rows are available. Close the cursor now (rather than whenever is called). The cursor will be unusable from this point forward; a exception will be raised if any operation is attempted with the cursor. Required by the DB-API. Does nothing in . Required by the DB-API. Does nothing in . Although the class of the module implements this attribute, the database engine’s own support for the determination of “rows affected”/”rows selected” is quirky. For statements, the number of modifications are summed up into . As required by the Python DB API Spec, the attribute “is -1 in case no has been performed on the cursor or the rowcount of the last operation is not determinable by the interface”. This includes statements because we cannot determine the number of rows a query produced until all rows were fetched. With SQLite versions before 3.6.5, is set to 0 if you make a without any condition. This read-only attribute provides the row id of the last inserted row. It is only updated after successful or statements using the method. For other statements, after or , or if the insertion failed, the value of is left unchanged. The initial value of is . Inserts into tables are not recorded. Changed in version 3.6: Added support for the statement. Read/write attribute that controls the number of rows returned by . The default value is 1 which means a single row would be fetched per call. This read-only attribute provides the column names of the last query. To remain compatible with the Python DB API, it returns a 7-tuple for each column where the last six items of each tuple are . It is set for statements without any matching rows as well. This read-only attribute provides the SQLite database used by the object. A object created by calling will have a attribute that refers to con:\n\nThe following Python types can thus be sent to SQLite without any problem: This is how SQLite types are converted to Python types by default: The type system of the module is extensible in two ways: you can store additional Python types in an SQLite database via object adaptation, and you can let the module convert SQLite types to different Python types via converters. Using adapters to store additional Python types in SQLite databases¶ As described before, SQLite supports only a limited set of types natively. To use other Python types with SQLite, you must adapt them to one of the sqlite3 module’s supported types for SQLite: one of NoneType, int, float, str, bytes. There are two ways to enable the module to adapt a custom Python type to one of the supported ones. This is a good approach if you write the class yourself. Let’s suppose you have a class like this: Now you want to store the point in a single SQLite column. First you’ll have to choose one of the supported types to be used for representing the point. Let’s just use str and separate the coordinates using a semicolon. Then you need to give your class a method which must return the converted value. The parameter protocol will be . The other possibility is to create a function that converts the type to the string representation and register the function with . The module has two default adapters for Python’s built-in and types. Now let’s suppose we want to store objects not in ISO representation, but as a Unix timestamp. Writing an adapter lets you send custom Python types to SQLite. But to make it really useful we need to make the Python to SQLite to Python roundtrip work. Let’s go back to the class. We stored the x and y coordinates separated via semicolons as strings in SQLite. First, we’ll define a converter function that accepts the string as a parameter and constructs a object from it. Converter functions always get called with a object, no matter under which data type you sent the value to SQLite. Now you need to make the module know that what you select from the database is actually a point. There are two ways of doing this:\n• None Explicitly via the column name Both ways are described in section Module functions and constants, in the entries for the constants and . The following example illustrates both approaches. There are default adapters for the date and datetime types in the datetime module. They will be sent as ISO dates/ISO timestamps to SQLite. The default converters are registered under the name “date” for and under the name “timestamp” for . This way, you can use date/timestamps from Python without any additional fiddling in most cases. The format of the adapters is also compatible with the experimental SQLite date/time functions. The following example demonstrates this. If a timestamp stored in SQLite has a fractional part longer than 6 numbers, its value will be truncated to microsecond precision by the timestamp converter. The default “timestamp” converter ignores UTC offsets in the database and always returns a naive object. To preserve UTC offsets in timestamps, either leave converters disabled, or register an offset-aware converter with .\n\nThe underlying library operates in mode by default, but the Python module by default does not. mode means that statements that modify the database take effect immediately. A or statement disables mode, and a , a , or a that ends the outermost transaction, turns mode back on. The Python module by default issues a statement implicitly before a Data Modification Language (DML) statement (i.e. / / / ). You can control which kind of statements implicitly executes via the isolation_level parameter to the call, or via the property of connections. If you specify no isolation_level, a plain is used, which is equivalent to specifying . Other possible values are and . You can disable the module’s implicit transaction management by setting to . This will leave the underlying library operating in mode. You can then completely control the transaction state by explicitly issuing , , , and statements in your code. Note that disregards ; any transaction control must be added explicitly. Changed in version 3.6: used to implicitly commit an open transaction before DDL statements. This is no longer the case.\n\nUsing the nonstandard , and methods of the object, your code can be written more concisely because you don’t have to create the (often superfluous) objects explicitly. Instead, the objects are created implicitly and these shortcut methods return the cursor objects. This way, you can execute a statement and iterate over it directly using only a single call on the object. # close is not a shortcut method and it's not called automatically, # so the connection object should be closed manually Accessing columns by name instead of by index¶ One useful feature of the module is the built-in class designed to be used as a row factory. Rows wrapped with this class can be accessed both by index (like tuples) and case-insensitively by name: \"select 'John' as name, 42 as age\" Using the connection as a context manager¶ Connection objects can be used as context managers that automatically commit or rollback transactions. In the event of an exception, the transaction is rolled back; otherwise, the transaction is committed: # con.rollback() is called after the with block finishes with an exception, the # exception is still raised and must be caught # Connection object used as context manager only commits or rollbacks transactions, # so the connection object should be closed manually"
    },
    {
        "link": "https://docs.python.org/tr/3.9/library/sqlite3.html",
        "document": ""
    },
    {
        "link": "https://digitalocean.com/community/tutorials/how-to-use-the-sqlite3-module-in-python-3",
        "document": "The author selected the COVID-19 Relief Fund to receive a donation as part of the Write for DOnations program.\n\nSQLite is a self-contained, file-based SQL database. SQLite comes bundled with Python and can be used in any of your Python applications without having to install any additional software.\n\nIn this tutorial, we’ll go through the module in Python 3. We’ll create a connection to a SQLite database, add a table to that database, insert data into that table, and read and modify data in that table.\n\nFor this tutorial, we’ll be working primarily with an inventory of fish that we need to modify as fish are added to or removed from a fictional aquarium.\n\nTo get the most out of this tutorial, it is recommended to have some familiarity with programming in Python and some basic background with SQL.\n\nYou can review these tutorials for the necessary background information:\n• How to Code in Python3\n• An Introduction to Queries in MySQL\n\nWhen we connect to a SQLite database, we are accessing data that ultimately resides in a file on our computer. SQLite databases are fully featured SQL engines that can be used for many purposes. For now, we’ll consider a database that tracks the inventory of fish at a fictional aquarium.\n\nWe can connect to a SQLite database using the Python module:\n\ngives our Python program access to the module. The function returns a object that we will use to interact with the SQLite database held in the file . The file is created automatically by if does not already exist on our computer.\n\nWe can verify we successfully created our object by running:\n\nIf we run this Python code, we will see output like:\n\nis the total number of database rows that have been changed by . Since we have not executed any SQL commands yet, 0 is correct.\n\nIf, at any time, we find we want to start this tutorial again, we can delete the file from our computer.\n\nNow that we have connected to the SQLite database, we can start inserting and reading data from it.\n\nIn a SQL database, data is stored in tables. Tables define a set of columns, and contain 0 or more rows with data for each of the defined columns.\n\nWe will create a table named that tracks the following data:\n\nThe table will track a value for , , and for each fish at the aquarium. Two example rows are listed: one row for a named , and one row for a named .\n\nWe can create this table in SQLite using the we made in Step 1:\n\nreturns a object. objects allow us to send SQL statements to a SQLite database using . The string is a SQL statement that creates a table named with the three columns described earlier: of type , species of type , and of type .\n\nNow that we have created a table, we can insert rows of data into it:\n\nWe call two times: once to insert a row for the shark in tank , and once to insert a row for the cuttlefish in tank . is a SQL statement that allows us to add rows to a table.\n\nIn the next section, we will use a SQL statement to inspect the rows we just inserted into our table.\n\nIn Step 2, we added two rows to a SQLite table named . We can retrieve those rows using a SQL statement:\n\nIf we run this code, we will see output like the following:\n\nThe function runs a statement to retrieve values for the , , and columns in the table. retrieves all the results of the statement. When we we see a list of two tuples. Each tuple has three entries; one entry for each column we selected from the table. The two tuples have the data we inserted in Step 2: one tuple for the , and one tuple for the .\n\nIf we wanted to retrieve rows in the table that match a specific set of criteria, we can use a clause:\n\nIf we run this, we will see output like the following:\n\nAs with the previous example, allows us to fetch all the results of a statement. The clause in the statement filters for rows where the value of is . Notice that we use to substitute our variable into the statement. We expect to only match one row, and indeed we only see the row for the returned.\n\nRows in a SQLite database can be modified using and SQL statements.\n\nLet’s say, for example, that Sammy the shark was moved to tank number 2. We can change Sammy’s row in the table to reflect this change:\n\nWe issue an SQL statement to change the of to its new value of . The clause in the statement ensures we only change the value of if a row has .\n\nIf we run the following statement, we can confirm our update was made correctly:\n\nIf we run this, we will see output like the following:\n\nNotice that the row for now has the value of for its column.\n\nLet’s say that Sammy the shark was released into the wild and no longer held by the aquarium. Since Sammy no longer lives at the aquarium, it would make sense to remove the row from the table.\n\nWe issue a SQL statement to remove the row for the . The clause in the statement ensures we only delete a row if that row has .\n\nIf we run the following statement, we can confirm our deletion was made correctly:\n\nIf we run this code, we will see output like the following:\n\nNotice that the row for the is now gone, and only the remains.\n\nIn this tutorial, we’ve used two primary objects to interact with the SQLite database: a object named , and a object named .\n\nIn the same way that Python files should be closed when we are done working with them, and objects should also be closed when they are no longer needed.\n\nWe can use a statement to help us automatically close and objects:\n\nis a convenience function provided by the module. When a statement exits, ensures that is called on whatever object is passed to it. The function is used twice in this example. Once to ensure that the object returned by is automatically closed, and a second time to ensure that the object returned by is automatically closed.\n\nIf we run this code, we will see output like the following:\n\nSince is a SQL statement that always returns a single row with a single column with a value of , it makes sense to see a single tuple with as its only value returned by our code.\n\nThe module is a powerful part of the Python standard library; it lets us work with a fully featured on-disk SQL database without installing any additional software.\n\nIn this tutorial, we learned how to use the module to connect to a SQLite database, add data to that database, as well as read and modify data in that database. Along the way, we also learned about the risks of SQL injection attacks and how to use to automatically call on Python objects in statements.\n\nFrom here we can learn more about SQL databases in SQLite vs MySQL vs PostgreSQL: A Comparison Of Relational Database Management Systems."
    },
    {
        "link": "http://pysqlite.readthedocs.org/en/latest/sqlite3.html",
        "document": "SQLite is a C library that provides a lightweight disk-based database that doesn’t require a separate server process and allows accessing the database using a nonstandard variant of the SQL query language. Some applications can use SQLite for internal data storage. It’s also possible to prototype an application using SQLite and then port the code to a larger database such as PostgreSQL or Oracle.\n\npysqlite was written by Gerhard Häring and provides a SQL interface compliant with the DB-API 2.0 specification described by PEP 249.\n\nTo use the module, you must first create a object that represents the database. Here the data will be stored in the file:\n\nYou can also supply the special name to create a database in RAM.\n\nOnce you have a , you can create a object and call its method to perform SQL commands:\n\nUsually your SQL operations will need to use values from Python variables. You shouldn’t assemble your query using Python’s string operations because doing so is insecure; it makes your program vulnerable to an SQL injection attack.\n\nInstead, use the DB-API’s parameter substitution. Put as a placeholder wherever you want to use a value, and then provide a tuple of values as the second argument to the cursor’s method. (Other database modules may use a different placeholder, such as or .) For example:\n\nTo retrieve data after executing a SELECT statement, you can either treat the cursor as an iterator, call the cursor’s method to retrieve a single matching row, or call to get a list of the matching rows.\n\nThis example uses the iterator form:\n\nThis constant is meant to be used with the detect_types parameter of the function. Setting it makes the module parse the declared type for each column it returns. It will parse out the first word of the declared type, i. e. for “integer primary key”, it will parse out “integer”, or for “number(10)” it will parse out “number”. Then for that column, it will look into the converters dictionary and use the converter function registered for that type there. This constant is meant to be used with the detect_types parameter of the function. Setting this makes the SQLite interface parse the column name for each column it returns. It will look for a string formed [mytype] in there, and then decide that ‘mytype’ is the type of the column. It will try to find an entry of ‘mytype’ in the converters dictionary and then use the converter function found there to return the value. The column name found in is only the first word of the column name, i. e. if you use something like in your SQL, then we will parse out everything until the first blank for the column name: the column name would simply be “x”. Opens a connection to the SQLite database file database. You can use to open a database connection to a database that resides in RAM instead of on disk. When a database is accessed by multiple connections, and one of the processes modifies the database, the SQLite database is locked until that transaction is committed. The timeout parameter specifies how long the connection should wait for the lock to go away until raising an exception. The default for the timeout parameter is 5.0 (five seconds). For the isolation_level parameter, please see the property of objects. SQLite natively supports only the types TEXT, INTEGER, REAL, BLOB and NULL. If you want to use other types you must add support for them yourself. The detect_types parameter and the using custom converters registered with the module-level function allow you to easily do that. detect_types defaults to 0 (i. e. off, no type detection), you can set it to any combination of and to turn type detection on. By default, the module uses its class for the connect call. You can, however, subclass the class and make use your class instead by providing your class for the factory parameter. Consult the section SQLite and Python types of this manual for details. The module internally uses a statement cache to avoid SQL parsing overhead. If you want to explicitly set the number of statements that are cached for the connection, you can set the cached_statements parameter. The currently implemented default is to cache 100 statements. Registers a callable to convert a bytestring from the database into a custom Python type. The callable will be invoked for all database values that are of the type typename. Confer the parameter detect_types of the function for how the type detection works. Note that the case of typename and the name of the type in your query must match! Registers a callable to convert the custom Python type type into one of SQLite’s supported types. The callable callable accepts as single parameter the Python value, and must return a value of the following types: int, long, float, str (UTF-8 encoded), unicode or buffer. Returns if the string sql contains one or more complete SQL statements terminated by semicolons. It does not verify that the SQL is syntactically correct, only that there are no unclosed string literals and the statement is terminated by a semicolon. This can be used to build a shell for SQLite, as in the following example: \"Enter your SQL commands to execute in SQLite.\" By default you will not get any tracebacks in user-defined functions, aggregates, converters, authorizer callbacks etc. If you want to debug them, you can call this function with flag as True. Afterwards, you will get tracebacks from callbacks on . Use to disable the feature again.\n\nA SQLite database connection has the following attributes and methods: Get or set the current isolation level. for autocommit mode or one of “DEFERRED”, “IMMEDIATE” or “EXCLUSIVE”. See section Controlling Transactions for a more detailed explanation. The cursor method accepts a single optional parameter cursorClass. If supplied, this must be a custom cursor class that extends . This method commits the current transaction. If you don’t call this method, anything you did since the last call to is not visible from from other database connections. If you wonder why you don’t see the data you’ve written to the database, please check you didn’t forget to call this method. This method rolls back any changes to the database since the last call to . This closes the database connection. Note that this does not automatically call . If you just close your database connection without calling first, your changes will be lost! This is a nonstandard shortcut that creates an intermediate cursor object by calling the cursor method, then calls the cursor’s method with the parameters given. This is a nonstandard shortcut that creates an intermediate cursor object by calling the cursor method, then calls the cursor’s method with the parameters given. This is a nonstandard shortcut that creates an intermediate cursor object by calling the cursor method, then calls the cursor’s method with the parameters given. Creates a user-defined function that you can later use from within SQL statements under the function name name. num_params is the number of parameters the function accepts, and func is a Python callable that is called as the SQL function. The function can return any of the types supported by SQLite: unicode, str, int, long, float, buffer and None. The aggregate class must implement a method, which accepts the number of parameters num_params, and a method which will return the final result of the aggregate. The method can return any of the types supported by SQLite: unicode, str, int, long, float, buffer and None. Creates a collation with the specified name and callable. The callable will be passed two string arguments. It should return -1 if the first is ordered lower than the second, 0 if they are ordered equal and 1 if the first is ordered higher than the second. Note that this controls sorting (ORDER BY in SQL) so your comparisons don’t affect other SQL operations. Note that the callable will get its parameters as Python bytestrings, which will normally be encoded in UTF-8. The following example shows a custom collation that sorts “the wrong way”: To remove a collation, call with None as callable: You can call this method from a different thread to abort any queries that might be executing on the connection. The query will then abort and the caller will get an exception. This routine registers a callback. The callback is invoked for each attempt to access a column of a table in the database. The callback should return if access is allowed, if the entire SQL statement should be aborted with an error and if the column should be treated as a NULL value. These constants are available in the module. The first argument to the callback signifies what kind of operation is to be authorized. The second and third argument will be arguments or depending on the first argument. The 4th argument is the name of the database (“main”, “temp”, etc.) if applicable. The 5th argument is the name of the inner-most trigger or view that is responsible for the access attempt or if this access attempt is directly from input SQL code. Please consult the SQLite documentation about the possible values for the first argument and the meaning of the second and third argument depending on the first one. All necessary constants are available in the module. This routine returns the current value of the limit specified by the constant limit_id. Please consult the SQLite documentation about the possible values for the limit_id parameter. This routine sets a new value for the limit specified by the constant limit_id. Please consult the SQLite documentation about the possible values for the limit_id parameter. This routine registers a callback. The callback is invoked for every n instructions of the SQLite virtual machine. This is useful if you want to get called from SQLite during long-running operations, for example to update a GUI. If you want to clear any previously installed progress handler, call the method with for handler. This routine allows/disallows the SQLite engine to load SQLite extensions from shared libraries. SQLite extensions can define new functions, aggregates or whole new virtual table implementations. One well-known extension is the fulltext-search extension distributed with SQLite. # alternatively you can load the extension using an API call: \"select rowid, name, ingredients from recipe where name match 'pie'\" This routine loads a SQLite extension from a shared library. You have to enable extension loading with before you can use this routine. You can change this attribute to a callable that accepts the cursor and the original row as a tuple and will return the real result row. This way, you can implement more advanced ways of returning results, such as returning an object that can also access columns by name. If returning a tuple doesn’t suffice and you want name-based access to columns, you should consider setting to the highly-optimized type. provides both index-based and case-insensitive name-based access to columns with almost no memory overhead. It will probably be better than your own custom dictionary-based approach or even a db_row based solution. Using this attribute you can control what objects are returned for the data type. By default, this attribute is set to and the module will return Unicode objects for . If you want to return bytestrings instead, you can set it to . For efficiency reasons, there’s also a way to return Unicode objects only for non-ASCII data, and bytestrings otherwise. To activate it, set this attribute to . You can also set it to any other callable that accepts a single bytestring parameter and returns the resulting object. See the following example code for illustration: # by default, rows are returned as Unicode # but we can make pysqlite always return bytestrings ... # the bytestrings will be encoded in UTF-8, unless you stored garbage in the # we can also implement a custom text_factory ... # here we implement one that will ignore Unicode characters that cannot be \"this is latin1 and would normally create errors\" # objects, if the data is in ASCII only, and otherwise return unicode objects Returns the total number of database rows that have been modified, inserted, or deleted since the database connection was opened. Returns an iterator to dump the database in an SQL text format. Useful when saving an in-memory database for later restoration. This function provides the same capabilities as the command in the sqlite3 shell.\n\nA instance has the following attributes and methods: A SQLite database cursor has the following attributes and methods: Close the cursor now (rather than whenever __del__ is called). The cursor will be unusable from this point forward; an Error (or subclass) exception will be raised if any operation is attempted with the cursor. Executes an SQL statement. The SQL statement may be parametrized (i. e. placeholders instead of SQL literals). The module supports two kinds of placeholders: question marks (qmark style) and named placeholders (named style). This example shows how to use parameters with qmark style: \"select name_last, age from people where name_last=? and age=?\" This example shows how to use the named style: \"select name_last, age from people where name_last=:who and age=:age\" will only execute a single SQL statement. If you try to execute more than one statement with it, it will raise a Warning. Use if you want to execute multiple SQL statements with one call. Executes an SQL command against all parameter sequences or mappings found in the sequence sql. The module also allows using an iterator yielding parameters instead of a sequence. This is a nonstandard convenience method for executing multiple SQL statements at once. It issues a statement first, then executes the SQL script it gets as a parameter. sql_script can be a bytestring or a Unicode string. Fetches the next row of a query result set, returning a single sequence, or when no more data is available. Fetches the next set of rows of a query result, returning a list. An empty list is returned when no more rows are available. The number of rows to fetch per call is specified by the size parameter. If it is not given, the cursor’s arraysize determines the number of rows to be fetched. The method should try to fetch as many rows as indicated by the size parameter. If this is not possible due to the specified number of rows not being available, fewer rows may be returned. Note there are performance considerations involved with the size parameter. For optimal performance, it is usually best to use the arraysize attribute. If the size parameter is used, then it is best for it to retain the same value from one call to the next. Fetches all (remaining) rows of a query result, returning a list. Note that the cursor’s arraysize attribute can affect the performance of this operation. An empty list is returned when no rows are available. Although the class of the module implements this attribute, the database engine’s own support for the determination of “rows affected”/”rows selected” is quirky. For statements, SQLite reports as 0 if you make a without any condition. For statements, the number of modifications are summed up into . As required by the Python DB API Spec, the attribute “is -1 in case no has been performed on the cursor or the rowcount of the last operation is not determinable by the interface”. This includes statements because we cannot determine the number of rows a query produced until all rows were fetched. This read-only attribute provides the rowid of the last modified row. It is only set if you issued a statement using the method. For operations other than or when is called, is set to . This read-only attribute provides the column names of the last query. To remain compatible with the Python DB API, it returns a 7-tuple for each column where the last six items of each tuple are . It is set for statements without any matching rows as well.\n\nThe following Python types can thus be sent to SQLite without any problem: This is how SQLite types are converted to Python types by default: The type system of the module is extensible in two ways: you can store additional Python types in a SQLite database via object adaptation, and you can let the module convert SQLite types to different Python types via converters. Using adapters to store additional Python types in SQLite databases¶ As described before, SQLite supports only a limited set of types natively. To use other Python types with SQLite, you must adapt them to one of the sqlite3 module’s supported types for SQLite: one of NoneType, int, long, float, str, unicode, buffer. The module uses Python object adaptation, as described in PEP 246 for this. The protocol to use is . There are two ways to enable the module to adapt a custom Python type to one of the supported ones. This is a good approach if you write the class yourself. Let’s suppose you have a class like this: Now you want to store the point in a single SQLite column. First you’ll have to choose one of the supported types first to be used for representing the point. Let’s just use str and separate the coordinates using a semicolon. Then you need to give your class a method which must return the converted value. The parameter protocol will be . The other possibility is to create a function that converts the type to the string representation and register the function with . The type/class to adapt must be a new-style class, i. e. it must have as one of its bases. The module has two default adapters for Python’s built-in and types. Now let’s suppose we want to store objects not in ISO representation, but as a Unix timestamp. Writing an adapter lets you send custom Python types to SQLite. But to make it really useful we need to make the Python to SQLite to Python roundtrip work. Let’s go back to the class. We stored the x and y coordinates separated via semicolons as strings in SQLite. First, we’ll define a converter function that accepts the string as a parameter and constructs a object from it. Converter functions always get called with a string, no matter under which data type you sent the value to SQLite. Now you need to make the module know that what you select from the database is actually a point. There are two ways of doing this:\n• Explicitly via the column name Both ways are described in section Module functions and constants, in the entries for the constants and . The following example illustrates both approaches. There are default adapters for the date and datetime types in the datetime module. They will be sent as ISO dates/ISO timestamps to SQLite. The default converters are registered under the name “date” for and under the name “timestamp” for . This way, you can use date/timestamps from Python without any additional fiddling in most cases. The format of the adapters is also compatible with the experimental SQLite date/time functions. The following example demonstrates this.\n\nUsing the nonstandard , and methods of the object, your code can be written more concisely because you don’t have to create the (often superfluous) objects explicitly. Instead, the objects are created implicitly and these shortcut methods return the cursor objects. This way, you can execute a statement and iterate over it directly using only a single call on the object. # Using a dummy WHERE clause to not let SQLite take the shortcut table deletes. Accessing columns by name instead of by index¶ One useful feature of the module is the built-in class designed to be used as a row factory. Rows wrapped with this class can be accessed both by index (like tuples) and case-insensitively by name: Using the connection as a context manager¶ With Python 2.5 or higher, connection objects can be used as context managers that automatically commit or rollback transactions. In the event of an exception, the transaction is rolled back; otherwise, the transaction is committed: # con.rollback() is called after the with block finishes with an exception, the # exception is still raised and must be catched"
    },
    {
        "link": "https://linkedin.com/advice/0/what-best-practices-handling-user-authentication-bozif",
        "document": ""
    },
    {
        "link": "https://simeononsecurity.com/articles/python-security-best-practices-protecting-code-data",
        "document": "Python Security Best Practices: Protecting Your Code and Data\n\nPython is a powerful and versatile programming language that is widely used for various purposes, including web development, data analysis, and machine learning. However, like any other software, Python applications are susceptible to security vulnerabilities. In this article, we will discuss best practices for Python security to help you protect your code and data from potential threats.\n\nEnsuring the security of your Python applications is crucial for several reasons:\n• None Data Protection: Python applications often handle sensitive data, such as user information, financial records, or intellectual property. A security breach can lead to data theft or unauthorized access, resulting in severe consequences.\n• None System Integrity: Vulnerabilities in Python code can be exploited to gain unauthorized access to systems, manipulate data, or disrupt services. By implementing security best practices, you can safeguard the integrity of your systems and prevent unauthorized activities.\n• None Reputation and Trust: Security breaches not only harm your organization but also erode the trust of your customers and users. By prioritizing security, you demonstrate a commitment to protecting their interests and data, enhancing your reputation as a reliable and trustworthy provider.\n\nImplementing robust security measures in your Python applications helps mitigate risks and ensures the confidentiality, integrity, and availability of your data. It is essential to establish a strong security foundation to protect against cyber threats and maintain the trust of your users and stakeholders.\n\nTo enhance the security of your Python applications, it is essential to follow these best practices:\n\nRegularly updating your Python interpreter to the latest stable version ensures that you have the latest security patches and bug fixes. The Python community actively addresses vulnerabilities and releases updates to improve the security and stability of the language. Visit the Python website to download the latest version.\n\nBy keeping your Python interpreter up to date, you benefit from the latest security enhancements that address known vulnerabilities. These updates are designed to mitigate risks and protect your applications from potential attacks. Additionally, staying updated allows you to leverage new features and improvements introduced in newer versions of Python.\n\nFor example, if you are using Python 3.7 and a critical security vulnerability is discovered, the Python community will release a patch specifically addressing that vulnerability. By updating your Python interpreter to the latest version, such as Python 3.9, you ensure that your code is protected against known security issues.\n\nUpdating your Python interpreter is a straightforward process. Simply visit the Python downloads page and choose the appropriate installer for your operating system. Follow the installation instructions provided to upgrade your Python interpreter to the latest version.\n\nRemember to periodically check for updates and make it a best practice to update your Python interpreter regularly to stay ahead of potential security risks.\n\nAdopting secure coding practices minimizes the likelihood of introducing security vulnerabilities into your Python code. By following these practices, you can strengthen the security posture of your applications and protect against common attack vectors. Let’s explore some key practices:\n• None Input Validation: Validate all user inputs to prevent injection attacks and other input-related security issues. Implement techniques such as whitelisting, input sanitization, and parameterized queries to ensure that user-supplied data is validated and safe to use. For example, when accepting user input through a web form, validate and sanitize the input before processing or storing it in a database. This helps prevent malicious code or unintended input from compromising the application.\n• None Avoid Code Injection: Never execute user-supplied code without proper validation and sanitization. Code injection attacks occur when an attacker is able to inject and execute arbitrary code within your application’s context. To prevent this, carefully evaluate and validate any code provided by users before executing it. Use secure coding practices and libraries that provide protection against code injection vulnerabilities.\n• None Secure Password Handling: When working with passwords, it is crucial to handle them securely. Hash and salt passwords using appropriate hashing algorithms and key stretching techniques. Storing plain-text passwords is highly discouraged as it exposes users to significant risks. Instead, store only the password hashes and ensure their secure storage. Use strong hashing algorithms such as bcrypt or Argon2 and consider applying techniques like salt and pepper to further enhance password security. By implementing secure password handling practices, you can protect user credentials even if the underlying database is compromised.\n\nIt is important to note that secure coding practices go beyond these examples. Always be vigilant and keep up with the latest security guidelines and recommendations to ensure that your Python code remains secure.\n\nRole-Based Access Control (RBAC) is a powerful security model that restricts access to resources based on the roles assigned to users. By implementing RBAC in your Python applications, you can ensure that users only have the necessary privileges to perform their assigned tasks, minimizing the risk of unauthorized access and reducing the attack surface.\n\nIn RBAC, each user is assigned one or more roles, and each role is associated with specific permissions and access rights. For example, in a web application, you may have roles like admin, user, and guest. The admin role may have full access to all features and functionalities, while the user role may have limited access, and the guest role may have minimal or read-only access.\n• None Identifying Roles: Analyze your application’s functionality and determine the different roles that users can have. Consider the specific permissions and privileges associated with each role.\n• None Assigning Roles: Assign roles to users based on their responsibilities and the level of access they require. This can be done through user management systems or databases.\n• None Defining Permissions: Define the permissions associated with each role. For example, an admin role might have permissions to create, read, update, and delete records, while a user role might only have read and update permissions.\n• None Enforcing RBAC: Implement RBAC mechanisms within your Python application to enforce role-based access control. This can involve using decorators, middleware, or access control libraries to check the role of the user and verify their permissions before allowing access to specific resources.\n\nBy implementing RBAC, you establish a granular access control system that ensures users have the appropriate level of access based on their roles. This helps prevent unauthorized actions and restricts potential damage in the event of a security breach.\n\nTo learn more about implementing RBAC in Python, you can refer to the official Python Security documentation or explore relevant Python libraries and frameworks that provide RBAC functionalities, such as Flask-Security, Django Guardian, or Pyramid Authorization.\n\nWhen handling sensitive data in your Python applications, it is crucial to employ strong encryption techniques to protect the confidentiality and integrity of the data. By using well-established encryption algorithms and protocols, such as AES (Advanced Encryption Standard) and TLS (Transport Layer Security), you can ensure that data is encrypted both at rest and in transit.\n\nEncryption is the process of transforming data into an unreadable format, known as ciphertext, using encryption algorithms and cryptographic keys. Only authorized parties with the corresponding decryption keys can decipher the ciphertext and access the original data.\n\nHere are some examples of how you can protect sensitive data in Python:\n• None Data Encryption: Use encryption algorithms like AES to encrypt sensitive data before storing it in databases or other storage systems. This helps ensure that even if the data is accessed without authorization, it remains unreadable and unusable.\n• None TLS Encryption: When transmitting sensitive data over networks, such as during API calls or user authentication, use TLS encryption to establish secure and encrypted connections. TLS ensures that data exchanged between a client and a server is encrypted, preventing eavesdropping and data tampering.\n\nBy applying encryption techniques to protect sensitive data, you add an extra layer of security to your Python applications. This significantly reduces the risk of data breaches and unauthorized access to sensitive information.\n\nTo learn more about encryption in Python and how to implement it effectively, you can refer to relevant libraries and documentation, such as the Python Cryptography library and the official TLS RFC for understanding the TLS protocol.\n\nRemember that encryption is just one aspect of protecting sensitive data. It is equally important to implement secure storage, access controls, and secure key management practices to ensure comprehensive data protection.\n\nIf your Python application interacts with databases, it is essential to follow security practices to protect against potential vulnerabilities. Consider the following best practices:\n• None Use Prepared Statements: When executing database queries, utilize prepared statements or parameterized queries to prevent SQL injection attacks. Prepared statements separate SQL code from user-provided data, reducing the risk of unauthorized database access. For example, in Python, you can use libraries like SQLAlchemy or psycopg2 to implement prepared statements and protect against SQL injection vulnerabilities.\n• None Implement Least Privilege: Ensure that the database user associated with your Python application has the minimum necessary privileges required for its functionality. By following the principle of least privilege, you restrict the capabilities of the database user to only what is necessary, minimizing the potential impact of a compromised database connection. For example, if your application only requires read-only access to certain tables, grant the database user read-only privileges for those specific tables rather than full access to the entire database.\n\nBy using prepared statements and implementing least privilege, you strengthen the security of your database access and mitigate the risks associated with common attack vectors. It is also important to stay updated with the latest security guidelines and best practices provided by database vendors and relevant documentation.\n\nTo learn more about secure database access in Python, you can refer to the documentation and resources of popular database libraries such as SQLAlchemy for working with relational databases, psycopg2 for PostgreSQL, or specific documentation provided by your chosen database management system.\n\nRemember, securing database access is a critical aspect of protecting your data and maintaining the integrity of your Python applications.\n\nPython projects often rely on third-party libraries and frameworks to enhance functionality and streamline development. However, it is crucial to regularly update these dependencies to ensure the security and stability of your project.\n\nStaying vigilant about updating dependencies allows you to benefit from security patches and bug fixes released by the library maintainers. By keeping your dependencies up to date, you mitigate the risk of potential vulnerabilities and ensure that your project is running on the latest stable versions.\n\nTo effectively manage dependencies, consider the following practices:\n• None Track Vulnerabilities: Stay informed about reported vulnerabilities in your project dependencies. Websites like Snyk provide vulnerability databases and tools that can help you identify and address vulnerabilities in your dependencies. By regularly monitoring these vulnerabilities, you can take timely actions to update or replace affected dependencies.\n• None Update Dependencies Promptly: When security patches or updates are released for your project dependencies, update them promptly. Delaying updates increases the risk of exploitation, as attackers may target known vulnerabilities in outdated versions.\n• None Automate Dependency Management: Consider using dependency management tools such as Pipenv or Conda to automate dependency installation, version control, and updates. These tools can simplify the process of managing dependencies, ensuring that updates are applied consistently across different environments.\n\nRemember, maintaining up-to-date dependencies is an ongoing process. Set up a regular schedule to review and update your project dependencies, keeping security as a top priority. By staying proactive and vigilant, you can significantly reduce the risk of potential security vulnerabilities in your Python projects.\n\nTo enhance the security of your Python applications, it is essential to implement comprehensive logging and monitoring mechanisms. Logging allows you to track events and activities within your application, while monitoring provides real-time visibility into the system’s behavior, enabling the detection and investigation of security incidents.\n\nBy enabling logging, you can capture relevant information about the execution of your application, including errors, warnings, and user activities. Properly configured logging helps you identify issues, debug problems, and trace security-related events. For example, you can log authentication attempts, access to sensitive resources, or suspicious activities that may indicate a security breach.\n\nAdditionally, monitoring enables you to observe your application’s runtime behavior and detect any anomalies or security-related patterns. This can be done using tools and services that provide real-time monitoring, log aggregation, and alerting capabilities. For instance, services like AWS CloudWatch, Datadog, or Prometheus offer monitoring solutions that can be integrated with your Python applications.\n\nBy enabling logging and monitoring, you can:\n• None Detect Security Incidents: Log entries and monitoring data can help you identify security incidents or suspicious activities, allowing you to respond quickly and effectively.\n• None Investigate Breaches: When a security incident occurs, logs and monitoring data provide valuable information for post-incident investigations and forensic analysis.\n• None Improve Security Posture: By analyzing logs and monitoring data, you can gain insights into the effectiveness of your security measures, identify potential vulnerabilities, and take proactive steps to enhance your application’s security posture.\n\nRemember to configure logging and monitoring appropriately, balancing the level of detail captured with the potential impact on performance and storage. It is also essential to regularly review and analyze the collected logs and monitoring data to stay proactive in identifying and addressing security concerns.\n\nImplementing log management solutions and utilizing monitoring tools empowers you to stay ahead of potential security threats and protect your Python applications effectively.\n\nTo reinforce Python security best practices, it is crucial to invest in educating and training your Python developers. By providing them with the necessary knowledge and skills, you empower your development team to write secure code and detect potential security issues early in the development lifecycle.\n\nHere are some steps you can take to promote developer education and training:\n• None Security Awareness Programs: Conduct regular security awareness programs to educate developers about common security vulnerabilities and secure coding practices. These programs can include workshops, webinars, or online training sessions tailored to Python application development.\n• None Secure Coding Guidelines: Establish secure coding guidelines specific to Python development, outlining recommended practices and code patterns that mitigate common vulnerabilities. These guidelines can cover topics such as input validation, secure authentication, data encryption, and secure handling of sensitive information.\n• None Code Reviews and Pair Programming: Encourage a culture of collaboration and learning through code reviews and pair programming. By reviewing code together, developers can share knowledge, identify security weaknesses, and suggest improvements. This helps in maintaining code quality and adherence to secure coding practices.\n• None Security-focused Tools: Integrate security-focused tools, such as static code analysis tools, into your development workflow. These tools can automatically identify potential security issues, insecure coding patterns, and vulnerabilities in the codebase. For Python, you can explore tools like Bandit or Pylint to analyze your code for security vulnerabilities.\n• None Continuous Learning: Encourage developers to stay updated with the latest security trends, best practices, and emerging threats in the Python ecosystem. This can be achieved through participation in security conferences, webinars, or by following reputable security resources like the OWASP (Open Web Application Security Project) community.\n\nBy investing in developer education and training, you create a strong foundation for building secure Python applications. Promoting a security-focused mindset among developers helps in preventing security incidents, reducing vulnerabilities, and ensuring the overall security of your software.\n\nRemember, security is a continuous process, and ongoing education and training are necessary to stay ahead of evolving threats and maintain the highest standards of security in your Python development projects.\n\nHere is a concise cheat sheet summarizing the Python security best practices discussed in this article:\n• None Keep your Python interpreter updated to the latest stable version to benefit from security patches and bug fixes. Visit the Python website - Downloads to download the latest version.\n• None Follow secure coding practices, including input validation to prevent injection attacks, avoiding code injection by validating and sanitizing user-supplied code, and secure password handling by using appropriate hashing algorithms and password storage techniques.\n• None Implement Role-Based Access Control (RBAC) to restrict unauthorized access. RBAC assigns roles to users based on their responsibilities and grants access privileges accordingly. Refer to the NIST - Role-Based Access Control documentation for more details.\n• None Protect sensitive data using strong encryption techniques. Utilize well-established encryption algorithms like AES (Advanced Encryption Standard) and ensure secure storage and transmission of sensitive information. You can refer to the AES Wikipedia page for more information.\n• None Secure database access by using prepared statements to prevent SQL injection attacks and implementing least privilege to restrict database user permissions. These practices minimize the risk of unauthorized access to sensitive data. Learn more about prepared statements in the SQLAlchemy documentation and least privilege in the OWASP RBAC Cheat Sheet .\n• None Regularly update dependencies to address security vulnerabilities and benefit from bug fixes. Tools like Snyk - Open Source Security Platform can help you identify vulnerabilities in your project dependencies.\n• None Enable logging and monitoring to detect and investigate security incidents. Logging captures relevant information about application events, while monitoring provides real-time visibility into system behavior. Consider using services like AWS CloudWatch, Datadog, or Prometheus for comprehensive monitoring.\n• None Educate and train developers on secure coding practices and common security vulnerabilities. Promote security awareness programs, establish secure coding guidelines, and encourage code reviews and pair programming. Explore security tools like Bandit or Pylint for static code analysis.\n\nFor a more comprehensive guide on Python security, refer to the official Python Security documentation .\n\nProtecting your Python code and data from security vulnerabilities should be a top priority for any developer or organization. By following the best practices outlined in this article, you can minimize the risk of security breaches and ensure the integrity and confidentiality of your applications. Stay informed about the latest security threats, adopt secure coding practices, and prioritize security throughout the development lifecycle.\n\nRemember, securing your Python applications is an ongoing process. Regularly update your code, stay informed about emerging threats, and continuously enhance your security practices to stay one step ahead of potential attackers."
    },
    {
        "link": "https://stackoverflow.com/questions/7014953/i-need-to-securely-store-a-username-and-password-in-python-what-are-my-options",
        "document": "There are a few options for storing passwords and other secrets that a Python program needs to use, particularly a program that needs to run in the background where it can't just ask the user to type in the password.\n• Checking the password in to source control where other developers or even the public can see it.\n• Other users on the same server reading the password from a configuration file or source code.\n• Having the password in a source file where others can see it over your shoulder while you are editing it.\n\nThis isn't always an option, but it's probably the best. Your private key is never transmitted over the network, SSH just runs mathematical calculations to prove that you have the right key.\n\nIn order to make it work, you need the following:\n• The database or whatever you are accessing needs to be accessible by SSH. Try searching for \"SSH\" plus whatever service you are accessing. For example, \"ssh postgresql\". If this isn't a feature on your database, move on to the next option.\n• Create an account to run the service that will make calls to the database, and generate an SSH key.\n• Either add the public key to the service you're going to call, or create a local account on that server, and install the public key there.\n\nThis one is the simplest, so it might be a good place to start. It's described well in the Twelve Factor App. The basic idea is that your source code just pulls the password or other secrets from environment variables, and then you configure those environment variables on each system where you run the program. It might also be a nice touch if you use default values that will work for most developers. You have to balance that against making your software \"secure by default\".\n\nHere's an example that pulls the server, user name, and password from environment variables.\n\nLook up how to set environment variables in your operating system, and consider running the service under its own account. That way you don't have sensitive data in environment variables when you run programs in your own account. When you do set up those environment variables, take extra care that other users can't read them. Check file permissions, for example. Of course any users with root permission will be able to read them, but that can't be helped. If you're using systemd, look at the service unit, and be careful to use instead of for any secrets. values can be viewed by any user with .\n\nThis is very similar to the environment variables, but you read the secrets from a text file. I still find the environment variables more flexible for things like deployment tools and continuous integration servers. If you decide to use a configuration file, Python supports several formats in the standard library, like TOML, JSON, INI, netrc, and XML. You can also find external packages like PyYAML. Personally, I find JSON and YAML the simplest to use, and YAML allows comments. TOML support was added to the core libraries in 3.11, but I haven't tried it yet.\n\nThree things to consider with configuration files:\n• Where is the file? Maybe a default location like , and a command-line option to use a different location.\n• Make sure other users can't read the file.\n• Obviously, don't commit the configuration file to source code. You might want to commit a template that users can copy to their home directory.\n\nSome projects just put their secrets right into a Python module.\n\nThen import that module to get the values.\n\nOne project that uses this technique is Django. Obviously, you shouldn't commit to source control, although you might want to commit a file called that users can copy and modify.\n\nI see a few problems with this technique:\n• Developers might accidentally commit the file to source control. Adding it to reduces that risk.\n• Some of your code is not under source control. If you're disciplined and only put strings and numbers in here, that won't be a problem. If you start writing logging filter classes in here, stop!\n\nIf your project already uses this technique, it's easy to transition to environment variables. Just move all the setting values to environment variables, and change the Python module to read from those environment variables."
    },
    {
        "link": "https://stackoverflow.com/questions/73642345/how-to-securely-pass-credentials-in-python",
        "document": "You can use an environmental file in your project root directory and load in the variables from this file during runtime, in Python you can do this with the package.\n\nAnd from there, you can use the and as normal to authenticate and login to the website.\n\nSecurity notice: Be sure to add the file to your so you avoid pushing your environmental file to version control."
    },
    {
        "link": "https://reddit.com/r/learnpython/comments/1h17o0e/how_to_safely_store_passwords_for_use_in_programs",
        "document": "TL;DR: As part of my job, I need to perform data analysis and submit data on both local network databases as well as online databases and portals. Currently at my job for these programs, the passwords needed to access the various databases and portals are just stored in text files that anyone with access to that machine can open and view, which doesn't seem particularly \"secure,\" so I was hoping there would be a more secure way to store passwords that the programs could then use.\n\nMy Python background is almost exclusively from my physics education, meaning most of what I know is how to create and use functions, classes, arrays, math modules, and how to create physics simulations/animations. As such, my knowledge on other areas, such as security, is lackluster to non-existent.\n\nThat said, I recently started a new job where my primary duty is to perform data analysis and submit that data to various entities. Much of the data that I need to access is either stored in databases on my company's local network or in online databases that the other companies we work with host and I also need to access web portals to submit data to other companies. Most of these databases/portals require passwords to access, and currently, all of the programs (which were created well before I started work here) just store the necessary password information in text files that the programs can pull from and then pass to whatever is requiring the password. This works well enough, but the passwords are just sitting in text files, so anyone with access to those folders (and some of these folders are on network share drives) could easily open them up and see the passwords. Currently, my employer is obviously fine with this arrangement, but I feel there should be a relatively simple solution to make this process much more secure.\n\nAs such, I was wondering if there were any better methods to store passwords that the programs could then pull those passwords from, which don't involve easy to access files that anyone with access to the appropriate folders could open. I know I could set it up so that the programs require a user to enter the appropriate password each time they need to run, however, most of these programs need to run automatically on a routine basis with little to no user input, so that's not an option.\n\nAny ideas/advice would be much appreciated."
    }
]