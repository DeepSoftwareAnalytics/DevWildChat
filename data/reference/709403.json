[
    {
        "link": "https://numpy.org/devdocs/release/1.20.0-notes.html",
        "document": "This NumPy release is the largest so made to date, some 684 PRs contributed by 184 people have been merged. See the list of highlights below for more details. The Python versions supported for this release are 3.7-3.9, support for Python 3.6 has been dropped. Highlights are\n• None Annotations for NumPy functions. This work is ongoing and improvements can be expected pending feedback from users.\n• None Wider use of SIMD to increase execution speed of ufuncs. Much work has been done in introducing universal functions that will ease use of modern features across different hardware platforms. This work is ongoing.\n• None Preliminary work in changing the dtype and casting implementations in order to provide an easier path to extending dtypes. This work is ongoing but enough has been done to allow experimentation and feedback.\n• None Extensive documentation improvements comprising some 185 PR merges. This work is ongoing and part of the larger project to improve NumPy’s online presence and usefulness to new users.\n• None Further cleanups related to removing Python 2.7. This improves code readability and removes technical debt.\n\nUsing the aliases of builtin types like is deprecated# For a long time, has been an alias of the builtin . This is repeatedly a cause of confusion for newcomers, and existed mainly for historic reasons. These aliases have been deprecated. The table below shows the full list of deprecated aliases, along with their exact meaning. Replacing uses of items in the first column with the contents of the second column will work identically and silence the deprecation warning. The third column lists alternative NumPy names which may occasionally be preferential. See also Data types for additional details. To give a clear guideline for the vast majority of cases, for the types , , (and ) using the plain version is shorter and clear, and generally a good replacement. For and you can use and if you wish to be more explicit about the precision. For a direct replacement with or is also good and will not change behavior, but the precision will continue to depend on the computer and operating system. If you want to be more explicit and review the current use, you have the following alternatives:\n• None or to specify the precision exactly. This ensures that results cannot depend on the computer or operating system.\n• None or (the default), but be aware that it depends on the computer and operating system.\n• None which is 32bit on 32bit machines 64bit on 64bit machines. This can be the best type to use for indexing. When used with or changing it to the NumPy name as mentioned above will have no effect on the output. If used as a scalar with: changing it can subtly change the result. In this case, the Python version or is normally preferable, although the NumPy version may be useful for consistency with NumPy arrays (for example, NumPy behaves differently for things like division by zero). Passing to functions with a non-optional shape argument is deprecated# Previously, this was an alias for passing . This deprecation is emitted by PyArray_IntpConverter in the C API. If your API is intended to support passing , then you should check for prior to invoking the converter, so as to be able to distinguish and . Indexing errors will be reported even when index result is empty# In the future, NumPy will raise an IndexError when an integer array index contains out of bound values even if a non-indexed dimension is of length 0. This will now emit a DeprecationWarning. This can happen when the array is previously empty, or an empty slice is involved: Previously the non-empty index was not checked for correctness. It will now be checked causing a deprecation warning which will be turned into an error. This also applies to assignments. Inexact matches for and are deprecated# Inexact and case insensitive matches for and were valid inputs earlier and will give a DeprecationWarning now. For example, below are some example usages which are now deprecated and will give a DeprecationWarning: The module numpy.dual is deprecated. Instead of importing functions from numpy.dual, the functions should be imported directly from NumPy or SciPy. use with or generic ufunc outer calls such as . Previously, matrix was converted to an array here. This will not be done in the future requiring a manual conversion to arrays. The remaining numeric-style type codes , , , , and have been deprecated. The lower-case variants should be used instead. For bytes and string and are further alternatives. The method of is deprecated# The documentation has warned against using this function since NumPy 1.8. Use instead of . ArrayLike objects which do not define and # Objects which define one of the protocols , , or but are not sequences (usually defined by having a and ) will behave differently during array-coercion in the future. When nested inside sequences, such as , these were handled as a single Python object rather than an array. In the future they will behave identically to: This change should only have an effect if is not 0-D. The solution to this warning may depend on the object:\n• None Some array-likes may expect the new behaviour, and users can ignore the warning. The object can choose to expose the sequence protocol to opt-in to the new behaviour.\n• None For example, will allow conversion to an array-like using rather than . Users may work around the warning, or use the new convention when it becomes available. Unfortunately, using the new behaviour can only be achieved by calling . If you wish to ensure that the old behaviour remains unchanged, please create an object array and then fill it explicitly, for example: This will ensure NumPy knows to not enter the array-like and use it as a object instead.\n\nNumPy dtypes are not direct instances of anymore. Code that may have used will always return and must be updated to use the correct version . This change also affects the C-side macro if compiled against a NumPy older than 1.16.6. If code uses this macro and wishes to compile against an older version of NumPy, it must replace the macro (see also C API changes section). Same kind casting in concatenate with # When is called with , the flattened arrays were cast with . Any other axis choice uses “same kind”. That different default has been deprecated and “same kind” casting will be used instead. The new keyword argument can be used to retain the old behaviour. NumPy Scalars are cast when assigned to arrays# When creating or assigning to arrays, in all relevant cases NumPy scalars will now be cast identically to NumPy arrays. In particular this changes the behaviour in some cases which previously raised an error: will succeed and return an undefined result (usually the smallest possible integer). This also affects assignments: At this time, NumPy retains the behaviour for: The above changes do not affect Python scalars: remains unaffected ( is a Python , not a NumPy one). Unlike signed integers, unsigned integers do not retain this special case, since they always behaved more like casting. The following code stops raising an error: To avoid backward compatibility issues, at this time assignment from scalar to strings of too short length remains supported. This means that succeeds now, when it failed before. In the long term this may be deprecated or the unsafe cast may be allowed generally to make assignment of arrays and scalars behave consistently. Array coercion changes when Strings and other types are mixed# When strings and other types are mixed, such as: The results will change, which may lead to string dtypes with longer strings in some cases. In particularly, if is not provided any numerical value will lead to a string results long enough to hold all possible numerical values. (e.g. “S32” for floats). Note that you should always provide when converting non-strings to strings. If is provided the results will be largely identical to before, but NumPy scalars (not a Python float like ), will still enforce a uniform string length: Previously the first version gave the same result as the second. Array coercion has been restructured. In general, this should not affect users. In extremely rare corner cases where array-likes are nested: Things will now be more consistent with: This can subtly change output for some badly defined array-likes. One example for this are array-like objects which are not also sequences of matching shape. In NumPy 1.20, a warning will be given when an array-like is not also a sequence (but behaviour remains identical, see deprecations). If an array like is also a sequence (defines and ) NumPy will now only use the result given by , , or . This will result in differences when the (nested) sequence describes a different shape. Writing to the result of will export readonly buffers# In NumPy 1.17 started warning when the resulting array was written to. This warning was skipped when the array was used through the buffer interface (e.g. ). The same thing will now occur for the two protocols , and returning read-only buffers instead of giving a warning. Numeric-style type names have been removed from type dictionaries# To stay in sync with the deprecation for and other numeric-style (capital case) types. These were removed from and . You should use the lower case versions instead. Note that corresponds to and corresponds to . The numpy style (new) versions, denote the full size and not the size of the real/imaginary part. The function now raises TypeError for array arguments# The previous behavior was to fall back to addition and add the two arrays, which was thought to be unexpected behavior for a concatenation function. An abstract property has been removed from as it was no longer used in the derived convenience classes. This may affect users who have derived classes from and overridden the methods for representation and display, e.g. , , , etc. Float and timedelta promotion consistently raises a TypeError. aligns with now and both raise a TypeError. Previously, returned which was considered a bug. Uint64 and timedelta promotion consistently raises a TypeError. aligns with now and both raise a TypeError. Previously, returned which was considered a bug. Previously, failed to unpack if it was called with and a structured datatype was passed to the argument (or was passed and a structured datatype was inferred). For example: Structured arrays will now correctly unpack into a list of arrays, one for each column: Previously, and failed to return meaningful output. This bug potentially affects , , , and when an input with dtype other than the default and and equivalent Python types were used. The methods have been fixed to handle varying precision correctly. Previously, if a boolean array index matched the size of the indexed array but not the shape, it was incorrectly allowed in some cases. In other cases, it gave an error, but the error was incorrectly a with a message about broadcasting instead of the correct . For example, the following used to incorrectly give ValueError: operands could not be broadcast together with shapes (2,2) (1,4) : And the following used to incorrectly return : Both now correctly give IndexError: boolean index did not match indexed array along dimension 0; dimension is 2 but corresponding boolean dimension is 1 . When iterating while casting values, an error may stop the iteration earlier than before. In any case, a failed casting operation always returned undefined, partial results. Those may now be even more undefined and partial. For users of the C-API such cast errors will now cause the iternext() function to return 0 and thus abort iteration. Currently, there is no API to detect such an error directly. It is necessary to check , which may be problematic in combination with . These issues always existed, but new API could be added if required by users. f2py generated code may return unicode instead of byte strings# Some byte strings previously returned by f2py generated code may now be unicode strings. This results from the ongoing Python2 -> Python3 cleanup. The first element of the tuple must be an integer# This has been the documented interface for many years, but there was still code that would accept a byte string representation of the pointer address. That code has been removed, passing the address as a byte string will now raise an error. Previously, constructing an instance of with all-zero coefficients would cast the coefficients to . This affected the output dtype of methods which construct instances internally, such as . The numpy.i file for swig is Python 3 only.# Uses of Python 2.7 C-API functions have been updated to Python 3 only. Users who need the old version should take it from an older version of NumPy. In calls using , , and similar a TypeError will now be correctly raised unless all elements have the identical void length. An example for this is: Which previously returned an array with dtype which cannot represent faithfully.\n\nThe keyword argument is added and allows to only consider specified elements or subaxes from an array in the Boolean evaluation of and . This new keyword is available to the functions and both via directly or in the methods of . Any broadcastable Boolean array or a scalar can be set as . It defaults to to evaluate the functions for all elements in an array if is not set by the user. Examples are given in the documentation of the functions. The keyword argument is added and allows to limit the scope in the calculation of , and to only a subset of elements. It is available both via directly or in the methods of . Any broadcastable Boolean array or a scalar can be set as . It defaults to to evaluate the functions for all elements in an array if is not set by the user. Examples are given in the documentation of the functions. The keyword argument option is added as an alias for and acts as the default option; using it has the direct transforms unscaled and the inverse transforms scaled by . Using the new keyword argument option has the direct transforms scaled by and the inverse transforms unscaled (i.e. exactly opposite to the default option ). Type annotations have been added for large parts of NumPy. There is also a new module that contains useful types for end-users. The currently available types are\n• None : for objects that can be coerced to an array\n• None : for objects that can be coerced to a dtype The types in can now be imported at runtime. Code like the following will now work: Because f2py is released together with NumPy, provides a way to track the version f2py used to generate the module. tests can be run via runtests.py# Currently running mypy with the NumPy stubs configured requires either:\n• None Adding the source directory to MYPYPATH and linking to the Both options are somewhat inconvenient, so add a option to runtests that handles setting things up for you. This will also be useful in the future for any typing codegen since it will ensure the project is built before type checking. allows negation of libraries when determining BLAS/LAPACK libraries. This may be used to remove an item from the library resolution phase, i.e. to disallow NetLIB libraries one could do: That will use any of the accelerated libraries instead. It is now possible to pass , , and flags to ASV build when the argument is used. The NVIDIA HPC SDK nvfortran compiler is now supported# Support for the nvfortran compiler, a version of pgfortran, has been added. The option is now available for and . It specifies which data-type the returned result should have. By default the functions still return a result.\n\nThe string representation ( ) of all six polynomial types in has been updated to give the polynomial as a mathematical expression instead of an array of coefficients. Two package-wide formats for the polynomial expressions are available - one using Unicode characters for superscripts and subscripts, and another using only ASCII characters. Object arrays containing multi-line objects have a more readable # If elements of an object array have a containing new lines, then the wrapped lines will be aligned by column. Notably, this improves the of nested arrays: Support was added to to provide an output and using keyword arguments. The argument cannot be provided in conjunction with the one. Callback functions in f2py are now thread safe. can now use file-like objects, for instance This allows SciPy to be built on AIX. Use f90 compiler specified by the command line args# The compiler command selection for Fortran Portland Group Compiler is changed in . This only affects the linking command. This forces the use of the executable provided by the command line option (if provided) instead of the pgfortran executable. If no executable is provided to the command line option it defaults to the pgf90 executable, which is an alias for pgfortran according to the PGI documentation. Add NumPy declarations for Cython 3.0 and later# The pxd declarations for Cython 3.0 were improved to avoid using deprecated NumPy C-API features. Extension modules built with Cython 3.0+ that use NumPy can now set the C macro to avoid C compiler warnings about deprecated API usage. Make sure the window functions provided by NumPy are symmetric. There were previously small deviations from symmetry due to numerical precision that are now avoided by better arrangement of the computation."
    },
    {
        "link": "https://numpy.org/doc/2.2/release/1.20.0-notes.html",
        "document": "This NumPy release is the largest so made to date, some 684 PRs contributed by 184 people have been merged. See the list of highlights below for more details. The Python versions supported for this release are 3.7-3.9, support for Python 3.6 has been dropped. Highlights are\n• None Annotations for NumPy functions. This work is ongoing and improvements can be expected pending feedback from users.\n• None Wider use of SIMD to increase execution speed of ufuncs. Much work has been done in introducing universal functions that will ease use of modern features across different hardware platforms. This work is ongoing.\n• None Preliminary work in changing the dtype and casting implementations in order to provide an easier path to extending dtypes. This work is ongoing but enough has been done to allow experimentation and feedback.\n• None Extensive documentation improvements comprising some 185 PR merges. This work is ongoing and part of the larger project to improve NumPy’s online presence and usefulness to new users.\n• None Further cleanups related to removing Python 2.7. This improves code readability and removes technical debt.\n\nUsing the aliases of builtin types like is deprecated# For a long time, has been an alias of the builtin . This is repeatedly a cause of confusion for newcomers, and existed mainly for historic reasons. These aliases have been deprecated. The table below shows the full list of deprecated aliases, along with their exact meaning. Replacing uses of items in the first column with the contents of the second column will work identically and silence the deprecation warning. The third column lists alternative NumPy names which may occasionally be preferential. See also Data types for additional details. To give a clear guideline for the vast majority of cases, for the types , , (and ) using the plain version is shorter and clear, and generally a good replacement. For and you can use and if you wish to be more explicit about the precision. For a direct replacement with or is also good and will not change behavior, but the precision will continue to depend on the computer and operating system. If you want to be more explicit and review the current use, you have the following alternatives:\n• None or to specify the precision exactly. This ensures that results cannot depend on the computer or operating system.\n• None or (the default), but be aware that it depends on the computer and operating system.\n• None which is 32bit on 32bit machines 64bit on 64bit machines. This can be the best type to use for indexing. When used with or changing it to the NumPy name as mentioned above will have no effect on the output. If used as a scalar with: changing it can subtly change the result. In this case, the Python version or is normally preferable, although the NumPy version may be useful for consistency with NumPy arrays (for example, NumPy behaves differently for things like division by zero). Passing to functions with a non-optional shape argument is deprecated# Previously, this was an alias for passing . This deprecation is emitted by PyArray_IntpConverter in the C API. If your API is intended to support passing , then you should check for prior to invoking the converter, so as to be able to distinguish and . Indexing errors will be reported even when index result is empty# In the future, NumPy will raise an IndexError when an integer array index contains out of bound values even if a non-indexed dimension is of length 0. This will now emit a DeprecationWarning. This can happen when the array is previously empty, or an empty slice is involved: Previously the non-empty index was not checked for correctness. It will now be checked causing a deprecation warning which will be turned into an error. This also applies to assignments. Inexact matches for and are deprecated# Inexact and case insensitive matches for and were valid inputs earlier and will give a DeprecationWarning now. For example, below are some example usages which are now deprecated and will give a DeprecationWarning: The module numpy.dual is deprecated. Instead of importing functions from numpy.dual, the functions should be imported directly from NumPy or SciPy. use with or generic ufunc outer calls such as . Previously, matrix was converted to an array here. This will not be done in the future requiring a manual conversion to arrays. The remaining numeric-style type codes , , , , and have been deprecated. The lower-case variants should be used instead. For bytes and string and are further alternatives. The method of is deprecated# The documentation has warned against using this function since NumPy 1.8. Use instead of . ArrayLike objects which do not define and # Objects which define one of the protocols , , or but are not sequences (usually defined by having a and ) will behave differently during array-coercion in the future. When nested inside sequences, such as , these were handled as a single Python object rather than an array. In the future they will behave identically to: This change should only have an effect if is not 0-D. The solution to this warning may depend on the object:\n• None Some array-likes may expect the new behaviour, and users can ignore the warning. The object can choose to expose the sequence protocol to opt-in to the new behaviour.\n• None For example, will allow conversion to an array-like using rather than . Users may work around the warning, or use the new convention when it becomes available. Unfortunately, using the new behaviour can only be achieved by calling . If you wish to ensure that the old behaviour remains unchanged, please create an object array and then fill it explicitly, for example: This will ensure NumPy knows to not enter the array-like and use it as a object instead.\n\nNumPy dtypes are not direct instances of anymore. Code that may have used will always return and must be updated to use the correct version . This change also affects the C-side macro if compiled against a NumPy older than 1.16.6. If code uses this macro and wishes to compile against an older version of NumPy, it must replace the macro (see also C API changes section). Same kind casting in concatenate with # When is called with , the flattened arrays were cast with . Any other axis choice uses “same kind”. That different default has been deprecated and “same kind” casting will be used instead. The new keyword argument can be used to retain the old behaviour. NumPy Scalars are cast when assigned to arrays# When creating or assigning to arrays, in all relevant cases NumPy scalars will now be cast identically to NumPy arrays. In particular this changes the behaviour in some cases which previously raised an error: will succeed and return an undefined result (usually the smallest possible integer). This also affects assignments: At this time, NumPy retains the behaviour for: The above changes do not affect Python scalars: remains unaffected ( is a Python , not a NumPy one). Unlike signed integers, unsigned integers do not retain this special case, since they always behaved more like casting. The following code stops raising an error: To avoid backward compatibility issues, at this time assignment from scalar to strings of too short length remains supported. This means that succeeds now, when it failed before. In the long term this may be deprecated or the unsafe cast may be allowed generally to make assignment of arrays and scalars behave consistently. Array coercion changes when Strings and other types are mixed# When strings and other types are mixed, such as: The results will change, which may lead to string dtypes with longer strings in some cases. In particularly, if is not provided any numerical value will lead to a string results long enough to hold all possible numerical values. (e.g. “S32” for floats). Note that you should always provide when converting non-strings to strings. If is provided the results will be largely identical to before, but NumPy scalars (not a Python float like ), will still enforce a uniform string length: Previously the first version gave the same result as the second. Array coercion has been restructured. In general, this should not affect users. In extremely rare corner cases where array-likes are nested: Things will now be more consistent with: This can subtly change output for some badly defined array-likes. One example for this are array-like objects which are not also sequences of matching shape. In NumPy 1.20, a warning will be given when an array-like is not also a sequence (but behaviour remains identical, see deprecations). If an array like is also a sequence (defines and ) NumPy will now only use the result given by , , or . This will result in differences when the (nested) sequence describes a different shape. Writing to the result of will export readonly buffers# In NumPy 1.17 started warning when the resulting array was written to. This warning was skipped when the array was used through the buffer interface (e.g. ). The same thing will now occur for the two protocols , and returning read-only buffers instead of giving a warning. Numeric-style type names have been removed from type dictionaries# To stay in sync with the deprecation for and other numeric-style (capital case) types. These were removed from and . You should use the lower case versions instead. Note that corresponds to and corresponds to . The numpy style (new) versions, denote the full size and not the size of the real/imaginary part. The function now raises TypeError for array arguments# The previous behavior was to fall back to addition and add the two arrays, which was thought to be unexpected behavior for a concatenation function. An abstract property has been removed from as it was no longer used in the derived convenience classes. This may affect users who have derived classes from and overridden the methods for representation and display, e.g. , , , etc. Float and timedelta promotion consistently raises a TypeError. aligns with now and both raise a TypeError. Previously, returned which was considered a bug. Uint64 and timedelta promotion consistently raises a TypeError. aligns with now and both raise a TypeError. Previously, returned which was considered a bug. Previously, failed to unpack if it was called with and a structured datatype was passed to the argument (or was passed and a structured datatype was inferred). For example: Structured arrays will now correctly unpack into a list of arrays, one for each column: Previously, and failed to return meaningful output. This bug potentially affects , , , and when an input with dtype other than the default and and equivalent Python types were used. The methods have been fixed to handle varying precision correctly. Previously, if a boolean array index matched the size of the indexed array but not the shape, it was incorrectly allowed in some cases. In other cases, it gave an error, but the error was incorrectly a with a message about broadcasting instead of the correct . For example, the following used to incorrectly give ValueError: operands could not be broadcast together with shapes (2,2) (1,4) : And the following used to incorrectly return : Both now correctly give IndexError: boolean index did not match indexed array along dimension 0; dimension is 2 but corresponding boolean dimension is 1 . When iterating while casting values, an error may stop the iteration earlier than before. In any case, a failed casting operation always returned undefined, partial results. Those may now be even more undefined and partial. For users of the C-API such cast errors will now cause the iternext() function to return 0 and thus abort iteration. Currently, there is no API to detect such an error directly. It is necessary to check , which may be problematic in combination with . These issues always existed, but new API could be added if required by users. f2py generated code may return unicode instead of byte strings# Some byte strings previously returned by f2py generated code may now be unicode strings. This results from the ongoing Python2 -> Python3 cleanup. The first element of the tuple must be an integer# This has been the documented interface for many years, but there was still code that would accept a byte string representation of the pointer address. That code has been removed, passing the address as a byte string will now raise an error. Previously, constructing an instance of with all-zero coefficients would cast the coefficients to . This affected the output dtype of methods which construct instances internally, such as . The numpy.i file for swig is Python 3 only.# Uses of Python 2.7 C-API functions have been updated to Python 3 only. Users who need the old version should take it from an older version of NumPy. In calls using , , and similar a TypeError will now be correctly raised unless all elements have the identical void length. An example for this is: Which previously returned an array with dtype which cannot represent faithfully.\n\nThe keyword argument is added and allows to only consider specified elements or subaxes from an array in the Boolean evaluation of and . This new keyword is available to the functions and both via directly or in the methods of . Any broadcastable Boolean array or a scalar can be set as . It defaults to to evaluate the functions for all elements in an array if is not set by the user. Examples are given in the documentation of the functions. The keyword argument is added and allows to limit the scope in the calculation of , and to only a subset of elements. It is available both via directly or in the methods of . Any broadcastable Boolean array or a scalar can be set as . It defaults to to evaluate the functions for all elements in an array if is not set by the user. Examples are given in the documentation of the functions. The keyword argument option is added as an alias for and acts as the default option; using it has the direct transforms unscaled and the inverse transforms scaled by . Using the new keyword argument option has the direct transforms scaled by and the inverse transforms unscaled (i.e. exactly opposite to the default option ). Type annotations have been added for large parts of NumPy. There is also a new module that contains useful types for end-users. The currently available types are\n• None : for objects that can be coerced to an array\n• None : for objects that can be coerced to a dtype The types in can now be imported at runtime. Code like the following will now work: Because f2py is released together with NumPy, provides a way to track the version f2py used to generate the module. tests can be run via runtests.py# Currently running mypy with the NumPy stubs configured requires either:\n• None Adding the source directory to MYPYPATH and linking to the Both options are somewhat inconvenient, so add a option to runtests that handles setting things up for you. This will also be useful in the future for any typing codegen since it will ensure the project is built before type checking. allows negation of libraries when determining BLAS/LAPACK libraries. This may be used to remove an item from the library resolution phase, i.e. to disallow NetLIB libraries one could do: That will use any of the accelerated libraries instead. It is now possible to pass , , and flags to ASV build when the argument is used. The NVIDIA HPC SDK nvfortran compiler is now supported# Support for the nvfortran compiler, a version of pgfortran, has been added. The option is now available for and . It specifies which data-type the returned result should have. By default the functions still return a result.\n\nThe string representation ( ) of all six polynomial types in has been updated to give the polynomial as a mathematical expression instead of an array of coefficients. Two package-wide formats for the polynomial expressions are available - one using Unicode characters for superscripts and subscripts, and another using only ASCII characters. Object arrays containing multi-line objects have a more readable # If elements of an object array have a containing new lines, then the wrapped lines will be aligned by column. Notably, this improves the of nested arrays: Support was added to to provide an output and using keyword arguments. The argument cannot be provided in conjunction with the one. Callback functions in f2py are now thread safe. can now use file-like objects, for instance This allows SciPy to be built on AIX. Use f90 compiler specified by the command line args# The compiler command selection for Fortran Portland Group Compiler is changed in . This only affects the linking command. This forces the use of the executable provided by the command line option (if provided) instead of the pgfortran executable. If no executable is provided to the command line option it defaults to the pgf90 executable, which is an alias for pgfortran according to the PGI documentation. Add NumPy declarations for Cython 3.0 and later# The pxd declarations for Cython 3.0 were improved to avoid using deprecated NumPy C-API features. Extension modules built with Cython 3.0+ that use NumPy can now set the C macro to avoid C compiler warnings about deprecated API usage. Make sure the window functions provided by NumPy are symmetric. There were previously small deviations from symmetry due to numerical precision that are now avoided by better arrangement of the computation."
    },
    {
        "link": "https://numpy.org/doc/2.0/release/1.20.0-notes.html",
        "document": "This NumPy release is the largest so made to date, some 684 PRs contributed by 184 people have been merged. See the list of highlights below for more details. The Python versions supported for this release are 3.7-3.9, support for Python 3.6 has been dropped. Highlights are\n• None Annotations for NumPy functions. This work is ongoing and improvements can be expected pending feedback from users.\n• None Wider use of SIMD to increase execution speed of ufuncs. Much work has been done in introducing universal functions that will ease use of modern features across different hardware platforms. This work is ongoing.\n• None Preliminary work in changing the dtype and casting implementations in order to provide an easier path to extending dtypes. This work is ongoing but enough has been done to allow experimentation and feedback.\n• None Extensive documentation improvements comprising some 185 PR merges. This work is ongoing and part of the larger project to improve NumPy’s online presence and usefulness to new users.\n• None Further cleanups related to removing Python 2.7. This improves code readability and removes technical debt.\n\nUsing the aliases of builtin types like is deprecated# For a long time, has been an alias of the builtin . This is repeatedly a cause of confusion for newcomers, and existed mainly for historic reasons. These aliases have been deprecated. The table below shows the full list of deprecated aliases, along with their exact meaning. Replacing uses of items in the first column with the contents of the second column will work identically and silence the deprecation warning. The third column lists alternative NumPy names which may occasionally be preferential. See also Data types for additional details. To give a clear guideline for the vast majority of cases, for the types , , (and ) using the plain version is shorter and clear, and generally a good replacement. For and you can use and if you wish to be more explicit about the precision. For a direct replacement with or is also good and will not change behavior, but the precision will continue to depend on the computer and operating system. If you want to be more explicit and review the current use, you have the following alternatives:\n• None or to specify the precision exactly. This ensures that results cannot depend on the computer or operating system.\n• None or (the default), but be aware that it depends on the computer and operating system.\n• None which is 32bit on 32bit machines 64bit on 64bit machines. This can be the best type to use for indexing. When used with or changing it to the NumPy name as mentioned above will have no effect on the output. If used as a scalar with: changing it can subtly change the result. In this case, the Python version or is normally preferable, although the NumPy version may be useful for consistency with NumPy arrays (for example, NumPy behaves differently for things like division by zero). Passing to functions with a non-optional shape argument is deprecated# Previously, this was an alias for passing . This deprecation is emitted by PyArray_IntpConverter in the C API. If your API is intended to support passing , then you should check for prior to invoking the converter, so as to be able to distinguish and . Indexing errors will be reported even when index result is empty# In the future, NumPy will raise an IndexError when an integer array index contains out of bound values even if a non-indexed dimension is of length 0. This will now emit a DeprecationWarning. This can happen when the array is previously empty, or an empty slice is involved: Previously the non-empty index was not checked for correctness. It will now be checked causing a deprecation warning which will be turned into an error. This also applies to assignments. Inexact matches for and are deprecated# Inexact and case insensitive matches for and were valid inputs earlier and will give a DeprecationWarning now. For example, below are some example usages which are now deprecated and will give a DeprecationWarning: The module numpy.dual is deprecated. Instead of importing functions from numpy.dual, the functions should be imported directly from NumPy or SciPy. use with or generic ufunc outer calls such as . Previously, matrix was converted to an array here. This will not be done in the future requiring a manual conversion to arrays. The remaining numeric-style type codes , , , , and have been deprecated. The lower-case variants should be used instead. For bytes and string and are further alternatives. The method of is deprecated# The documentation has warned against using this function since NumPy 1.8. Use instead of . ArrayLike objects which do not define and # Objects which define one of the protocols , , or but are not sequences (usually defined by having a and ) will behave differently during array-coercion in the future. When nested inside sequences, such as , these were handled as a single Python object rather than an array. In the future they will behave identically to: This change should only have an effect if is not 0-D. The solution to this warning may depend on the object:\n• None Some array-likes may expect the new behaviour, and users can ignore the warning. The object can choose to expose the sequence protocol to opt-in to the new behaviour.\n• None For example, will allow conversion to an array-like using rather than . Users may work around the warning, or use the new convention when it becomes available. Unfortunately, using the new behaviour can only be achieved by calling . If you wish to ensure that the old behaviour remains unchanged, please create an object array and then fill it explicitly, for example: This will ensure NumPy knows to not enter the array-like and use it as a object instead.\n\nNumPy dtypes are not direct instances of anymore. Code that may have used will always return and must be updated to use the correct version . This change also affects the C-side macro if compiled against a NumPy older than 1.16.6. If code uses this macro and wishes to compile against an older version of NumPy, it must replace the macro (see also C API changes section). Same kind casting in concatenate with # When is called with , the flattened arrays were cast with . Any other axis choice uses “same kind”. That different default has been deprecated and “same kind” casting will be used instead. The new keyword argument can be used to retain the old behaviour. NumPy Scalars are cast when assigned to arrays# When creating or assigning to arrays, in all relevant cases NumPy scalars will now be cast identically to NumPy arrays. In particular this changes the behaviour in some cases which previously raised an error: will succeed and return an undefined result (usually the smallest possible integer). This also affects assignments: At this time, NumPy retains the behaviour for: The above changes do not affect Python scalars: remains unaffected ( is a Python , not a NumPy one). Unlike signed integers, unsigned integers do not retain this special case, since they always behaved more like casting. The following code stops raising an error: To avoid backward compatibility issues, at this time assignment from scalar to strings of too short length remains supported. This means that succeeds now, when it failed before. In the long term this may be deprecated or the unsafe cast may be allowed generally to make assignment of arrays and scalars behave consistently. Array coercion changes when Strings and other types are mixed# When strings and other types are mixed, such as: The results will change, which may lead to string dtypes with longer strings in some cases. In particularly, if is not provided any numerical value will lead to a string results long enough to hold all possible numerical values. (e.g. “S32” for floats). Note that you should always provide when converting non-strings to strings. If is provided the results will be largely identical to before, but NumPy scalars (not a Python float like ), will still enforce a uniform string length: Previously the first version gave the same result as the second. Array coercion has been restructured. In general, this should not affect users. In extremely rare corner cases where array-likes are nested: Things will now be more consistent with: This can subtly change output for some badly defined array-likes. One example for this are array-like objects which are not also sequences of matching shape. In NumPy 1.20, a warning will be given when an array-like is not also a sequence (but behaviour remains identical, see deprecations). If an array like is also a sequence (defines and ) NumPy will now only use the result given by , , or . This will result in differences when the (nested) sequence describes a different shape. Writing to the result of will export readonly buffers# In NumPy 1.17 started warning when the resulting array was written to. This warning was skipped when the array was used through the buffer interface (e.g. ). The same thing will now occur for the two protocols , and returning read-only buffers instead of giving a warning. Numeric-style type names have been removed from type dictionaries# To stay in sync with the deprecation for and other numeric-style (capital case) types. These were removed from and . You should use the lower case versions instead. Note that corresponds to and corresponds to . The numpy style (new) versions, denote the full size and not the size of the real/imaginary part. The function now raises TypeError for array arguments# The previous behavior was to fall back to addition and add the two arrays, which was thought to be unexpected behavior for a concatenation function. An abstract property has been removed from as it was no longer used in the derived convenience classes. This may affect users who have derived classes from and overridden the methods for representation and display, e.g. , , , etc. Float and timedelta promotion consistently raises a TypeError. aligns with now and both raise a TypeError. Previously, returned which was considered a bug. Uint64 and timedelta promotion consistently raises a TypeError. aligns with now and both raise a TypeError. Previously, returned which was considered a bug. Previously, failed to unpack if it was called with and a structured datatype was passed to the argument (or was passed and a structured datatype was inferred). For example: Structured arrays will now correctly unpack into a list of arrays, one for each column: Previously, and failed to return meaningful output. This bug potentially affects , , , and when an input with dtype other than the default and and equivalent Python types were used. The methods have been fixed to handle varying precision correctly. Previously, if a boolean array index matched the size of the indexed array but not the shape, it was incorrectly allowed in some cases. In other cases, it gave an error, but the error was incorrectly a with a message about broadcasting instead of the correct . For example, the following used to incorrectly give ValueError: operands could not be broadcast together with shapes (2,2) (1,4) : And the following used to incorrectly return : Both now correctly give IndexError: boolean index did not match indexed array along dimension 0; dimension is 2 but corresponding boolean dimension is 1 . When iterating while casting values, an error may stop the iteration earlier than before. In any case, a failed casting operation always returned undefined, partial results. Those may now be even more undefined and partial. For users of the C-API such cast errors will now cause the iternext() function to return 0 and thus abort iteration. Currently, there is no API to detect such an error directly. It is necessary to check , which may be problematic in combination with . These issues always existed, but new API could be added if required by users. f2py generated code may return unicode instead of byte strings# Some byte strings previously returned by f2py generated code may now be unicode strings. This results from the ongoing Python2 -> Python3 cleanup. The first element of the tuple must be an integer# This has been the documented interface for many years, but there was still code that would accept a byte string representation of the pointer address. That code has been removed, passing the address as a byte string will now raise an error. Previously, constructing an instance of with all-zero coefficients would cast the coefficients to . This affected the output dtype of methods which construct instances internally, such as . The numpy.i file for swig is Python 3 only.# Uses of Python 2.7 C-API functions have been updated to Python 3 only. Users who need the old version should take it from an older version of NumPy. In calls using , , and similar a TypeError will now be correctly raised unless all elements have the identical void length. An example for this is: Which previously returned an array with dtype which cannot represent faithfully.\n\nThe keyword argument is added and allows to only consider specified elements or subaxes from an array in the Boolean evaluation of and . This new keyword is available to the functions and both via directly or in the methods of . Any broadcastable Boolean array or a scalar can be set as . It defaults to to evaluate the functions for all elements in an array if is not set by the user. Examples are given in the documentation of the functions. The keyword argument is added and allows to limit the scope in the calculation of , and to only a subset of elements. It is available both via directly or in the methods of . Any broadcastable Boolean array or a scalar can be set as . It defaults to to evaluate the functions for all elements in an array if is not set by the user. Examples are given in the documentation of the functions. The keyword argument option is added as an alias for and acts as the default option; using it has the direct transforms unscaled and the inverse transforms scaled by . Using the new keyword argument option has the direct transforms scaled by and the inverse transforms unscaled (i.e. exactly opposite to the default option ). Type annotations have been added for large parts of NumPy. There is also a new module that contains useful types for end-users. The currently available types are\n• None : for objects that can be coerced to an array\n• None : for objects that can be coerced to a dtype The types in can now be imported at runtime. Code like the following will now work: Because f2py is released together with NumPy, provides a way to track the version f2py used to generate the module. tests can be run via runtests.py# Currently running mypy with the NumPy stubs configured requires either:\n• None Adding the source directory to MYPYPATH and linking to the Both options are somewhat inconvenient, so add a option to runtests that handles setting things up for you. This will also be useful in the future for any typing codegen since it will ensure the project is built before type checking. allows negation of libraries when determining BLAS/LAPACK libraries. This may be used to remove an item from the library resolution phase, i.e. to disallow NetLIB libraries one could do: That will use any of the accelerated libraries instead. It is now possible to pass , , and flags to ASV build when the argument is used. The NVIDIA HPC SDK nvfortran compiler is now supported# Support for the nvfortran compiler, a version of pgfortran, has been added. The option is now available for and . It specifies which data-type the returned result should have. By default the functions still return a result.\n\nThe string representation ( ) of all six polynomial types in has been updated to give the polynomial as a mathematical expression instead of an array of coefficients. Two package-wide formats for the polynomial expressions are available - one using Unicode characters for superscripts and subscripts, and another using only ASCII characters. Object arrays containing multi-line objects have a more readable # If elements of an object array have a containing new lines, then the wrapped lines will be aligned by column. Notably, this improves the of nested arrays: Support was added to to provide an output and using keyword arguments. The argument cannot be provided in conjunction with the one. Callback functions in f2py are now thread safe. can now use file-like objects, for instance This allows SciPy to be built on AIX. Use f90 compiler specified by the command line args# The compiler command selection for Fortran Portland Group Compiler is changed in . This only affects the linking command. This forces the use of the executable provided by the command line option (if provided) instead of the pgfortran executable. If no executable is provided to the command line option it defaults to the pgf90 executable, which is an alias for pgfortran according to the PGI documentation. Add NumPy declarations for Cython 3.0 and later# The pxd declarations for Cython 3.0 were improved to avoid using deprecated NumPy C-API features. Extension modules built with Cython 3.0+ that use NumPy can now set the C macro to avoid C compiler warnings about deprecated API usage. Make sure the window functions provided by NumPy are symmetric. There were previously small deviations from symmetry due to numerical precision that are now avoided by better arrangement of the computation."
    },
    {
        "link": "https://numpy.org/doc/1.25/release/1.20.0-notes.html",
        "document": "This NumPy release is the largest so made to date, some 684 PRs contributed by 184 people have been merged. See the list of highlights below for more details. The Python versions supported for this release are 3.7-3.9, support for Python 3.6 has been dropped. Highlights are\n• None Annotations for NumPy functions. This work is ongoing and improvements can be expected pending feedback from users.\n• None Wider use of SIMD to increase execution speed of ufuncs. Much work has been done in introducing universal functions that will ease use of modern features across different hardware platforms. This work is ongoing.\n• None Preliminary work in changing the dtype and casting implementations in order to provide an easier path to extending dtypes. This work is ongoing but enough has been done to allow experimentation and feedback.\n• None Extensive documentation improvements comprising some 185 PR merges. This work is ongoing and part of the larger project to improve NumPy’s online presence and usefulness to new users.\n• None Further cleanups related to removing Python 2.7. This improves code readability and removes technical debt.\n\nUsing the aliases of builtin types like is deprecated# For a long time, has been an alias of the builtin . This is repeatedly a cause of confusion for newcomers, and existed mainly for historic reasons. These aliases have been deprecated. The table below shows the full list of deprecated aliases, along with their exact meaning. Replacing uses of items in the first column with the contents of the second column will work identically and silence the deprecation warning. The third column lists alternative NumPy names which may occasionally be preferential. See also Data types for additional details. To give a clear guideline for the vast majority of cases, for the types , , (and ) using the plain version is shorter and clear, and generally a good replacement. For and you can use and if you wish to be more explicit about the precision. For a direct replacement with or is also good and will not change behavior, but the precision will continue to depend on the computer and operating system. If you want to be more explicit and review the current use, you have the following alternatives:\n• None or to specify the precision exactly. This ensures that results cannot depend on the computer or operating system.\n• None or (the default), but be aware that it depends on the computer and operating system.\n• None which is 32bit on 32bit machines 64bit on 64bit machines. This can be the best type to use for indexing. When used with or changing it to the NumPy name as mentioned above will have no effect on the output. If used as a scalar with: changing it can subtly change the result. In this case, the Python version or is normally preferable, although the NumPy version may be useful for consistency with NumPy arrays (for example, NumPy behaves differently for things like division by zero). Passing to functions with a non-optional shape argument is deprecated# Previously, this was an alias for passing . This deprecation is emitted by PyArray_IntpConverter in the C API. If your API is intended to support passing , then you should check for prior to invoking the converter, so as to be able to distinguish and . Indexing errors will be reported even when index result is empty# In the future, NumPy will raise an IndexError when an integer array index contains out of bound values even if a non-indexed dimension is of length 0. This will now emit a DeprecationWarning. This can happen when the array is previously empty, or an empty slice is involved: Previously the non-empty index was not checked for correctness. It will now be checked causing a deprecation warning which will be turned into an error. This also applies to assignments. Inexact matches for and are deprecated# Inexact and case insensitive matches for and were valid inputs earlier and will give a DeprecationWarning now. For example, below are some example usages which are now deprecated and will give a DeprecationWarning: The module numpy.dual is deprecated. Instead of importing functions from numpy.dual, the functions should be imported directly from NumPy or SciPy. use with or generic ufunc outer calls such as . Previously, matrix was converted to an array here. This will not be done in the future requiring a manual conversion to arrays. The remaining numeric-style type codes , , , , and have been deprecated. The lower-case variants should be used instead. For bytes and string and are further alternatives. The method of is deprecated# The documentation has warned against using this function since NumPy 1.8. Use instead of . ArrayLike objects which do not define and # Objects which define one of the protocols , , or but are not sequences (usually defined by having a and ) will behave differently during array-coercion in the future. When nested inside sequences, such as , these were handled as a single Python object rather than an array. In the future they will behave identically to: This change should only have an effect if is not 0-D. The solution to this warning may depend on the object:\n• None Some array-likes may expect the new behaviour, and users can ignore the warning. The object can choose to expose the sequence protocol to opt-in to the new behaviour.\n• None For example, will allow conversion to an array-like using rather than . Users may work around the warning, or use the new convention when it becomes available. Unfortunately, using the new behaviour can only be achieved by calling . If you wish to ensure that the old behaviour remains unchanged, please create an object array and then fill it explicitly, for example: This will ensure NumPy knows to not enter the array-like and use it as a object instead.\n\nNumPy dtypes are not direct instances of anymore. Code that may have used will always return and must be updated to use the correct version . This change also affects the C-side macro if compiled against a NumPy older than 1.16.6. If code uses this macro and wishes to compile against an older version of NumPy, it must replace the macro (see also C API changes section). Same kind casting in concatenate with # When is called with , the flattened arrays were cast with . Any other axis choice uses “same kind”. That different default has been deprecated and “same kind” casting will be used instead. The new keyword argument can be used to retain the old behaviour. NumPy Scalars are cast when assigned to arrays# When creating or assigning to arrays, in all relevant cases NumPy scalars will now be cast identically to NumPy arrays. In particular this changes the behaviour in some cases which previously raised an error: will succeed and return an undefined result (usually the smallest possible integer). This also affects assignments: At this time, NumPy retains the behaviour for: The above changes do not affect Python scalars: remains unaffected ( is a Python , not a NumPy one). Unlike signed integers, unsigned integers do not retain this special case, since they always behaved more like casting. The following code stops raising an error: To avoid backward compatibility issues, at this time assignment from scalar to strings of too short length remains supported. This means that succeeds now, when it failed before. In the long term this may be deprecated or the unsafe cast may be allowed generally to make assignment of arrays and scalars behave consistently. Array coercion changes when Strings and other types are mixed# When strings and other types are mixed, such as: The results will change, which may lead to string dtypes with longer strings in some cases. In particularly, if is not provided any numerical value will lead to a string results long enough to hold all possible numerical values. (e.g. “S32” for floats). Note that you should always provide when converting non-strings to strings. If is provided the results will be largely identical to before, but NumPy scalars (not a Python float like ), will still enforce a uniform string length: Previously the first version gave the same result as the second. Array coercion has been restructured. In general, this should not affect users. In extremely rare corner cases where array-likes are nested: Things will now be more consistent with: This can subtly change output for some badly defined array-likes. One example for this are array-like objects which are not also sequences of matching shape. In NumPy 1.20, a warning will be given when an array-like is not also a sequence (but behaviour remains identical, see deprecations). If an array like is also a sequence (defines and ) NumPy will now only use the result given by , , or . This will result in differences when the (nested) sequence describes a different shape. Writing to the result of will export readonly buffers# In NumPy 1.17 started warning when the resulting array was written to. This warning was skipped when the array was used through the buffer interface (e.g. ). The same thing will now occur for the two protocols , and returning read-only buffers instead of giving a warning. Numeric-style type names have been removed from type dictionaries# To stay in sync with the deprecation for and other numeric-style (capital case) types. These were removed from and . You should use the lower case versions instead. Note that corresponds to and corresponds to . The numpy style (new) versions, denote the full size and not the size of the real/imaginary part. The function now raises TypeError for array arguments# The previous behavior was to fall back to addition and add the two arrays, which was thought to be unexpected behavior for a concatenation function. An abstract property has been removed from as it was no longer used in the derived convenience classes. This may affect users who have derived classes from and overridden the methods for representation and display, e.g. , , , etc. Float and timedelta promotion consistently raises a TypeError. aligns with now and both raise a TypeError. Previously, returned which was considered a bug. Uint64 and timedelta promotion consistently raises a TypeError. aligns with now and both raise a TypeError. Previously, returned which was considered a bug. Previously, failed to unpack if it was called with and a structured datatype was passed to the argument (or was passed and a structured datatype was inferred). For example: Structured arrays will now correctly unpack into a list of arrays, one for each column: Previously, and failed to return meaningful output. This bug potentially affects , , , and when an input with dtype other than the default and and equivalent Python types were used. The methods have been fixed to handle varying precision correctly. Previously, if a boolean array index matched the size of the indexed array but not the shape, it was incorrectly allowed in some cases. In other cases, it gave an error, but the error was incorrectly a with a message about broadcasting instead of the correct . For example, the following used to incorrectly give ValueError: operands could not be broadcast together with shapes (2,2) (1,4) : And the following used to incorrectly return : Both now correctly give IndexError: boolean index did not match indexed array along dimension 0; dimension is 2 but corresponding boolean dimension is 1 . When iterating while casting values, an error may stop the iteration earlier than before. In any case, a failed casting operation always returned undefined, partial results. Those may now be even more undefined and partial. For users of the C-API such cast errors will now cause the iternext() function to return 0 and thus abort iteration. Currently, there is no API to detect such an error directly. It is necessary to check , which may be problematic in combination with . These issues always existed, but new API could be added if required by users. f2py generated code may return unicode instead of byte strings# Some byte strings previously returned by f2py generated code may now be unicode strings. This results from the ongoing Python2 -> Python3 cleanup. The first element of the tuple must be an integer# This has been the documented interface for many years, but there was still code that would accept a byte string representation of the pointer address. That code has been removed, passing the address as a byte string will now raise an error. Previously, constructing an instance of with all-zero coefficients would cast the coefficients to . This affected the output dtype of methods which construct instances internally, such as . The numpy.i file for swig is Python 3 only.# Uses of Python 2.7 C-API functions have been updated to Python 3 only. Users who need the old version should take it from an older version of NumPy. In calls using , , and similar a TypeError will now be correctly raised unless all elements have the identical void length. An example for this is: Which previously returned an array with dtype which cannot represent faithfully.\n\nThe keyword argument is added and allows to only consider specified elements or subaxes from an array in the Boolean evaluation of and . This new keyword is available to the functions and both via directly or in the methods of . Any broadcastable Boolean array or a scalar can be set as . It defaults to to evaluate the functions for all elements in an array if is not set by the user. Examples are given in the documentation of the functions. The keyword argument is added and allows to limit the scope in the calculation of , and to only a subset of elements. It is available both via directly or in the methods of . Any broadcastable Boolean array or a scalar can be set as . It defaults to to evaluate the functions for all elements in an array if is not set by the user. Examples are given in the documentation of the functions. The keyword argument option is added as an alias for and acts as the default option; using it has the direct transforms unscaled and the inverse transforms scaled by . Using the new keyword argument option has the direct transforms scaled by and the inverse transforms unscaled (i.e. exactly opposite to the default option ). Type annotations have been added for large parts of NumPy. There is also a new module that contains useful types for end-users. The currently available types are\n• None : for objects that can be coerced to an array\n• None : for objects that can be coerced to a dtype The types in can now be imported at runtime. Code like the following will now work: Because f2py is released together with NumPy, provides a way to track the version f2py used to generate the module. tests can be run via runtests.py# Currently running mypy with the NumPy stubs configured requires either:\n• None Adding the source directory to MYPYPATH and linking to the Both options are somewhat inconvenient, so add a option to runtests that handles setting things up for you. This will also be useful in the future for any typing codegen since it will ensure the project is built before type checking. allows negation of libraries when determining BLAS/LAPACK libraries. This may be used to remove an item from the library resolution phase, i.e. to disallow NetLIB libraries one could do: That will use any of the accelerated libraries instead. It is now possible to pass , , and flags to ASV build when the argument is used. The NVIDIA HPC SDK nvfortran compiler is now supported# Support for the nvfortran compiler, a version of pgfortran, has been added. The option is now available for and . It specifies which data-type the returned result should have. By default the functions still return a result.\n\nThe string representation ( ) of all six polynomial types in has been updated to give the polynomial as a mathematical expression instead of an array of coefficients. Two package-wide formats for the polynomial expressions are available - one using Unicode characters for superscripts and subscripts, and another using only ASCII characters. Object arrays containing multi-line objects have a more readable # If elements of an object array have a containing new lines, then the wrapped lines will be aligned by column. Notably, this improves the of nested arrays: Support was added to to provide an output and using keyword arguments. The argument cannot be provided in conjunction with the one. Callback functions in f2py are now thread safe. can now use file-like objects, for instance This allows SciPy to be built on AIX. Use f90 compiler specified by the command line args# The compiler command selection for Fortran Portland Group Compiler is changed in . This only affects the linking command. This forces the use of the executable provided by the command line option (if provided) instead of the pgfortran executable. If no executable is provided to the command line option it defaults to the pgf90 executable, which is an alias for pgfortran according to the PGI documentation. Add NumPy declarations for Cython 3.0 and later# The pxd declarations for Cython 3.0 were improved to avoid using deprecated NumPy C-API features. Extension modules built with Cython 3.0+ that use NumPy can now set the C macro to avoid C compiler warnings about deprecated API usage. Make sure the window functions provided by NumPy are symmetric. There were previously small deviations from symmetry due to numerical precision that are now avoided by better arrangement of the computation."
    },
    {
        "link": "https://github.com/tslearn-team/tslearn/issues/386",
        "document": "DeprecationWarning: is a deprecated alias for the builtin . To silence this warning, use by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use here.\n\n Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
    },
    {
        "link": "https://docs.opencv.org/4.x/d4/d86/group__imgproc__filter.html",
        "document": "Functions and classes described in this section are used to perform various linear or non-linear filtering operations on 2D images (represented as Mat's). It means that for each pixel location \\((x,y)\\) in the source image (normally, rectangular), its neighborhood is considered and used to compute the response. In case of a linear filter, it is a weighted sum of pixel values. In case of morphological operations, it is the minimum or maximum values, and so on. The computed response is stored in the destination image at the same location \\((x,y)\\). It means that the output image will be of the same size as the input image. Normally, the functions support multi-channel arrays, in which case every channel is processed independently. Therefore, the output image will also have the same number of channels as the input one.\n\nAnother common feature of the functions and classes described in this section is that, unlike simple arithmetic functions, they need to extrapolate values of some non-existing pixels. For example, if you want to smooth an image using a Gaussian \\(3 \\times 3\\) filter, then, when processing the left-most pixels in each row, you need pixels to the left of them, that is, outside of the image. You can let these pixels be the same as the left-most image pixels (\"replicated border\" extrapolation method), or assume that all the non-existing pixels are zeros (\"constant border\" extrapolation method), and so on. OpenCV enables you to specify the extrapolation method. For details, see BorderTypes\n\nApplies the bilateral filter to an image. The function applies bilateral filtering to the input image, as described in http://www.dai.ed.ac.uk/CVonline/LOCAL_COPIES/MANDUCHI1/Bilateral_Filtering.html bilateralFilter can reduce unwanted noise very well while keeping edges fairly sharp. However, it is very slow compared to most filters. Sigma values: For simplicity, you can set the 2 sigma values to be the same. If they are small (< 10), the filter will not have much effect, whereas if they are large (> 150), they will have a very strong effect, making the image look \"cartoonish\". Filter size: Large filters (d > 5) are very slow, so it is recommended to use d=5 for real-time applications, and perhaps d=9 for offline applications that need heavy noise filtering. This filter does not work inplace. Destination image of the same size and type as src . Diameter of each pixel neighborhood that is used during filtering. If it is non-positive, it is computed from sigmaSpace. Filter sigma in the color space. A larger value of the parameter means that farther colors within the pixel neighborhood (see sigmaSpace) will be mixed together, resulting in larger areas of semi-equal color. Filter sigma in the coordinate space. A larger value of the parameter means that farther pixels will influence each other as long as their colors are close enough (see sigmaColor ). When d>0, it specifies the neighborhood size regardless of sigmaSpace. Otherwise, d is proportional to sigmaSpace. border mode used to extrapolate pixels outside of the image, see BorderTypes\n\nPerforms initial step of meanshift segmentation of an image. The function implements the filtering stage of meanshift segmentation, that is, the output of the function is the filtered \"posterized\" image with color gradients and fine-grain texture flattened. At every pixel (X,Y) of the input image (or down-sized input image, see below) the function executes meanshift iterations, that is, the pixel (X,Y) neighborhood in the joint space-color hyperspace is considered: where (R,G,B) and (r,g,b) are the vectors of color components at (X,Y) and (x,y), respectively (though, the algorithm does not depend on the color space used, so any 3-component color space can be used instead). Over the neighborhood the average spatial value (X',Y') and average color vector (R',G',B') are found and they act as the neighborhood center on the next iteration: After the iterations over, the color components of the initial pixel (that is, the pixel from where the iterations started) are set to the final value (average color at the last iteration): When maxLevel > 0, the gaussian pyramid of maxLevel+1 levels is built, and the above procedure is run on the smallest layer first. After that, the results are propagated to the larger layer and the iterations are run again only on those pixels where the layer colors differ by more than sr from the lower-resolution layer of the pyramid. That makes boundaries of color regions sharper. Note that the results will be actually different from the ones obtained by running the meanshift procedure on the whole original image (i.e. when maxLevel==0). The destination image of the same format and the same size as the source. Maximum level of the pyramid for the segmentation.\n\nCalculates the first, second, third, or mixed image derivatives using an extended Sobel operator. In all cases except one, the \\(\\texttt{ksize} \\times \\texttt{ksize}\\) separable kernel is used to calculate the derivative. When \\(\\texttt{ksize = 1}\\), the \\(3 \\times 1\\) or \\(1 \\times 3\\) kernel is used (that is, no Gaussian smoothing is done). can only be used for the first or the second x- or y- derivatives. There is also the special value that corresponds to the \\(3\\times3\\) Scharr filter that may give more accurate results than the \\(3\\times3\\) Sobel. The Scharr aperture is for the x-derivative, or transposed for the y-derivative. The function calculates an image derivative by convolving the image with the appropriate kernel: The Sobel operators combine Gaussian smoothing and differentiation, so the result is more or less resistant to the noise. Most often, the function is called with ( xorder = 1, yorder = 0, ksize = 3) or ( xorder = 0, yorder = 1, ksize = 3) to calculate the first x- or y- image derivative. The first case corresponds to a kernel of: The second case corresponds to a kernel of: output image of the same size and the same number of channels as src . output image depth, see combinations; in the case of 8-bit input images it will result in truncated derivatives. size of the extended Sobel kernel; it must be 1, 3, 5, or 7. optional scale factor for the computed derivative values; by default, no scaling is applied (see getDerivKernels for details). optional delta value that is added to the results prior to storing them in dst. pixel extrapolation method, see BorderTypes. BORDER_WRAP is not supported."
    },
    {
        "link": "https://geeksforgeeks.org/python-opencv-filter2d-function",
        "document": "In this article, we are going to see about the filter2d() function from OpenCV. In a nutshell, with this function, we can convolve an image with the kernel (typically a 2d matrix) to apply a filter on the images.\n\nUsing this function, we can create a convolution between the image and the given kernel for creating filters like smoothing and blurring, sharpening, and edge detection in an image. This function will simply convolute the 2d matrix with the image at pixel level and produce an output image. To understand this concept, we shall first skim through the concept of the kernel.\n\nKernel: A simple 2d matrix used in convolution or Convolution Matrix or a mask used to blur, sharpen and edge detect an image.\n\nWorking of the kernel: So, how this kernel works? Let’s see, we all know that images are represented as pixel values in OpenCV. These pixels are arranged as a matrix to form an image and as we know that a kernel is a simple 2d matrix with specific values in it based on the function of the kernel like if the kernel is used for blurring and sharpening the images are different.\n\nLet us take an example, In this image take the first 3 rows and columns like a matrix and we have a kernel of 3 by 3 matrix. Each of the pixels in the image has a pixel value (i.e. pixel intensity) as shown. Now the convolution is done by multiplying the values of each pixel value with the kernel value in the respective places and adding all the values which were just weighted by the kernel by multiplying and forming one pixel (the center pixel which in this case it is [2,2]). And this method is repeated for the rest of the pixel value matrices in the image.\n\nNote: We have specific kernels [2d convolution matrices] to do specific tasks like blurring, sharpening, and edge detection. And the kernel shown in the image is just an example and not any specific kernel.\n\nWith the use of these kernels, we can form the filtered image by simply convoluting the pixel values of the image and the values in the kernel.\n\nWe are creating a kernel by NumPy which will look like this and passing the kernel as a parameter of the filter2d function.\n\nExample 1: Blur an image with a 2d convolution matrix\n\nExample 2: Edge detect an image with a 2d convolution matrix\n\nWe are creating a kernel by NumPy array which will look like this and passing the kernel as a parameter of the filter2d function."
    },
    {
        "link": "https://docs.opencv.org/3.4/d4/dbd/tutorial_filter_2d.html",
        "document": "Next Tutorial: Adding borders to your images\n\nIn this tutorial you will learn how to:\n• Use the OpenCV function filter2D() to create your own linear filters.\n\nIn a very general sense, correlation is an operation between every part of an image and an operator (kernel).\n\nA kernel is essentially a fixed size array of numerical coefficients along with an anchor point in that array, which is typically located at the center.\n\nHow does correlation with a kernel work?\n\nAssume you want to know the resulting value of a particular location in the image. The value of the correlation is calculated in the following way:\n• Place the kernel anchor on top of a determined pixel, with the rest of the kernel overlaying the corresponding local pixels in the image.\n• Multiply the kernel coefficients by the corresponding image pixel values and sum the result.\n• Place the result to the location of the anchor in the input image.\n• Repeat the process for all pixels by scanning the kernel over the entire image.\n\nExpressing the procedure above in the form of an equation we would have:\n\nFortunately, OpenCV provides you with the function filter2D() so you do not have to code all these operations.\n\nWhat does this program do?\n• None Performs a normalized box filter. For instance, for a kernel of size \\(size = 3\\), the kernel would be:\n\nThe program will perform the filter operation with kernels of sizes 3, 5, 7, 9 and 11.\n• The filter output (with each kernel) will be shown during 500 milliseconds\n\nThe tutorial code's is shown in the lines below.\n\nPerform an infinite loop updating the kernel size and applying our linear filter to the input image. Let's analyze that more in detail:\n• First we define the kernel our filter is going to use. Here it is:\n\nThe first line is to update the kernel_size to odd values in the range: \\([3,11]\\). The second line actually builds the kernel by setting its value to a matrix filled with \\(1's\\) and normalizing it by dividing it between the number of elements.\n• After setting the kernel, we can generate the filter by using the function filter2D() :\n• The arguments denote:\n• ddepth: The depth of dst. A negative value (such as \\(-1\\)) indicates that the depth is the same as the source.\n• kernel: The kernel to be scanned through the image\n• anchor: The position of the anchor relative to its kernel. The location Point(-1, -1) indicates the center by default.\n• delta: A value to be added to each pixel during the correlation. By default it is \\(0\\)\n• BORDER_DEFAULT: We let this value by default (more details in the following tutorial)\n• Our program will effectuate a while loop, each 500 ms the kernel size of our filter will be updated in the range indicated.\n• After compiling the code above, you can execute it giving as argument the path of an image. The result should be a window that shows an image blurred by a normalized filter. Each 0.5 seconds the kernel size should change, as can be seen in the series of snapshots below:"
    },
    {
        "link": "https://askpython.com/python-modules/opencv-filter2d",
        "document": "Hello everyone! In this tutorial, we will learn how to use OpenCV method to apply filters on images such as sharpening, bluring and finding edges in the images. So lets get started.\n\nAlso read: Read Images in Python using OpenCV\n\nWhile dealing with images in Image Processing, function is used to change the pixel intensity value of an image based on the surrounding pixel intensity values. This method can enhance or remove certain features of an image to create a new image.\n\nSyntax to define function in python is as follows:\n• src: The source image on which to apply the fitler. It is a matrix that represents the image in pixel intensity values.\n• ddepth: It is the desirable depth of destination image. Value -1 represents that the resulting image will have same depth as the source image.\n• kernel: kernel is the filter matrix applied on the image.\n\nMore formally, function convolves an image with the kernel which results in an image becoming blur or sharpen and enhances the image features.\n\nAlso known as convolution matrix or mask, kernel is a small 2-dimensional matrix containing values that represent how much part of surrounding pixel values it should take to calculate intensity value of the current pixel. Usually, kernels are square matrices of odd length like 3×3, 5×5, 7×7 matrices.\n\nThus, the kernel act as a weighted matrix and is used for the blurring of images, sharpening of images, detection of edges in the images, etc. in image processing. This is done by convolution between image and kernel.\n\nIn Image Processing, Convolution is simply an element wise multiplication of kernel and some part of source image to produce a new single data point representing a pixel, doing it on every possible part of image to create a new image.\n\nIn Convolution, we take a submatrix from source image of same size as that of kernel, multiply each element of source image with corresponding element of kernel, perform addition on the previous computation and normalize the data so as to represent the data as pixel value.\n\nConsider an example as shown in the image below:\n\nConvolution on an image can result in an image of size less than the source image. The difference depends on the size of our kernel. However, there are ways to deal with it as discussed here.\n\nUsing OpenCV filter2d() with different kernels\n\nLet’s apply the function on an image with different kernels and see what results we get. For this example, we will use the following image.\n\nYou can learn more about sharpening images. This short snippet will sharpen the image shown above.\n\nLet’s look at edge detection with the OpenCV filter2D() function.\n\nIn this tutorial, you learned about Convolution and kernels in image processing and how OpenCV filter2D() function is used in python to manipulate images. Now you can play around and try different kernel filters to get different image effects."
    },
    {
        "link": "https://stackoverflow.com/questions/43392956/explanation-for-ddepth-parameter-in-cv2-filter2d-opencv",
        "document": "It has information about what kinds of data stored in an image, and that can be unsigned char ( ), signed char ( ), unsigned short ( ), and so on...\n\nAs for type, the type has information combined from 2 values:\n\nIt can be for example (which is equal to ), , , (which is equal to ) etc.\n\nFor more discussion, it can be found in the following two articles"
    },
    {
        "link": "https://learnopencv.com/image-filtering-using-convolution-in-opencv",
        "document": "Have you ever tried to blur or sharpen an image in Photoshop, or with the help of a mobile application? If yes, then you have already used convolution kernels. Here, we will explain how to use convolution in OpenCV for image filtering.\n\nYou will use 2D-convolution kernels and the OpenCV Computer Vision library to apply different blurring and sharpening techniques to an image. We will show you how to implement these techniques, both in Python and C++.\n• An Introduction to Convolution Kernels in Image Processing\n• How to Use Kernels to Sharpen or Blur Images?\n• Applying Identity Kernel to an Image in OpenCV\n• Applying Gaussian Blurring to an Image in OpenCV\n• Applying Median Blurring to an Image in OpenCV\n• Applying Bilateral Filtering to an Image in OpenCV\n\nLet’s start by taking a look at the code that will be used to filter images. Each line of code will be discussed in detail so that you fully understand it.\n\nAn Introduction to Convolution Kernels in Image Processing\n\nIn image processing, a convolution kernel is a 2D matrix that is used to filter images. Also known as a convolution matrix, a convolution kernel is typically a square, MxN matrix, where both M and N are odd integers (e.g. 3×3, 5×5, 7×7 etc.). See the 3×3 example matrix given below.\n\n\n\nSuch kernels can be used to perform mathematical operations on each pixel of an image to achieve a desired effect (like blurring or sharpening an image). But why would you want to blur an image? Here are two important reasons:\n• Because it reduces certain types of noise in an image. For this reason, blurring is often referred to as smoothing.\n• To remove a distracting background, you might intentionally blur portions of an image, as is done in ‘Portrait’ mode, on mobile device cameras.\n\nBeing a fundamental processing technique in Computer Vision, filtering images with kernels has many more applications.\n\nHow to Use Kernels to Sharpen or Blur Images\n\nFiltering of a source image is achieved by convolving the kernel with the image. In simple terms, convolution of an image with a kernel represents a simple mathematical operation, between the kernel and its corresponding elements in the image.\n• Assume that the center of the kernel is positioned over a specific pixel (p), in an image.\n• Then multiply the value of each element in the kernel (1 in this case), with the corresponding pixel element (i.e. its pixel intensity) in the source image.\n• Now, sum the result of those multiplications and compute the average.\n• Finally, replace the value of pixel (p), with the average value you just computed.\n\nOnce you perform this operation for every pixel in the source image, using the above 3×3 kernel, the resulting filtered image will appear blurred. This is because the convolution operation with this kernel has an averaging effect, which tends to smooth or blur the image. You will soon see for yourself how the value of individual elements in a kernel dictate the nature of filtering. For example, by changing the value of the kernel elements, you can also achieve a sharpening effect. The concept is simple yet very powerful, and is therefore used in numerous image processing pipelines.\n\nNow that you have learned to use convolution kernels, let’s explore how this is implemented in OpenCV.\n\nYou can also click here and visit the Colab notebook for this tutorial. You can run all the experiments there, without setting up your local system.\n\nWe will be using the following image for all our coding operations.\n\nApplying the Identity Kernel to an Image in OpenCV\n\nBefore we describe how to implement blurring and sharpening kernels, let’s first learn about the identity kernel. The identity kernel is a square matrix, where the middle element is 1, and all other elements are zero, as shown below.\n\nWhat makes an identity matrix special is that multiplying it with any other matrix will return the original matrix. Let’s now demonstrate how to use this identity kernel with OpenCV filtering functions. In this first example, we will use the above identity kernel to show that the filtering operation leaves the original image unchanged.\n\nStart by importing OpenCV and Numpy, as shown in the code below.\n\nThe following steps are performed in the code below:\n• Use the function in OpenCV to perform the linear filtering operation\n• Display the original and filtered images, using\n• Save the filtered image to disk, using\n• The first argument is the source image\n• The second argument is , which indicates the depth of the resulting image. A value of -1 indicates that the final image will also have the same depth as the source image\n• The final input argument is the , which we apply to the source image\n\nHere is the code, both in Python and C++.\n\nAs you can see in the below image, the filtered image (on the right) appears identical to the original image (on the left).\n\nNext, we will demonstrate how to blur an image. Here too, we will define a custom kernel, and use the function in OpenCV to apply the filtering operation on the source image.\n\nBegin by defining a 5×5 kernel, consisting of only ones. Note that we also divide the kernel by 25. Why is that? Well, before you apply any convolution to an image, using a 2D-convolution matrix, you need to ensure that all the values are normalized. This is done by dividing each element of the kernel, by the number of elements in the kernel, which in this case is 25. This ensures all values stay within the range of [0,1].\n\nNow use the function to filter the image. As you can see, can be used to convolve an image, with any user-defined kernel.\n\nLook at the results in image given below and note how the filtered image (on the right) has been blurred compared to the original image (on the left).\n\nYou can also blur an image, using OpenCV’s built-in function. Essentially a convenience function, use it to blur images, where you need not specifically define a kernel. Simply specify the kernel size, using the input argument, as shown in the code below. The blur function will then internally create a 5×5 blur kernel, and apply it to the source image.\n\nThe example below, which uses the function will generate exactly the same output as the example above, which had used the function.\n\nApplying Gaussian Blurring to an Image in OpenCV\n\nWe will now apply a Gaussian blur to an image, using OpenCV. This technique uses a Gaussian filter, which performs a weighted average, as opposed to the uniform average described in the first example. In this case, the Gaussian blur weights pixel values, based on their distance from the center of the kernel. Pixels further from the center have less influence on the weighted average. The following code convolves an image, using the function in OpenCV.\n• The first argument, , specifies the source image that you want to filter.\n• The second argument is , which defines the size of the Gaussian kernel. Here, we are using a 5×5 kernel.\n• The final two arguments are and , which are both set to 0. These are the Gaussian kernel standard deviations, in the X (horizontal) and Y (vertical) direction. The default setting of is zero. If you simply set to zero, then the standard deviations are computed from the kernel size (width and height respectively). You can also explicitly set the size of each argument to positive values greater than zero.\n\nThe result is shown in figure given below. As you can see, there is a slight amount of blurring in the filtered image on the right.\n\nApplying Median Blurring to an Image in OpenCV\n\nWe can also apply median blurring, using the function in OpenCV. In median blurring, each pixel in the source image is replaced by the median value of the image pixels in the kernel area.\n\nThis function has just two required arguments:\n• The first is the source image.\n• The second is the kernel size, which must be an odd, positive integer.\n\nSee the results of median blurring in figure given below. Note how for the same kernel size, the effect of median blurring is more prominent than Gaussian blurring. Median burring is often used to reduce ‘salt and pepper’ noise in images, as shown here.\n\nYou can also sharpen an image with a 2D-convolution kernel. First define a custom 2D kernel, and then use the function to apply the convolution operation to the image.\n\nIn the code below, the 3×3 kernel defines a sharpening kernel. Check out this resource to learn more about commonly used kernels.\n\nSo, what kind of results do we get? Have a look at figure given below. The sharpening effects are very impressive. The sharpened image on the right reveals cracks in the wood that were not visible before.\n\nApplying Bilateral Filtering to an Image in OpenCV\n\nWhile blurring can be an effective way to reduce noise in an image, it is often not desirable to blur the entire image, as important details and sharp edges may be lost. In such cases, can make your life easier.\n• This technique applies the filter selectively to blur similar intensity pixels in a neighborhood. Sharp edges are preserved, wherever possible.\n• It lets you control not only the spatial size of the filter, but also the degree to which the neighboring pixels are included in the filtered output. This is done, based on variation in their color intensity, and also distance from the filtered pixel.\n\nBilateral filtering essentially applies a 2D Gaussian (weighted) blur to the image, while also considering the variation in intensities of neighboring pixels to minimize the blurring near edges (which we wish to preserve). What this means is that the shape of the kernel actually depends on the local image content, at every pixel location.\n\nHere’s a concrete example. Assume, you are filtering a region in an image, near an edge. A simple Gaussian blur filter would blur the edge because it lies near the filtered region (close to the center of the Gaussian filter). But the bilateral filter can sense the edge, because it also considers differences in pixel intensities. So, it will compute a much lower weight for the pixels straddling the edge, thereby reducing their influence on the filtered region. Regions of more uniform intensity are blurred heavier, as they are not associated with strong edges.\n\nThankfully, OpenCV provides the function to filter images.\n\nThis function has four required arguments:\n• The first argument of the function is the source image.\n• The next argument d, defines the diameter of the pixel neighborhood used for filtering.\n• The next two arguments, and define the standard deviation of the (1D) color-intensity distribution and (2D) spatial distribution respectively.\n• The parameter defines the spatial extent of the kernel, in both the x and y directions (just like the Gaussian blur filter previously described).\n• The parameter defines the one-dimensional Gaussian distribution, which specifies the degree to which differences in pixel intensity can be tolerated.\n\nThe final (weighted) value for a pixel in the filtered image is a product of its spatial and intensity weight. Thus,\n• pixels that are similar and near the filtered pixel will have influence\n• pixels that are far away from the filtered pixel will have little influence (due to the spatial Gaussian)\n• pixels that have dissimilar intensities will have little influence (due to the color-intensity Gaussian), even if they are close to the center of the kernel.\n\nCheck out the results of bilateral filtering in figure given below. See how regions of more uniform pixel intensity have been smoothed (blurred), while preserving the fine cracks (edges) in the wood. Bilateral filtering is a very effective technique, but can prove computationally expensive (especially for large kernel sizes). So choose wisely, depending on your particular application.\n\nWe started with the concept of convolution kernels and how they can be used to filter images. Then learned how they can be used to perform mathematical operations on each pixel of an image to achieve a desired effect, such as blurring or sharpening. Saw how to implement 2D filtering, using OpenCV. After understanding the identity kernel, we went on to create more custom kernels that can be used with the function in OpenCV. Explored some important built-in filtering functions in OpenCV like and . Finally, demonstrating the in OpenCV, seeing how it smoothens an image while maintaining crisp edges."
    },
    {
        "link": "https://pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python",
        "document": "I’m going to start today’s blog post by asking a series of questions which will then be addressed later in the tutorial:\n• What do they do?\n• Why do we use them?\n• How do we apply them?\n• And what role do convolutions play in deep learning?\n\nThe word “convolution” sounds like a fancy, complicated term — but it’s really not. In fact, if you’ve ever worked with computer vision, image processing, or OpenCV before, you’ve already applied convolutions, whether you realize it or not!\n\nHave you opened Photoshop or GIMP to sharpen an image? You guessed it — convolution.\n\nConvolutions are one of the most critical, fundamental building-blocks in computer vision and image processing. But the term itself tends to scare people off — in fact, on the the surface, the word even appears to have a negative connotation.\n\nTrust me, convolutions are anything but scary. They’re actually quite easy to understand.\n\nIn reality, an (image) convolution is simply an element-wise multiplication of two matrices followed by a sum.\n\nSeriously. That’s it. You just learned what convolution is:\n• Take two matrices (which both have the same dimensions).\n• Multiply them, element-by-element (i.e., not the dot-product, just a simple multiplication).\n\nTo understand more about convolutions, why we use them, how to apply them, and the overall role they play in deep learning + image classification, be sure to keep reading this post.\n\nThink of it this way — an image is just a multi-dimensional matrix. Our image has a width (# of columns) and a height (# of rows), just like a matrix.\n\nBut unlike the traditional matrices you may have worked with back in grade school, images also have a depth to them — the number of channels in the image. For a standard RGB image, we have a depth of 3 — one channel for each of the Red, Green, and Blue channels, respectively.\n\nGiven this knowledge, we can think of an image as a big matrix and kernel or convolutional matrix as a tiny matrix that is used for blurring, sharpening, edge detection, and other image processing functions.\n\nEssentially, this tiny kernel sits on top of the big image and slides from left-to-right and top-to-bottom, applying a mathematical operation (i.e., a convolution) at each (x, y)-coordinate of the original image.\n\nIt’s normal to hand-define kernels to obtain various image processing functions. In fact, you might already be familiar with blurring (average smoothing, Gaussian smoothing, median smoothing, etc.), edge detection (Laplacian, Sobel, Scharr, Prewitt, etc.), and sharpening — all of these operations are forms of hand-defined kernels that are specifically designed to perform a particular function.\n\nSo that raises the question, is there a way to automatically learn these types of filters? And even use these filters for image classification and object detection?\n\nYou bet there is.\n\nBut before we get there, we need to understand kernels and convolutions a bit more.\n\nAgain, let’s think of an image as a big matrix and a kernel as tiny matrix (at least in respect to the original “big matrix” image):\n\nAs the figure above demonstrates, we are sliding the kernel from left-to-right and top-to-bottom along the original image.\n\nAt each (x, y)-coordinate of the original image, we stop and examine the neighborhood of pixels located at the center of the image kernel. We then take this neighborhood of pixels, convolve them with the kernel, and obtain a single output value. This output value is then stored in the output image at the same (x, y)-coordinates as the center of the kernel.\n\nIf this sounds confusing, no worries, we’ll be reviewing an example in the “Understanding Image Convolutions” section later in this blog post.\n\nBut before we dive into an example, let’s first take a look at what a kernel looks like:\n\nAbove we have defined a square 3 x 3 kernel (any guesses on what this kernel is used for?)\n\nKernels can be an arbitrary size of M x N pixels, provided that both M and N are odd integers.\n\nNote: Most kernels you’ll typically see are actually square N x N matrices.\n\nWe use an odd kernel size to ensure there is a valid integer (x, y)-coordinate at the center of the image:\n\nOn the left, we have a 3 x 3 matrix. The center of the matrix is obviously located at x=1, y=1 where the top-left corner of the matrix is used as the origin and our coordinates are zero-indexed.\n\nBut on the right, we have a 2 x 2 matrix. The center of this matrix would be located at x=0.5, y=0.5. But as we know, without applying interpolation, there is no such thing as pixel location (0.5, 0.5) — our pixel coordinates must be integers! This reasoning is exactly why we use odd kernel sizes — to always ensure there is a valid (x, y)-coordinate at the center of the kernel.\n\nNow that we have discussed the basics of kernels, let’s talk about a mathematical term called convolution.\n• A kernel matrix that we are going to apply to the input image.\n• An output image to store the output of the input image convolved with the kernel.\n\nConvolution itself is actually very easy. All we need to do is:\n• Select an (x, y)-coordinate from the original image.\n• Place the center of the kernel at this (x, y)-coordinate.\n• Take the element-wise multiplication of the input image region and the kernel, then sum up the values of these multiplication operations into a single value. The sum of these multiplications is called the kernel output.\n• Use the same (x, y)-coordinates from Step #1, but this time, store the kernel output in the same (x, y)-location as the output image.\n\nBelow you can find an example of convolving (denoted mathematically as the “*” operator) a 3 x 3 region of an image with a 3 x 3 kernel used for blurring:\n\nAfter applying this convolution, we would set the pixel located at the coordinate (i, j) of the output image O to O_i,j = 126.\n\nThat’s all there is to it!\n\nConvolution is simply the sum of element-wise matrix multiplication between the kernel and neighborhood that the kernel covers of the input image.\n\nThat was fun discussing kernels and convolutions — but now let’s move on to looking at some actual code to ensure you understand how kernels and convolutions are implemented. This source code will also help you understand how to apply convolutions to images.\n\nOpen up a new file, name it , and let’s get to work:\n\nWe start on Lines 2-5 by importing our required Python packages. You should already have NumPy and OpenCV installed on your system, but you might not have scikit-image installed. To install scikit-image, just use :\n\nNext, we can start defining our custom method:\n\nThe function requires two parameters: the (grayscale) that we want to convolve with the .\n\nGiven both our and (which we presume to be NumPy arrays), we then determine the spatial dimensions (i.e., width and height) of each (Lines 10 and 11).\n\nBefore we continue, it’s important to understand that the process of “sliding” a convolutional matrix across an image, applying the convolution, and then storing the output will actually decrease the spatial dimensions of our output image.\n\nWhy is this?\n\nRecall that we “center” our computation around the center (x, y)-coordinate of the input image that the kernel is currently positioned over. This implies there is no such thing as “center” pixels for pixels that fall along the border of the image. The decrease in spatial dimension is simply a side effect of applying convolutions to images. Sometimes this effect is desirable and other times its not, it simply depends on your application.\n\nHowever, in most cases, we want our output image to have the same dimensions as our input image. To ensure this, we apply padding (Lines 16-19). Here we are simply replicating the pixels along the border of the image, such that the output image will match the dimensions of the input image.\n\nOther padding methods exist, including zero padding (filling the borders with zeros — very common when building Convolutional Neural Networks) and wrap around (where the border pixels are determined by examining the opposite end of the image). In most cases, you’ll see either replicate or zero padding.\n\nWe are now ready to apply the actual convolution to our image:\n\nLines 24 and 25 loop over our , “sliding” the kernel from left-to-right and top-to-bottom 1 pixel at a time.\n\nLine 29 extracts the Region of Interest (ROI) from the using NumPy array slicing. The will be centered around the current (x, y)-coordinates of the . The will also have the same size as our , which is critical for the next step.\n\nConvolution is performed on Line 34 by taking the element-wise multiplication between the and , followed by summing the entries in the matrix.\n\nThe output value is then stored in the array at the same (x, y)-coordinates (relative to the input image).\n\nWe can now finish up our method:\n\nWhen working with images, we typically deal with pixel values falling in the range [0, 255]. However, when applying convolutions, we can easily obtain values that fall outside this range.\n\nIn order to bring our image back into the range [0, 255], we apply the function of scikit-image (Line 41). We also convert our image back to an unsigned 8-bit integer data type on Line 42 (previously, the image was a floating point type in order to handle pixel values outside the range [0, 255]).\n\nFinally, the image is returned to the calling function on Line 45.\n\nNow that we’ve defined our function, let’s move on to the driver portion of the script. This section of our program will handle parsing command line arguments, defining a series of kernels we are going to apply to our image, and then displaying the output results:\n\nLines 48-51 handle parsing our command line arguments. We only need a single argument here, , which is the path to our input path.\n\nWe then move on to Lines 54 and 55 which define a 7 x 7 kernel and a 21 x 21 kernel used to blur/smooth an image. The larger the kernel is, the more the image will be blurred. Examining this kernel, you can see that the output of applying the kernel to an ROI will simply be the average of the input region.\n\nWe define a sharpening kernel on Lines 58-61, used to enhance line structures and other details of an image. Explaining each of these kernels in detail is outside the scope of this tutorial, so if you’re interested in learning more about kernel construction, I would suggest starting here and then playing around with the excellent kernel visualization tool on Setosa.io.\n\nLines 65-68 define a Laplacian operator that can be used as a form of edge detection.\n\nNote: The Laplacian is also very useful for detecting blur in images.\n\nFinally, we’ll define two Sobel filters on Lines 71-80. The first (Lines 71-74) is used to detect vertical changes in the gradient of the image. Similarly, Lines 77-80 constructs a filter used to detect horizontal changes in the gradient.\n\nGiven all these kernels, we lump them together into a set of tuples called a “kernel bank”:\n\nFinally, we are ready to apply our to our image:\n\nLines 95 and 96 load our image from disk and convert it to grayscale. Convolution operators can certainly be applied to RGB (or other multi-channel images), but for the sake of simplicity in this blog post, we’ll only apply our filters to grayscale images).\n\nWe start looping over our set of kernels in the on Line 99 and then apply the current to the image on Line 104 by calling our custom method which we defined earlier.\n\nAs a sanity check, we also call which also applies our to the image. The function is a much more optimized version of our function. The main reason I included the implementation of in this blog post is to give you a better understanding of how convolutions work under the hood.\n\nFinally, Lines 108-112 display the output images to our screen.\n\nExample Convolutions with OpenCV and Python\n\nToday’s example image comes from a photo I took a few weeks ago at my favorite bar in South Norwalk, CT — Cask Republic. In this image you’ll see a glass of my favorite beer (Smuttynose Findest Kind IPA) along with three 3D-printed Pokemon from the (unfortunately, now closed) Industrial Chimp shop:\n\nTo run our script, just issue the following command:\n\nYou’ll then see the results of applying our kernel to the input image:\n\nOn the left, we have our original image. Then in the center we have the results from the function. And on the right, the results from . As the results demonstrate, our output matches , indicating that our function is working properly. Furthermore, our original image now appears “blurred” and “smoothed”, thanks to the smoothing kernel.\n\nComparing Figure 7 and Figure 8, notice how as the size of the averaging kernel increases, the amount of blur in the output image increases as well.\n\nWe can also sharpen our image:\n\nAnd find horizontal edges using Sobel as well:\n\nThe Role of Convolutions in Deep Learning\n\nAs you’ve gathered through this blog post, we must manually hand-define each of our kernels for applying various operations such as smoothing, sharpening, and edge detection.\n\nThat’s all fine and good, but what if there was a way to learn these filters instead? Is it possible to define a machine learning algorithm that can look at images and eventually learn these types of operators?\n\nIn fact, there is — these types of algorithms are a sub-type of Neural Networks called Convolutional Neural Networks (CNNs). By applying convolutional filters, nonlinear activation functions, pooling, and backpropagation, CNNs are able to learn filters that can detect edges and blob-like structures in lower-level layers of the network — and then use the edges and structures as building blocks, eventually detecting higher-level objects (i.e., faces, cats, dogs, cups, etc.) in the deeper layers of the network.\n\nExactly how do CNNs do this?\n\nI’ll show you — but it will have to wait for another few blog posts until we cover enough basics.\n\nIn today’s blog post, we discussed image kernels and convolutions. If we think of an image as a big matrix, then an image kernel is just a tiny matrix that sits on top of the image.\n\nThis kernel then slides from left-to-right and top-to-bottom, computing the sum of element-wise multiplications between the input image and the kernel along the way — we call this value the kernel output. The kernel output is then stored in an output image at the same (x, y)-coordinates as the input image (after accounting for any padding to ensure the output image has the same dimensions as the input).\n\nGiven our newfound knowledge of convolutions, we defined an OpenCV and Python function to apply a series of kernels to an image. These operators allowed us to blur an image, sharpen it, and detect edges.\n\nFinally, we briefly discussed the roles kernels/convolutions play in deep learning, specifically Convolutional Neural Networks, and how these filters can be learned automatically instead of needing to manually define them first.\n\nIn next week’s blog post, I’ll be showing you how to train your first Convolutional Neural Network from scratch using Python — be sure to signup for the PyImageSearch Newsletter using the form below to be notified when the blog post goes live!"
    },
    {
        "link": "https://medium.com/analytics-vidhya/2d-convolution-using-python-numpy-43442ff5f381",
        "document": "2D Convolutions are instrumental when creating convolutional neural networks or just for general image processing filters such as blurring, sharpening, edge detection, and many more. They are based on the idea of using a kernel and iterating through an input image to create an output image. If you are new to convolutions I would high reccommend the playlist by deeplearning.ai on convolutional neural networks.\n\nIn this article we will be implementing a 2D Convolution and then applying an edge detection kernel to an image using the 2D Convolution.\n\nFor this implementation of a 2D Convolution we will need 2 libraries:\n\nOpenCV will be used to pre-process the image while NumPy will be used to implement the actual convolution.\n\nIn order to get the best results with a 2D convolution, it is generally recommended that you process the image in grayscale. To do this we can write a method. Let’s start with:\n\nThis method will have 1 parameter which will be the image file name. You will want to make sure your image is stored in the same directory as the python file, else you may have to specify the full path. To read the contents and turn it to grayscale, we can add the following lines of code:\n\nWhen reading images with OpenCV, the default mode is BGR and not RGB, so we will want to specify the code parameter as BGR2GRAY, allowing us to turn the BGR image into a grayscaled image. We will then return the new image.\n\nTo start the 2D Convolution method, we will have the following method header:\n\nSuch that the image and kernel are specified by the user and the default padding around the image is 0 and default stride is 1.\n\nThe next thing that we must do is apply cross correlation to our kernel and this can be done using NumPy very easily through just flipping the matrix horizontally then vertically. This looks like:\n\nWe then need to compute the matrix size of our outputted image. This can very simply be done through the formula:\n\nThis must be implemented in each dimension (x, y). To start, we must gather the x and y size of the image and kernel. This can be done through:\n\nWe can then apply the size formula for each output dimension:\n\nThen we can create a fresh matrix with the deduced dimensions:\n\nThis method specifically relies on padding being even on each side. First we want to check if the padding is 0 and if it is we do not want to apply unnecessary operations in order to avoid errors. So we start off with the following conditional statement:\n\nWe then create a fresh array of zeroes with the padded dimensions. This can be done through:\n\nNote: We multiply the padding by 2 because we are applying even padding on all sides so a padding of 1 would increase the dimension of the padded image by 2.\n\nWe then replace the inner portion of the padded image with the actual image:\n\nIf there is no padding we have an else statement to make the padded image equal to the image:\n\nNow we get to the core of the convolution. We must iterate through the image and apply element wise multiplication and then sum it and set it equal to the respective element in the output array. To start, we can write our first loop:\n\nThis will be used it iterate through all of y dimension elements. We then have a break statement:\n\nThis statement allows us to check if we are at the end of the image in the y direction. It will exit the complete convolution once we to reach the very bottom right of the image matrix.\n\nWe then have a conditional statement to take account of strides:\n\nThis will make sure that the step size is equivalent to the specified stride amount.\n\nWe then have a loop that iterates through each element in the x dimension:\n\nThe next thing we check for is if the kernel is at the very right of the image. If it is then it will break out of the x loop and then move down in the y direction and restart the convolution process.\n\nFinally, we have the main convolution operator that applies a convolution, sums the elements, and appends it to the output matrix:\n\nThe complete convolution method looks like this:\n\nI decided to apply an edge detection kernel to my 2D Convolution. This was my original image:\n\nThe kernel I used was:\n\nUpon applying the convolution, I received the following edges:\n\nI think its safe to say it worked pretty well! My complete code can be found here on Github. If you have any questions or would just like to express some thoughts, you can reach me on twitter @samratdotjs!\n\nThank you for reading!"
    },
    {
        "link": "https://geeksforgeeks.org/image-filtering-using-convolution-in-opencv",
        "document": "In this article, filtering of images using convolution in OpenCV (Open Source Computer Vision) is discussed. In order to use the OpenCV library in Python, the following libraries should be installed as a prerequisite:\n\nTo install the following libraries, run the following commands in the command prompt:\n\nThe fundamental and the most basic operation in image processing is convolution. This can be achieved by using Kernels. Kernel is a matrix that is generally smaller than the image and the center of the kernel matrix coincides with the pixels.\n\nIn a 2D Convolution, the kernel matrix is a 2-dimensional, Square, A x B matrix, where both A and B are odd integers\n\nThe position of the output image is obtained by multiplying each value of the matrix with the corresponding value of the image matrix and then summing them up. Based on these operations performed, various effects like blurring and sharpening of the images can be performed.\n\nIdentity Kernel is the simplest and the most basic kernel operation that could be performed. The output image produced is exactly like the image that is given as the input. It does change the input image. It is a square matrix with the center element equal to 1. All the other elements of the matrix are 0. The code given below demonstrates the operation of Identity Kernel:"
    },
    {
        "link": "https://medium.com/@akashsingh9303/image-processing-using-convolution-kernels-in-python-a-practical-guide-2da3252b033a",
        "document": "Discover how convolution kernels can revolutionize image processing in Python! My latest article explores various techniques to enhance, detect, and transform images, empowering you to unlock new possibilities in your projects. Join me on this journey to master the art of image manipulation!\n\nIn image processing, convolution kernels (or filters) are essential tools used to detect edges, enhance features, and apply stylized effects to images. In this article, I will demonstrate how to apply various kernels to an image using Python, OpenCV, and NumPy. We’ll explore edge detection techniques with Laplacian, Sobel, Prewitt, Kirsch Compass, and Emboss kernels, along with their practical uses.\n\nFirst, let’s ensure that we have the necessary libraries installed: OpenCV, NumPy, and Matplotlib.\n\nFor this tutorial, we will load an image in color and convert it to the RGB format so it can be displayed correctly using matplotlib.\n\nHere are the different kernels we’ll be applying to the image. These kernels help in edge detection, sharpening, and adding stylized effects to images. Each kernel is a matrix that, when convolved with the image, transforms its appearance in various ways.\n\nUsed for edge detection, the Laplacian kernel highlights areas of rapid intensity change in the image.\n\nThe Emboss kernel gives a 3D effect, making the image appear raised or sunken.\n\nUsed for edge detection in multiple directions, the Kirsch Compass kernel is directional and sensitive to intensity changes.\n\nPrewitt kernels are simpler edge detection filters that calculate intensity gradients in horizontal (Prewitt X) and vertical (Prewitt Y) directions.\n\nNow, let’s apply these kernels to the image using OpenCV’s filter2D() function. This function convolves the kernel with the image, producing a filtered output.\n\nFinally, let’s display the original image alongside the filtered images. This will allow us to visually compare how each kernel affects the image.\n\nConvolution kernels are powerful tools in image processing, allowing us to perform operations such as edge detection, sharpening, and stylizing images. By applying different kernels, we can highlight various features in an image, such as edges or textures. The code presented here demonstrates how to apply these transformations using Python, OpenCV, and NumPy, making it a valuable technique in computer vision applications.\n\nI hope this article has given you a practical introduction to using convolution kernels for image processing in Python. Feel free to experiment with different images and kernels to see how they affect the output. Image processing techniques like these are widely used in fields like computer vision, artificial intelligence, and even art!\n\nIf you enjoyed this article and found it helpful, feel free to like, comment, and share it! Follow me for more content on Python programming and image processing."
    }
]