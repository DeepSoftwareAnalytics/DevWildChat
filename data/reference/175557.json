[
    {
        "link": "https://numpy.org/doc/2.1/reference/random/index.html",
        "document": "The module implements pseudo-random number generators (PRNGs or RNGs, for short) with the ability to draw samples from a variety of probability distributions. In general, users will create a instance with and call the various methods on it to obtain samples from different distributions.\n\nOur RNGs are deterministic sequences and can be reproduced by specifying a seed integer to derive its initial state. By default, with no seed provided, will seed the RNG from nondeterministic data from the operating system and therefore generate different numbers each time. The pseudo-random sequences will be independent for all practical purposes, at least those purposes for which our pseudo-randomness was good for in the first place.\n\nSeeds should be large positive integers. can take positive integers of any size. We recommend using very large, unique numbers to ensure that your seed is different from anyone else’s. This is good practice to ensure that your results are statistically independent from theirs unless you are intentionally trying to reproduce their result. A convenient way to get such a seed number is to use to get an arbitrary 128-bit integer.\n\nSee the documentation on and for more advanced options for controlling the seed in specialized scenarios.\n\nand its associated infrastructure was introduced in NumPy version 1.17.0. There is still a lot of code that uses the older and the functions in . While there are no plans to remove them at this time, we do recommend transitioning to as you can. The algorithms are faster, more flexible, and will receive more improvements in the future. For the most part, can be used as a replacement for . See Legacy random generation for information on the legacy infrastructure, What’s new or different for information on transitioning, and NEP 19 for some of the reasoning for the transition."
    },
    {
        "link": "https://numpy.org/doc/2.0/reference/random/index.html",
        "document": "The module implements pseudo-random number generators (PRNGs or RNGs, for short) with the ability to draw samples from a variety of probability distributions. In general, users will create a instance with and call the various methods on it to obtain samples from different distributions.\n\nOur RNGs are deterministic sequences and can be reproduced by specifying a seed integer to derive its initial state. By default, with no seed provided, will seed the RNG from nondeterministic data from the operating system and therefore generate different numbers each time. The pseudo-random sequences will be independent for all practical purposes, at least those purposes for which our pseudo-randomness was good for in the first place.\n\nSeeds should be large positive integers. can take positive integers of any size. We recommend using very large, unique numbers to ensure that your seed is different from anyone else’s. This is good practice to ensure that your results are statistically independent from theirs unless you are intentionally trying to reproduce their result. A convenient way to get such a seed number is to use to get an arbitrary 128-bit integer.\n\nSee the documentation on and for more advanced options for controlling the seed in specialized scenarios.\n\nand its associated infrastructure was introduced in NumPy version 1.17.0. There is still a lot of code that uses the older and the functions in . While there are no plans to remove them at this time, we do recommend transitioning to as you can. The algorithms are faster, more flexible, and will receive more improvements in the future. For the most part, can be used as a replacement for . See Legacy random generation for information on the legacy infrastructure, What’s new or different for information on transitioning, and NEP 19 for some of the reasoning for the transition."
    },
    {
        "link": "https://docs.python.org/3/library/random.html",
        "document": "This module implements pseudo-random number generators for various distributions.\n\nFor integers, there is uniform selection from a range. For sequences, there is uniform selection of a random element, a function to generate a random permutation of a list in-place, and a function for random sampling without replacement.\n\nOn the real line, there are functions to compute uniform, normal (Gaussian), lognormal, negative exponential, gamma, and beta distributions. For generating distributions of angles, the von Mises distribution is available.\n\nAlmost all module functions depend on the basic function , which generates a random float uniformly in the half-open range . Python uses the Mersenne Twister as the core generator. It produces 53-bit precision floats and has a period of 2**19937-1. The underlying implementation in C is both fast and threadsafe. The Mersenne Twister is one of the most extensively tested random number generators in existence. However, being completely deterministic, it is not suitable for all purposes, and is completely unsuitable for cryptographic purposes.\n\nThe functions supplied by this module are actually bound methods of a hidden instance of the class. You can instantiate your own instances of to get generators that don’t share state.\n\nClass can also be subclassed if you want to use a different basic generator of your own devising: see the documentation on that class for more details.\n\nThe module also provides the class which uses the system function to generate random numbers from sources provided by the operating system.\n\nReturn a random element from the non-empty sequence seq. If seq is empty, raises . Return a k sized list of elements chosen from the population with replacement. If the population is empty, raises . If a weights sequence is specified, selections are made according to the relative weights. Alternatively, if a cum_weights sequence is given, the selections are made according to the cumulative weights (perhaps computed using ). For example, the relative weights are equivalent to the cumulative weights . Internally, the relative weights are converted to cumulative weights before making selections, so supplying the cumulative weights saves work. If neither weights nor cum_weights are specified, selections are made with equal probability. If a weights sequence is supplied, it must be the same length as the population sequence. It is a to specify both weights and cum_weights. The weights or cum_weights can use any numeric type that interoperates with the values returned by (that includes integers, floats, and fractions but excludes decimals). Weights are assumed to be non-negative and finite. A is raised if all weights are zero. For a given seed, the function with equal weighting typically produces a different sequence than repeated calls to . The algorithm used by uses floating-point arithmetic for internal consistency and speed. The algorithm used by defaults to integer arithmetic with repeated selections to avoid small biases from round-off error. Changed in version 3.9: Raises a if all weights are zero. To shuffle an immutable sequence and return a new shuffled list, use instead. Note that even for small , the total number of permutations of x can quickly grow larger than the period of most random number generators. This implies that most permutations of a long sequence can never be generated. For example, a sequence of length 2080 is the largest that can fit within the period of the Mersenne Twister random number generator. Return a k length list of unique elements chosen from the population sequence. Used for random sampling without replacement. Returns a new list containing elements from the population while leaving the original population unchanged. The resulting list is in selection order so that all sub-slices will also be valid random samples. This allows raffle winners (the sample) to be partitioned into grand prize and second place winners (the subslices). Members of the population need not be hashable or unique. If the population contains repeats, then each occurrence is a possible selection in the sample. Repeated elements can be specified one at a time or with the optional keyword-only counts parameter. For example, is equivalent to . To choose a sample from a range of integers, use a object as an argument. This is especially fast and space efficient for sampling from a large population: . If the sample size is larger than the population size, a is raised. Changed in version 3.11: The population must be a sequence. Automatic conversion of sets to lists is no longer supported.\n\nThe following functions generate specific real-valued distributions. Function parameters are named after the corresponding variables in the distribution’s equation, as used in common mathematical practice; most of these equations can be found in any statistics text. Return the next random floating-point number in the range Return a random floating-point number N such that for and for . The end-point value may or may not be included in the range depending on floating-point rounding in the expression . Return a random floating-point number N such that and with the specified mode between those bounds. The low and high bounds default to zero and one. The mode argument defaults to the midpoint between the bounds, giving a symmetric distribution. Beta distribution. Conditions on the parameters are and . Returned values range between 0 and 1. Exponential distribution. lambd is 1.0 divided by the desired mean. It should be nonzero. (The parameter would be called “lambda”, but that is a reserved word in Python.) Returned values range from 0 to positive infinity if lambd is positive, and from negative infinity to 0 if lambd is negative. Changed in version 3.12: Added the default value for . Gamma distribution. (Not the gamma function!) The shape and scale parameters, alpha and beta, must have positive values. (Calling conventions vary and some sources define ‘beta’ as the inverse of the scale). Normal distribution, also called the Gaussian distribution. mu is the mean, and sigma is the standard deviation. This is slightly faster than the function defined below. Multithreading note: When two threads call this function simultaneously, it is possible that they will receive the same return value. This can be avoided in three ways. 1) Have each thread use a different instance of the random number generator. 2) Put locks around all calls. 3) Use the slower, but thread-safe function instead. Changed in version 3.11: mu and sigma now have default arguments. Log normal distribution. If you take the natural logarithm of this distribution, you’ll get a normal distribution with mean mu and standard deviation sigma. mu can have any value, and sigma must be greater than zero. Normal distribution. mu is the mean, and sigma is the standard deviation. Changed in version 3.11: mu and sigma now have default arguments. mu is the mean angle, expressed in radians between 0 and 2*pi, and kappa is the concentration parameter, which must be greater than or equal to zero. If kappa is equal to zero, this distribution reduces to a uniform random angle over the range 0 to 2*pi. Weibull distribution. alpha is the scale parameter and beta is the shape parameter.\n\n# Even integer from 0 to 100 inclusive ['four', 'two', 'ace', 'three'] # of 52 playing cards, and determine the proportion of cards # Estimate the probability of getting 5 or more heads from 7 spins # of a biased coin that settles on heads 60% of the time. # Probability of the median of 5 samples being in middle two quartiles Example of statistical bootstrapping using resampling with replacement to estimate a confidence interval for the mean of a sample: Example of a resampling permutation test to determine the statistical significance or p-value of an observed difference between the effects of a drug versus a placebo: # Example from \"Statistics is Easy\" by Dennis Shasha and Manda Wilson 'at least as extreme as the observed difference of leads us to reject the null' 'hypothesis that there is no difference between the drug and the placebo.' Simulation of arrival times and service deliveries for a multiserver queue: # time when each server becomes available Statistics for Hackers a video tutorial by Jake Vanderplas on statistical analysis using just a few fundamental concepts including simulation, sampling, shuffling, and cross-validation. Economics Simulation a simulation of a marketplace by Peter Norvig that shows effective use of many of the tools and distributions provided by this module (gauss, uniform, sample, betavariate, choice, triangular, and randrange). A Concrete Introduction to Probability (using Python) a tutorial by Peter Norvig covering the basics of probability theory, how to write simulations, and how to perform data analysis using Python.\n\nThese recipes show how to efficiently make random selections from the combinatoric iterators in the module: \"Choose r elements with replacement. Order the result to match the iterable.\" # Result will be in set(itertools.combinations_with_replacement(iterable, r)). The default returns multiples of 2⁻⁵³ in the range 0.0 ≤ x < 1.0. All such numbers are evenly spaced and are exactly representable as Python floats. However, many other representable floats in that interval are not possible selections. For example, isn’t an integer multiple of 2⁻⁵³. The following recipe takes a different approach. All floats in the interval are possible selections. The mantissa comes from a uniform distribution of integers in the range 2⁵² ≤ mantissa < 2⁵³. The exponent comes from a geometric distribution where exponents smaller than -53 occur half as often as the next larger exponent. All real valued distributions in the class will use the new method: The recipe is conceptually equivalent to an algorithm that chooses from all the multiples of 2⁻¹⁰⁷⁴ in the range 0.0 ≤ x < 1.0. All such numbers are evenly spaced, but most have to be rounded down to the nearest representable Python float. (The value 2⁻¹⁰⁷⁴ is the smallest positive unnormalized float and is equal to .) Generating Pseudo-random Floating-Point Values a paper by Allen B. Downey describing ways to generate more fine-grained floats than normally generated by ."
    },
    {
        "link": "https://w3schools.com/python/numpy/numpy_random.asp",
        "document": "Random number does NOT mean a different number every time. Random means something that can not be predicted logically.\n\nComputers work on programs, and programs are definitive set of instructions. So it means there must be some algorithm to generate a random number as well.\n\nIf there is a program to generate random number it can be predicted, thus it is not truly random.\n\nCan we make truly random numbers?\n\nYes. In order to generate a truly random number on our computers we need to get the random data from some outside source. This outside source is generally our keystrokes, mouse movements, data on network etc.\n\nWe do not need truly random numbers, unless it is related to security (e.g. encryption keys) or the basis of application is the randomness (e.g. Digital roulette wheels).\n\nIn this tutorial we will be using pseudo random numbers.\n\nNumPy offers the module to work with random numbers.\n\nThe random module's method returns a random float between 0 and 1.\n\nIn NumPy we work with arrays, and you can use the two methods from the above examples to make random arrays.\n\nThe method takes a parameter where you can specify the shape of an array.\n\nThe method also allows you to specify the shape of the array.\n\nThe method allows you to generate a random value based on an array of values.\n\nThe method takes an array as a parameter and randomly returns one of the values.\n\nThe method also allows you to return an array of values.\n\nAdd a parameter to specify the shape of the array."
    },
    {
        "link": "https://note.nkmk.me/en/python-numpy-random",
        "document": "In NumPy, you can generate random numbers with the module.\n\nFrom NumPy version 1.17 onwards, it is recommended to use the instance. However, legacy functions such as and remain available (as of version 1.26.1).\n\nFor the Python standard library's module, refer to the following article.\n\nThe NumPy version used in this article is as follows. Note that functionality may vary between versions.\n\nHow to use\n\nFirst, use instances, which have been recommended since version 1.17.\n\nYou can generate different types of random numbers using methods of the instance.\n\nFor example, the method generates uniformly distributed random floating-point numbers ( ) from 0.0 (inclusive) to 1.0 (exclusive).\n\nThe argument determines the shape. The default ( ) returns a scalar value. Specifying an integer ( ) returns a one-dimensional array ( ), and specifying a tuple returns an array ( ) of that shape.\n\nIn the method, is the first argument.\n\nAlthough not shown in the example, arrays of three dimensions or more can also be generated by increasing the number of elements in the tuple.\n\nMore methods will be discussed later.\n\nYou can specify any non-negative integer as a seed for . Without specification, a different seed is used each time.\n\nFor more details on random seeds, refer to the official documentation.\n\nuses PCG64 as the random number generator.\n\nTo use a different random number generator than the default PCG64, employ the constructor with a such as MT19937 or SFC64.\n\nYou can optionally specify a seed when creating a . Regardless of the chosen random number generator, the same methods can be used.\n\nWhile instances have been the recommended choice since version 1.17, legacy methods remain accessible.\n\nThese are retained for backward compatibility, so it's better to use the faster and continuously improving for writing new code.\n\nand its associated infrastructure was introduced in NumPy version 1.17.0. There is still a lot of code that uses the older and the functions in . While there are no plans to remove them at this time, we do recommend transitioning to as you can. The algorithms are faster, more flexible, and will receive more improvements in the future.\n\nBefore the introduction of , was used.\n\nGenerate an instance using and call its various methods.\n\nYou can fix the seed.\n\nThe methods of are also available as functions.\n\nUse to fix the seed.\n\nRandom numbers uniformly distributed from 0.0 (inclusive) to 1.0 (exclusive), as denoted by , can be generated using the 's method.\n\nThe first argument is .\n\nThis method corresponds to and . In , the shape is specified as consecutive positional arguments .\n\nUniformly distributed random floating-point numbers in any range can be generated using the 's method.\n\nSpecify the first argument , the second argument , and the third argument . is inclusive and is exclusive in the range .\n\nUniformly distributed random integers in any range can be generated using the 's method.\n\nSpecify the first argument , the second argument , and the third argument .\n\nSpecifying sets the range to .\n\nSetting the argument to includes the upper limit in the range ( or ).\n\nThis method corresponds to . However, does not have an argument, and the upper limit is always excluded from the range.\n\nRandom numbers following a standard normal distribution (mean=0, standard deviation=1) can be generated using the 's method.\n\nThe first argument is .\n\nThis method corresponds to and . In , the shape is specified as consecutive positional arguments .\n\nRandom numbers following a normal distribution (Gaussian distribution) with specified mean and standard deviation can be generated using the 's method.\n\nSpecify the first argument (mean), the second argument (standard deviation), and the third argument .\n\nIn addition to uniform and normal distributions, various other distributions are also available for random number generation.\n\nThere are distributions like the binomial, beta, gamma, and Poisson distributions. Refer to the official documentation for the parameters that can be specified."
    },
    {
        "link": "https://stackoverflow.com/questions/23058560/plotting-dynamic-data-using-matplotlib",
        "document": "I'm writing an application do display data that changes dynamically (the data being read from a socket).\n\nAs a dummy case, I try to draw a sine with an amplitude multiplied by 1.1 each second:\n\nThis obviously not the way do it, but it shows my intentions.\n\nHow can it be done correctly?\n\nEDIT: The following is the traceback output of the code suggested in @mskimm answer:\n\nit turns out that same code works when run in qtconsole... (any idea why?) How ever, each print rescaling to plot, so the \"animation effect\" is missing. I try to use but that just caused no plot at all."
    },
    {
        "link": "https://geeksforgeeks.org/matplotlib-pyplot-ion-in-python",
        "document": "Matplotlib is an amazing visualization library in Python for 2D plots of arrays. Matplotlib is a multi-platform data visualization library built on NumPy arrays and designed to work with the broader SciPy stack.\n\nThe matplotlib.pyplot.ion() is used to turn on interactive mode. To check the status of interactive mode one can run the below commands,\n\nMatplotlib also interacts with different backends behind the scenes. The workhorse behind rendering charts in Matplotlib is its backends. Some interactive backends dynamically update and pop up to users after every change. By default, the interactive mode is turned off.\n\nAlso Read: How to turn Interactive Mode\n\nThere are various example for use Matplotlib in interactive mode or How to use Matplotlib in interactive mode with Matplotlib.pyplot.ion() . Here we are discussing some generally use example those are following.\n\nIn this example code utilizes Matplotlib to generate an interactive plot with two random data collections, represented by red ‘x’ and blue ‘+’ markers. It includes a filled green region between the collections where the second one surpasses the first, and a legend with a colored background is placed at the upper center of the plot.\n\nIn this example The code sets up an interactive Matplotlib plot, plots a line with points (1.4, 2.5), and adds a title. It retrieves the current Axes object and plots another line with points (3.1, 2.2) on the same plot\n\nIn this example code initializes an interactive Matplotlib plot, creating a sine wave and plotting it in blue. It then iterates through phases, updating the y-data of the sine wave and redrawing the plot, resulting in an animated sine wave with a short pause between frames.\n\nMatplotlib ion() function fails to be interactive , Why ?\n\nHow to use Matplotlib in interactive mode?\n\nMatplotlib plot not showing with plt.ion() in a python script, but working in python shell , Why ?"
    },
    {
        "link": "https://stackoverflow.com/questions/10944621/dynamically-updating-plot-in-matplotlib",
        "document": "I am making an application in Python which collects data from a serial port and plots a graph of the collected data against arrival time. The time of arrival for the data is uncertain. I want the plot to be updated when data is received. I searched on how to do this and found two methods:\n• Clear the plot and re-draw the plot with all the points again.\n• Animate the plot by changing it after a particular interval.\n\nI do not prefer the first one as the program runs and collects data for a long time (a day for example), and redrawing the plot will be pretty slow. The second one is also not preferable as time of arrival of data is uncertain and I want the plot to update only when the data is received.\n\nIs there a way in which I can update the plot just by adding more points to it only when the data is received?"
    },
    {
        "link": "https://github.com/matplotlib/matplotlib/issues/7759",
        "document": "Hi, after computer change, matplotlib don't work dynamically.\n\n Before, it was able to update the figure at each iteration of a loop. Today only the last data are plotted.\n\n Configuration :\n\n HP zBook 15 G3 with NVidia Quadro\n\nA figure inside a loop are not updated at each step\n• I expect to see one plot at each step of the for loop\n• All of them had been installed from Ubuntu repository using synaptic"
    },
    {
        "link": "https://oreilly.com/library/view/python-data-science/9781491912126/ch04.html",
        "document": "We’ll now take an in-depth look at the Matplotlib tool for visualization in Python. Matplotlib is a multiplatform data visualization library built on NumPy arrays, and designed to work with the broader SciPy stack. It was conceived by John Hunter in 2002, originally as a patch to IPython for enabling interactive MATLAB-style plotting via gnuplot from the IPython command line. IPython’s creator, Fernando Perez, was at the time scrambling to finish his PhD, and let John know he wouldn’t have time to review the patch for several months. John took this as a cue to set out on his own, and the Matplotlib package was born, with version 0.1 released in 2003. It received an early boost when it was adopted as the plotting package of choice of the Space Telescope Science Institute (the folks behind the Hubble Telescope), which financially supported Matplotlib’s development and greatly expanded its capabilities.\n\nOne of Matplotlib’s most important features is its ability to play well with many operating systems and graphics backends. Matplotlib supports dozens of backends and output types, which means you can count on it to work regardless of which operating system you are using or which output format you wish. This cross-platform, everything-to-everyone approach has been one of the great strengths of Matplotlib. It has led to a large userbase, which in turn has led to an active developer base and Matplotlib’s powerful tools and ubiquity within the scientific Python world.\n\nIn recent years, however, the interface and style of Matplotlib have begun to show their age. Newer tools like ggplot and ggvis in the R language, along with web visualization toolkits based on D3js and HTML5 canvas, often make Matplotlib feel clunky and old-fashioned. Still, I’m of the opinion that we cannot ignore Matplotlib’s strength as a well-tested, cross-platform graphics engine. Recent Matplotlib versions make it relatively easy to set new global plotting styles (see “Customizing Matplotlib: Configurations and Stylesheets”), and people have been developing new packages that build on its powerful internals to drive Matplotlib via cleaner, more modern APIs—for example, Seaborn (discussed in “Visualization with Seaborn”), ggplot, HoloViews, Altair, and even Pandas itself can be used as wrappers around Matplotlib’s API. Even with wrappers like these, it is still often useful to dive into Matplotlib’s syntax to adjust the final plot output. For this reason, I believe that Matplotlib itself will remain a vital piece of the data visualization stack, even if new tools mean the community gradually moves away from using the Matplotlib API directly.\n\nPerhaps the simplest of all plots is the visualization of a single function . Here we will take a first look at creating a simple plot of this type. As with all the following sections, we’ll start by setting up the notebook for plotting and importing the functions we will use: For all Matplotlib plots, we start by creating a figure and an axes. In their simplest form, a figure and axes can be created as follows (Figure 4-5): In Matplotlib, the figure (an instance of the class ) can be thought of as a single container that contains all the objects representing axes, graphics, text, and labels. The axes (an instance of the class ) is what we see above: a bounding box with ticks and labels, which will eventually contain the plot elements that make up our visualization. Throughout this book, we’ll commonly use the variable name to refer to a figure instance, and to refer to an axes instance or group of axes instances. Once we have created an axes, we can use the function to plot some data. Let’s start with a simple sinusoid (Figure 4-6): Alternatively, we can use the pylab interface and let the figure and axes be created for us in the background (Figure 4-7; see “Two Interfaces for the Price of One” for a discussion of these two interfaces): If we want to create a single figure with multiple lines, we can simply call the function multiple times (Figure 4-8): That’s all there is to plotting simple functions in Matplotlib! We’ll now dive into some more details about how to control the appearance of the axes and lines. The first adjustment you might wish to make to a plot is to control the line colors and styles. The function takes additional arguments that can be used to specify these. To adjust the color, you can use the keyword, which accepts a string argument representing virtually any imaginable color. The color can be specified in a variety of ways (Figure 4-9): # specify color by name If no color is specified, Matplotlib will automatically cycle through a set of default colors for multiple lines. Similarly, you can adjust the line style using the keyword (Figure 4-10): # For short, you can use the following codes: Example of various line styles If you would like to be extremely terse, these and codes can be combined into a single nonkeyword argument to the function (Figure 4-11): Controlling colors and styles with the shorthand syntax These single-character color codes reflect the standard abbreviations in the RGB (Red/Green/Blue) and CMYK (Cyan/Magenta/Yellow/blacK) color systems, commonly used for digital color graphics. There are many other keyword arguments that can be used to fine-tune the appearance of the plot; for more details, I’d suggest viewing the docstring of the function using IPython’s help tools (see “Help and Documentation in IPython”). Matplotlib does a decent job of choosing default axes limits for your plot, but sometimes it’s nice to have finer control. The most basic way to adjust axis limits is to use the and methods (Figure 4-12): If for some reason you’d like either axis to be displayed in reverse, you can simply reverse the order of the arguments (Figure 4-13): Example of reversing the y-axis A useful related method is (note here the potential confusion between axes with an e, and axis with an i). The method allows you to set the and limits with a single call, by passing a list that specifies (Figure 4-14): The method goes even beyond this, allowing you to do things like automatically tighten the bounds around the current plot (Figure 4-15): It allows even higher-level specifications, such as ensuring an equal aspect ratio so that on your screen, one unit in is equal to one unit in (Figure 4-16): Example of an “equal” layout, with units matched to the output resolution For more information on axis limits and the other capabilities of the method, refer to the docstring. As the last piece of this section, we’ll briefly look at the labeling of plots: titles, axis labels, and simple legends. Titles and axis labels are the simplest such labels—there are methods that can be used to quickly set them (Figure 4-17): You can adjust the position, size, and style of these labels using optional arguments to the function. For more information, see the Matplotlib documentation and the docstrings of each of these functions. When multiple lines are being shown within a single axes, it can be useful to create a plot legend that labels each line type. Again, Matplotlib has a built-in way of quickly creating such a legend. It is done via the (you guessed it) method. Though there are several valid ways of using this, I find it easiest to specify the label of each line using the keyword of the plot function (Figure 4-18): As you can see, the function keeps track of the line style and color, and matches these with the correct label. More information on specifying and formatting plot legends can be found in the docstring; additionally, we will cover some more advanced legend options in “Customizing Plot Legends”. While most functions translate directly to methods (such as → , → , etc.), this is not the case for all commands. In particular, functions to set limits, labels, and titles are slightly modified. For transitioning between MATLAB-style functions and object-oriented methods, make the following changes: In the object-oriented interface to plotting, rather than calling these functions individually, it is often more convenient to use the method to set all these properties at once (Figure 4-19): Example of using ax.set to set multiple properties at once\n\nMatplotlib’s default tick locators and formatters are designed to be generally sufficient in many common situations, but are in no way optimal for every plot. This section will give several examples of adjusting the tick locations and formatting for the particular plot type you’re interested in. Before we go into examples, it will be best for us to understand further the object hierarchy of Matplotlib plots. Matplotlib aims to have a Python object representing everything that appears on the plot: for example, recall that the is the bounding box within which plot elements appear. Each Matplotlib object can also act as a container of sub-objects; for example, each can contain one or more objects, each of which in turn contain other objects representing plot contents. The tick marks are no exception. Each has attributes and , which in turn have attributes that contain all the properties of the lines, ticks, and labels that make up the axes. Within each axis, there is the concept of a major tick mark and a minor tick mark. As the names would imply, major ticks are usually bigger or more pronounced, while minor ticks are usually smaller. By default, Matplotlib rarely makes use of minor ticks, but one place you can see them is within logarithmic plots (Figure 4-73): Example of logarithmic scales and labels We see here that each major tick shows a large tick mark and a label, while each minor tick shows a smaller tick mark with no label. We can customize these tick properties—that is, locations and labels—by setting the and objects of each axis. Let’s examine these for the x axis of the plot just shown: We see that both major and minor tick labels have their locations specified by a (which makes sense for a logarithmic plot). Minor ticks, though, have their labels formatted by a ; this says that no labels will be shown. We’ll now show a few examples of setting these locators and formatters for various plots. Perhaps the most common tick/label formatting operation is the act of hiding ticks or labels. We can do this using and , as shown here (Figure 4-74): Notice that we’ve removed the labels (but kept the ticks/gridlines) from the x axis, and removed the ticks (and thus the labels as well) from the y axis. Having no ticks at all can be useful in many situations—for example, when you want to show a grid of images. For instance, consider Figure 4-75, which includes images of different faces, an example often used in supervised machine learning problems (for more information, see “In-Depth: Support Vector Machines”): # Get some face data from scikit-learn Notice that each image has its own axes, and we’ve set the locators to null because the tick values (pixel number in this case) do not convey relevant information for this particular visualization. Reducing or Increasing the Number of Ticks One common problem with the default settings is that smaller subplots can end up with crowded labels. We can see this in the plot grid shown in Figure 4-76: Particularly for the x ticks, the numbers nearly overlap, making them quite difficult to decipher. We can fix this with the , which allows us to specify the maximum number of ticks that will be displayed. Given this maximum number, Matplotlib will use internal logic to choose the particular tick locations (Figure 4-77): # For every axis, set the x and y major locator This makes things much cleaner. If you want even more control over the locations of regularly spaced ticks, you might also use , which we’ll discuss in the following section. Matplotlib’s default tick formatting can leave a lot to be desired; it works well as a broad default, but sometimes you’d like to do something more. Consider the plot shown in Figure 4-78, a sine and a cosine: There are a couple changes we might like to make. First, it’s more natural for this data to space the ticks and grid lines in multiples of . We can do this by setting a , which locates ticks at a multiple of the number you provide. For good measure, we’ll add both major and minor ticks in multiples of (Figure 4-79): But now these tick labels look a little bit silly: we can see that they are multiples of , but the decimal representation does not immediately convey this. To fix this, we can change the tick formatter. There’s no built-in formatter for what we want to do, so we’ll instead use , which accepts a user-defined function giving fine-grained control over the tick outputs (Figure 4-80): This is much better! Notice that we’ve made use of Matplotlib’s LaTeX support, specified by enclosing the string within dollar signs. This is very convenient for display of mathematical symbols and formulae; in this case, is rendered as the Greek character . The offers extremely fine-grained control over the appearance of your plot ticks, and comes in very handy when you’re preparing plots for presentation or publication. We’ve mentioned a couple of the available formatters and locators. We’ll conclude this section by briefly listing all the built-in locator and formatter options. For more information on any of these, refer to the docstrings or to the Matplotlib online documentation. Each of the following is available in the namespace: Ticks and range are a multiple of base Finds up to a max number of ticks at nice locations Set the strings from a list of labels Set the strings manually for the labels Use a format string for each value We’ll see additional examples of these throughout the remainder of the book.\n\nOne common type of visualization in data science is that of geographic data. Matplotlib’s main tool for this type of visualization is the Basemap toolkit, which is one of several Matplotlib toolkits that live under the namespace. Admittedly, Basemap feels a bit clunky to use, and often even simple visualizations take much longer to render than you might hope. More modern solutions, such as leaflet or the Google Maps API, may be a better choice for more intensive map visualizations. Still, Basemap is a useful tool for Python users to have in their virtual toolbelts. In this section, we’ll show several examples of the type of map visualization that is possible with this toolkit. Installation of Basemap is straightforward; if you’re using conda you can type this and the package will be downloaded: We add just a single new import to our standard boilerplate: Once you have the Basemap toolkit installed and imported, geographic plots are just a few lines away (the graphics in Figure 4-102 also require the package in Python 2, or the package in Python 3): The meaning of the arguments to Basemap will be discussed momentarily. The useful thing is that the globe shown here is not a mere image; it is a fully functioning Matplotlib axes that understands spherical coordinates and allows us to easily over-plot data on the map! For example, we can use a different map projection, zoom in to North America, and plot the location of Seattle. We’ll use an etopo image (which shows topographical features both on land and under the ocean) as the map background (Figure 4-103): Plotting data and labels on the map This gives you a brief glimpse into the sort of geographic visualizations that are possible with just a few lines of Python. We’ll now discuss the features of Basemap in more depth, and provide several examples of visualizing map data. Using these brief examples as building blocks, you should be able to create nearly any map visualization that you desire. The first thing to decide when you are using maps is which projection to use. You’re probably familiar with the fact that it is impossible to project a spherical map, such as that of the Earth, onto a flat surface without somehow distorting it or breaking its continuity. These projections have been developed over the course of human history, and there are a lot of choices! Depending on the intended use of the map projection, there are certain map features (e.g., direction, area, distance, shape, or other considerations) that are useful to maintain. The Basemap package implements several dozen such projections, all referenced by a short format code. Here we’ll briefly demonstrate some of the more common ones. We’ll start by defining a convenience routine to draw our world map along with the longitude and latitude lines: # lats and longs are returned as a dictionary # cycle through these lines and set the desired style The simplest of map projections are cylindrical projections, in which lines of constant latitude and longitude are mapped to horizontal and vertical lines, respectively. This type of mapping represents equatorial regions quite well, but results in extreme distortions near the poles. The spacing of latitude lines varies between different cylindrical projections, leading to different conservation properties, and different distortion near the poles. In Figure 4-104, we show an example of the equidistant cylindrical projection, which chooses a latitude scaling that preserves distances along meridians. Other cylindrical projections are the Mercator ( ) and the cylindrical equal-area ( ) projections. The additional arguments to Basemap for this view specify the latitude ( ) and longitude ( ) of the lower-left corner ( ) and upper-right corner ( ) for the desired map, in units of degrees. Pseudo-cylindrical projections relax the requirement that meridians (lines of constant longitude) remain vertical; this can give better properties near the poles of the projection. The Mollweide projection ( ) is one common example of this, in which all meridians are elliptical arcs (Figure 4-105). It is constructed so as to preserve area across the map: though there are distortions near the poles, the area of small patches reflects the true area. Other pseudo-cylindrical projections are the sinusoidal ( ) and Robinson ( ) projections. The extra arguments to here refer to the central latitude ( ) and longitude ( ) for the desired map. Perspective projections are constructed using a particular choice of perspective point, similar to if you photographed the Earth from a particular point in space (a point which, for some projections, technically lies within the Earth!). One common example is the orthographic projection ( ), which shows one side of the globe as seen from a viewer at a very long distance. Thus, it can show only half the globe at a time. Other perspective-based projections include the gnomonic projection ( ) and stereographic projection ( ). These are often the most useful for showing small portions of the map. Here is an example of the orthographic projection (Figure 4-106): A conic projection projects the map onto a single cone, which is then unrolled. This can lead to very good local properties, but regions far from the focus point of the cone may become very distorted. One example of this is the Lambert conformal conic projection ( ), which we saw earlier in the map of North America. It projects the map onto a cone arranged in such a way that two standard parallels (specified in by and ) have well-represented distances, with scale decreasing between them and increasing outside of them. Other useful conic projections are the equidistant conic ( ) and the Albers equal-area ( ) projection (Figure 4-107). Conic projections, like perspective projections, tend to be good choices for representing small to medium patches of the globe. If you’re going to do much with map-based visualizations, I encourage you to read up on other available projections, along with their properties, advantages, and disadvantages. Most likely, they are available in the Basemap package. If you dig deep enough into this topic, you’ll find an incredible subculture of geo-viz geeks who will be ready to argue fervently in support of their favorite projection for any given application! Earlier we saw the and methods for projecting global images on the map, as well as the and methods for drawing lines of constant latitude and longitude. The Basemap package contains a range of useful functions for drawing borders of physical features like continents, oceans, lakes, and rivers, as well as political boundaries such as countries and US states and counties. The following are some of the available drawing functions that you may wish to explore using IPython’s help features:\n• Draw a mask between the land and sea, for use with projecting images on one or the other Draw the map boundary, including the fill color for oceans Fill the continents with a given color; optionally fill lakes with another color\n• Draw an etopo relief image onto the map For the boundary-based features, you must set the desired resolution when creating a Basemap image. The argument of the class sets the level of detail in boundaries, either (crude), (low), (intermediate), (high), (full), or if no boundaries will be used. This choice is important: setting high-resolution boundaries on a global map, for example, can be very slow. Here’s an example of drawing land/sea boundaries, and the effect of the resolution parameter. We’ll create both a low- and high-resolution map of Scotland’s beautiful Isle of Skye. It’s located at 57.3°N, 6.2°W, and a map of 90,000×120,000 kilometers shows it well (Figure 4-108): Notice that the low-resolution coastlines are not suitable for this level of zoom, while high-resolution works just fine. The low level would work just fine for a global view, however, and would be much faster than loading the high-resolution border data for the entire globe! It might require some experimentation to find the correct resolution parameter for a given view; the best route is to start with a fast, low-resolution plot and increase the resolution as needed. Perhaps the most useful piece of the Basemap toolkit is the ability to over-plot a variety of data onto a map background. For simple plotting and text, any function works on the map; you can use the instance to project latitude and longitude coordinates to coordinates for plotting with , as we saw earlier in the Seattle example. In addition to this, there are many map-specific functions available as methods of the instance. These work very similarly to their standard Matplotlib counterparts, but have an additional Boolean argument , which if set to allows you to pass raw latitudes and longitudes to the method, rather than projected coordinates. Some of these map-specific methods are: We’ll see examples of a few of these as we continue. For more information on these functions, including several example plots, see the online Basemap documentation. Recall that in “Customizing Plot Legends”, we demonstrated the use of size and color in a scatter plot to convey information about the location, size, and population of California cities. Here, we’ll create this plot again, but using Basemap to put the data in context. We start with loading the data, as we did before: # Extract the data we're interested in Next, we set up the map projection, scatter the data, and then create a colorbar and legend (Figure 4-109): This shows us roughly where larger populations of people have settled in California: they are clustered near the coast in the Los Angeles and San Francisco areas, stretched along the highways in the flat central valley, and avoiding almost completely the mountainous regions along the borders of the state. As an example of visualizing some more continuous geographic data, let’s consider the “polar vortex” that hit the eastern half of the United States in January 2014. A great source for any sort of climatic data is NASA’s Goddard Institute for Space Studies. Here we’ll use the GIS 250 temperature data, which we can download using shell commands (these commands may have to be modified on Windows machines). The data used here was downloaded on 6/12/2016, and the file size is approximately 9 MB: The data comes in NetCDF format, which can be read in Python by the library. You can install this library as shown here: We read the data as follows: The file contains many global temperature readings on a variety of dates; we need to select the index of the date we’re interested in—in this case, January 15, 2014: Now we can load the latitude and longitude data, as well as the temperature anomaly for this index: Finally, we’ll use the method to draw a color mesh of the data. We’ll look at North America, and use a shaded relief map in the background. Note that for this data we specifically chose a divergent colormap, which has a neutral color at zero and two contrasting colors at negative and positive values (Figure 4-110). We’ll also lightly draw the coastlines over the colors for reference: The data paints a picture of the localized, extreme temperature anomalies that happened during that month. The eastern half of the United States was much colder than normal, while the western half and Alaska were much warmer. Regions with no recorded temperature show the map background.\n\nMatplotlib has proven to be an incredibly useful and popular visualization tool, but even avid users will admit it often leaves much to be desired. There are several valid complaints about Matplotlib that often come up:\n• Prior to version 2.0, Matplotlib’s defaults are not exactly the best choices. It was based off of MATLAB circa 1999, and this often shows.\n• Matplotlib’s API is relatively low level. Doing sophisticated statistical visualization is possible, but often requires a lot of boilerplate code.\n• Matplotlib predated Pandas by more than a decade, and thus is not designed for use with Pandas s. In order to visualize data from a Pandas , you must extract each and often concatenate them together into the right format. It would be nicer to have a plotting library that can intelligently use the labels in a plot. An answer to these problems is Seaborn. Seaborn provides an API on top of Matplotlib that offers sane choices for plot style and color defaults, defines simple high-level functions for common statistical plot types, and integrates with the functionality provided by Pandas s. To be fair, the Matplotlib team is addressing this: it has recently added the tools (discussed in “Customizing Matplotlib: Configurations and Stylesheets”), and is starting to handle Pandas data more seamlessly. The 2.0 release of the library will include a new default stylesheet that will improve on the current status quo. But for all the reasons just discussed, Seaborn remains an extremely useful add-on. Here is an example of a simple random-walk plot in Matplotlib, using its classic plot formatting and colors. We start with the typical imports: Now we create some random walk data: Although the result contains all the information we’d like it to convey, it does so in a way that is not all that aesthetically pleasing, and even looks a bit old-fashioned in the context of 21st-century data visualization. Now let’s take a look at how it works with Seaborn. As we will see, Seaborn has many of its own high-level plotting routines, but it can also overwrite Matplotlib’s default parameters and in turn get even simple Matplotlib scripts to produce vastly superior output. We can set the style by calling Seaborn’s method. By convention, Seaborn is imported as : Now let’s rerun the same two lines as before (Figure 4-112): # same plotting code as above! The main idea of Seaborn is that it provides high-level commands to create a variety of plot types useful for statistical data exploration, and even some statistical model fitting. Let’s take a look at a few of the datasets and plot types available in Seaborn. Note that all of the following could be done using raw Matplotlib commands (this is, in fact, what Seaborn does under the hood), but the Seaborn API is much more convenient. Often in statistical data visualization, all you want is to plot histograms and joint distributions of variables. We have seen that this is relatively straightforward in Matplotlib (Figure 4-113): Rather than a histogram, we can get a smooth estimate of the distribution using a kernel density estimation, which Seaborn does with (Figure 4-114): Histograms and KDE can be combined using (Figure 4-115): If we pass the full two-dimensional dataset to , we will get a two-dimensional visualization of the data (Figure 4-116): We can see the joint distribution and the marginal distributions together using . For this plot, we’ll set the style to a white background (Figure 4-117): There are other parameters that can be passed to —for example, we can use a hexagonally based histogram instead (Figure 4-118): When you generalize joint plots to datasets of larger dimensions, you end up with pair plots. This is very useful for exploring correlations between multidimensional data, when you’d like to plot all pairs of values against each other. We’ll demo this with the well-known Iris dataset, which lists measurements of petals and sepals of three iris species: Visualizing the multidimensional relationships among the samples is as easy as calling (Figure 4-119): A pair plot showing the relationships between four variables Sometimes the best way to view data is via histograms of subsets. Seaborn’s makes this extremely simple. We’ll take a look at some data that shows the amount that restaurant staff receive in tips based on various indicator data (Figure 4-120): Out[14]: total_bill tip sex smoker day time size 0 16.99 1.01 Female No Sun Dinner 2 1 10.34 1.66 Male No Sun Dinner 3 2 21.01 3.50 Male No Sun Dinner 3 3 23.68 3.31 Male No Sun Dinner 2 4 24.59 3.61 Female No Sun Dinner 4 An example of a faceted histogram Factor plots can be useful for this kind of visualization as well. This allows you to view the distribution of a parameter within bins defined by any other parameter (Figure 4-121): An example of a factor plot, comparing distributions given various discrete factors Similar to the pair plot we saw earlier, we can use to show the joint distribution between different datasets, along with the associated marginal distributions (Figure 4-122): The joint plot can even do some automatic kernel density estimation and regression (Figure 4-123): Time series can be plotted with . In the following example (visualized in Figure 4-124), we’ll use the Planets data that we first saw in “Aggregation and Grouping”: We can learn more by looking at the method of discovery of each of these planets, as illustrated in Figure 4-125: Number of planets discovered by year and type (see the online appendix for a full-scale figure) For more information on plotting with Seaborn, see the Seaborn documentation, a tutorial, and the Seaborn gallery. Here we’ll look at using Seaborn to help visualize and understand finishing results from a marathon. I’ve scraped the data from sources on the Web, aggregated it and removed any identifying information, and put it on GitHub where it can be downloaded (if you are interested in using Python for web scraping, I would recommend Web Scraping with Python by Ryan Mitchell). We will start by downloading the data from the Web, and loading it into Pandas: By default, Pandas loaded the time columns as Python strings (type ); we can see this by looking at the attribute of the : Let’s fix this by providing a converter for the times: That looks much better. For the purpose of our Seaborn plotting utilities, let’s next add columns that give the times in seconds: To get an idea of what the data looks like, we can plot a over the data (Figure 4-126): The relationship between the split for the first half-marathon and the finishing time for the full marathon The dotted line shows where someone’s time would lie if they ran the marathon at a perfectly steady pace. The fact that the distribution lies above this indicates (as you might expect) that most people slow down over the course of the marathon. If you have run competitively, you’ll know that those who do the opposite—run faster during the second half of the race—are said to have “negative-split” the race. Let’s create another column in the data, the split fraction, which measures the degree to which each runner negative-splits or positive-splits the race: Where this split difference is less than zero, the person negative-split the race by that fraction. Let’s do a distribution plot of this split fraction (Figure 4-127): The distribution of split fractions; 0.0 indicates a runner who completed the first and second halves in identical times Out of nearly 40,000 participants, there were only 250 people who negative-split their marathon. Let’s see whether there is any correlation between this split fraction and other variables. We’ll do this using a , which draws plots of all these correlations (Figure 4-128): The relationship between quantities within the marathon dataset It looks like the split fraction does not correlate particularly with age, but does correlate with the final time: faster runners tend to have closer to even splits on their marathon time. (We see here that Seaborn is no panacea for Matplotlib’s ills when it comes to plot styles: in particular, the x-axis labels overlap. Because the output is a simple Matplotlib plot, however, the methods in “Customizing Ticks” can be used to adjust such things if desired.) The difference between men and women here is interesting. Let’s look at the histogram of split fractions for these two groups (Figure 4-129): The distribution of split fractions by gender The interesting thing here is that there are many more men than women who are running close to an even split! This almost looks like some kind of bimodal distribution among the men and women. Let’s see if we can suss out what’s going on by looking at the distributions as a function of age. A nice way to compare distributions is to use a violin plot (Figure 4-130): This is yet another way to compare the distributions between men and women. Let’s look a little deeper, and compare these violin plots as a function of age. We’ll start by creating a new column in the array that specifies the decade of age that each person is in (Figure 4-131): A violin plot showing the split fraction by gender and age Looking at this, we can see where the distributions of men and women differ: the split distributions of men in their 20s to 50s show a pronounced over-density toward lower splits when compared to women of the same age (or of any age, for that matter). Also surprisingly, the 80-year-old women seem to outperform everyone in terms of their split time. This is probably due to the fact that we’re estimating the distribution from small numbers, as there are only a handful of runners in that range: Back to the men with negative splits: who are these runners? Does this split fraction correlate with finishing quickly? We can plot this very easily. We’ll use , which will automatically fit a linear regression to the data (Figure 4-132): Apparently the people with fast splits are the elite runners who are finishing within ~15,000 seconds, or about 4 hours. People slower than that are much less likely to have a fast second split."
    }
]