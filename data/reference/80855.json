[
    {
        "link": "https://docs.scala-lang.org/tour/case-classes.html",
        "document": "Case classes are like regular classes with a few key differences which we will go over. Case classes are good for modeling immutable data. In the next step of the tour, we’ll see how they are useful in pattern matching.\n\nA minimal case class requires the keywords , an identifier, and a parameter list (which may be empty):\n\nAlthough that is usually left out, it is possible to explicitly use the keyword, as . This is because case classes have an method by default which takes care of object construction.\n\nWhen you create a case class with parameters, the parameters are public s.\n\nYou can’t reassign because it is a (i.e. immutable). It is possible to use s in case classes but this is discouraged.\n\nInstances of case classes are compared by structure and not by reference:\n\nEven though and refer to different objects, the value of each object is equal.\n\nYou can create a (shallow) copy of an instance of a case class simply by using the method. You can optionally change the constructor arguments.\n\nThe recipient of is used as the sender of but the of was copied directly.\n• Learn more about case classes in the Scala Book"
    },
    {
        "link": "https://docs.scala-lang.org/overviews/scala-book/case-classes.html",
        "document": "Another Scala feature that provides support for functional programming is the case class. A case class has all of the functionality of a regular class, and more. When the compiler sees the keyword in front of a , it generates code for you, with the following benefits:\n• Case class constructor parameters are public fields by default, so accessor methods are generated for each parameter.\n• An method is created in the companion object of the class, so you don’t need to use the keyword to create a new instance of the class.\n• An method is generated, which lets you use case classes in more ways in expressions.\n• A method is generated in the class. You may not use this feature in Scala/OOP code, but it’s used all the time in Scala/FP.\n• and methods are generated, which let you compare objects and easily use them as keys in maps.\n• A default method is generated, which is helpful for debugging.\n\nThese features are all demonstrated in the following sections.\n\nWith you don’t need\n\nWhen you define a class as a class, you don’t have to use the keyword to create a new instance:\n\nAs discussed in the previous lesson, this works because a method named is generated inside ’s companion object.\n\nCase class constructor parameters are fields by default, so an accessor method is generated for each parameter:\n\nBut, mutator methods are not generated:\n\nBecause in FP you never mutate data structures, it makes sense that constructor fields default to .\n\nIn the previous lesson on companion objects you saw how to write methods. A great thing about a case class is that it automatically generates an method for your class, so you don’t have to write one.\n\nTo demonstrate this, imagine that you have this trait:\n\nThen, create these case classes to extend that trait:\n\nBecause those are defined as case classes — and they have built-in methods — you can write a match expression like this:\n\nNotice these two patterns in the statements:\n\nThose patterns work because and are defined as case classes that have methods whose type signature conforms to a certain standard. Technically, the specific type of pattern matching shown in these examples is known as a constructor pattern.\n\nTo show how that code works, create an instance of and :\n\nNext, this is what the output looks like in the REPL when you call with those two instances:\n\nA class also has an automatically-generated method that’s extremely helpful when you need to perform the process of a) cloning an object and b) updating one or more of the fields during the cloning process. As an example, this is what the process looks like in the REPL:\n\nAs shown, when you use the method, all you have to do is supply the names of the fields you want to modify during the cloning process.\n\nBecause you never mutate data structures in FP, this is how you create a new instance of a class from an existing instance. This process can be referred to as, “update as you copy.”\n\nCase classes also have automatically-generated and methods, so instances can be compared:\n\nThese methods also let you easily use your objects in collections like sets and maps.\n\nFinally, classes also have a good default method implementation, which at the very least is helpful when debugging code:\n\nWhile all of these features are great benefits to functional programming, as they write in the book, Programming in Scala (Odersky, Spoon, and Venners), “the biggest advantage of case classes is that they support pattern matching.” Pattern matching is a major feature of FP languages, and Scala’s case classes provide a simple way to implement pattern matching in match expressions and other areas."
    },
    {
        "link": "https://docs.scala-lang.org/overviews/core/custom-collections.html",
        "document": "This article shows how to implement custom collection types on top of the collections framework. It is recommended to first read the article about the architecture of the collections.\n\nWhat needs to be done if you want to integrate a new collection class, so that it can profit from all predefined operations with the right types? In the next few sections you’ll be walked through three examples that do this, namely capped sequences, sequences of RNA bases and prefix maps implemented with Patricia tries.\n\nSay you want to create an immutable collection containing at most elements: if more elements are added then the first elements are removed.\n\nThe first task is to find the supertype of our collection: is it , , or just ? In our case, it is tempting to choose because our collection can contain duplicates and iteration order is determined by insertion order. However, some properties of are not satisfied:\n\nConsequently, the only sensible choice as a base collection type is .\n\nThe above listing presents the first version of our capped collection implementation. It will be refined later. The class has a private constructor that takes the collection capacity, length, offset (first element index) and the underlying array as parameters. The public constructor takes only the capacity of the collection. It sets the length and offset to 0, and uses an empty array of elements.\n\nThe method defines how elements can be appended to a given collection: it creates a new underlying array of elements, copies the current elements and adds the new element. As long as the number of elements does not exceed the , the new element is appended after the previous elements. However, as soon as the maximal capacity has been reached, the new element replaces the first element of the collection (at index).\n\nThe method implements indexed access: it translates the given index into its corresponding index in the underlying array by adding the .\n\nThese two methods, and , implement the specific behavior of the collection type. In addition to them, we have to implement to make the generic collection operations (such as , , etc.) work on collections. Here we implement it by using indexed access.\n\nLast, we override to return the name of the collection, . This name is used by the operation.\n\nHere are some interactions with the collection:\n\nYou can see that if we try to grow the collection with more than four elements, the first elements are dropped (see ). The operations behave as expected except for the last one: after calling we get back a instead of the expected collection. This is because all that was done in class was making extend . This class has a method that returns an , and that’s implemented in terms of ’s default implementation, . So, that’s what you were seeing on the last line of the previous interaction.\n\nNow that you understand why things are the way they are, the next question should be what needs to be done to change them? One way to do this would be to override the method in class , maybe like this:\n\nThis would do the job for . But what about , or , or ? In fact there are over fifty methods on collections that return again a collection. For consistency, all of these would have to be overridden. This looks less and less like an attractive option. Fortunately, there is a much easier way to achieve the same effect, as shown in the next section.\n\nThe Capped class needs to inherit not only from , but also from its implementation trait . This is shown in the above listing of class . The new implementation differs from the previous one in only two aspects. First, class now also extends . Second, its member is overridden to return an . As explained in the previous sections, the trait implements all concrete methods of in a generic way. For instance, the return type of methods like , , or is the third type parameter passed to class , i.e., in class , it is . Similarly, the return type of methods like , or is defined by the second type parameter passed to class , i.e., in class , it is itself.\n\nOperations returning collections are implemented in in terms of the and operations. The parent class implements the and such that they only return collections instead of the expected collections. Consequently, we override the and operations to make them return a collection. Another inherited operation returning a too general type is . We override it to return a collection too. All these overrides simply forward to the collection factory referred to by the member, whose value is an instance of class .\n\nThe class provides convenient factory methods to build collections. Eventually, these methods delegate to the operation, which builds an empty instance, and , which uses the operation to grow a collection.\n\nWith the refined implementation of the class, the transformation operations work now as expected, and the class provides seamless conversions from other collections:\n\nThis implementation now behaves correctly, but we can still improve a few things:\n• since our collection is strict, we can take advantage of the better performance offered by strict implementations of transformation operations,\n• since our , and operation just forward to the member, we can use the trait that provides such implementations.\n\nThat is it. The final class:\n• extends the trait, which overrides all transformation operations to take advantage of strict builders,\n• extends the trait, which overrides the , and operations to forward to the ,\n• overrides a few operations for performance: the now uses indexed access, and the delegates to the view. The operation is also overridden because the size is always known.\n\nIts implementation requires a little bit of protocol. In essence, you have to inherit from the template trait in addition to just inheriting from a collection type, override the member to return a more specific factory, and finally implement abstract methods (such as in our case), if any.\n\nTo start with the second example, say you want to create a new immutable sequence type for RNA strands. These are sequences of bases A (adenine), U (uracil), G (guanine), and C (cytosine). The definitions for bases are set up as shown in the listing of RNA bases below:\n\nThe next task is to define a class for strands of RNA. Conceptually, a strand of RNA is simply a . However, RNA strands can get quite long, so it makes sense to invest some work in a compact representation. Because there are only four bases, a base can be identified with two bits, and you can therefore store sixteen bases as two-bit values in an integer. The idea, then, is to construct a specialized subclass of , which uses this packed representation.\n\nThe RNA strands class listing above presents the first version of this class. The class has a constructor that takes an array of s as its first argument. This array contains the packed RNA data, with sixteen bases in each element, except for the last array element, which might be partially filled. The second argument, , specifies the total number of bases on the array (and in the sequence). Class extends and . These traits define the following abstract methods:\n• , automatically implemented by defining a parametric field of the same name,\n• (indexing method), implemented by first extracting an integer value from the array, then extracting the correct two-bit number from that integer using right shift ( ) and mask ( ). The private constants , , and come from the companion object. specifies the size of each packet (i.e., two); specifies the number of two-bit packets per integer; and is a bit mask that isolates the lowest bits in a word.\n\nWe also override the following members used by transformation operations such as and :\n• , implemented by the method of the companion object,\n• , implemented by using the default builder and transforming its result into an with the method.\n\nNote that the constructor of class is . This means that clients cannot create sequences by calling , which makes sense, because it hides the representation of sequences in terms of packed arrays from the user. If clients cannot see what the representation details of RNA sequences are, it becomes possible to change these representation details at any point in the future without affecting client code. In other words, this design achieves a good decoupling of the interface of RNA sequences and its implementation. However, if constructing an RNA sequence with is impossible, there must be some other way to create new RNA sequences, else the whole class would be rather useless. In fact there are two alternatives for RNA sequence creation, both provided by the companion object. The first way is method , which converts a given sequence of bases (i.e., a value of type ) into an instance of class . The method does this by packing all the bases contained in its argument sequence into an array, then calling ’s private constructor with that array and the length of the original sequence as arguments. This makes use of the fact that a private constructor of a class is visible in the class’s companion object.\n\nThe second way to create an value is provided by the method in the object. It takes a variable number of arguments and simply forwards them as a sequence to . Here are the two creation schemes in action:\n\nAlso note that the type parameters of the trait that we inherit from are: , and . The first one stands for the type of elements, the second one stands for the type constructor used by transformation operations that return a collection with a different type of elements, and the third one stands for the type used by transformation operations that return a collection with the same type of elements. In our case, it is worth noting that the second one is whereas the third one is . This means that operations like or return an , whereas operations like or return an .\n\nHere is an example showing the usage of and :\n\nHowever, transformation operations that return a collection with a different element type always return an .\n\nHow should these methods be adapted to RNA strands? The desired behavior would be to get back an RNA strand when mapping bases to bases or appending two RNA strands with :\n\nOn the other hand, mapping bases to some other type over an RNA strand cannot yield another RNA strand because the new elements have the wrong type. It has to yield a sequence instead. In the same vein appending elements that are not of type to an RNA strand can yield a general sequence, but it cannot yield another RNA strand.\n\nThis is what you’d expect in the ideal case. But this is not what the class provides. In fact, all examples will return instances of , not just the last two. If you run the first three commands above with instances of this class you obtain:\n\nSo the result of and is never an RNA strand, even if the element type of the generated collection is . To see how to do better, it pays to have a close look at the signature of the method (or of , which has a similar signature). The method is originally defined in class with the following signature:\n\nHere is the type of elements of the collection, and is the type constructor passed as a second parameter to the trait.\n\nIn our implementation, this type constructor is , this is why we always get a as a result.\n\nTo address this shortcoming, you need to overload the methods that return an for the case where is known to be , to return an instead.\n\nCompared to class we added overloads for methods , , , , , and .\n\nThis implementation now behaves correctly, but we can still improve a few things. Since our collection is strict, we could take advantage of the better performance offered by strict builders in transformation operations. Also, if we try to convert an into an it fails:\n• extends the trait, which overrides all transformation operations to take advantage of strict builders,\n• uses utility operations provided by the trait such as to implement overload of transformation operations that return an collection,\n• has a companion object that extends , which makes it possible to use it as a parameter of a call (to convert any collection of bases to an , e.g. ),\n• moves the and implementations to the companion object.\n\nThe discussion so far centered on the minimal amount of definitions needed to define new sequences with methods that obey certain types. But in practice you might also want to add new functionality to your sequences or to override existing methods for better efficiency. An example of this is the overridden method in class . is an important method in its own right because it implements loops over collections. Furthermore, many other collection methods are implemented in terms of . So it makes sense to invest some effort optimizing the method’s implementation. The standard implementation of in will simply select every ‘th element of the collection using , where ranges from 0 to the collection’s length minus one. So this standard implementation selects an array element and unpacks a base from it once for every element in an RNA strand. The overriding in class is smarter than that. For every selected array element it immediately applies the given function to all bases contained in it. So the effort for array selection and bit unpacking is much reduced.\n\nAs a third example you’ll learn how to integrate a new kind of mutable map into the collection framework. The idea is to implement a mutable map with as the type of keys by a “Patricia trie”. The term Patricia is in fact an abbreviation for “Practical Algorithm to Retrieve Information Coded in Alphanumeric” and trie comes from retrieval (a trie is also called a radix tree or prefix tree). The idea is to store a set or a map as a tree where subsequent characters in a search key uniquely determine a path through the tree. For instance a Patricia trie storing the strings “abc”, “abd”, “al”, “all” and “xy” would look like this:\n\nTo find the node corresponding to the string “abc” in this trie, simply follow the subtree labeled “a”, proceed from there to the subtree labelled “b”, to finally reach its subtree labelled “c”. If the Patricia trie is used as a map, the value that’s associated with a key is stored in the nodes that can be reached by the key. If it is a set, you simply store a marker saying that the node is present in the set.\n\nPatricia tries support very efficient lookups and updates. Another nice feature is that they support selecting a subcollection by giving a prefix. For instance, in the patricia tree above you can obtain the sub-collection of all keys that start with an “a” simply by following the “a” link from the root of the tree.\n\nBased on these ideas we will now walk you through the implementation of a map that’s implemented as a Patricia trie. We call the map a , which means that it provides a method that selects a submap of all keys starting with a given prefix. We’ll first define a prefix map with the keys shown in the running example:\n\nThen calling on will yield another prefix map:\n\nThe previous listing shows the definition of . The map has keys of type and the values are of parametric type . It extends and . You have seen this pattern already for sequences in the RNA strand example; then as now inheriting an implementation class such as serves to get the right result type for transformations such as .\n\nA prefix map node has two mutable fields: and . The field contains an optional value that’s associated with the node. It is initialized to . The field contains a map from characters to values. It is initialized to the empty map.\n\nYou might ask why we picked an immutable map as the implementation type for ? Would not a mutable map have been more standard, since as a whole is also mutable? The answer is that immutable maps that contain only a few elements are very efficient in both space and execution time. For instance, maps that contain fewer than 5 elements are represented as a single object. By contrast, the standard mutable map is a , which typically occupies around 80 bytes, even if it is empty. So if small collections are common, it’s better to pick immutable over mutable. In the case of Patricia tries, we’d expect that most nodes except the ones at the very top of the tree would contain only a few successors. So storing these successors in an immutable map is likely to be more efficient.\n\nNow have a look at the first method that needs to be implemented for a map: . The algorithm is as follows: To get the value associated with the empty string in a prefix map, simply select the optional stored in the root of the tree (the current map). Otherwise, if the key string is not empty, try to select the submap corresponding to the first character of the string. If that yields a map, follow up by looking up the remainder of the key string after its first character in that map. If the selection fails, the key is not stored in the map, so return with . The combined selection over an option value is elegantly expressed using . When applied to an optional value that is , it returns . Otherwise is and the function is applied to the encapsulated value , yielding a new option, which is returned by the flatmap.\n\nThe next two methods to implement for a mutable map are and .\n\nThe method is very similar to , except that before returning any associated value, the field containing that value is set to . The method first calls to navigate to the tree node that needs to be updated, then sets the field of that node to the given value. The method navigates through the tree, creating sub-maps as necessary if some prefix of characters is not yet contained as a path in the tree.\n\nThe last abstract method to implement for a mutable map is . This method needs to produce an iterator that yields all key/value pairs stored in the map. For any given prefix map this iterator is composed of the following parts: First, if the map contains a defined value, , in the field at its root, then is the first element returned from the iterator. Furthermore, the iterator needs to traverse the iterators of all submaps stored in the field, but it needs to add a character in front of every key string returned by those iterators. More precisely, if is the submap reached from the root through a character , and is an element returned from , then the root’s iterator will return instead. This logic is implemented quite concisely as a concatenation of two expressions in the implementation of the method in . The first expression iterates over . This makes use of the fact that values define an iterator method that returns either no element, if the option value is , or exactly one element , if the option value is .\n\nHowever, in all these cases, to build the right kind of collection you need to start with an empty collection of that kind. This is provided by the method, which simply returns a fresh .\n\nWe’ll now turn to the companion object . In fact, it is not strictly necessary to define this companion object, as class can stand well on its own. The main purpose of object is to define some convenience factory methods. It also defines an implicit conversion to for a better interoperability with other collections. This conversion is triggered when one writes, for instance, . The operation takes a as parameter but the companion object does not extend (and it can not because a fixes the type of collection elements, whereas has a polymorphic type of values).\n\nThe two convenience methods are and . The same methods are present for all other collections in Scala’s collection framework, so it makes sense to define them here, too. With the two methods, you can write literals like you do for any other collection:\n\nTo summarize, if you want to fully integrate a new collection class into the framework you need to pay attention to the following points:\n• Decide whether the collection should be mutable or immutable.\n• Pick the right base traits for the collection.\n• Inherit from the right implementation trait to implement most collection operations.\n• Overload desired operations that do not return, by default, a collection as specific as they could. A complete list of such operations is given as an appendix.\n\nYou have now seen how Scala’s collections are built and how you can add new kinds of collections. Because of Scala’s rich support for abstraction, each new collection type has a large number of methods without having to reimplement them all over again.\n\nThis page contains material adapted from the book Programming in Scala by Odersky, Spoon and Venners. We thank Artima for graciously agreeing to its publication.\n\nAppendix: Methods to overload to support the “same result type” principle\n\nYou want to add overloads to specialize transformation operations such that they return a more specific result type. Examples are:\n• , on , when the mapping function returns a , should return a (instead of an ),\n• , on , when the mapping function returns a pair, should return a (instead of an ),\n• , on , when an implicit is available for the resulting element type, should return a (instead of a ).\n\nTypically, this happens when the collection fixes some type parameter of its template trait. For instance in the case of the collection type, we fix the element type to , and in the case of the collection type, we fix the type of keys to .\n\nThe following table lists transformation operations that might return an undesirably wide type. You might want to overload these operations to return a more specific type.\n\nSince the new internal API of the Scala 2.13 collections is very different from the previous collections API, authors of custom collection types should use separate source directories (per Scala version) to define them.\n\nWith sbt you can achieve this by adding the following setting to your project:\n\nAnd then you can define a Scala 2.13 compatible implementation of your collection in the source directory, and an implementation for the previous Scala versions in the source directory.\n\nYou can see how this has been put in practice in scalacheck and scalaz."
    },
    {
        "link": "https://stackoverflow.com/questions/12963347/using-custom-scala-types-in-list",
        "document": "All those types are simply type aliases, not independent types.\n\nType aliases are simply different names for the same type. So even if you could write it, your list would be equivalent to having written:\n\nAnd similarly, you could never use these types to write a function that is required to accept a quantity in MB, since all of these types are the same thing.\n\nTo separate out B, KB, MB, etc as different \"kinds\" of integer, you would need them to be subtypes of , not type aliases for . But is a final type, so you can't subtype it anyway.\n\nA much better approach is to just let represent a raw number, and instead implement a type that represents an together with a unit. There are several approaches you can take for this, but I'd do it something like this:\n\nNow 3 megabytes is and 17 bytes is . You have nice statically enforced separation between arbitrary integers and quantities, and you always have the unit as a data object (no need to be able to statically infer it) whenever you have a quantity. You can put the objects , , , etc in a list, and do whatever manipulation with them you want.\n\nAlternatively you could make the unit objects themselves contain some information about their order or ratios between them, rather than storing that information in an external list.\n\nYou can even do wacky things with implicit conversions using this scheme. Something like this springs to mind:\n\nWith that, once you've imported the implicit, you can simply write things like or instead of or ."
    },
    {
        "link": "https://scala-slick.org/doc/3.3.0/userdefined.html",
        "document": "This chapter describes how to use custom data types and database functions with Slick’s Scala API.\n\nIn the code examples below we assume the following imports: If you’re new to Slick, please start with the Getting Started page.\n\nIf your database system supports a scalar function that is not available as a method in Slick you can define it as a SimpleFunction. There are predefined methods for creating unary, binary and ternary functions with fixed parameter and return types.\n\nIf you need more flexibility regarding the types (e.g. for varargs, polymorphic functions, or to support Option and non-Option types in a single function), you can use to get an untyped instance and write your own wrapper function with the proper type-checking:\n\nSimpleBinaryOperator and SimpleLiteral work in a similar way. For even more flexibility (e.g. function-like expressions with unusual syntax), you can use SimpleExpression.\n\nFor database functions that return complete tables or stored procedures please use Plain SQL Queries. Stored procedures that return multiple result sets are currently not supported.\n\nIf you need a custom column type you can implement ColumnType. The most common scenario is mapping an application-specific type to an already supported type in the database. This can be done much simpler by using MappedColumnType which takes care of all the boilerplate. It comes with the usual import from the profile.\n\nYou can also subclass MappedJdbcType for a bit more flexibility.\n\nIf you have a wrapper class (which can optionally be a case class and/or value class) for an underlying value of some supported type, you can make it extend MappedTo to get a macro-generated implicit for free. Such wrapper classes are commonly used for type-safe table-specific primary key types:\n\nRecord types are data structures containing a statically known number of components with individually declared types. Out of the box, Slick supports Scala tuples (up to arity 22) and Slick’s own HList implementation. Record types can be nested and mixed arbitrarily.\n\nIn order to use custom record types (case classes, custom HLists, tuple-like types, etc.) in queries you need to tell Slick how to map them between queries and results. You can do that using a Shape extending MappedScalaProductShape.\n\nThe distinguishing feature of a polymorphic record type is that it abstracts over its element types, so you can use the same record type for both, lifted and plain element types. You can add support for custom polymorphic record types using an appropriate implicit Shape.\n\nHere is an example for a type :\n\nThe implicit method in this example provides a Shape for a of two element types whenever Shapes for the individual element types are available.\n\nWith these definitions in place, we can use the record type in every location in Slick where a tuple or would be acceptable:\n\nCustom case classes are frequently used as monomorphic record types (i.e. record types where the element types are fixed). In order to use them in Slick, you need to define the case class for a record of plain values (as usual) plus an additional case class for a matching record of lifted values.\n\nIn order to provide a Shape for a custom case class, you can use CaseClassShape:\n\nNote that this mechanism can be used as an alternative to client-side mappings with the operator. It requires a bit more boilerplate but allows you to use the same field names in both, plain and lifted records.\n\nIn the following example we are combining a mapped case class and the mapped type in another mapped case class."
    },
    {
        "link": "https://scala-lang.org/api/2.12.x/scala/collection/Seq.html",
        "document": "extends PartialFunction ] with Iterable ] with GenSeq ] with GenericTraversableTemplate Seq ] with SeqLike ]]"
    },
    {
        "link": "https://docs.scala-lang.org/overviews/scala-book/collections-methods.html",
        "document": "A great strength of the Scala collections classes is that they come with dozens of pre-built methods. The benefit of this is that you no longer need to write custom loops every time you need to work on a collection. (If that’s not enough of a benefit, it also means that you no longer have to read custom loops written by other developers.)\n\nBecause there are so many methods available to you, they won’t all be shown here. Instead, just some of the most commonly-used methods will be shown, including:\n\nThe following methods will work on all of the collections “sequence” classes, including , , , , etc., but these examples will use a unless otherwise specified.\n\nAs a very important note, none of these methods mutate the collection that they’re called on. They all work in a functional style, so they return a new collection with the modified results.\n\nThe following examples will use these lists:\n\nThis is what those lists look like in the REPL:\n\nThe method steps through each element in the existing list, applying the algorithm you supply to each element, one at a time; it then returns a new list with all of the modified elements.\n\nHere’s an example of the method being applied to the list:\n\nAs we showed in the lesson on anonymous functions, you can also write the anonymous function like this:\n\nHowever, in this lesson we’ll always use the first, shorter form.\n\nWith that background, here’s an example of the method being applied to the and lists:\n\nAs that last example shows, it’s perfectly legal (and very common) to use map to return a list with a different type ( ) from the original type ( ).\n\nThe method creates a new, filtered list from the given list. Here are a few examples:\n\nThe method is used to loop over all elements in a collection. As we mentioned in a previous lesson, is used for side-effects, such as printing information. Here’s an example with the list:\n\nThe list is a little long, so you may not want to print out all of those elements. But a great thing about Scala’s approach is that you can chain methods together to solve problems like this. For example, this is one way to print the first three elements from :\n\nThe method comes from Lisp and functional programming languages. It’s used to print the first element (the head element) of a list:\n\nBecause a is a sequence of characters, you can also treat it like a list. This is how works on these strings:\n\nis a great method to work with, but as a word of caution it can also throw an exception when called on an empty collection:\n\nThe method also comes from Lisp and functional programming languages. It’s used to print every element in a list after the head element. A few examples:\n\nJust like , also works on strings:\n\nNote that like , will also throw an exception when called on an empty collection:\n\nThe and methods give you a nice way of taking the elements out of a list that you want to create a new list. This is :\n\nAnd this is :\n\nand are essentially the opposite of and . This is :\n\nAnd this is :\n\nWhen you hear the term, “map reduce,” the “reduce” part refers to methods like . It takes a function (or anonymous function) and applies that function to successive elements in the list.\n\nThe best way to explain is to create a little helper method you can pass into it. For example, this is an method that adds two integers together, and also gives us some nice debug output:\n\nNow, given that method and this list:\n\nthis is what happens when you pass the method into :\n\nAs that result shows, uses to reduce the list into a single value, in this case, the sum of the integers in the list.\n\nOnce you get used to , you’ll write a “sum” algorithm like this:\n\nSimilarly, this is what a “product” algorithm looks like:\n\nThat might be a little mind-blowing if you’ve never seen it before, but after a while you’ll get used to it.\n\nThere are literally dozens of additional methods on the Scala sequence classes that will keep you from ever needing to write another loop. However, because this is a simple introduction book they won’t all be covered here. For more information, see the collections overview of sequence traits."
    },
    {
        "link": "https://stackoverflow.com/questions/49518202/how-to-default-to-immutable-seq-in-scala",
        "document": "I learned today that scala's can mean that both a mutable or immutable Seq can fulfill its type alias. (I stumbled over a blogpost talking about it.)\n\nIn my codebase, I try to follow functional programming best practices and while I did assume to enforce an immutable Sequence, it may not be and hence causing an entry-point for unintended side-effects.\n\nIn order to protect against mutable Seq I could type my functions using a Sequence with:\n\nin each of my files in which I am expecting a .\n\nI also do not prefer to read in my code base.\n\nFor me, should behave just like alias and be immutable by default.\n\nIs there a way I can make the default alias to point to its immutable counterpart for my project without hindering vendor imports?"
    },
    {
        "link": "https://stackoverflow.com/questions/39711114/scala-merge-option-sequences",
        "document": "What about a neat for comprehension:\n\nOr, you could just do a somewhat cumbersome pattern matching:\n\nI think this at least creates less intermediate collections than the double flatten."
    },
    {
        "link": "https://docs.scala-lang.org/overviews/collections/seqs.html",
        "document": "The Seq trait represents sequences. A sequence is a kind of iterable that has a and whose elements have fixed index positions, starting from .\n\nThe operations on sequences, summarized in the table below, fall into the following categories:\n• Indexing and length operations , , , , and . For a , the operation means indexing; hence a sequence of type is a partial function that takes an argument (an index) and which yields a sequence element of type . In other words extends . The elements of a sequence are indexed from zero up to the of the sequence minus one. The method on sequences is an alias of the method of general collections. The method allows you to compare the lengths of a sequences with an Int even if the sequences has infinite length.\n• Index search operations , , , , , , , , which return the index of an element equal to a given value or matching some predicate.\n• Addition operations , , , which return new sequences obtained by adding elements at the front or the end of a sequence.\n• Update operations , , which return a new sequence obtained by replacing some elements of the original sequence.\n• Sorting operations , , , which sort sequence elements according to various criteria.\n• Reversal operations , , , which yield or process sequence elements in reverse order.\n• Comparisons , , , , , which relate two sequences or search an element in a sequence.\n• Multiset operations , , , , which perform set-like operations on the elements of two sequences or remove duplicates.\n\nIf a sequence is mutable, it offers in addition a side-effecting method, which lets sequence elements be updated. As always in Scala, syntax like is just a shorthand for , so gives convenient assignment syntax for free. Note the difference between and . changes a sequence element in place, and is only available for mutable sequences. is available for all sequences and always returns a new sequence instead of modifying the original.\n\nTrait Seq has two subtraits LinearSeq, and IndexedSeq. These do not add any new operations, but each offers different performance characteristics: A linear sequence has efficient and operations, whereas an indexed sequence has efficient , , and (if mutable) operations. Frequently used linear sequences are and . Frequently used indexed sequences are and . The class provides an interesting compromise between indexed and linear access. It has both effectively constant time indexing overhead and constant time linear access overhead. Because of this, vectors are a good foundation for mixed access patterns where both indexed and linear accesses are used. You’ll learn more on vectors later.\n\nAn important sub-category of mutable sequences is s. They allow not only updates of existing elements but also element insertions, element removals, and efficient additions of new elements at the end of the buffer. The principal new methods supported by a buffer are and for element addition at the end, and for addition at the front, and for element insertions, as well as and for element removal. These operations are summarized in the following table.\n\nTwo often used implementations of buffers are and . As the name implies, a is backed by a , and supports efficient conversion of its elements to a , whereas an is backed by an array, and can be quickly converted into one."
    }
]