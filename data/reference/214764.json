[
    {
        "link": "https://docs.python.org/3/library/unittest.html",
        "document": "The unit testing framework was originally inspired by JUnit and has a similar flavor as major unit testing frameworks in other languages. It supports test automation, sharing of setup and shutdown code for tests, aggregation of tests into collections, and independence of the tests from the reporting framework.\n\nTo achieve this, supports some important concepts in an object-oriented way:\n\nThe module provides a rich set of tools for constructing and running tests. This section demonstrates that a small subset of the tools suffice to meet the needs of most users. Here is a short script to test three string methods: # check that s.split fails when the separator is not a string A testcase is created by subclassing . The three individual tests are defined with methods whose names start with the letters . This naming convention informs the test runner about which methods represent tests. The crux of each test is a call to to check for an expected result; or to verify a condition; or to verify that a specific exception gets raised. These methods are used instead of the statement so the test runner can accumulate all test results and produce a report. The and methods allow you to define instructions that will be executed before and after each test method. They are covered in more detail in the section Organizing test code. The final block shows a simple way to run the tests. provides a command-line interface to the test script. When run from the command line, the above script produces an output that looks like this: Passing the option to your test script will instruct to enable a higher level of verbosity, and produce the following output: The above examples show the most commonly used features which are sufficient to meet many everyday testing needs. The remainder of the documentation explores the full feature set from first principles. Changed in version 3.11: The behavior of returning a value from a test method (other than the default value), is now deprecated.\n\nThe unittest module can be used from the command line to run tests from modules, classes or even individual test methods: You can pass in a list with any combination of module names, and fully qualified class or method names. Test modules can be specified by file path as well: This allows you to use the shell filename completion to specify the test module. The file specified must still be importable as a module. The path is converted to a module name by removing the ‘.py’ and converting path separators into ‘.’. If you want to execute a test file that isn’t importable as a module you should execute the file directly instead. You can run tests with more detail (higher verbosity) by passing in the -v flag: When executed without arguments Test Discovery is started: For a list of all the command-line options: Changed in version 3.2: In earlier versions it was only possible to run individual test methods and not modules or classes. The standard output and standard error streams are buffered during the test run. Output during a passing test is discarded. Output is echoed normally on test fail or error and is added to the failure messages. - during the test run waits for the current test to end and then reports all the results so far. A second - raises the normal exception. See Signal Handling for the functions that provide this functionality. Stop the test run on the first error or failure. Only run test methods and classes that match the pattern or substring. This option may be used multiple times, in which case all test cases that match any of the given patterns are included. Patterns that contain a wildcard character ( ) are matched against the test name using ; otherwise simple case-sensitive substring matching is used. Patterns are matched against the fully qualified test method name as imported by the test loader. For example, matches , , but not . Show the N slowest test cases (N=0 for all). Added in version 3.2: The command-line options , and were added. The command line can also be used for test discovery, for running all of the tests in a project or just a subset.\n\nUnittest supports simple test discovery. In order to be compatible with test discovery, all of the test files must be modules or packages importable from the top-level directory of the project (this means that their filenames must be valid identifiers). Test discovery is implemented in , but can also be used from the command line. The basic command-line usage is: As a shortcut, is the equivalent of . If you want to pass arguments to test discovery the sub-command must be used explicitly. The sub-command has the following options: The , , and options can be passed in as positional arguments in that order. The following two command lines are equivalent: As well as being a path it is possible to pass a package name, for example , as the start directory. The package name you supply will then be imported and its location on the filesystem will be used as the start directory. Test discovery loads tests by importing them. Once test discovery has found all the test files from the start directory you specify it turns the paths into package names to import. For example will be imported as . If you have a package installed globally and attempt test discovery on a different copy of the package then the import could happen from the wrong place. If this happens test discovery will warn you and exit. If you supply the start directory as a package name rather than a path to a directory then discover assumes that whichever location it imports from is the location you intended, so you will not get the warning. Test modules and packages can customize test loading and discovery by through the load_tests protocol. Changed in version 3.4: Test discovery supports namespace packages for the start directory. Note that you need to specify the top level directory too (e.g. ). Changed in version 3.11: dropped the namespace packages support in Python 3.11. It has been broken since Python 3.7. Start directory and subdirectories containing tests must be regular package that have file. Directories containing start directory still can be a namespace package. In this case, you need to specify start directory as dotted package name, and target directory explicitly. For example:\n\nThe basic building blocks of unit testing are test cases — single scenarios that must be set up and checked for correctness. In , test cases are represented by instances. To make your own test cases you must write subclasses of or use . The testing code of a instance should be entirely self contained, such that it can be run either in isolation or in arbitrary combination with any number of other test cases. The simplest subclass will simply implement a test method (i.e. a method whose name starts with ) in order to perform specific testing code: Note that in order to test something, we use one of the assert* methods provided by the base class. If the test fails, an exception will be raised with an explanatory message, and will identify the test case as a failure. Any other exceptions will be treated as errors. Tests can be numerous, and their set-up can be repetitive. Luckily, we can factor out set-up code by implementing a method called , which the testing framework will automatically call for every single test we run: The order in which the various tests will be run is determined by sorting the test method names with respect to the built-in ordering for strings. If the method raises an exception while the test is running, the framework will consider the test to have suffered an error, and the test method will not be executed. Similarly, we can provide a method that tidies up after the test method has been run: If succeeded, will be run whether the test method succeeded or not. Such a working environment for the testing code is called a test fixture. A new TestCase instance is created as a unique test fixture used to execute each individual test method. Thus , , and will be called once per test. It is recommended that you use TestCase implementations to group tests together according to the features they test. provides a mechanism for this: the test suite, represented by ’s class. In most cases, calling will do the right thing and collect all the module’s test cases for you and execute them. However, should you want to customize the building of your test suite, you can do it yourself: You can place the definitions of test cases and test suites in the same modules as the code they are to test (such as ), but there are several advantages to placing the test code in a separate module, such as :\n• None The test module can be run standalone from the command line.\n• None The test code can more easily be separated from shipped code.\n• None There is less temptation to change test code to fit the code it tests without a good reason.\n• None Test code should be modified much less frequently than the code it tests.\n• None Tested code can be refactored more easily.\n• None Tests for modules written in C must be in separate modules anyway, so why not be consistent?\n• None If the testing strategy changes, there is no need to change the source code.\n\nUnittest supports skipping individual test methods and even whole classes of tests. In addition, it supports marking a test as an “expected failure,” a test that is broken and will fail, but shouldn’t be counted as a failure on a . Skipping a test is simply a matter of using the decorator or one of its conditional variants, calling within a or test method, or raising directly. Basic skipping looks like this: \"not supported in this library version\" # Tests that work for only a certain version of the library. # test code that depends on the external resource This is the output of running the example above in verbose mode: 'not supported in this library version' Classes can be skipped just like methods: can also skip the test. This is useful when a resource that needs to be set up is not available. It’s easy to roll your own skipping decorators by making a decorator that calls on the test when it wants it to be skipped. This decorator skips the test unless the passed object has a certain attribute: The following decorators and exception implement test skipping and expected failures: Unconditionally skip the decorated test. reason should describe why the test is being skipped. Skip the decorated test if condition is true. Skip the decorated test unless condition is true. Mark the test as an expected failure or error. If the test fails or errors in the test function itself (rather than in one of the test fixture methods) then it will be considered a success. If the test passes, it will be considered a failure. This exception is raised to skip a test. Usually you can use or one of the skipping decorators instead of raising this directly. Skipped tests will not have or run around them. Skipped classes will not have or run. Skipped modules will not have or run.\n\nClass and module level fixtures are implemented in . When the test suite encounters a test from a new class then from the previous class (if there is one) is called, followed by from the new class. Similarly if a test is from a different module from the previous test then from the previous module is run, followed by from the new module. After all the tests have run the final and are run. Note that shared fixtures do not play well with [potential] features like test parallelization and they break test isolation. They should be used with care. The default ordering of tests created by the unittest test loaders is to group all tests from the same modules and classes together. This will lead to / (etc) being called exactly once per class and module. If you randomize the order, so that tests from different modules and classes are adjacent to each other, then these shared fixture functions may be called multiple times in a single test run. Shared fixtures are not intended to work with suites with non-standard ordering. A still exists for frameworks that don’t want to support shared fixtures. If there are any exceptions raised during one of the shared fixture functions the test is reported as an error. Because there is no corresponding test instance an object (that has the same interface as a ) is created to represent the error. If you are just using the standard unittest test runner then this detail doesn’t matter, but if you are a framework author it may be relevant. These must be implemented as class methods: If you want the and on base classes called then you must call up to them yourself. The implementations in are empty. If an exception is raised during a then the tests in the class are not run and the is not run. Skipped classes will not have or run. If the exception is a exception then the class will be reported as having been skipped instead of as an error. These should be implemented as functions: If an exception is raised in a then none of the tests in the module will be run and the will not be run. If the exception is a exception then the module will be reported as having been skipped instead of as an error. To add cleanup code that must be run even in the case of an exception, use : Add a function to be called after to cleanup resources used during the test class. Functions will be called in reverse order to the order they are added ( ). They are called with any arguments and keyword arguments passed into when they are added. If fails, meaning that is not called, then any cleanup functions added will still be called. Enter the supplied context manager. If successful, also add its method as a cleanup function by and return the result of the method. This function is called unconditionally after , or after if raises an exception. It is responsible for calling all the cleanup functions added by . If you need cleanup functions to be called prior to then you can call yourself. pops methods off the stack of cleanup functions one at a time, so it can be called at any time."
    },
    {
        "link": "https://realpython.com/python-unittest",
        "document": "The Python standard library ships with a testing framework named , which you can use to write automated tests for your code. The package has an object-oriented approach where test cases derive from a base class, which has several useful methods.\n\nThe framework supports many features that will help you write consistent unit tests for your code. These features include test cases, fixtures, test suites, and test discovery capabilities.\n\nIn this tutorial, you’ll learn how to:\n• Explore the assert methods that provides\n• Use from the command line\n\nTo get the most out of this tutorial, you should be familiar with some important Python concepts, such as object-oriented programming, inheritance, and assertions. Having a good understanding of code testing is a plus.\n\nCode testing or software testing is a fundamental part of a modern software development cycle. Through code testing, you can verify that a given software project works as expected and fulfills its requirements. Testing enforces code quality and robustness. You’ll do code testing during the development stage of an application or project. You’ll write tests that isolate sections of your code and verify its correctness. A well-written battery or suite of tests can also serve as documentation for the project at hand. You’ll find several different concepts and techniques around testing. Most of them surpass the scope of this tutorial. However, unit testing is an important and relevant concept. A unit test is a test that operates on an individual unit of software. A unit test aims to validate that the tested unit works as designed. A unit is often a small part of a program that takes a few inputs and produces an output. Functions, methods, and other callables are good examples of units that you’d need to test. In Python, there are several tools to help you write, organize, run, and automate your unit test. In the Python standard library, you’ll find two of these tools: Python’s module is a lightweight testing framework that provides quick and straightforward test automation. It can read the test cases from your project’s documentation and your code’s docstrings. This framework is shipped with the Python interpreter as part of the batteries-included philosophy. Note: To dive deeper into , check out the Python’s doctest: Document and Test Your Code at Once tutorial. The package is also a testing framework. However, it provides a more complete solution than . In the following sections, you’ll learn and work with to create suitable unit tests for your Python code.\n\nOrganizing Your Tests With the Class The package defines the class, which is primarily designed for writing unit tests. To start writing your test cases, you just need to import the class and subclass it. Then, you’ll add methods whose names should begin with . These methods will test a given unit of code using different inputs and check for the expected results. The function takes a number as an argument and returns its absolute value. In this test case, you have three test methods. Each method checks for a specific input and output combination. To create the test case, you subclass the class and add three methods. The first method checks whether returns the correct value when you pass a positive number. The second method checks the expected behavior with a negative number. Finally, the third method checks the return value of when you use as an argument. Note that to check the conditions, you use the method, which your class inherits from . More on these types of methods in a moment. For now, you’re nearly ready to write and run your first test case with . Before you write tests with , you need some code to test. Suppose that you need to get a person’s age, process that information, and display their current life stage. For example, if the person’s age is:\n• Between and , both included, the function should return .\n• Greater than and less than or equal to , the function should return .\n• Greater than and less than or equal to , the function should return .\n• Greater than and less than or equal to , the function should return .\n• Negative or greater than , the function should return . In this situation, you can write a function like the following: This function should return correct results with different age values. To make sure that the function works correctly, you can write some tests. Following the pattern from the previous section, you’ll start by subclassing and add some methods that will help you test different input values and the corresponding results: In this example, you create a subclass of with the descriptive name . Note that the class name starts with , which is a widely used convention to make the purpose of the class immediately clear to anyone reading your code. Also, note that the containing file is called . By default, supports test discovery based on the name of test modules. The default naming pattern is . Here, the asterisk ( ) represents any sequence of characters, so starting your modules with is recommended if you want to take advantage of the default test discovery configuration. Then, you define six methods. Each method tests for an input value and the expected result. The methods use the method from the parent class to check whether the function’s output equals the expected value. Note: The methods of are convenient shortcuts for common assertions that you’ll typically perform while testing code. You’ll learn more about these methods in the Exploring the Available Assert Methods section. Note that the tests above check every possible branch in the function. However, they don’t cover the boundary cases where the input age is the lower or upper limit of the interval. To make sure that the function responds as expected in those cases, you can add the following tests: These test methods have two assertions each. The first assertion checks for the upper limit of the age interval, and the second assertion checks for the lower limit of the next age interval. Using multiple assertions in a test method helps you reduce boilerplate code. For example, if you use a single assertion to write these tests, then you’ll have to write six test methods instead of just three. Each method will need a unique name, which can be a challenge. In general, using multiple assertions in your test methods has the following pros:\n• Efficiency: Multiple assertions in a single test can reduce repetitive code. It can also make tests run faster in those scenarios where you have setup and teardown requirements for each test.\n• Contextual testing: Multiple assertions might be necessary to check that a function behaves correctly in a specific context.\n• Convenience: Multiple assertions in a test can be more straightforward and less tedious to write compared to writing multiple single-assertion tests. The approach also has its cons:\n• Clarity and isolation: When a test with multiple assertions fails, it can be harder to immediately identify which assertion caused the failure. This can go against your debugging process.\n• Breakage risk: When an early assertion in a test fails, subsequent assertions are not executed. This can hide additional issues.\n• Test purpose blurring: When a test has multiple assertions, it can become less focused. This can make the test harder to understand. With the test cases in place, you’re ready to run them and see whether your function works as expected. Once you’ve written the tests, you need a way to run them. You’ll have at least two standard ways to run tests with :\n• Use the command-line interface of To make a test module executable in , you can add the following code to the end of the module: The function from allows you to load and run a set of tests. You can also use this function to make the test module executable. Once you’ve added these lines of code, you can run the module as a regular Python script: This command runs the tests from . In the output, every dot represents a passing test. Then, you have a quick summary of the number of run tests and the execution time. All the tests passed, so you get an at the end of the output. Note: You’ll learn about the command-line interface in the Using From the Command Line section. Among other arguments, the function takes the one. With this argument, you can tweak the output’s verbosity, which has three possible values: Go ahead and update the call to as in the following snippet: In the highlighted line, you set the verbosity level to . This update makes generate a more detailed output when you run the test module: This output is more detailed. It shows the tests and their result. At the end, it summarizes the test run as usual. If you want to make the detailed output more descriptive, then you can add docstrings to your tests like in the following code snippet: \"\"\"Test for boundary between 'Child' and 'Adolescent'\"\"\" \"\"\"Test for boundary between 'Adolescent' and 'Adult'\"\"\" \"\"\"Test for boundary between 'Adult' and 'Golden age'\"\"\" In this update of your test methods, you add human-readable docstrings. Now, when you run the test with a verbosity of , you get the following output: python test_age.py Test for boundary between 'Adolescent' and 'Adult' ... ok Test for boundary between 'Adult' and 'Golden age' ... ok Test for boundary between 'Child' and 'Adolescent' ... ok Now, apart from the odd function names, uses the docstrings to improve the output’s readability, which is great. The framework also supports skipping individual test methods and even whole test case classes. Skipping tests allows you to temporarily bypass a test case without permanently removing it from your test suite. Here are some common situations where you may need to skip tests:\n• Incomplete feature: When you have an incomplete feature, you’ll need to skip the related tests to avoid false negatives.\n• External services: When some of your tests depend on external services or resources that aren’t available, you may need to skip them until the service is back.\n• Conditional execution: When you have tests that depend on specific conditions, such as a platform or a Python version, then you can conditionally skip the tests based on dynamic conditions.\n• Known failures: When your code has a known bug, you might skip the failing test with a reference to the bug report.\n• Performance considerations: When you have tests that are time-consuming or resource-intensive, you might want to skip them during regular development cycles to speed up the testing process.\n• Deprecated features: When you have deprecated features that haven’t been removed yet, you can skip their related tests until the feature is removed entirely. The following decorators will help you with the goal of skipping tests during your test running process: Skips the decorated test if is true Skips the decorated test unless is true In these decorators, the argument should describe why the test will be skipped. Consider the following toy example that shows how the decorators work: \"The test should be skipped\" In this sample test module, you have three test methods. The first one never runs because you use the decorator on it. The second test method only runs if you’re on a Python version equal to or greater than 3.12. Finally, the last test method runs if you’re on a Windows box. Here’s how the output looks on Windows with Python 3.11: In this case, the only test that runs is the last one because you’re on Windows. The first test doesn’t run because of the decorator, and the second test doesn’t run because the Python version is less than 3.12. Here’s the output of these test in macOS or Linux with Python 3.12: In this test run, the first test doesn’t run. The second test runs because the Python version is the expected. The final test doesn’t run because the current platform isn’t Windows. The framework allows you to distinguish between similar tests using the context manager. For example, say that you have a function that checks whether a given number is even: This function uses the modulo operator to check whether the input number is even. Here are some basic tests for the function: These tests take positive and negative numbers and check whether the function’s result is correct by comparing it with the appropriate Boolean value. However, you’ve only tested a couple of input values. If you want to expand the input dataset, then you can use subtests. To create a subtest, you’ll use the method, which returns a context manager that executes the enclosed code block as a subtest. You can use this context manager to provide multiple input values for your tests. Here’s the above example using subtests to check for multiple numbers: In this example, you use a loop that iterates over a list of input values. Then, you use the statement to manage the context that constructs. In that context, you run the assertion with the current number, which works as a subtest. Go ahead and run the test to check the results.\n\nAs you’ve read in previous sections, the class provides a set of assert methods. You can use these methods to check multiple conditions while writing your tests. You’ll find over twenty methods in total. They let you compare single values, such as numbers and Booleans, and collections, such as lists, tuples, dictionaries, and more. You’ll also find a few methods that you can use to check for those situations where your code raises exceptions. You’ll learn about all these methods in the following sections. Comparing the result of a code unit with the expected value is a common way to check whether the unit works okay. The class defines a rich set of methods that allows you to do this type of check: You’ve already seen a couple of examples that use . The method works similarly but with the opposite logic. To illustrate how the and methods work, say that you have the following function: This is a Boolean-valued function, also known as a predicate function, that returns if the input number is prime and otherwise. Here’s how you can test this function with : In this example, you have a class with two methods. The first method tests with a prime number, which must result in , so you use for the check. The second method tests with a non-prime number, which must result in , and you use in this case. Note: In the above tests, you could’ve done something like , and the test will work the same. However, using the dedicated method, you can better communicate the test’s intention. If you run the script, then you get the following output: Both tests pass successfully. So, your function works okay. In this example, the number of tests is quite small, so you can take advantage of subtests to run with several different numbers. also implements methods that are related to the identity of objects. In Python’s CPython implementation, an object’s identity is the memory address where the object lives. This identity is a unique identifier that distinguishes one object from another. An object’s identity is a read-only property, which means that you can’t change an object’s identity once you’ve created the object. To check an object’s identity, you’ll use the and operators. Here are a few assert methods that help you check for an object’s identity: x is not None As you can conclude from this table, these methods are shortcuts for the and operators, as suggested by the method names. With the first two methods, you can compare two objects between them. With the final two methods, you can compare an object against , which is the Python null value. Consider the following toy example that checks for the identity of objects: In the first test, you create a list containing strings. Then, you derive an alias from the original list. Aliases of an object hold a reference to the same object. So, when you compare them with , your check succeeds because both variables refer to the same object with the same identity. In the second test, you create two different and independent list objects with the same data. These lists don’t point to the same object in memory, so they have different identities. In this example, you use the methods, which should succeed because the compared objects don’t have the same identity. Go ahead and run the tests: When you run the file, you’ll see that both tests pass. Identity tests like this one are useful when you’re testing a function or method that must return cached or singleton objects. Another common need when writing tests is to compare collections, such as lists, tuples, strings, dictionaries, and sets. The class also has shortcut methods for these types of comparisons. Here’s a summary of those methods: These methods run equality tests between different collection types. Unlike the methods in the previous section, these compare the values of objects rather than their identities. Note: The method automatically calls the specialized methods in the table above. So, in most cases, you won’t need to call these methods directly. Instead, you can just use . However, you can use the specialized methods to add extra clarity to your tests and improve readability. Here’s a quick example that showcases several of these methods: In this example, you have several toy tests. The first test compares a tuple with a string using the method because they’re both sequences. The test passes because both sequences contain the same set of characters. Note that you can’t perform this test with the method, so this is a real specialized use case. Next, you write similar tests to compare string, list, tuple, dictionary, and set objects. It’s important to highlight that the and methods compare their target objects using the same rules for regular comparisons between dictionaries and sets. They compare the items without considering their order in the collection. Now, go ahead and run the file from your command line to check the results. A membership test is a check that allows you to determine whether a given value is or is not in a collection of values. You’ll run these tests with the and operators. Again, the class has methods for these types of checks: These two methods provide shortcuts for you to run membership tests on your code. Here’s a quick example of how they work: In the first test, you check whether is in the list of values, . To do this, you use the method. In the second test, you use to check whether the value is not in the target list, . Checking the type of the object that a function, method, or callable returns may be another common requirement in testing. For this purpose, the also has dedicated assert methods: These two methods are based on the built-in function, which you can use to check whether the input object is of a given type. As an example, say that you have the following class hierarchy: In this example, you have a class that is at the top of your class hierarchy. Then, you have two concrete classes that inherit from and extend it with new attributes. Finally, you have a factory function that you’ll use to create instances of your classes. To test this code with , you can do something like the following: In the first two tests, you use to check whether the current object is an instance of and , respectively. In the final test, you check the function. In this case, you use the base class as the comparison type. Sometimes, you’ll need to check for exceptions. Yes, sometimes your own code will raise exceptions as part of its behavior. The class also provides assert methods that allow you to check for exceptions: The first method allows checking for explicit exceptions without considering the associated error message, and the second method checks for exceptions and considers the associated message using regular expressions. To illustrate how you can use these methods in your testing code, consider the following reimplementation of your function: In this updated version of , you have two conditional statements. The first conditional ensures that the input number is an integer. If that’s not the case, then your code raises a with an appropriate error message. The second conditional checks for input numbers greater than . If the input number is or lower, then you raise a . The rest of the code is similar to what you’ve already seen. How would you write tests to check that the function raises the appropriate exceptions? To do this, you can use the method: The first two tests are familiar. They cover the primary use case of your function. The third and fourth tests check for those cases where the function gets an argument of an incorrect type. These tests specifically check for floating-point numbers and strings. The fifth test checks for those situations where the input is or . In those cases, the function must raise a , so that’s what the assertions catch. Finally, the sixth test checks for negative numbers, which must also raise a . You can run the test from your command line to check how they work. The class also provides some additional assert methods that help you with warnings and logs: The block logs on with minimum The block does not log on with minimum The first two methods allow you to check for warnings, which are a special category of exceptions in Python. A common example of a warning is a , which appears when you use deprecated features of the language. The final two methods allow you to handle logging. These methods return context managers to test whether a message is logged on the or one of its children, with at least the given . As with many things in Python, you can also create your assert methods to facilitate your test writing process. To do this, you can subclass and extend the class with new assertion methods. For example, say that you frequently need to check that all the values in a list are integer numbers. In that case, you can create a test case class like the following: This class inherits from . So, it provides all the assert methods you’ve seen so far. In addition, you extend the functionality of with a new assert method called , which takes a list of values and checks whether all the values are integer numbers. Here’s how you can use this class in practice: In this class, you define a test that uses the method to test a list where all the values are integers. This test must pass successfully. You can experiment with other lists where the values don’t have the correct type to see how the class works.\n\nUsing From the Command Line The package also provides a command-line interface (CLI) that you can use to discover and run your tests. With this interface, you can run tests from modules, classes, and even individual test methods. In the following sections, you’ll learn the basics of how to use the framework’s CLI to discover and run your tests. With the command-line interface of , you can run tests directly from modules, classes, and from individual test methods. The following sample commands cover those use cases: The first command will run all the tests from and . You can add more modules to the list if you need to. The second command allows you to run all the tests from a given class. Finally, the last command lets you run a specific test method from a given class. As an example, run the following command to execute the tests in your file: Note that for this command to work, the target module must be available in the import path of your current Python environment. Otherwise, you’ll get an import error. To avoid this issue, you can also run the tests by passing in the module’s file path: With this command, will find and load the test module from the provided path, which saves you from getting an import error. The framework supports test discovery. The test loader can inspect each module in a given directory looking for classes derived from . Then, the loader groups the found classes within a complete test suite. For example, to discover and run all the tests that you’ve written so far, run the following command in the directory that contains them: This command locates all tests in the current directory, groups them in a test suite, and finally runs them. You can use the as a shortcut for the above command. Note: The string in the above output will reflect the number of tests that you currently have in the target directory. You can use the or command-line options with the subcommand to specify the directory where your tests reside. Other command-line options of include: Allows for using glob patterns and defaults to With these command-line options, you can tweak your test discovery process to fulfill your test automation needs. You’ll also find that the CLI supports several command-line options. Here’s a summary of them: Buffers the standard output and error streams during the test execution Waits for the current test to run and reports all the results up to the point is pressed during the test execution Stops the test run on the first error or failure Only runs test methods and classes that match the pattern or substring Shows the N slowest test cases ( for all) With these command-line options, you can fine-tune how your tests run. In day-to-day test running, the option is probably the most commonly used. This option works the same as setting the argument to when calling the function.\n\nGrouping Your Tests With the Class The framework has a class called that you can use to create groups of tests and run them selectively. Test suites can be useful in many situations, including the following:\n• Complex projects: In complex projects with many features, test suites help you organize tests into manageable and logical groups.\n• Different testing levels: Test suites allow you to organize your tests according to their testing levels, including unit tests, integration tests, and system tests.\n• Selective testing: Test suites allow you to create logical groups of tests that you can run selectively, saving time and resources.\n• Environment-specific testing: Test suites allow group tests that are supposed to run on specific platforms, such as Windows, Linux, macOS, or others. To illustrate how to create test suites, say that you have a module called that defines basic arithmetic and statistical operations: In this module, you have several functions. Some of them are basic arithmetic operations, and others are statistical operations. From a testing point of view, a good approach is to write the following test cases: These tests work as expected. Suppose you need a way to run the arithmetic and statistical tests separately. In this case, you can create test suites. In the following sections, you’ll learn how to do that. The class allows you to create test suites. The class constructor takes the argument that must be an iterable of tests or other test suites. So, you can create your test suites like in the following code snippet: In the function, you create a list of all tests from the test case. Then, you create and return a test suite using the constructor with the list of tests as an argument. To run the suite, you create a and pass the suite to its method. If you run this file, then you get the following output: This command only runs the four tests in the suite, skipping the rest of the tests in the file. You can also use the method to add individual tests to an existing suite. To do this, you can do something like the following: This new version of works like the previous section. Instead of using the class constructor to build the test suite, you use the method. This approach can be useful when you have an existing test suite, and you need to add more tests to it. The class also has a method that you can use to add several tests in one go. This method takes an iterable of test cases, test suites, or a combination of them. Consider the following example that creates a test suite with the statistical tests: In this example, you create a list of tests from the class. Then, you create a instance and add the list of tests using . Finally, you return the test suite as usual. Go ahead and run the file from your command line: This time, the command only runs the statistical tests. As you can see, test suites are a great way to run tests selectively. Adding tests to a suite manually can be a tedious task. It can also be error-prone and represent a maintenance burden. Fortunately, has other tools that can help you create test suites quickly. The function is one of these tools. The function is a hook that provides for customizing test loading and suite creation, either for modules or packages of tests. The function takes three mandatory arguments. Here’s the signature: The argument will hold a test loader, which normally is an instance of . When you define in a module, the argument will receive the tests that are loaded from the module by default. When you define the function in a package, the will get the test loaded from the package’s file. Finally, the argument is a glob pattern that you can use when discovering the tests. When you call in a test module, the function defined in the module gets called automatically, and takes care of passing in the required arguments. This behavior allows you to build a test suite with minimal boilerplate code. Here’s an example of how to create two test suites. One for the arithmetic tests and another for the statistical tests: After you create the test suite, you use the method to add multiple tests in one go. To build the list of tests, you call the on the loader argument, which is the default test loader. Note that in this example, you don’t use the or the argument. The former is useful in test packages where you’d like to add tests to those found in and build a test suite from there. The argument is also for loading tests from packages rather than from modules.\n\nA test fixture is a preparation that you perform before and after running one or more tests. The preparations before the test run are known as setup, while the tasks that you perform after the test run are called teardown. The setup process may involve the creation of temporary files, objects, databases, dataframes, network connections, and so on. In contrast, the teardown phase may require releasing resources, removing temporary files, closing connections, and similar tasks. The framework allows you to create setup and teardown fixtures in your test cases classes by overriding the following methods in your subclasses: An instance method that calls before running each test method in a test case class. An instance method that calls after running each test method in a test case class. A class method that calls before running the tests in a test case class. A class method that calls after running the tests in a test case class. The last two methods are class methods, which means that you need to use the decorator to create them. Here’s how they should look: These methods only take the current test class as an argument. Remember that they run only once per class. To create module-level fixtures, you need to use module-level functions rather than methods on a subclass. The required functions are the following: Runs before all test cases in the containing module Runs after all test cases have run If an exception occurs in the function, then none of the tests in the module run, and the function won’t run either. In the following sections, you’ll learn how to create fixtures using the capabilities of . As an example of how to use fixtures, say that you have the following implementation of a stack data structure: In this module, you define the class that provides the and methods. The former method appends a new item to the top of the stack, while the latter method removes and returns the item at the top of the stack. Then, you implement three special methods. The method supports the built-in function. The method allows you to use instances in loops. Finally, the method allows you to support the built-in function. Now, say that you need to write a subclass to test this class. The test class will have to test all the features of your class. In this situation, you have at least two options:\n• You can create a new an independent instance of for every test.\n• You can create a single instance of the class for all the tests. The first approach sounds tedious and may require a lot of repetitive code. The second approach sounds better, so you decide to go with it. In this situation, you can use a class-level setup fixture to create the instance of and reuse it in every test: In this test module, you create the to test the different features of your class. The first two methods define the setup and teardown logic, which consist of creating and removing an instance of , respectively. When you run the tests, automatically calls and before and after running each test method. This way, every test method has a fresh instance to work on. In other words, these two methods save you from creating a fresh instance of in each test method. If you use the and class methods, then you can create class-level fixtures. This type of fixture only runs once per test case class. The method runs before the test methods, and runs after all the test methods have run. This behavior is known as shared fixtures because all the test methods depend on a single setup and teardown run. Note that shared fixtures break test isolation. In other words, the results of a test will depend on previously run tests. So, they should be used with care. To illustrate how class-level fixtures work, say you have the following class: The class represents an employee of your company. The class has four attributes to store information about each employee. Because you’re planning to create a large number of instances of this class, you use the attribute to reduce the memory footprint. The employees’ data lives in a CSV file that looks something like the following: You need to define a function that reads this file and returns a list of employees. This function can look something like the following: In the function, you read a CSV file using the from the module. Then, you run a loop to create a list of instances with the read data. Now, you want to write tests for this function: In this , you have the method. In this method, you create a new temporary file using from the module. To populate this file, you use the sample data stored in the constant. After wiring the sample data to the temporary file, you close the file and call to create the list of employees. With these actions, you’ve set up everything to test the function. Note that all these actions run only once before all the test methods run. In the , you remove the temporary file to clean up your file system and free the acquired resources. This method will run after the test methods have run. Finally, you have three test methods that check different aspects of the generated list of employees. You can also create module-level fixtures. To make these types of fixtures, you need to define the following functions at the module level: These fixtures run once per module. The setup fixture runs before all the test cases in the module, and the teardown fixture runs after all the test cases in the module have run. If an exception happens in the function, then none of the tests in the module will run, and the won’t run either. If the raised exception is a exception, then the module will be reported as skipped instead of an error. Module-level fixtures are useful when you have several subclasses in a module, and some of them will benefit from a common setup and teardown logic. The classic example is a test module with a few test cases that check for database-related functionalities. These tests may need an active connection to the database, which you can create in the function and close in the function.\n\nUp to this point, you haven’t dealt with failing tests in . However, failing tests are probably the most important part of any code testing process. Failing tests allow you to fix your code and make it work as expected. The framework provides descriptive outputs for failing tests. These outputs can help you debug your code and fix it. Consider the following function that tries to solve the FizzBuzz challenge, where you return for numbers divisible by , for those divisible by , and for those divisible by both and . Go ahead and create a file and add the following code to it: This function works okay for numbers divisible by or . However, there is a slight issue with numbers that are divisible by both. The first two tests will pass. However, the third test won’t pass because the function has a bug. Go ahead and run the tests so that you can check the output of a failing test: In this output, the first highlighted line points you to the failing test. The second highlighted line lets you know the exact line where you can find the failing assertion. Finally, the third highlighted line tells you that the actual result and the expected result are unequal. The failing test tells you that the function has an issue with numbers that are divisible by both and . So, you need to modify the code to make the test pass: In this update, you moved the condition that checks for numbers divisible by and to the beginning of the function. Now you can run the tests again: Your function works correctly after the update. This quick example uncovers the essence of code testing, where you write tests to ensure that your code works as expected so you can fix any issue that the tests reveal. A well-known philosophy around code testing is the test-driven development (TDD) methodology. In TDD, you convert the code’s requirements into test cases before you write the actual code. For example, say that you want to code a function that takes a number from to and return the strings , , or . Instead of writing the function right away, you start writing the following tests: The first test provides a way to check whether the function validates the input argument, which must be a number between and . The other tests check the three possible inputs and the expected output for each of them. Now you can write your function to gradually pass the tests: \"choice must be 0, 1, or 2\" In this snippet, you wrote the code to pass the first test. Go ahead and run the tests from your command line: In this output, the first line contains the text. The dot means that you have a passing test, which is the test. The Fs mean that you have three failing tests, which are those that deal with the function’s primary goal. Next, you can write the required code to pass the rest of the tests: \"choice must be 0, 1, or 2\" In this snippet, you add the required code to pass the test. Now you can run the tests again: This time you have two failing tests, the and tests. During the development, you realize that there’s a better way to code the function: \"choice must be 0, 1, or 2\" In this final implementation of , you have a list containing the possible return values. Then, you use the input argument to index the list and return the appropriate string. Go ahead and run your tests again: Great! Your function passes all the tests. To code this function, you’ve used an incremental development process driven by test cases. At the end of the process, your code works as expected. So, it’s ready to use!"
    },
    {
        "link": "https://reddit.com/r/learnpython/comments/ugyqv4/unit_testing_best_practices_good_examples",
        "document": "I've wanted to write unit tests for every project I've worked on, but I find myself unsure where to begin, so I never do. I always find myself thinking \"this definitely needs to be tested\" while developing a new feature, and then I get overwhelmed by how the tests should be written/formatted and end up just testing everything I can think of in console and then moving on.\n\nI use PyCharm and not sure if I should be using the built in \"New Unit Test\" feature which uses the unittest module, or if I should just be writing from scratch...\n\nWith this kind of thing, I learn best by example. Although general guidelines would be really helpful and appreciated, it'll be even better to just see someone's unit tests that have been deemed \"good\" by someone other than myself. If anyone could help me out I'd really appreciate it Thank you :)"
    },
    {
        "link": "https://testomat.io/blog/a-guide-to-the-basics-of-python-testing-how-to-write-unit-tests-and-organize-execution-test-cases",
        "document": "Unit tests play a critical role in software testing, as they allow teams to identify bugs in a digital product early in development – even before end users discover them.\n\nUnit testing is considered to be a rather expensive and time-consuming process for developers, but this statement is quite controversial when it comes to Python code testing. After all, this interpreted, object-oriented, high-level programming language offers Devs, SDETs and AQAs several tools that can be used to greatly simplify writing test cases and their execution.\n\nPython Testing Basics: What Types of Testing Are Available?\n\nPython3 is the latest version of the Python programming language, which features improved performance, more consistent syntax, and easier-to-understand code.\n\nIt supports four types of testing, which differ in the level of detail of the code being tested and the purpose of running tests:\n• Feature Testing. This is a type of QA process aimed at checking whether the functioning of a software product meets the requirements specified in the specification.\n• Unit Testing. This is a process that allows testing separate modules of source code – the smallest functional units of software.\n• Integration Testing. This stage implies complex testing of several components of a software product that are integrated with each other. This type of testing is usually performed after running unit tests.\n• Performance Testing. This type of testing allows you to evaluate the stability, speed, scalability, and responsiveness of a digital solution under a certain workload.\n\nIn this article, we will cover Python unit testing in detail with the unittest framework and focus on preparing for the QA process, writing tests and their execution.\n\nWe chose this framework because it is de facto standard Python testing framework and built-in into Python program language libraries.\n\nUnittest framework is a tool for unit testing that uses an object-oriented approach and provides users with basic features available in other popular frameworks – for example, JUnit. These include test automation, code sharing, combining tests into collections etc.\n\nGetting to Know the Unittest Module\n\nIn this section, we will talk about how to write unittest tests. We’ll touch on the concepts of TestCase class, assert methods and look at options for running tests.\n\nPlease note: as we noted on top ⬆️ this framework is included in the Python standard library, so there is no additional setup required.\n\nThe Unittest testing tool supports some important concepts in realizing the key test functions.\n\nOne way to create your own test cases in unittest is to write a subclass of the TestCase class. This subclass implements test methods, whose name starts with test, to execute the required testing code, look at example in code:\n\nNote that assert*() methods are used in this framework to perform validation. Here are the most frequently used ones:\n\nHow to Set up Unit Testing in Python?\n\nBefore you run unit testing in Python, there are some prerequisites to consider:\n• Make sure you have an up-to-date version of Python installed on your system. If you need it, you can download the Python source code and installers from the official website. At the time of writing, the latest version is Python 3.12.4.\n• Choose a testing framework that best suits the needs of your project. There are many Python testing tools available on the market, the most popular are the Pytest, Doctest, PyUnit (unittest) frameworks – we’ll look at the last in detail below in this guide.\n• Create a clear test project structure. This includes organizing all the tests, modules, and Python code files. This will optimize the testing process.\n• Check the Python dependencies after installation. This can be done using the pip package management system. Use the pip check command to run the check. If all dependencies are installed and compatible, the result will be as follows:\n• Create virtual environments. It ensures that the packages and their versions are specific to your project and do not interfere with the packages in other projects and vice versa. venv\\Scripts\\activate // Activate the virtual environment on Windows. source venv/bin/activate // Activate the virtual environment on macOS and Linux.\n\nSelect the supporting tools. For example, Visual Studio Code (VS Code), PyCharm editors, as key advantages in the context of the topic at hand are their built-in support for Python and unit testing. Third-party test Runners, Real-time test reporters, test coverage, CI\\CD tools etc.\n\nSuppose we have a class called Calculator, which contains methods for performing simple arithmetic operations: addition, subtraction, division, and multiplication:\n\nLet’s demonstrate how testing in the unittest framework is performed across our knowledge:\n• Create a Virtual Environment. Navigate to your project directory and create a virtual environment and do not forget to activate it:\n• Create a calculator App. class Calculator: def add(self, a, b): return a + b def subtract(self, a, b): return a - b def multiply(self, a, b): return a * b def divide(self, a, b): if b == 0: raise ValueError(\"Cannot divide by zero\") return a / b\n• Write Unit Tests. Create a file named for your unit tests. import unittest from calculator import Calculator class TestCalculator(unittest.TestCase): def setUp(self): self.calc = Calculator() def test_add(self): self.assertEqual(self.calc.add(1, 2), 3) self.assertEqual(self.calc.add(-1, 1), 0) self.assertEqual(self.calc.add(-1, -1), -2) def test_subtract(self): self.assertEqual(self.calc.subtract(2, 1), 1) self.assertEqual(self.calc.subtract(-1, 1), -2) self.assertEqual(self.calc.subtract(-1, -1), 0) def test_multiply(self): self.assertEqual(self.calc.multiply(2, 3), 6) self.assertEqual(self.calc.multiply(-1, 1), -1) self.assertEqual(self.calc.multiply(-1, -1), 1) def test_divide(self): self.assertEqual(self.calc.divide(6, 3), 2) self.assertEqual(self.calc.divide(-1, 1), -1) self.assertEqual(self.calc.divide(-1, -1), 1) with self.assertRaises(ValueError): self.calc.divide(1, 0) if __name__ == '__main__': unittest.main()\n• Run the tests. With the virtual environment activated, run the tests using the following command: You should see output similar to this:\n\nBy choosing the unittest framework for unit testing in Python, your team will be able to discover certain positive aspects of this tool:\n\n No need for additional installations. Unittest is part of Python’s standard library, allowing you to quickly get started testing without any prior configuration or installation.\n• Clear syntax. The Framework uses an object-oriented approach based on test classes, which is familiar to many developers.\n• Automated test discovery. This speeds up testing because the tool automatically discovers and runs all the tests in a catalog.\n• Built-in test runner. Testers have no need to turn to third-party tools. However, it is possible, if you want to do it. The framework integrates perfectly with other test runners.\n• Extensive functionality. This is achieved by supporting Test fixture, Test case, Test suite, and Test runner concepts.\n\nAll of the above benefits will become available to your QA team if you follow some tips for organizing Python unit testing, which we present below.\n\nRegardless of the tools you use to write unit tests and run them, it is recommended that you follow certain guidelines to get the best results.\n\nCreate clear test cases. It is better if they are short enough and easy to understand. To do this, use clear wording for test methods, which will make it obvious what code fragment is being tested. This allows you to understand the purpose of testing accurately.\n\nWrite isolated tests. Make sure that each of your tests does not depend on the results and state of other tests. This guarantees their stability due to their independence from external factors.\n• Carefully select the assertions you use. For this purpose, choose an assertion that matches the purpose of the test. It is also advisable to limit yourself to one assertion per test method.\n• When writing tests, consider boundary cases. These may be invalid input data, exceptional values, etc. This will help to detect unexpected behavior.\n• Include unit tests in the CI\\CD pipeline. This will automatically run tests in case of changes in source code and ensure consistent execution.\n• Work on improving test coverage. Regularly study reports on test coverage of the code base to identify areas for improvement.\n• Don’t ignore test refactoring. Keep unit tests up-to-date and readable so that they retain their value as the code base grows.\n• Maintain quality test documentation. Add comments and descriptions for complex tests. This will help developers and other members of the QA team understand testing goals and optimize workflows.\n\nWe hope this guide will help you optimize your Python testing process on your project by using a framework that allows you to create simple and reliable unit tests for your Python codebase.\n\nStill have questions? Contact our expert and get detailed advice on all current trends in modern software testing."
    },
    {
        "link": "https://medium.com/@sooryanarayan_5231/automating-testing-in-python-using-unittest-framework-777e14ef15f7",
        "document": "In today’s fast-paced software development landscape, ensuring the reliability and stability of our codebase is paramount. One of the most effective ways to achieve this is through automated testing. By automating the testing process, we can systematically verify the correctness of our code, catch bugs early, and maintain the quality of our software throughout its lifecycle.\n\nPython, with its simplicity and versatility, provides powerful tools for automated testing. Among these tools, the framework stands out as a robust and feature-rich solution for writing and running automated tests. In this article, we'll explore the fundamentals of automating testing in Python using the framework.\n\nWe’ll start by understanding the basics of unit testing and how it fits into the software development process. Then, we’ll delve into the framework, learning how to write test cases, use assertion methods to verify expected outcomes, and organize tests into test suites.\n\nSuppose you have a simple Python script with a function that adds two numbers together. Here’s the script ( ):\n\nNow, let’s write test cases for this script using the framework. We'll create a test class that inherits from and define test methods within it.\n• We import and the function from our script ( ).\n• We create a class named that inherits from . Each test case is defined as a method within this class.\n• We ensure that each test method’s name starts with , which is a naming convention recognized by to identify test methods.\n• Inside each test method, we use assertion methods like to verify the expected behavior of our function.\n• Finally, we use to run the tests when the script is executed directly.\n\nYou should see the output indicating whether the tests passed or failed. If all tests pass, you’ll see something like:\n\nIf any test fails, the output will provide details about which test(s) failed and why.\n\nSome of the commonly used assertion methods in “unittest” framework are:-\n\n1. assertEqual(a, b): Checks if is equal to .\n\n2. assertNotEqual(a, b): Checks if is not equal to .\n\n5. assertIs(a, b): Checks if is identical to (checks if and reference the same object).\n\n6. assertIsNot(a, b): Checks if is not identical to (checks if and do not reference the same object).\n\n7. assertIsNone(x): Checks if is None.\n\n8. assertIsNotNone(x): Checks if is not None.\n\n9. assertIn(a, b): Checks if is contained in .\n\n10. assertNotIn(a, b): Checks if is not contained in .\n\n11. assertGreater(a, b): Checks if is greater than .\n\n12. assertGreaterEqual(a, b): Checks if is greater than or equal to .\n\n13. assertLess(a, b): Checks if is less than .\n\n14. assertLessEqual(a, b): Checks if is less than or equal to .\n\n15. assertRaises(exception, callable, *args, kwargs): Checks if calling with and raises an exception of the specified type .\n\nSuppose we have a function called that performs division operation. We want to ensure that this function raises a when the denominator is zero.\n\nHere’s the implementation of the function:\n\nNow, let’s write a test case to verify that raises a when the denominator is zero:\n\nWhen we run this test case using , it will execute the method and check if the function raises a as expected. If the test passes, it indicates that the function behaves correctly when encountering a division by zero scenario. If the test fails, it means that the function doesn't raise the expected exception, indicating a potential bug in the code.\n\nThis example demonstrates how to use to verify that a function raises a specific exception under certain conditions. It's useful for ensuring that our code handles exceptional cases correctly.\n\nKey testing methods and features available in \" :\n\n1.setUp() and tearDown(): These are special methods that are called before and after each test method. They are used to set up and clean up resources needed for testing. is typically used to initialize objects or resources required for testing, while is used to release or clean up those resources after the test completes.\n\n2.setUpClass() and tearDownClass(): These are class-level setup and teardown methods that are called once before and after all the test methods in a test case class. They are useful for setting up expensive resources that can be shared across multiple test methods.\n\n3.Skipping tests: We can skip certain tests under specific conditions using the decorator or and methods.\n\n4.Parameterized tests: We can run the same test with different sets of input parameters using parameterized tests. This can be achieved using the decorator or the method.\n\nThe method in the framework allows us to run multiple sub-tests within a single test method. It's useful when we have a set of inputs and expected outputs and want to ensure that each combination is tested independently, even if one of them fails.\n\nHere’s an example demonstrating the usage of :\n\nSuppose we have a function called that multiplies two numbers. We want to test this function with different sets of inputs and expected outputs.\n\nNow, let’s write a test case using to test the function with multiple input-output combinations:\n\nIf any of the sub-tests fail, will report the failure but continue with the remaining sub-tests. This allows us to identify and fix multiple issues in a single test run, rather than stopping at the first failure.\n\nUsing helps improve test granularity and provides better insight into which specific combinations of inputs and outputs failed in case of a test failure.\n\n5.Test discovery: can automatically discover and run test cases from modules and packages using the command-line interface or by running without specifying a test case.\n\n6.Test suites: We can create custom test suites to group related tests together and run them as a single unit.\n\nIn this example we examine the use of different methods while testing with database connection.\n\nWe import the module for creating test cases, the module for interacting with SQLite databases, and the module for parameterized testing.\n\nWe define a test case class named , which inherits from . Test case classes contain individual test methods that define the tests to be executed.\n\nWe define class methods and using the decorator. is called once before any test methods in the class are executed, and is called once after all test methods in the class have been executed. Inside , we establish a connection to an SQLite in-memory database ( ) and create a table named to store user information. Inside , we close the database connection.\n\nWe define instance methods and without the decorator. These methods are called before and after each test method in the class, respectively. Inside , we start a transaction ( ) to isolate changes made by each test method. Inside , we roll back the transaction ( ) to undo any changes made during the test method.\n\nWe define a test method named and use the decorator to parameterize the test method. This allows us to run the test method with multiple sets of input parameters. Inside the test method, we insert a user with the specified name into the table, commit the transaction, and then retrieve the inserted user from the database. We use assertions to verify that the user was inserted correctly.\n\nWe define another test method named to test deleting a user from the database. Inside the test method, we insert a user named 'Bob' into the table, delete the user, and then verify that the user was deleted from the database.\n\nWe use the condition to check if the script is being run directly. If so, we call to run the test cases defined in the class.\n\nIn conclusion, automating testing in Python using the framework offers numerous benefits for software development projects. By writing test cases that verify the behavior of our code under different conditions, we can catch bugs early in the development process, ensure code quality, and facilitate code maintenance and refactoring.\n\nWith , we can leverage a variety of assertion methods to verify the correctness of our code, set up and tear down resources for each test case, and even parameterize tests to run with different inputs. Additionally, features like test discovery, skipping tests, and custom test suites provide flexibility and scalability for testing projects of any size.\n\nBy incorporating automated testing into our development workflow, we can increase confidence in our codebase, streamline the debugging process, and ultimately deliver more reliable software to our users. With its robust features and ease of use, empowers us to write effective and comprehensive test suites that contribute to the overall success of our projects."
    },
    {
        "link": "https://realpython.com/instance-class-and-static-methods-demystified",
        "document": "Instance, class, and static methods each serve a distinct role in Python, and knowing when to use one over another is key to writing clean, maintainable code. Instance methods operate on individual objects using , while class methods use to access class-level data. Static methods, on the other hand, provide organizational structure without relying on class or instance state.\n\nWhen you understand the differences between these three method types, you’ll be in a better spot to know when to write an instance method, class method, or a static method. Ultimately, this’ll help you design better maintainable object-oriented Python code.\n\nBy the end of this tutorial, you’ll understand that:\n• Instance methods access the state of a specific object through the parameter.\n• You create class methods with the decorator and use them for operations that involve class-level data.\n• You use static methods for utility functionality that doesn’t need class or instance data, and you create them with the decorator.\n• Using class methods and static methods in your classes can improve class design and code maintainability.\n\nKeep reading to see all three method types in action. You’ll even bake some digital pizza while working on a real-world example with all three method types in a class. If you develop an intuitive understanding for their differences, you’ll be able to write object-oriented Python code that communicates its intent more clearly and is easier to maintain in the long run.\n\nIf you’re here for a quick reminder of how the three method types differ from one another, then consider the following overview that compares them:\n• Instance methods use a parameter pointing to an instance of the class. They can access and modify instance state through and class state through . These are the most common methods in Python classes.\n• Class methods use a parameter pointing to the class itself. They can modify class-level state through , but they can’t modify individual instance state.\n• Static methods don’t take or parameters. They can’t modify instance or class state directly, and you’ll mainly use them for organizational purposes and namespacing. If you need to revisit information quickly, there’s nothing quite like a table. So here are the most important aspects of the three different types of methods in Python classes summed up in a table: Factory methods, alternative constructors, or any method that deals with class-level data. Utility methods that don’t need instance or class data. That’s enough super-condensed, repetitive reference information! If you want to know what all of this means in practice, and you like to learn by running code snippets and reasoning about them, then keep on reading. Next, you’ll explore the differences between instance, class, and static methods in a somewhat abstract code example. Abstract you say? Don’t worry—it involves runnable code, and it’s there to set the stage for a more practical example later on.\n\nGain Insight Through an Abstract Example To get warmed up, you’ll write a small Python file called with a bare-bones Python class that contains stripped-down examples of all three method types: Inside , you create —a descriptively named custom class with the sole purpose of demoing the differences between instance methods, class methods, and static methods. Consequently, you also implement one of each of the three method types and name them accordingly. They each return a tuple containing information to help you trace what’s going on, as well as the arguments the method received, such as and . The output will help you understand which objects each of the methods can access. Note: Naming these parameters and is just a convention—but it’s a strong one in the Python community! You could name them and and get the same result. However, if you stray from the convention, then you may get disapproving looks from your coworkers or anyone reading your code. For functionality, all that matters is that you position them first in the parameter list for the method. For maintainability, sanity, and out of respect for others, you should always use and in the classes you define. Now it’s time to call these demo methods in a new REPL session. Import and create an instance of it, then start by calling the instance method: The output confirms that has access to the object instance through the argument. Python prints the object instance as . When you call the instance method, Python replaces the argument with the instance object, . Instance methods can also access the class itself through the attribute. This makes instance methods powerful in terms of access restrictions. They can modify state on the object instance and on the class itself. Next, you can try out the class method: Calling shows that the method doesn’t have access to the instance object that the instance method had access to. However, it can access the class, which you can see by the output . This output represents the class object itself. Remember that everything in Python is an object, even classes themselves! Notice how Python automatically passes the class as the first argument to the function when you call . Calling a class method in Python through the dot notation triggers this behavior. The parameter on instance methods works in the same way. Now, Python automatically passes the instance as the first argument when you call an instance method on an instance object. You get your information message as output but no additional objects. This confirms that static methods can neither access the object instance state nor the class state. They work like regular functions but belong to the namespace of the class. They also belong to the namespace of each instance. Note: Were you surprised that you can successfully call directly on the instance object? Behind the scenes, Python enforces access restrictions by not passing in or when you call a static method using the dot notation. Now, take a look at what happens when you attempt to call these methods on the class itself without creating an object instance beforehand. To do this properly, you should start a new REPL session to ensure there are no existing instances of the class: You’re able to call and just fine, but attempting to call fails with a . This is to be expected because in this case, you didn’t create an object instance and tried calling an instance method directly on the class itself. Since there’s no way for Python to populate the argument, the call fails. However, you don’t need to call an instance method on the instance object like you did previously. In the end, that’s just syntactic sugar that Python implements to make the call more intuitive. If you want, you can ignore the syntactic sugar of the dot notation syntax and pass the instance object manually to get the same result: In this case, you manually pass the instance to the instance method while calling the instance method on the class object. Doing so produces the same result as calling the instance method on the instance, without explicitly passing . Now that you’ve worked through this bare-bones example and have a better understanding of how the different method types work, you’re ready to look at a more realistic example of when to use each of the three method types.\n\nApply Your Knowledge With a Practical Example The basic example from the previous section shows the distinction between instance methods, class methods, and static methods. However, it’s quite abstract and doesn’t give you a good idea of why and when you might want to use one method type over another. To connect what you learned with the real world, you’ll now explore this topic with a more realistic example. Everyone loves pizza, so it’ll be your delicious and circular gateway to implementing instance methods, class methods, and a static method in the real world. Go ahead and define a basic class in : The class contains the two special methods and . Both of these methods operate on the instance, so you don’t need to add a decorator. It’s common to set up these two special methods for most of your custom Python classes:\n• provides a string representation for when you need to display an object. If you’re not familiar with these two special methods, then you may want to first read more about class constructors and customizing object rerpresentation. But feel free to skip that and keep going with this tutorial. Understanding special methods isn’t crucial to grasp how to distinguish between instance, class, and static methods. The class defines a data attribute called . You can use any iterable containing the pizza toppings when you create an instance of the class. However, the method casts this into a list, as your class definition will assume this attribute is a list. You can explore your new class in a REPL session: Yum! Cheese and tomato pizza. That’s already a good start, but of course there’s a lot more to pizza. You want to customize the toppings on your pizza, so it’s time to add two instance methods that can handle the task. When to Use Instance Methods Instance methods are the most common methods in Python classes. You use them when you want to implement functionality that can access and change the state of an instance. Maybe you’ll have to deal with fussy customers in a pizza restaurant who want to change the toppings on their pizza. So, you’ll go ahead and add two instance methods to your class. As you learned earlier, an instance method is a function that has access to a specific instance of the class. Therefore, an instance method can change the data stored in the object. The Python community uses the parameter name by convention to refer to the instance within an instance method. It’s so common that your integrated development environment (IDE) may automatically fill this parameter for you. Add two instance methods called and to the class: With this edit to , you add two new instance methods that can change the state of a instance—allowing you to add and remove toppings to satisfy your customers’ every taste bud. You can now call these instance methods in a new REPL session to try out their functionality: The data contained within the attribute changes when you call these instance methods. Therefore, a instance contains the data about the toppings and the ability to make changes to the data. This is the key principle of objects in object-oriented programming. So, when should you use instance methods? In short, you should use instance methods when you need to access and edit the data that an instance of your class holds. When to Use Class Methods You use a class method when you need to access or modify class-level data, such as class attributes. Another common use case for is to create factory methods that return class instances with specific configurations. Everyone has their favorite pizza variation, and with the existing code you can already create an endless number of delicious pizza variations: However, the Italians figured out their pizza taxonomy centuries ago, so each delicious type of pizza has its own name. It’s a good idea to take advantage of that rich pizza history and give the users of your class a better interface for creating the types of pizza they crave. A nice, clean way to do that is by using class methods as factory methods for the different kinds of pizza you can create: Note how the and factory methods use the argument instead of calling the constructor directly. This is a trick you can use to follow the Don’t Repeat Yourself (DRY) principle. If you decide to rename this class at some point, you won’t have to remember to update the constructor name in all of the factory methods. Now, what can you do with these factory methods? It’s time to try them out. Since you made changes to , you’ll need a new REPL session: You can use the factory methods to create new objects that are configured the way you want them. They all use the same constructor internally and simply provide a shortcut for remembering the various toppings. Since these methods still create an instance of the class, you can also use other methods on the instances they create, such as : Another way to look at this use of class methods is that they allow you to define alternative constructors for your classes. Python only allows one method per class, but it’s possible to add as many alternative constructors as necessary by using class methods. This can make the interface for your classes self-documenting and simplify their usage. So, when should you use class methods? In short, you should use class methods when you need to access and edit the data that’s tied to your class object rather than an instance of it. You can also use them to create alternative constructors for your class. When to Use Static Methods You can use static methods when you need utility functions that don’t access or modify class or instance data, but where the functionality they provide still logically belongs within the class’s namespace. Let’s stretch the pizza analogy even thinner, and add a static method that allows users to quickly fetch the diameter in inches based on common pizza sizes: \"\"\"Returns the diameter in inches for common pizza sizes.\"\"\" You added a static method that allows you to input a string describing a pizza size. The method then returns the diameter of that size in inches. The static method doesn’t have access to the instance or the class—and it doesn’t need that access. All that the method does is perform a dictionary lookup to return a number. You can call the static method both on a instance and the class itself: That functionality makes sense because the toppings on a pizza won’t influence what size your medium pizza will be—even though you may wish that it did! It’s purely for convenience and organizational purposes that static methods are part of the namespaces of the class and the instance. That convenience can be helpful because as a programmer-turned-pizza-baker, you may still sometimes need to look up how large a specific size of pizza should be. With , you can do that quickly. Static methods can’t access class or instance state because they don’t take a or argument. While this may seem like a limitation, it also clearly signals that the method is independent of everything else in the class. Flagging a method as a static method is a hint that a method won’t modify class or instance state. This restriction is also enforced by the Python runtime. Using enables you to communicate clearly about parts of your class architecture so that new development work is naturally guided to happen within these set boundaries. Note: Of course, it’s possible to defy these restrictions. But in practice, static methods can often help prevent accidental modifications that would go against the original design intent. Static methods also have benefits when it comes to writing test code since they’re completely independent from the rest of the class. You don’t have to worry about setting up a complete class instance before you can test the static method in a unit test. You can just fire away like you would to test a regular function. This can make future maintenance less of an effort. So, when should you use static methods? In short, you should use static methods when you want to tie utility functionality related to your class right into its namespace."
    },
    {
        "link": "https://stackoverflow.com/questions/6412146/python-decorator-as-a-staticmethod",
        "document": "This is not how is supposed to be used. objects are descriptors that return the wrapped object, so they only work when accessed as . Example\n\nInside the scope of , you would always get the latter object, which is not callable.\n\nI'd strongly recommend to move the decorator to the module scope -- it does not seem to belong inside the class. If you want to keep it inside the class, don't make it a , but rather simply it at the end of the class body -- it's not meant to be used from outside the class in this case."
    },
    {
        "link": "https://geeksforgeeks.org/class-method-vs-static-method-python",
        "document": "In this article, we will cover the basic difference between the class method vs Static method in Python and when to use the class method and static method in python.\n\nWhat is Class Method in Python?\n\nThe @classmethod decorator is a built-in function decorator that is an expression that gets evaluated after your function is defined. The result of that evaluation shadows your function definition. A class method receives the class as an implicit first argument, just like an instance method receives the instance\n• None A class method is a method that is bound to the and not the object of the class.\n• None They have the access to the state of the class as it takes a class parameter that points to the class and not the object instance.\n• None It can modify a class state that would apply across all the instances of the class. For example, it can modify a class variable that will be applicable to all the instances.\n\nWhat is the Static Method in Python?\n\nA static method does not receive an implicit first argument. A static method is also a method that is bound to the class and not the object of the class. This method can’t access or modify the class state. It is present in a class because it makes sense for the method to be present in class.\n\nThe difference between the Class method and the static method is:\n• None A class method takes cls as the first parameter while a static method needs no specific parameters.\n• None A class method can access or modify the class state while a static method can’t access or modify it.\n• None In general, static methods know nothing about the class state. They are utility-type methods that take some parameters and work upon those parameters. On the other hand class methods must have class as a parameter.\n• None We use @classmethod decorator in python to create a class method and we use @staticmethod decorator to create a static method in python.\n\nWhen to use the class or static method?\n• None We generally use the class method to create factory methods. Factory methods return class objects ( similar to a constructor ) for different use cases.\n• None We generally use static methods to create utility functions.\n\nHow to define a class method and a static method?\n\nTo define a class method in python, we use @classmethod decorator, and to define a static method we use @staticmethod decorator. \n\nLet us look at an example to understand the difference between both of them. Let us say we want to create a class Person. Now, python doesn’t support method overloading like C++ or Java so we use class methods to create factory methods. In the below example we use a class method to create a person object from birth year.\n\nAs explained above we use static methods to create utility functions. In the below example we use a static method to check if a person is an adult or not.\n\nBelow is the complete Implementation\n\nHow to define a class method in Python?\n\nHow to define a static method in Python?\n\nWhen should you use class methods over static methods in Python?\n\nClass Methods: Use when you need to access or modify the class state or when the method needs to work with class variables or other class methods. Static Methods: Use when the method does not access or modify class or instance state, and it performs a utility function that is related to the class but does not need access to class-specific data.\n\nCan class methods and static methods be used interchangeably?"
    },
    {
        "link": "https://medium.com/towards-data-science/python-decorators-in-oop-3189c526ead6",
        "document": "A guide on classmethods, staticmethods and the property decorator The Object Oriented Programming paradigm became popular in the ’60s and ‘70s, in languages like Lisp and Smalltalk. Such features were also added to existing languages like Ada, Fortran and Pascal. Python is an object oriented programming language, though it doesn’t support strong encapsulation. Introductory topics in object-oriented programming in Python — and more generally — include things like defining classes, creating objects, instance variables, the basics of inheritance, and maybe even some special methods like . But when we have an advanced look, we could talk about things like the use of decorators, or writing a custom method, metaclasses, and Multiple Inheritance. In this post, we’ll first discuss what decorators are, followed by a discussion on classmethods and staticmethods along with the property decorator. Classmethods, staticmethods and property are examples of what are called descriptors. These are objects which implement the , or methods. But, that’s a topic for another post.\n\nDecorators are functions (or classes) that provide enhanced functionality to the original function (or class) without the programmer having to modify their structure. Suppose we want to add a method to our class that takes a student’s score and total marks and then returns a percentage. The get_percent function — Image by author using draw.io Our percent function can be defined like so: Let’s define our decorator, creatively named . It takes a function as input and outputs another function ( , in this case). Our decorator — Image by author using draw.io\n• takes our two arguments and\n• calls the function object passed to the\n• then calculates the grade that corresponding to the percent scored.\n• Finally, it returns the calculated percentage along with the grade. How applying the decorator works — Image by author using draw.io We can implement our decorator like so. Now, to improve the function, just use the symbol with the decorator name above our function, which has exactly the same definition as before. To use this, we don’t need to modify our call statement. Executing this: What basically happens is that the function is replaced by when we apply the decorator. We’ll place the method inside the class, and place our decorator outside the class. Since is an instance method, we add a argument to it. How are decorators used in classes? We’ll see three popular decorators used in classes and their use-cases. The kinds of methods in our class A — Image by author using draw.io\n\nLet’s first talk about instance methods. Instance methods are those methods that are called by an object, and hence are passed information about that object. This is done through the argument as a convention, and when that method is called, the object’s information is passed implicitly through . For example, we could add a method to our class that calculates a student’s grade and percentage (using the get_percent method) and generates a report as a string with the student’s name, percentage, and grade. Coming to a class method, this type of function is called on a class, and hence, it requires a class to be passed to it. This is done with the argument by convention. And we also add the decorator to our class method. It looks something like this: Since class-methods work with a class, and not an instance, they can be used as part of a factory pattern, where objects are returned based on certain parameters. For example, there are multiple ways to create a Dataframe in pandas. There are methods like: , , etc. which all return a dataframe object. Though their actual implementation is pretty complex, they basically take something like a dictionary, manipulate that and then return a dataframe object after parsing that data. Coming back to our example, let's define a few ways to create instances of our class.\n• by two separate arguments: for example, <name>, 20 and 85\n• by a comma-separated string: for example, “<name>, 20, 85”.\n• by a tuple: for example, (<name>, 20, 85) To accomplish this in Java, we could simply overload our constructor: In python, a clean way to do it would be through classmethods: We also define the method, so we can directly print a Student object to see if it has been instantiated properly. Our class now looks like this: Now, to test this, let’s create three objects, each from a different kind of data. The output is exactly as expected from the definition of the method above:\n\nA static method doesn’t care about an instance, like an instance method. It doesn’t require a class being passed to it implicitly. A static method is a regular method, placed inside a class. It can be called using both a class and an object. We use the decorator for these kinds of methods. Why would this be useful? Why not just place such functions outside the class? Static methods are used instead of regular functions when it makes more sense to place the function inside the class. For example, placing utility methods that deal solely with a class or its objects is a good idea, since those methods won’t be used by anyone else. Coming to our example, we can make our method static, since it serves a general purpose and need not be bound to our objects. To do this, we can simply add above the method.\n\nThe property decorator provides methods for accessing (getter), modifying (setter), and deleting (deleter) the attributes of an object. The property decorator — Image by author using draw.io Let’s start with getter and setter methods. These methods are used to access and modify (respectively) a private instance. In Java, we would do something like this: Now, anytime you access or modify this value, you would use these methods. Since the variable is private, it can’t be accessed outside . In python, there is no keyword. We prepend a variable by a dunder( ) to show that it is private and shouldn’t be accessed or modified directly. Adding a before a variable name modifies that variable’s name from to , so direct access and modification like and won’t work. Still, this isn’t very strong since you could directly replace with the modified form to get a direct modification to work. Let’s take the following example to understand this: Taking our Student class example, let’s make the score attribute “private” by adding a __ before the variable name. If we directly went ahead and added and like Java, the main issue is that if we wanted to do this to existing code, we’d have to change every access from: Here’s where the decorator comes in. You can simply define , and methods using this feature. Our class now looks like this: To make the attribute read-only, just remove the setter method. Then, when we update , we get the following error: Traceback (most recent call last):\n\n File \"main.py\", line 16, in <module>\n\n student.score = 10\n\nAttributeError: can't set attribute The method lets you delete a protected or private attribute using the function. Using the same example as before, if we directly try and delete the score attribute, we get the following error: This gives:\n\nTraceback (most recent call last):\n\n File \"<string>\", line 17, in <module>\n\nAttributeError: can't delete attribute But when we add a deleter method, we can delete our private variable . The attribute has been successfully removed now. Printing out the value of gives “object has no attribute…”, since we deleted it. Traceback (most recent call last):\n\n File \"<string>\", line 23, in <module>\n\nFile \"<string>\", line 9, in x\n\nAttributeError: 'PythonClass' object has no attribute '__score' The property decorator is very useful when defining methods for data validation, like when deciding if a value to be assigned is valid and won’t lead to issues later in the code. Another use-case would be when wanting to display information in a specific way. Coming back to our example, if we wanted to display a student’s name as , instead of just , we could return the first string from a property getter on the name attribute: Now, any time we access , we get a formatted result. The decorator can also be used for logging changes. For example, in a method, you could add code to log the updating of a variable. Now, whenever the setter is called, which is when the variable is modified, the change is logged. Let’s say there was a totaling error in Bob’s math exam and he ends up getting 50 more marks. The above gives the following output, with the logged change visible: Finally, our class looks like this:\n\nNote#1: Where should you define a decorator wrt a class? There are many places you could define a decorator: outside the class, in a separate class, or maybe even in an inner class (with respect to the class we are using the decorator in). In this example, we simply defined outside the class. Though this works, the decorator now has nothing to do with our class, which we may not prefer. For a more detailed discussion on this, check out this post: Let’s suppose we need a decorator that we gonna use inside one specific class only. Something like this: Note#2: Are there options other than constructor overloading in Java to simulate the methods we discussed (like, from_str or from_tuple)? Apart from overloading the constructor, we could make use of static factory methods in java. We could define a static method like that would extract key information from the string passed to it and then return an object. Object-oriented programming is a very important paradigm to learn and use. Regardless of whether you’ll ever need to use the topics discussed here in your next project, it’s necessary to know the basics really well. Topics like the ones in this post aren’t used all that often compared to more basic concepts — like inheritance or the basic implementation of classes and objects — on which they are built. In any case, I hope this post gave you an idea of the other kinds of methods in Python OOP (apart from instance methods) and the property decorator."
    },
    {
        "link": "https://realpython.com/primer-on-python-decorators",
        "document": "Python decorators allow you to modify or extend the behavior of functions and methods without changing their actual code. When you use a Python decorator, you wrap a function with another function, which takes the original function as an argument and returns its modified version. This technique provides a simple way to implement higher-order functions in Python, enhancing code reusability and readability.\n\nBy the end of this tutorial, you’ll understand that:\n• Practical use cases for decorators include logging, enforcing access control, caching results, and measuring execution time.\n• Custom decorators are written by defining a function that takes another function as an argument, defines a nested wrapper function, and returns the wrapper.\n• Multiple decorators can be applied to a single function by stacking them before the function definition.\n• The order of decorators impacts the final output since each decorator wraps the next, influencing the behavior of the decorated function.\n\nYou can find all the examples from this tutorial by downloading the accompanying materials below:\n\nIn order to understand decorators, you must first understand some finer points of how functions work. There are many aspects to functions, but in the context of decorators, a function returns a value based on the given arguments. Here’s a basic example: In general, functions in Python may also have side effects rather than just turning an input into an output. The function is an example of this: it returns while having the side effect of outputting something to the console. However, to understand decorators, it’s enough to think about functions as tools that turn given arguments into values. In functional programming, you work almost entirely with pure functions that don’t have side effects. While not a purely functional language, Python supports many functional programming concepts, including treating functions as first-class objects. This means that functions can be passed around and used as arguments, just like any other object like , , , , and so on. Consider the following three functions: , together we're the awesomest!\" Here, and are regular functions that expect a name given as a string. The function, however, expects a function as its argument. You can, for example, pass it the or the function. To test your functions, you can run your code in interactive mode. You do this with the flag. For example, if your code is in a file named , then you run : 'Yo Bob, together we're the awesomest!' Note that refers to two functions, and , but in different ways. The function is named without parentheses. This means that only a reference to the function is passed. The function isn’t executed. The function, on the other hand, is written with parentheses, so it will be called as usual. This is an important distinction that’s crucial for how functions work as first-class objects. A function name without parentheses is a reference to a function, while a function name with trailing parentheses calls the function and refers to its return value. It’s possible to define functions inside other functions. Such functions are called inner functions. Here’s an example of a function with two inner functions: What happens when you call the function? Think about this for a minute. Then run in interactive mode to try it out. The output will be as follows: Note that the order in which the inner functions are defined does not matter. Like with any other functions, the printing only happens when the inner functions are executed. Furthermore, the inner functions aren’t defined until the parent function is called. They’re locally scoped to , meaning they only exist inside the function as local variables. Try calling . You’ll get an error: : name 'first_child' is not defined Whenever you call , the inner functions and are also called. But because of their local scope, they aren’t available outside of the function. Python also allows you to return functions from functions. In the following example, you rewrite to return one of the inner functions: Note that you’re returning without the parentheses. Recall that this means that you’re returning a reference to the function . In contrast, with parentheses refers to the result of evaluating the function. You can see this in the following example: The somewhat cryptic output means that the variable refers to the local function inside of , while points to . You can now use and as if they’re regular functions, even though you can’t directly access the functions they point to: You recognize the return values of the inner functions that you defined inside of . Finally, note that in the earlier example, you executed the inner functions within the parent function—for example, . However, in this last example, you didn’t add parentheses to the inner functions, such as , upon returning. That way, you got a reference to each function that you could call in the future.\n\nNow that you’ve seen that functions are just like any other object in Python, you’re ready to move on and see the magical beast that is the Python decorator. You’ll start with an example: \"Something is happening before the function is called.\" \"Something is happening after the function is called.\" Here, you’ve defined two regular functions, and , and one inner function. Then you redefined to apply to the original . Can you guess what happens when you call ? Try it in a REPL. Instead of running the file with the flag, you can also import the function manually: Something is happening before the function is called. Something is happening after the function is called. To understand what’s going on here, look back at the earlier examples. You’re applying everything that you’ve learned so far. The so-called decoration happens at the following line: In effect, the name now points to the inner function. Remember that you return as a function when you call : However, has a reference to the original as , and it calls that function between the two calls to . Before moving on, have a look at a second example. Because is a regular Python function, the way a decorator modifies a function can change dynamically. So as not to disturb your neighbors, the following example will only run the decorated code during the day: If you try to call after bedtime, nothing will happen: Here, doesn’t print any output. That’s because the test failed, so the wrapper didn’t call , the original . Look back at the code that you wrote in . The way you decorated is a little clunky. First of all, you end up typing the name three times. Additionally, the decoration gets hidden away below the definition of the function. Instead, Python allows you to use decorators in a simpler way with the symbol, sometimes called the pie syntax. The following example does the exact same thing as the first decorator example: \"Something is happening before the function is called.\" \"Something is happening after the function is called.\" So, is just a shorter way of saying . It’s how you apply a decorator to a function. Recall that a decorator is just a regular Python function. All the usual tools for reusability are available. Now, you’ll create a module where you store your decorators and that you can use in many other functions. Create a file called with the following content: The decorator calls the decorated function twice. You’ll soon see the effect of this in several examples. Note: You can name your inner function whatever you want, and a generic name like is usually okay. You’ll see a lot of decorators in this tutorial. To keep them apart, you’ll name the inner function with the same name as the decorator but with a prefix. You can now use this new decorator in other files by doing a regular import: When you run this example, you should see that the original is executed twice: There are two Whee! exclamations printed, confirming that does what it says on the tin. Free Bonus: Click here to get access to a free \"The Power of Python Decorators\" guide that shows you three advanced decorator patterns and techniques you can use to write cleaner and more Pythonic programs. Say that you have a function that accepts some arguments. Can you still decorate it? Give it a try: You now apply to , which expects a name. Unfortunately, calling this function raises an error: : wrapper_do_twice() takes 0 positional arguments but 1 was given The problem is that the inner function doesn’t take any arguments, but you passed to it. You could fix this by letting accept one argument, but then it wouldn’t work for the function that you created earlier. The solution is to use and in the inner wrapper function. Then it’ll accept an arbitrary number of positional and keyword arguments. Rewrite as follows: The inner function now accepts any number of arguments and passes them on to the function that it decorates. Now both your and examples work. Start a fresh REPL: You use the same decorator, , to decorate two different functions. This hints at one of the powers of decorators. They add behavior that can apply to many different functions. What happens to the return value of decorated functions? Well, that’s up to the decorator to decide. Say you decorate a simple function as follows: Oops, your decorator ate the return value from the function. Because the doesn’t explicitly return a value, the call ends up returning . To fix this, you need to make sure the wrapper function returns the return value of the decorated function. Change your file: Now you return the return value of the last call of the decorated function. Check out the example again: A great convenience when working with Python, especially in the interactive shell, is its powerful introspection ability. Introspection is the ability of an object to know about its own attributes at runtime. For instance, a function knows its own name and documentation: Help on built-in function print in module builtins: When you inspect , you can see its name and documentation. The introspection works for functions that you define yourself as well: Help on function wrapper_do_twice in module decorators: However, after being decorated, has gotten very confused about its identity. It now reports being the inner function inside the decorator. Although technically true, this isn’t very useful information. To fix this, decorators should use the decorator, which will preserve information about the original function. Update again: You don’t need to change anything about the decorated function, but you need to restart your REPL to see the effect: Help on function say_whee in module whee: Much better! Now is still itself after decoration. Note: The decorator uses to update special attributes like and that are used in the introspection. You’ve now learned the basics of how to create a decorator. However, isn’t a very exciting decorator, and there aren’t a lot of use cases for it. In the next section, you’ll implement several decorators that illustrate what you know so far and that you can use in your own code.\n\nYou’ll now look at a few more useful examples of decorators. You’ll notice that they’ll mainly follow the same pattern that you’ve learned so far: This formula is a good boilerplate template for building more complex decorators. You’ll continue to store your decorators in . Recall that you can download all the examples in this tutorial: Get Your Code: Click here to download the free sample code that shows you how to create and use Python decorators. You’ll start by creating a decorator. It’ll measure the time a function takes to execute and then print the duration to the console. Here’s the code: \"\"\"Print the runtime of the decorated function\"\"\" This decorator works by storing the time just before the function starts running in line 10 and just after the function finishes in line 12. The runtime of the function is then the difference between the two, calculated in line 13. You use , which does a good job of measuring time intervals. Now, add as an example of a function that spends some time, so that you can test . Here are some examples of timings: Run it yourself. Work through the definition of line by line. Make sure you understand how it works. Don’t worry if you don’t get everything, though. Decorators are advanced beings. Try to sleep on it or make a drawing of the program flow. Note: The decorator is great if you just want to get an idea about the runtime of your functions. If you want to do more precise measurements of code, then you should instead consider the module in the standard library. It temporarily disables garbage collection and runs multiple trials to strip out noise from short function calls. If you’re interested in learning more about timing functions, then have a look at Python Timer Functions: Three Ways to Monitor Your Code. The following decorator will print a function’s arguments and its return value every time you call the function: \"\"\"Print the function signature and return value\"\"\" The signature is created by joining the string representations of all the argument:\n• Line 9: You create a list of the positional arguments. Use to get a nice string representing each argument.\n• Line 10: You create a list of the keyword arguments. The f-string formats each argument as , and again, you use to represent the value.\n• Line 11: You join together the lists of positional and keyword arguments to one signature string with each argument separated by a comma.\n• Line 14: You print the return value after the function is executed. It’s time to see how the decorator works in practice by applying it to a simple function with one positional and one keyword argument: Note how the decorator prints the signature and return value of the function: This example might not seem immediately useful since the decorator just repeats what you wrote. It’s more powerful when applied to small convenience functions that you don’t call directly yourself. The following example calculates an approximation of the mathematical constant e: Here, you also apply a decorator to a function that has already been defined. In line 4, you decorate from the standard library. You can’t use the pie syntax, but you can still manually apply the decorator. The approximation of e is based on the following series expansion: When calling the function, you can see the decorator at work: In this example, you get a decent approximation of the true value e ≈ 2.718281828, adding only five terms. In this section, you’ll create a decorator that slows down your code. This might not seem very useful. Why would you want to slow down your Python code? Probably the most common use case is that you want to rate-limit a function that continuously checks whether a resource—like a web page—has changed. The decorator will sleep one second before it calls the decorated function: \"\"\"Sleep 1 second before calling the function\"\"\" In , you call to have your code take a pause before calling the decorated function. To see how the decorator works, you create a function. To see the effect of slowing down the code, you should run the example yourself: In , you check if is smaller than one. In that case, you print Liftoff!. If not, then you print the number and keep counting. Note: The function is a recursive function. In other words, it’s a function calling itself. To learn more about recursive functions in Python, see Thinking Recursively in Python. The decorator always sleeps for one second. Later, you’ll see how to control the rate by passing an argument to the decorator. Decorators don’t have to wrap the function that they’re decorating. They can also simply register that a function exists and return it unwrapped. You can use this, for example, to create a lightweight plugin architecture: The decorator only stores a reference to the decorated function in the global dictionary. Note that you don’t have to write an inner function or use in this example because you’re returning the original function unmodified. You can now register functions as follows: , together we're the awesomest!\" Note that the dictionary already contains references to each function object that’s registered as a plugin: Python applies decorators when you define a function, so and are immediately registered. You can then use to call these functions: The function randomly chooses one of the registered functions to use. In the f-string, you use the flag. This has the same effect as calling . The main benefit of this simple plugin architecture is that you don’t need to maintain a list of which plugins exist. That list is created when the plugins register themselves. This makes it trivial to add a new plugin: just define the function and decorate it with . If you’re familiar with in Python, then you might see some similarities to how the plugin architecture works. With , you get access to all global variables in the current scope, including your plugins: {..., # Many variables that aren't not shown here. Using the decorator, you can create your own curated list of interesting names, effectively hand-picking some functions from . The final example before moving on to some fancier decorators is commonly used when working with a web framework. In this example, you’ll use Flask to set up a web page that should only be visible to users that are logged in or otherwise authenticated: \"\"\"Make sure user is logged in before proceeding\"\"\" While this gives an idea about how to add authentication to your web framework, you should usually not write these types of decorators yourself. For Flask, you can use the Flask-Login extension instead, which adds more security and functionality.\n\nSo far, you’ve seen how to create simple decorators. You already have a pretty good understanding of what decorators are and how they work. Feel free to take a break from this tutorial to practice everything that you’ve learned. In the second part of this tutorial, you’ll explore more advanced features, including how to do the following:\n• Add several decorators to one function\n• Create decorators that can optionally take arguments Ready to dive in? Here you go! There are two different ways that you can use decorators on classes. The first one is very close to what you’ve already done with functions: you can decorate the methods of a class. This was one of the motivations for introducing decorators back in the day. Some commonly used decorators are even built-ins in Python, including , , and . The and decorators are used to define methods inside a class namespace that aren’t connected to a particular instance of that class. The decorator is used to customize getters and setters for class attributes. Expand the box below for an example using these decorators: The following definition of a class uses the , , and decorators: \"\"\"Get value of radius\"\"\" \"\"\"Calculate volume of cylinder with circle as base\"\"\" \"\"\"Value of π, could use math.pi instead though\"\"\" Inside you can see several different kinds of methods. Decorators are used to distinguish them:\n• is a mutable property. It can be set to a different value. However, by defining a setter method, you do some error testing to make sure isn’t set to a nonsensical negative number. Properties are accessed as attributes without parentheses.\n• is an immutable property. Properties without methods can’t be changed. Even though it’s defined as a method, it can be retrieved as an attribute without parentheses.\n• is a class method. It’s not bound to one particular instance of . Class methods are often used as factory methods that can create specific instances of the class.\n• is a static method. It’s not really dependent on the class, except that it’s part of its namespace. You can call static methods on either an instance or the class. You can use as follows: In these examples, you explore the different methods, attributes, and properties of . Next, define a class where you decorate some of its methods using the and decorators from earlier: Using this class, you can see the effect of the decorators: When you create a new instance of , Python calls under the hood, as your use of reveals. The decorator helps you monitor how much time is spent on . The other way to use decorators on classes is to decorate the whole class. This is, for example, done in the module: The meaning of the syntax is similar to the function decorators. In the example above, you could’ve decorated the class by writing . A common use of class decorators is to be a simpler alternative to some use cases of metaclasses. In both cases, you’re changing the definition of a class dynamically. Writing a class decorator is very similar to writing a function decorator. The only difference is that the decorator will receive a class and not a function as an argument. In fact, all the decorators that you saw above will work as class decorators. When you’re using them on a class instead of a function, their effect might not be what you want. In the following example, the decorator is applied to a class: Decorating a class doesn’t decorate its methods. Recall that is just shorthand for . Here, only measures the time that it takes to instantiate the class: The output from is only shown as is created. The call to isn’t timed. Later, you’ll see an example defining a proper class decorator, namely , which ensures that there’s only one instance of a class. You can apply several decorators to a function at once by stacking them on top of each other: Think about this as the decorators being executed in the order they’re listed. In other words, calls , which calls , or : The greeting is printed twice because of . However, the output from is only shown once, since it’s called before the decorator. Observe the difference if you change the order of and : Here, is applied to as well. You can see that both calls to are annotated with debugging information. Sometimes, it’s useful to pass arguments to your decorators. For instance, could be extended to a decorator. The number of times to execute the decorated function could then be given as an argument. If you define , you could do something like this: Think about how you’d implement . So far, the name written after the has referred to a function object that can be called with another function. To be consistent, you then need to return a function object that can act as a decorator. Luckily, you already know how to return functions! In general, you want something like the following: Typically, the decorator creates and returns an inner wrapper function, so writing the example out in full will give you an inner function within an inner function. While this might sound like the programming equivalent of the Inception, you’ll untangle it all in a moment: It looks a little messy, but you’ve only put the same decorator pattern that you’ve seen many times by now inside one additional that handles the arguments to the decorator. First, consider the innermost function: This function takes arbitrary arguments and returns the value of the decorated function, . This wrapper function also contains the loop that calls the decorated function times. This is no different from the earlier wrapper functions that you’ve seen, except that it’s using the parameter that must be supplied from the outside. One step out, you’ll find the decorator function: Again, looks exactly like the decorator functions that you’ve written earlier, except that it’s named differently. That’s because you reserve the base name— —for the outermost function, which is the one the user will call. As you’ve already seen, the outermost function returns a reference to the decorator function: There are a few subtle things happening in the function:\n• Defining as an inner function means that will refer to a function object, . Earlier, you used decorators like without parentheses. Now, you need to add parentheses when setting up the decorator, as in . This is necessary in order to add arguments.\n• The argument is seemingly not used in itself. But by passing , a closure is created where the value of is stored until uses it later. With everything set up, test your code to see if the results are as expected: That’s just the result that you were aiming for. With a little bit of care, you can also define decorators that can be used both with and without arguments. Most likely, you don’t need this, but it is nice to have the flexibility. Like Winnie-the-Pooh says: Both—but don’t bother about the bread, please. (Source) As you saw in the previous section, when a decorator uses arguments, you need to add an extra outer function. The challenge now is for your code to figure out if you’ve called the decorator with or without arguments. Since the function to decorate is only passed in directly if the decorator is called without arguments, the function must be an optional argument. This means that the decorator arguments must all be specified by keyword. You can enforce this with the special asterisk ( ) syntax, which means that all the following parameters are keyword-only: Here, the argument acts as a marker, noting whether the decorator has been called with arguments or not:\n• Line 1: If you’ve called without arguments, then the decorated function will be passed in as . If you’ve called it with arguments, then will be , and some of the keyword arguments may have been changed from their default values. The asterisk in the argument list means that you can’t call the remaining arguments as positional arguments.\n• Line 6: In this case, you called the decorator with arguments. Return a decorator function that takes a function as an argument and returns a wrapper function.\n• Line 8: In this case, you called the decorator without arguments. Apply the decorator to the function immediately. Using this boilerplate on the decorator in the previous section, you can write the following: Compare this with the original . The only changes are the added parameter and the … block at the end. Recipe 9.6 of the excellent Python Cookbook shows an alternative solution using . You can now apply to different functions to test that you can now use it with or without arguments: Recall that the default value of is , so using without any arguments is equivalent to using : Here, Whee! is repeated twice since that’s the default behavior of . As specified by the argument, the greeting is repeated three times. Sometimes, it’s useful to have a decorator that can keep track of state. As an example, you’ll create a decorator that counts the number of times a function is called. Note: In the beginning of this guide, you learned about pure functions returning a value based on given arguments. Stateful decorators are quite the opposite, where the return value will depend on the current state, as well as the given arguments. In the next section, you’ll see how to use classes to keep state. But in simple cases, you can also get away with using function attributes: The state—the number of calls to the function—is stored in the function attribute on the wrapper function. Here’s the effect of using it: You apply to your old friend, . Each time you call the function, you see that the call count increases. You can also manually query the attribute. The typical way to maintain state in Python is by using classes. In this section, you’ll see how to rewrite the example from the previous section to use a class as a decorator. Recall that the decorator syntax is just a quicker way of saying . Therefore, if is a class, it needs to take as an argument in its initializer. Furthermore, the class instance needs to be callable so that it can stand in for the decorated function. Note: Up until now, all the decorators that you’ve seen have been defined as functions. This is how you most often will create decorators. However, you can use any callable expression as a decorator. For a class instance to be callable, you implement the special method: The method is executed each time you try to call an instance of the class: Each time you call , the state changes as the count increases. Therefore, a typical implementation of a decorator class should implement and : The method must store a reference to the function, and it can do any other necessary initialization. The method will be called instead of the decorated function. It does essentially the same thing as the function in your earlier examples. Note that you need to use the function instead of . This decorator works the same as the one in the previous section: Each call to is counted and noted. In the next section, you’ll look at more examples of decorators.\n\nYou’ve come a long way now, having figured out how to create all kinds of decorators. You’ll wrap it up, putting your newfound knowledge to use by creating a few more examples that might be useful in the real world. As noted earlier, your previous implementation of always sleeps for one second. Now you know how to add parameters to decorators, so you can rewrite using an optional argument that controls how long it sleeps: \"\"\"Sleep given amount of seconds before calling the function\"\"\" You’re using the boilerplate introduced in the Creating Decorators With Optional Arguments section to make callable both with and without arguments. The same recursive function as earlier now sleeps two seconds between each count: As before, you must run the example yourself to see the effect of the decorator: There’ll be a two second pause between each number in the countdown. A singleton is a class with only one instance. There are several singletons in Python that you use frequently, including , , and . The fact that is a singleton allows you to compare for using the keyword, like you did when creating decorators with optional arguments: Using returns only for objects that are the exact same instance. The following decorator turns a class into a singleton by storing the first instance of the class as an attribute. Later attempts at creating an instance simply return the stored instance: As you see, this class decorator follows the same template as your function decorators. The only difference is that you’re using instead of as the parameter name to indicate that it’s meant to be a class decorator. Check it out in practice: By comparing object IDs and checking with the keyword, you confirm that is indeed the exact same instance as . Note: Singleton classes aren’t really used as often in Python as in other languages. The effect of a singleton is usually better implemented as a global variable inside a module. Class decorators are less common than function decorators. You should document these well, so that your users know how to apply them. Decorators can provide a nice mechanism for caching and memoization. As an example, look at a recursive definition of the Fibonacci sequence: While this implementation is straightforward, its runtime performance is terrible: To calculate the tenth Fibonacci number, you should only need to calculate the preceding Fibonacci numbers, but this implementation somehow needs a whopping 177 calculations. It gets worse quickly: 21,891 calculations are needed for and almost 2.7 million calculations for the thirtieth number. This is because the code keeps recalculating Fibonacci numbers that are already known. The usual solution is to implement Fibonacci numbers using a loop and a lookup table. However, caching the calculations will also do the trick. First add a decorator to your module: The cache works as a lookup table, as it stores calculations in a dictionary. You can add it to : You still use to monitor the performance of your calculations. With the cache, only does the necessary calculations once: Note that in the call to , no new calculations were needed since the eighth Fibonacci number had already been calculated for . In the standard library, a Least Recently Used (LRU) cache is available as . Additionally, you can use a regular cache with . These decorators have more features than the one you saw above. You should use or instead of writing your own cache decorator. In the next example, you don’t return the result immediately. Instead, you add a call to to see when a result is calculated and not just retrieved from the cache: The parameter specifies how many recent calls are cached. The default value is 128, but you can specify to cache all function calls. Using has the same effect as . However, be aware that this can cause memory problems if you’re caching many large objects. You can use the method to see how the cache performs, and you can tune it if needed. In your example, you used an artificially small to see the effect of elements being removed from the cache: In these examples, you calculate a few Fibonacci numbers. Your cache only holds four calculations at a time. For example, after calculating , it holds the seventh, eight, ninth, and tenth number. Therefore, you’re able to find without doing any recalculations. Then you ask for , but that fifth number has been deleted from the cache. It therefore needs to be calculated from scratch. In most applications, you don’t need to constrain your cache and can use directly. The following example is somewhat similar to the registering plugins example from earlier, in that it doesn’t really change the behavior of the decorated function. Instead, it simply adds as a function attribute: The following example calculates the volume of a cylinder based on its radius and height in centimeters: You’ve added information to that the result should be interpreted as cubic centimeters. You can later access the function attribute when needed: Note that you could’ve achieved something similar using function annotations: However, since annotations are used for type hints, it’s a bit clunky to combine such units as annotations with static type checking. Units become even more powerful and fun when connected with a library that can convert between units. One such library is . With installed ( ), you can convert the volume to cubic inches or gallons, for example: You use to create a quantity that has both a magnitude and a unit. By calling , you convert to other units. For example, the example cylinder is about 141 cubic centimeters, which translates to approximately 8.63 cubic inches and 0.0373 gallons. You could also modify the decorator to return a directly. Such a is made by multiplying a value with the unit. In , units must be looked up in a . You can store the registry as a function attribute on the decorator to avoid cluttering the namespace: \"\"\"Have a function return a Quantity with given unit\"\"\" With the decorator, converting units is practically effortless: When Usain Bolt ran 100 meters in 9.58 seconds at the 2009 world championships, he had an average speed of 10.4 meters per second. This translates to about 37.6 kilometers per hour and 23.4 miles per hour. You’ll now look at one last use case. Take a quick look at the following Flask route handler: Here you ensure that the key is part of the request. Although this validation works, it doesn’t really belong in the function itself. Additionally, there may be other routes that use the same validation. So, to keep it DRY, you can abstract out any unnecessary logic with a decorator. The following decorator will do the job: In the above code, the decorator takes a variable-length list as an argument so that you can pass in as many string arguments as necessary, each representing a key used to validate the JSON data:\n• Line 4: The list of keys that must be present in the JSON is given as arguments to the decorator.\n• Line 9: The wrapper function validates that each expected key is present in the JSON data. The route handler can then focus on its real job—updating grades—as it can safely assume that the JSON data are valid: You apply , which simplifies the logic inside ."
    },
    {
        "link": "https://docs.python.org/3/tutorial/classes.html",
        "document": "Classes provide a means of bundling data and functionality together. Creating a new class creates a new type of object, allowing new instances of that type to be made. Each class instance can have attributes attached to it for maintaining its state. Class instances can also have methods (defined by its class) for modifying its state.\n\nCompared with other programming languages, Python’s class mechanism adds classes with a minimum of new syntax and semantics. It is a mixture of the class mechanisms found in C++ and Modula-3. Python classes provide all the standard features of Object Oriented Programming: the class inheritance mechanism allows multiple base classes, a derived class can override any methods of its base class or classes, and a method can call the method of a base class with the same name. Objects can contain arbitrary amounts and kinds of data. As is true for modules, classes partake of the dynamic nature of Python: they are created at runtime, and can be modified further after creation.\n\nIn C++ terminology, normally class members (including the data members) are public (except see below Private Variables), and all member functions are virtual. As in Modula-3, there are no shorthands for referencing the object’s members from its methods: the method function is declared with an explicit first argument representing the object, which is provided implicitly by the call. As in Smalltalk, classes themselves are objects. This provides semantics for importing and renaming. Unlike C++ and Modula-3, built-in types can be used as base classes for extension by the user. Also, like in C++, most built-in operators with special syntax (arithmetic operators, subscripting etc.) can be redefined for class instances.\n\nBefore introducing classes, I first have to tell you something about Python’s scope rules. Class definitions play some neat tricks with namespaces, and you need to know how scopes and namespaces work to fully understand what’s going on. Incidentally, knowledge about this subject is useful for any advanced Python programmer. A namespace is a mapping from names to objects. Most namespaces are currently implemented as Python dictionaries, but that’s normally not noticeable in any way (except for performance), and it may change in the future. Examples of namespaces are: the set of built-in names (containing functions such as , and built-in exception names); the global names in a module; and the local names in a function invocation. In a sense the set of attributes of an object also form a namespace. The important thing to know about namespaces is that there is absolutely no relation between names in different namespaces; for instance, two different modules may both define a function without confusion — users of the modules must prefix it with the module name. By the way, I use the word attribute for any name following a dot — for example, in the expression , is an attribute of the object . Strictly speaking, references to names in modules are attribute references: in the expression , is a module object and is an attribute of it. In this case there happens to be a straightforward mapping between the module’s attributes and the global names defined in the module: they share the same namespace! Attributes may be read-only or writable. In the latter case, assignment to attributes is possible. Module attributes are writable: you can write . Writable attributes may also be deleted with the statement. For example, will remove the attribute from the object named by . Namespaces are created at different moments and have different lifetimes. The namespace containing the built-in names is created when the Python interpreter starts up, and is never deleted. The global namespace for a module is created when the module definition is read in; normally, module namespaces also last until the interpreter quits. The statements executed by the top-level invocation of the interpreter, either read from a script file or interactively, are considered part of a module called , so they have their own global namespace. (The built-in names actually also live in a module; this is called .) The local namespace for a function is created when the function is called, and deleted when the function returns or raises an exception that is not handled within the function. (Actually, forgetting would be a better way to describe what actually happens.) Of course, recursive invocations each have their own local namespace. A scope is a textual region of a Python program where a namespace is directly accessible. “Directly accessible” here means that an unqualified reference to a name attempts to find the name in the namespace. Although scopes are determined statically, they are used dynamically. At any time during execution, there are 3 or 4 nested scopes whose namespaces are directly accessible:\n• None the innermost scope, which is searched first, contains the local names\n• None the scopes of any enclosing functions, which are searched starting with the nearest enclosing scope, contain non-local, but also non-global names\n• None the next-to-last scope contains the current module’s global names\n• None the outermost scope (searched last) is the namespace containing built-in names If a name is declared global, then all references and assignments go directly to the next-to-last scope containing the module’s global names. To rebind variables found outside of the innermost scope, the statement can be used; if not declared nonlocal, those variables are read-only (an attempt to write to such a variable will simply create a new local variable in the innermost scope, leaving the identically named outer variable unchanged). Usually, the local scope references the local names of the (textually) current function. Outside functions, the local scope references the same namespace as the global scope: the module’s namespace. Class definitions place yet another namespace in the local scope. It is important to realize that scopes are determined textually: the global scope of a function defined in a module is that module’s namespace, no matter from where or by what alias the function is called. On the other hand, the actual search for names is done dynamically, at run time — however, the language definition is evolving towards static name resolution, at “compile” time, so don’t rely on dynamic name resolution! (In fact, local variables are already determined statically.) A special quirk of Python is that – if no or statement is in effect – assignments to names always go into the innermost scope. Assignments do not copy data — they just bind names to objects. The same is true for deletions: the statement removes the binding of from the namespace referenced by the local scope. In fact, all operations that introduce new names use the local scope: in particular, statements and function definitions bind the module or function name in the local scope. The statement can be used to indicate that particular variables live in the global scope and should be rebound there; the statement indicates that particular variables live in an enclosing scope and should be rebound there. This is an example demonstrating how to reference the different scopes and namespaces, and how and affect variable binding: The output of the example code is: After local assignment: test spam After nonlocal assignment: nonlocal spam After global assignment: nonlocal spam In global scope: global spam Note how the local assignment (which is default) didn’t change scope_test's binding of spam. The assignment changed scope_test's binding of spam, and the assignment changed the module-level binding. You can also see that there was no previous binding for spam before the assignment.\n\nA First Look at Classes¶ Classes introduce a little bit of new syntax, three new object types, and some new semantics. The simplest form of class definition looks like this: Class definitions, like function definitions ( statements) must be executed before they have any effect. (You could conceivably place a class definition in a branch of an statement, or inside a function.) In practice, the statements inside a class definition will usually be function definitions, but other statements are allowed, and sometimes useful — we’ll come back to this later. The function definitions inside a class normally have a peculiar form of argument list, dictated by the calling conventions for methods — again, this is explained later. When a class definition is entered, a new namespace is created, and used as the local scope — thus, all assignments to local variables go into this new namespace. In particular, function definitions bind the name of the new function here. When a class definition is left normally (via the end), a class object is created. This is basically a wrapper around the contents of the namespace created by the class definition; we’ll learn more about class objects in the next section. The original local scope (the one in effect just before the class definition was entered) is reinstated, and the class object is bound here to the class name given in the class definition header ( in the example). Class objects support two kinds of operations: attribute references and instantiation. Attribute references use the standard syntax used for all attribute references in Python: . Valid attribute names are all the names that were in the class’s namespace when the class object was created. So, if the class definition looked like this: then and are valid attribute references, returning an integer and a function object, respectively. Class attributes can also be assigned to, so you can change the value of by assignment. is also a valid attribute, returning the docstring belonging to the class: . Class instantiation uses function notation. Just pretend that the class object is a parameterless function that returns a new instance of the class. For example (assuming the above class): creates a new instance of the class and assigns this object to the local variable . The instantiation operation (“calling” a class object) creates an empty object. Many classes like to create objects with instances customized to a specific initial state. Therefore a class may define a special method named , like this: When a class defines an method, class instantiation automatically invokes for the newly created class instance. So in this example, a new, initialized instance can be obtained by: Of course, the method may have arguments for greater flexibility. In that case, arguments given to the class instantiation operator are passed on to . For example, Now what can we do with instance objects? The only operations understood by instance objects are attribute references. There are two kinds of valid attribute names: data attributes and methods. data attributes correspond to “instance variables” in Smalltalk, and to “data members” in C++. Data attributes need not be declared; like local variables, they spring into existence when they are first assigned to. For example, if is the instance of created above, the following piece of code will print the value , without leaving a trace: The other kind of instance attribute reference is a method. A method is a function that “belongs to” an object. Valid method names of an instance object depend on its class. By definition, all attributes of a class that are function objects define corresponding methods of its instances. So in our example, is a valid method reference, since is a function, but is not, since is not. But is not the same thing as — it is a method object, not a function object. Usually, a method is called right after it is bound: In the example, this will return the string . However, it is not necessary to call a method right away: is a method object, and can be stored away and called at a later time. For example: will continue to print until the end of time. What exactly happens when a method is called? You may have noticed that was called without an argument above, even though the function definition for specified an argument. What happened to the argument? Surely Python raises an exception when a function that requires an argument is called without any — even if the argument isn’t actually used… Actually, you may have guessed the answer: the special thing about methods is that the instance object is passed as the first argument of the function. In our example, the call is exactly equivalent to . In general, calling a method with a list of n arguments is equivalent to calling the corresponding function with an argument list that is created by inserting the method’s instance object before the first argument. In general, methods work as follows. When a non-data attribute of an instance is referenced, the instance’s class is searched. If the name denotes a valid class attribute that is a function object, references to both the instance object and the function object are packed into a method object. When the method object is called with an argument list, a new argument list is constructed from the instance object and the argument list, and the function object is called with this new argument list. Generally speaking, instance variables are for data unique to each instance and class variables are for attributes and methods shared by all instances of the class: As discussed in A Word About Names and Objects, shared data can have possibly surprising effects with involving mutable objects such as lists and dictionaries. For example, the tricks list in the following code should not be used as a class variable because just a single list would be shared by all Dog instances: Correct design of the class should use an instance variable instead: # creates a new empty list for each dog\n\nIf the same attribute name occurs in both an instance and in a class, then attribute lookup prioritizes the instance: Data attributes may be referenced by methods as well as by ordinary users (“clients”) of an object. In other words, classes are not usable to implement pure abstract data types. In fact, nothing in Python makes it possible to enforce data hiding — it is all based upon convention. (On the other hand, the Python implementation, written in C, can completely hide implementation details and control access to an object if necessary; this can be used by extensions to Python written in C.) Clients should use data attributes with care — clients may mess up invariants maintained by the methods by stamping on their data attributes. Note that clients may add data attributes of their own to an instance object without affecting the validity of the methods, as long as name conflicts are avoided — again, a naming convention can save a lot of headaches here. There is no shorthand for referencing data attributes (or other methods!) from within methods. I find that this actually increases the readability of methods: there is no chance of confusing local variables and instance variables when glancing through a method. Often, the first argument of a method is called . This is nothing more than a convention: the name has absolutely no special meaning to Python. Note, however, that by not following the convention your code may be less readable to other Python programmers, and it is also conceivable that a class browser program might be written that relies upon such a convention. Any function object that is a class attribute defines a method for instances of that class. It is not necessary that the function definition is textually enclosed in the class definition: assigning a function object to a local variable in the class is also ok. For example: Now , and are all attributes of class that refer to function objects, and consequently they are all methods of instances of — being exactly equivalent to . Note that this practice usually only serves to confuse the reader of a program. Methods may call other methods by using method attributes of the argument: Methods may reference global names in the same way as ordinary functions. The global scope associated with a method is the module containing its definition. (A class is never used as a global scope.) While one rarely encounters a good reason for using global data in a method, there are many legitimate uses of the global scope: for one thing, functions and modules imported into the global scope can be used by methods, as well as functions and classes defined in it. Usually, the class containing the method is itself defined in this global scope, and in the next section we’ll find some good reasons why a method would want to reference its own class. Each value is an object, and therefore has a class (also called its type). It is stored as .\n\nOf course, a language feature would not be worthy of the name “class” without supporting inheritance. The syntax for a derived class definition looks like this: The name must be defined in a namespace accessible from the scope containing the derived class definition. In place of a base class name, other arbitrary expressions are also allowed. This can be useful, for example, when the base class is defined in another module: Execution of a derived class definition proceeds the same as for a base class. When the class object is constructed, the base class is remembered. This is used for resolving attribute references: if a requested attribute is not found in the class, the search proceeds to look in the base class. This rule is applied recursively if the base class itself is derived from some other class. There’s nothing special about instantiation of derived classes: creates a new instance of the class. Method references are resolved as follows: the corresponding class attribute is searched, descending down the chain of base classes if necessary, and the method reference is valid if this yields a function object. Derived classes may override methods of their base classes. Because methods have no special privileges when calling other methods of the same object, a method of a base class that calls another method defined in the same base class may end up calling a method of a derived class that overrides it. (For C++ programmers: all methods in Python are effectively .) An overriding method in a derived class may in fact want to extend rather than simply replace the base class method of the same name. There is a simple way to call the base class method directly: just call . This is occasionally useful to clients as well. (Note that this only works if the base class is accessible as in the global scope.) Python has two built-in functions that work with inheritance:\n• None Use to check an instance’s type: will be only if is or some class derived from .\n• None Use to check class inheritance: is since is a subclass of . However, is since is not a subclass of . Python supports a form of multiple inheritance as well. A class definition with multiple base classes looks like this: For most purposes, in the simplest cases, you can think of the search for attributes inherited from a parent class as depth-first, left-to-right, not searching twice in the same class where there is an overlap in the hierarchy. Thus, if an attribute is not found in , it is searched for in , then (recursively) in the base classes of , and if it was not found there, it was searched for in , and so on. In fact, it is slightly more complex than that; the method resolution order changes dynamically to support cooperative calls to . This approach is known in some other multiple-inheritance languages as call-next-method and is more powerful than the super call found in single-inheritance languages. Dynamic ordering is necessary because all cases of multiple inheritance exhibit one or more diamond relationships (where at least one of the parent classes can be accessed through multiple paths from the bottommost class). For example, all classes inherit from , so any case of multiple inheritance provides more than one path to reach . To keep the base classes from being accessed more than once, the dynamic algorithm linearizes the search order in a way that preserves the left-to-right ordering specified in each class, that calls each parent only once, and that is monotonic (meaning that a class can be subclassed without affecting the precedence order of its parents). Taken together, these properties make it possible to design reliable and extensible classes with multiple inheritance. For more detail, see The Python 2.3 Method Resolution Order.\n\n“Private” instance variables that cannot be accessed except from inside an object don’t exist in Python. However, there is a convention that is followed by most Python code: a name prefixed with an underscore (e.g. ) should be treated as a non-public part of the API (whether it is a function, a method or a data member). It should be considered an implementation detail and subject to change without notice. Since there is a valid use-case for class-private members (namely to avoid name clashes of names with names defined by subclasses), there is limited support for such a mechanism, called name mangling. Any identifier of the form (at least two leading underscores, at most one trailing underscore) is textually replaced with , where is the current class name with leading underscore(s) stripped. This mangling is done without regard to the syntactic position of the identifier, as long as it occurs within the definition of a class. The private name mangling specifications for details and special cases. Name mangling is helpful for letting subclasses override methods without breaking intraclass method calls. For example: # provides new signature for update() # but does not break __init__() The above example would work even if were to introduce a identifier since it is replaced with in the class and in the class respectively. Note that the mangling rules are designed mostly to avoid accidents; it still is possible to access or modify a variable that is considered private. This can even be useful in special circumstances, such as in the debugger. Notice that code passed to or does not consider the classname of the invoking class to be the current class; this is similar to the effect of the statement, the effect of which is likewise restricted to code that is byte-compiled together. The same restriction applies to , and , as well as when referencing directly."
    },
    {
        "link": "https://geeksforgeeks.org/method-overriding-in-python",
        "document": "Method overriding is an ability of any object-oriented programming language that allows a subclass or child class to provide a specific implementation of a method that is already provided by one of its super-classes or parent classes. When a method in a subclass has the same name, the same parameters or signature, and same return type(or sub-type) as a method in its super-class, then the method in the subclass is said to override the method in the super-class.\n\nThe version of a method that is executed will be determined by the object that is used to invoke it. If an object of a parent class is used to invoke the method, then the version in the parent class will be executed, but if an object of the subclass is used to invoke the method, then the version in the child class will be executed. In other words, it is the type of the object being referred to (not the type of the reference variable) that determines which version of an overridden method will be executed.\n• None : This ensures that the parent class’s constructor is called, initializing any attributes defined in the parent class. It’s good practice to call the parent class constructor if it does important initialization.\n• Method Override is called on an instance of , it uses the\n\nMultiple Inheritance: When a class is derived from more than one base class it is called multiple Inheritance.\n\nExample: Let’s consider an example where we want to override a method of one parent class only.\n\nMultilevel Inheritance: When we have a child and grandchild relationship.\n\nExample: Let’s consider an example where we want to override only one method of one of its parent classes.\n\nCalling the Parent’s method within the overridden method\n\nParent class methods can also be called within the overridden methods. This can generally be achieved by two ways.\n\nUsing Classname: Parent’s class methods can be called by using the Parent inside the overridden method.\n\nPython function provides us the facility to refer to the parent class explicitly. It is basically useful where we have to call superclass functions. It returns the proxy object that allows us to refer parent class by ‘super’.\n\nWhat is Method Overriding in Python?\n\nWhat is Method Overloading in Python?\n\nMethod overloading refers to the ability to have multiple methods with the same name but different parameters within the same class. Python does not support method overloading by default. However, we can achieve method overloading-like behavior by providing default values for parameters or by using variable-length arguments. \n\n \n\n if a is not None and b is not None: \n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\nWhat is the Difference Between Overloading and Overriding?\n\nHow Can You Prevent Method Overriding in Python?\n\nPython does not provide built-in support for preventing method overriding, but you can achieve this behavior by convention or using a more complex design pattern, such as using decorators to check if a method in a base class is being overridden in a subclass. Example Using a Decorator to Discourage Overriding: \n\n\n\n\n\n\n\n\n\n\n\n\n\n print(\"This method should not be overridden\") \n\n\n\n\n\n\n\n \n\n\n\n \n\n \n\n raise TypeError(\"Method overriding has been prohibited for this method\") \n\n\n\n\n\n child.show() # This will raise an error before execution if checked properly\n\nWhat is Encapsulation in Python?\n\nEncapsulation in Python refers to the bundling of data with the methods that operate on that data. It restricts direct access to some of the object’s components, which can prevent the accidental modification of data. In Python, encapsulation is typically achieved by prefixing names of attributes or methods with a single underscore (weakly private) or double underscore (strongly private) to suggest or enforce that they are meant to be private. \n\n\n\n \n\n\n\n\n\n \n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n \n\n # print(c.__max_price) # This will raise an AttributeError"
    },
    {
        "link": "https://docs.python.org/3/reference/datamodel.html",
        "document": "Objects are Python’s abstraction for data. All data in a Python program is represented by objects or by relations between objects. (In a sense, and in conformance to Von Neumann’s model of a “stored program computer”, code is also represented by objects.) Every object has an identity, a type and a value. An object’s identity never changes once it has been created; you may think of it as the object’s address in memory. The operator compares the identity of two objects; the function returns an integer representing its identity. CPython implementation detail: For CPython, is the memory address where is stored. An object’s type determines the operations that the object supports (e.g., “does it have a length?”) and also defines the possible values for objects of that type. The function returns an object’s type (which is an object itself). Like its identity, an object’s type is also unchangeable. The value of some objects can change. Objects whose value can change are said to be mutable; objects whose value is unchangeable once they are created are called immutable. (The value of an immutable container object that contains a reference to a mutable object can change when the latter’s value is changed; however the container is still considered immutable, because the collection of objects it contains cannot be changed. So, immutability is not strictly the same as having an unchangeable value, it is more subtle.) An object’s mutability is determined by its type; for instance, numbers, strings and tuples are immutable, while dictionaries and lists are mutable. Objects are never explicitly destroyed; however, when they become unreachable they may be garbage-collected. An implementation is allowed to postpone garbage collection or omit it altogether — it is a matter of implementation quality how garbage collection is implemented, as long as no objects are collected that are still reachable. CPython implementation detail: CPython currently uses a reference-counting scheme with (optional) delayed detection of cyclically linked garbage, which collects most objects as soon as they become unreachable, but is not guaranteed to collect garbage containing circular references. See the documentation of the module for information on controlling the collection of cyclic garbage. Other implementations act differently and CPython may change. Do not depend on immediate finalization of objects when they become unreachable (so you should always close files explicitly). Note that the use of the implementation’s tracing or debugging facilities may keep objects alive that would normally be collectable. Also note that catching an exception with a … statement may keep objects alive. Some objects contain references to “external” resources such as open files or windows. It is understood that these resources are freed when the object is garbage-collected, but since garbage collection is not guaranteed to happen, such objects also provide an explicit way to release the external resource, usually a method. Programs are strongly recommended to explicitly close such objects. The … statement and the statement provide convenient ways to do this. Some objects contain references to other objects; these are called containers. Examples of containers are tuples, lists and dictionaries. The references are part of a container’s value. In most cases, when we talk about the value of a container, we imply the values, not the identities of the contained objects; however, when we talk about the mutability of a container, only the identities of the immediately contained objects are implied. So, if an immutable container (like a tuple) contains a reference to a mutable object, its value changes if that mutable object is changed. Types affect almost all aspects of object behavior. Even the importance of object identity is affected in some sense: for immutable types, operations that compute new values may actually return a reference to any existing object with the same type and value, while for mutable objects this is not allowed. For example, after , a and b may or may not refer to the same object with the value one, depending on the implementation. This is because is an immutable type, so the reference to can be reused. This behaviour depends on the implementation used, so should not be relied upon, but is something to be aware of when making use of object identity tests. However, after , c and d are guaranteed to refer to two different, unique, newly created empty lists. (Note that assigns the same object to both e and f.)"
    },
    {
        "link": "https://realpython.com/inheritance-composition-python",
        "document": "In Python, understanding inheritance and composition is crucial for effective object-oriented programming. Inheritance allows you to model an is a relationship, where a derived class extends the functionality of a base class. Composition, on the other hand, models a has a relationship, where a class contains objects of other classes to build complex structures. Both techniques promote code reuse, but they approach it differently.\n\nBy the end of this tutorial, you’ll understand that:\n• Composition and inheritance in Python model relationships between classes, enabling code reuse in different ways.\n• Composition is achieved by creating classes that contain objects of other classes, allowing for flexible designs.\n• Inheritance models an is a relationship, allowing derived classes to extend base class functionality.\n• Inheritance in Python is achieved by defining classes that derive from base classes, inheriting their interface and implementation.\n\nExploring the differences between inheritance and composition helps you choose the right approach for designing robust, maintainable Python applications. Understanding how and when to apply each concept is key to leveraging the full power of Python’s object-oriented programming capabilities.\n\nAn Overview of Inheritance in Python Everything in Python is an object. Modules are objects, class definitions and functions are objects, and of course, objects created from classes are objects too. Inheritance is a required feature of every object-oriented programming language. This means that Python supports inheritance, and as you’ll see later, it’s one of the few languages that supports multiple inheritance. When you write Python code using classes, you’re using inheritance even if you don’t know that you’re using it. Next up, take a look at what that means. The easiest way to see inheritance in Python is to jump into the Python interactive shell and write a little bit of code. You’ll start by writing the simplest class possible: You declared , which doesn’t do much, but it’ll illustrate the most basic inheritance concepts. Now that you have the class declared, you can create an instance of the class and use the function to list its members: The function returns a list of all the members in the specified object. You haven’t declared any members in , so where’s the list coming from? You can find out using the interactive interpreter: As you can see, the two lists are nearly identical. There are three additional members in : However, every single member of the class is also present in . This is because every class that you create in Python implicitly derives from . You could be more explicit and write , but it’s redundant and unnecessary. Note: In Python 2, you had to explicitly derive from for reasons beyond the scope of this tutorial, but you can read about it in the new-style and classic classes section of the Python 2 documentation. Okay, it’s not entirely true that every class in Python derives from . There’s one aptly named exception, which you’ll learn about next. Every class that you create in Python will implicitly derive from . However, there’s one exception to this rule: classes used to indicate errors by raising an exception. If you try to treat a normal Python class like an exception and it, then Python will present you with a : You created a new class to indicate a type of error. Then you tried to raise the class to signal an exception. Python does indeed raise an exception, but the output states that the exception is of type , not , and that all . is a base class provided for all error types. To create a new error type, you must derive your class from or one of its derived classes. The convention in Python is to derive your custom error types from , which in turn derives from . The correct way to define your error type is the following: In this example, explicitly inherits from instead of implicitly inheriting from . With that change, you’ve fulfilled the requirements for creating a custom exception, and you can now raise your new exception class. When you raise , the output correctly states that Python raised an error of the type . Inheritance is the mechanism that you’ll use to create hierarchies of related classes. These related classes will share a common interface that the base classes will define. Derived classes can specialize the interface by providing a particular implementation where applicable. In this section, you’ll start modeling an HR system. Along the way, you’ll explore the use of inheritance and see how derived classes can provide a concrete implementation of the base class interface. The HR system needs to process payroll for the company’s employees, but there are different types of employees depending on how their payroll is calculated. You start by implementing a class that processes payroll: implements a method that takes a collection of employees and prints their , , and check amount using the method exposed on each employee object. Now, you implement a base class, , that handles the common interface for every employee type: is the base class for all employee types. It’s constructed with an and a . What you’re saying is that every must have an as well as a assigned. The HR system requires that every processed must provide a interface that returns the weekly salary for the employee. The implementation of that interface differs depending on the type of . For example, administrative workers have a fixed salary, so every week they get paid the same amount: You create a derived class, , that inherits from . The class initializes with the and required by the base class, and you use to initialize the members of the base class. You can read all about in Supercharge Your Classes With Python . also requires a initialization parameter that represents the amount that the employee makes per week. The class provides the required method that the HR system uses. The implementation just returns the amount stored in . The company also employs manufacturing workers who are paid by the hour, so you add to the HR system: The class is initialized with and , like the base class, plus the and the required to calculate the payroll. You implement the method by returning the hours worked times the hourly rate. Finally, the company employs sales associates who are paid through a fixed salary plus a commission based on their sales, so you create a class: You derive from because both classes have a to consider. At the same time, you initialize with a value that’s based on the sales for the employee. With , you leverage the implementation of the base class to retrieve the salary, and you add the commission value. Since derives from , you have access to the property directly, and you could’ve implemented using the value of that property. The problem with accessing the property directly is that if the implementation of changes, then you’ll have to also change the implementation of . It’s better to rely on the already-implemented method in the base class and extend the functionality as needed. You’ve created your first class hierarchy for the system. The UML diagram of the classes looks like this: The diagram shows the inheritance hierarchy of the classes. The derived classes implement the interface, which the requires. The implementation requires that the objects in the collection contain an , , and implementation. Note: Interfaces are represented similarly to classes in UML diagrams, with the word Interface above the interface name. Interface names are usually prefixed with a capital . In Python, you don’t implement interfaces explicitly. Instead, interfaces are defined by the attributes used and methods called by other functions and methods. Next, create a new file and call it . This program creates the employees and passes them to the payroll system to process payroll: You can run the program in the command line and see the results: The program creates three employee objects, one for each of the derived classes. Then, it creates the payroll system and passes a list of the employees to its method, which calculates the payroll for each employee and prints the results. Notice how the base class doesn’t define a method. This means that if you were to create a plain object and pass it to the , then you’d get an error. You can try it in the Python interactive interpreter: While you can instantiate an object, can’t use the object. Why? Because it can’t call for . To be more explicit about the requirements of , you can convert the class, which is currently a concrete class, to an abstract class. That way, no employee is ever just an , but instead always a derived class that implements . The class in the example above is what is called an abstract base class. Abstract base classes exist to be inherited, but never instantiated. Python provides the module to formally define abstract base classes. You can use leading underscores in your class name to communicate that objects of that class shouldn’t be created. Underscores provide a friendly way to prevent misuse of your code, but they don’t prevent eager users from creating instances of that class. The module in the Python standard library provides functionality to prevent creating objects from abstract base classes. You can modify the implementation of the class to ensure that it can’t be instantiated: You derive from , making it an abstract base class. Then, you decorate the method with the decorator. This change has two nice side-effects:\n• You’re telling users of the module that objects of type can’t be created.\n• You’re telling other developers working on the module that if they derive from , then they must override the abstract method. You can see that you can’t create objects of type anymore using the interactive interpreter: The output shows that you can’t instantiate the class because it contains an abstract method, . Derived classes must override the method to allow creating objects of their type. When you derive one class from another, the derived class inherits both of the following:\n• The base class interface: The derived class inherits all the methods, properties, and attributes of the base class.\n• The base class implementation: The derived class inherits the code that implements the class interface. Most of the time, you’ll want to inherit the implementation of a class, but you’ll want to implement multiple interfaces so that you can use your objects in different situations. Modern programming languages are designed with this basic concept in mind. They allow you to inherit from a single class, but you can implement multiple interfaces. In Python, you don’t have to explicitly declare an interface. Any object that implements the desired interface can be used in place of another object. This is known as duck typing. Duck typing is usually explained as if it walks like a duck and it quacks like a duck, then it must be a duck. In other words, it’s enough to behave like a duck to be considered a duck. To illustrate this, you’ll now add a class to the example above, and it won’t derive from . Create a new file called and add the following code: The class doesn’t derive from , but it exposes the same interface that requires. Remember that requires a list of objects that implement the following interface:\n• An property or attribute that returns the employee’s ID\n• A property or attribute that represents the employee’s name\n• A method that doesn’t take any parameters and returns the payroll amount to process The class meets all these requirements, so can still calculate its payroll. You can modify the program to use the class: The program creates a object and adds it to the list that processes. You can now run the program and see its output: As you can see, the can still process the new object because it meets the desired interface. Since you don’t have to derive from a specific class for your objects to be reusable by the program, you may be asking why you should use inheritance instead of just implementing the desired interface. The following rules may help you to make this decision:\n• Use inheritance to reuse an implementation: Your derived classes should leverage most of their base class implementation. They must also model an is a relationship. A class might also have an and a , but a is not an , so in this case, you shouldn’t use inheritance.\n• Implement an interface to be reused: When you want your class to be reused by a specific part of your application, you implement the required interface in your class, but you don’t need to provide a base class, or inherit from another class. You can now clean up the example above to move on to the next topic. You can delete the file and then modify the module to its original state: You removed the import of the module since the class doesn’t need to be abstract. You also removed the abstract method from it since it doesn’t provide any implementation. Basically, you’re inheriting the implementation of the and attributes of the class in your derived classes. Since is just an interface to the method, you don’t need to implement it in the base class. Notice how the class derives from . This means that inherits the implementation and interface of . You can see how the method leverages the base class implementation because it relies on the result from to implement its own version. If you’re not careful, inheritance can lead you to a huge hierarchical class structure that’s hard to understand and maintain. This is known as the class explosion problem. You started building a class hierarchy of types used by the to calculate payroll. Now, you need to add some functionality to those classes so that you can use them with the new . tracks productivity based on employee roles. There are different employee roles:\n• Managers: They walk around yelling at people, telling them what to do. They’re salaried employees and make more money.\n• Secretaries: They do all the paperwork for managers and ensure that everything gets billed and payed on time. They’re also salaried employees but make less money.\n• Sales employees: They make a lot of phone calls to sell products. They have a salary, but they also get commissions for sales.\n• Factory workers: They manufacture the products for the company. They’re paid by the hour. With those requirements, you start to see that and its derived classes might belong somewhere other than the module because now they’re also used by the . You create an module and move the classes there: The implementation remains the same, but you move the classes to the module. Your module is now much smaller and focused on the payroll system: With both and in place, you can now update your program to support the change: You run the program and verify that it still works: With everything in place, you start adding the new classes: First, you add a class that derives from . The class exposes a method that the productivity system will use. The method takes the that the employee worked. Then you add , , and and then implement the interface, so they can be used by the productivity system—which you haven’t created yet. As a next step, you can create a new file called and add the class: The class tracks employees in the method that takes a list of employees and the number of hours to track. As outlined above, the productivity system makes use of on each of the objects in to accomplish the tracking. You can now add the productivity system to your program, and update it to represent different types of employees: Your updated program creates a list of employees of different types. The employee list is sent to the productivity system to track their work for forty hours. Then the same list of employees is sent to the payroll system to calculate their payroll. You can run the program to see the output: The program shows the employees working for forty hours through the productivity system. Then it calculates and displays the payroll for each of the employees. The program works as expected, but you had to add four new classes to support the changes. As new requirements come, your class hierarchy will inevitably grow, leading to the class explosion problem where your hierarchies will become so big that they’ll be hard to understand and maintain. The following diagram shows the new class hierarchy: The diagram shows how the class hierarchy is growing. Additional requirements might have an exponential effect on the number of classes with this design. Python is one of the few modern programming languages that supports multiple inheritance. Multiple inheritance is the ability to derive a class from multiple base classes at the same time. Multiple inheritance has a bad reputation to the extent that most modern programming languages don’t support it. Instead, modern programming languages support the concept of interfaces. In those languages, you inherit from a single base class and then implement multiple interfaces, so you can reuse your classes in different situations. This approach puts some constraints in your designs. You can only inherit the implementation of one class by directly deriving from it. You can implement multiple interfaces, but you can’t inherit the implementation of multiple classes. This constraint is good for software design because it forces you to design your classes with fewer dependencies on each other. You will see later in this tutorial that you can leverage multiple implementations through composition, which makes software more flexible. This section, however, is about multiple inheritance, so take a look at how it works. It turns out that sometimes temporary secretaries are hired when there’s too much paperwork to do. The class performs the role of a in the context of the , but for payroll purposes, it’s an . You look at your class design. It’s grown a little bit, but you can still understand how it works. It seems you have two options:\n• Derive from : You can derive from to inherit the method for the role, and then override the method to implement it as an .\n• Derive from : You can derive from to inherit the method, and then override the method to implement it as a . Then, you remember that Python supports multiple inheritance, so you decide to derive from both and : Python allows you to inherit from two different classes by specifying them between parentheses in the class declaration, and separating them with commas. Now, you modify your program to add the new temporary secretary employee: You run the program to test it: python program.py TypeError: SalaryEmployee.__init__() takes 4 positional arguments but 5 were given You get a exception saying that positional arguments where expected, but were given. This is because you derived first from and then from , so the interpreter is trying to use to initialize the object. Okay, go ahead and reverse it: Now, run the program again and see what happens: Now it seems that you’re missing a parameter, which is necessary to initialize , but that parameter doesn’t make sense in the context of a because it’s an . Maybe implementing will help: That didn’t work either. Okay, it’s time for you to dive into Python’s method resolution order (MRO) to see what’s going on. When a method or attribute of a class is accessed, Python uses the class MRO to find it. The MRO is also used by to determine which method or attribute to invoke. You can learn more about in Supercharge Your Classes With Python . You can evaluate the class MRO using the interactive interpreter: The MRO shows the order in which Python is going to look for a matching attribute or method. In the example, this is what happens when you create the object:\n• calls , which the MRO is going to match to , which is inherited from . You can bypass parts of the MRO. In this case, you want to skip the initialization of and . You can do this by reversing the inheritance order again back to how you had it initially. Then, you’ll directly call : When you put before , then the MRO of looks like the following: Because you explicitly specified that should use , you’re effectively skipping and in the MRO when initializing an object. That solves the problem of creating the object, but you’ll run into a similar problem when trying to calculate payroll. You can run the program to see the problem: The problem now is that because you reversed the inheritance order, the MRO is finding the method of before the one in . You need to override in and invoke the right implementation from it: The new method now directly invokes to ensure that you get the correct result. You can run the program again to see it working: The program now works as expected because you’re forcing the method resolution order by explicitly telling the interpreter which method you want to use. As you can see, multiple inheritance can be confusing, especially when you run into the diamond problem. The following diagram shows the diamond problem in your class hierarchy: The diagram shows the diamond problem with the current class design. uses multiple inheritance to derive from two classes that ultimately also derive from . This causes two paths to reach the base class, which is something you want to avoid in your designs. The diamond problem appears when you’re using multiple inheritance and deriving from two classes that have a common base class. This can cause the wrong version of a method to be called. As you’ve seen, Python provides a way to force the right method to be invoked, and analyzing the MRO can help you understand the problem. Still, when you run into the diamond problem, it’s better to rethink the design. You’ll now make some changes to leverage multiple inheritance, avoiding the diamond problem. Two different systems use the derived classes:\n• The payroll system that calculates the employee payroll This means that everything related to productivity should be together in one module, and everything related to payroll should be together in another. You can start making changes to the productivity module: The module implements the class, as well as the related roles that it supports. The classes implement the interface required by the system, but they don’t derive from . You can do the same with the module: The module implements the , which calculates payroll for the employees. It also implements the policy classes for payroll. As you can see, the policy classes don’t derive from anymore. You can now add the necessary classes to the module: The module imports policies and roles from the other modules and implements the different types. You’re still using multiple inheritance to inherit the implementation of the salary policy classes and the productivity roles, but the implementation of each class only needs to deal with initialization. Notice that you still need to explicitly initialize the salary policies in the constructors. You probably saw that the initializations of and are identical. Also, the initializations of and are the same. You won’t want to have this kind of code duplication in more complex designs, so you have to be careful when designing class hierarchies. Here’s the UML diagram for the new design: The diagram shows the relationships to define the and using multiple inheritance, but avoiding the diamond problem. You can run the program and see how it works: You’ve seen how inheritance and multiple inheritance work in Python. You can now explore the topic of composition.\n\nComposition is an object-oriented design concept that models a has a relationship. In composition, a class known as composite contains an object, or component, of another class. In other words, a composite class has a component of another class. Composition allows composite classes to reuse the implementation of the components it contains. The composite class doesn’t inherit the component class interface, but it can leverage its implementation. The composition relation between two classes is considered loosely coupled. That means that changes to the component class rarely affect the composite class, and changes to the composite class never affect the component class. This provides better adaptability to change and allows applications to introduce new requirements without affecting existing code. When looking at two competing software designs, one based on inheritance and another based on composition, the composition solution usually is more flexible. You can now look at how composition works. You’ve already used composition in your examples. If you look at the class, then you’ll see that it contains two attributes:\n• to contain the name of the employee These two attributes are objects that the class has. Therefore, you can say that an has an and has a . Another attribute for an might be an . Create a new Python file called and add code for an class: You implemented a basic address class that contains the usual components for an address. You made the attribute optional because not all addresses will have that component. You implemented to provide a pretty representation of an . You can see this implementation in the interactive interpreter: When you the variable, you’re invoking the special method . Since you overloaded the method to return a string formatted as an address, you get a nice, readable representation. Operator and Function Overloading in Custom Python Classes gives a good overview of the special methods available in classes that you can implement to customize the behavior of your objects. You can now add to the class through composition: You initialize the attribute to for now to make it optional, but by doing that, you can now assign an to an . Also notice that there’s no reference in the module to the module. Composition is a loosely coupled relationship that often doesn’t require the composite class to have knowledge of the component. The UML diagram representing the relationship between and looks like this: The diagram shows the basic composition relationship between and . You can now modify the class to leverage the attribute in : You check to see if the object has an address, and if it does, you print it. You can now modify the program to assign some addresses to the employees: You added a couple of addresses to the and objects. When you run the program, you’ll see the addresses printed: Notice how the payroll output for the and objects shows the addresses where the checks were sent. The class leverages the implementation of the class without any knowledge of what an object is or how it’s represented. This type of design is so flexible that you can change the class without any impact to the class. Composition is more flexible than inheritance because it models a loosely coupled relationship. Changes to a component class have minimal or no effects on the composite class. Designs based on composition are more suitable to change. You change behavior by providing new components that implement those behaviors instead of adding new classes to your hierarchy. Take a look at the multiple inheritance example above. Imagine how new payroll policies will affect the design. Try to picture what the class hierarchy will look like if new roles are needed. As you saw before, relying too heavily on inheritance can lead to class explosion. The biggest problem isn’t so much the number of classes in your design, but how tightly coupled the relationships between those classes are. Tightly coupled classes affect each other when changes are introduced. In this section, you’re going to use composition to implement a better design that still fits the requirements of the and the . You can start by implementing the functionality of the : The updated class defines some roles using a string identifier mapped to a role class that implements the role. It exposes a method that, given a role identifier, returns the role type object. If the role isn’t found, then Python raises a exception. It also exposes the previous functionality in the method, where given a list of employees, it tracks the productivity of those employees. You can now implement the different role classes: Each of the roles that you implemented exposes its own method that takes the number of worked. These methods return a string representing the duties. Note: If you’ve followed along throughout the section on inheritance, then you’ll notice that these roles are similar, but slightly different from that example. Feel free to continue working with the roles that you previously defined and their methods if you prefer. You’ll just need to adapt the relevant names to account for the change. The role classes are independent of each other, but they expose the same interface, so they’re interchangeable. You’ll see later how they’re used in the application. Now, you can implement the for the application: keeps an internal database of payroll policies for each employee. It exposes a method that, given an employee , returns its payroll policy. If a specified doesn’t exist in the system, then the method raises a exception. The implementation of works the same as before. It takes a list of employees, calculates the payroll, and prints the results. You can now implement the payroll policy classes: You first implement a class that serves as a base class for all the payroll policies. This class tracks the , which is common to all payroll policies. The other policy classes derive from . You use inheritance here because you want to leverage the implementation of . Also, , , and are a . is initialized with a value that then uses. is initialized with and implements by leveraging the base class . The class derives from because it wants to inherit its implementation. It’s initialized with the parameters, but it also requires a parameter. The is used to calculate the , which is implemented as a property so it gets calculated when requested. In the example, you’re assuming that a sale happens every five hours worked, and the is the number of sales times the value. implements the method by first leveraging the implementation in and then adding the calculated commission. You can now add an class to manage employee addresses: The class keeps an internal database of objects for each employee. It exposes a method that returns the address of the specified employee . If the employee doesn’t exist, then it raises a . The class implementation remains the same as before: The class manages the address components and provides a pretty representation of an address. So far, the new classes have been extended to support more functionality, but there are no significant changes to the previous design. This is going to change with the design of the module and its classes. You can start by implementing an class: keeps track of all the employees in the company. For each employee, it tracks the , , and . It has an instance of the , the , and the . These instances are used to create employees. It exposes an property that returns the list of employees. The objects are created in an internal method. Notice that you don’t have different types of classes. You just need to implement a single class: You initialize the class with the , , and attributes. This class also requires the productivity for the employee and the policy. The class exposes a method that takes the hours worked. This method first retrieves the from the . In other words, it delegates to the object to perform its duties. In the same way, it delegates to the object to track the work . The , as you saw, uses those hours to calculate the payroll if needed. The following diagram shows the composition design used: The diagram shows the design of composition-based policies. There’s a single that’s composed of other data objects like and depends on the and interfaces to delegate the work. There are multiple implementations of these interfaces. You can now use this design in your program: You can run the program to see its output: This design is what’s called policy-based design, where classes are composed of policies, and they delegate to those policies to do the work. Policy-based design was introduced in the book Modern C++ Design, and it uses template metaprogramming in C++ to achieve the results. Python doesn’t support templates, but you can achieve similar results using composition, as you saw in the example above. This type of design gives you all the flexibility you’ll need as requirements change. Imagine that you need to change the way payroll is calculated for an object at runtime. If your design relies on inheritance, then you need to find a way to change the type of an object to change its behavior. With composition, you just need to change the policy that the object uses. Imagine that your all of a sudden becomes a temporary employee who gets paid by the hour. You can modify the object during the execution of the program in the following way: The program gets the employee list from the and retrieves the first employee, which is the manager you want. Then it creates a new initialized at 55 dollars per hour and assigns it to the manager object. The new policy is now used by the , modifying the existing behavior. You can run the program again to see the result: The check for Mary Poppins, your manager, is now for 2200 dollars instead of the fixed weekly salary of 3000 dollars that she used to have. Notice how you added that business rule to the program without changing any of the existing classes. Consider what type of changes would’ve been required with an inheritance design. You would’ve had to create a new class and change the type of the manager employee. There’s no chance that you could’ve changed the policy at runtime.\n\nChoosing Between Inheritance and Composition in Python So far, you’ve seen how inheritance and composition work in Python. You’ve seen that derived classes inherit the interface and implementation of their base classes. You’ve also seen that composition allows you to reuse the implementation of another class. You’ve implemented two solutions to the same problem. The first solution used multiple inheritance, and the second one used composition. You’ve also seen that Python’s duck typing allows you to reuse objects with existing parts of a program by implementing the desired interface. In Python, it isn’t necessary to derive from a base class to reuse your classes. At this point, you might be asking when to use inheritance vs composition in Python. They both enable code reuse. Inheritance and composition can tackle similar problems in your Python programs. The general advice is to use the relationship that creates fewer dependencies between two classes. This relation is composition. Still, there’ll be times where inheritance will make more sense. The following sections provide some guidelines to help you make the right choice between inheritance and composition in Python. You should only use inheritance to model an is a relationship. Liskov’s substitution principle says that an object of type , which inherits from , can replace an object of type without altering the desirable properties of a program. Liskov’s substitution principle is the most important guideline to determine if inheritance is the appropriate design solution. Still, the answer might not be straightforward in all situations. Fortunately, there’s a simple test that you can use to determine if your design follows Liskov’s substitution principle. Let’s say you have a class, , that provides an implementation and interface you want to reuse in another class, . Your initial thought is that you can derive from and inherit both the interface and the implementation. To be sure this is the right design, you follow theses steps:\n• Evaluate is an : Think about this relationship and justify it. Does it make sense?\n• Evaluate is a : Reverse the relationship and justify it. Does it also make sense? If you can justify both relationships, then you should never inherit those classes from one another. Look at a more concrete example. You have a class that exposes an property. You need a class, which also has an . It seems that a is a special type of , so maybe you can derive from it and leverage both the interface and implementation. Before you jump into the implementation, you use Liskov’s substitution principle to evaluate the relationship. A is a because its area is calculated from the product of its times its . The constraint is that and must be equal. It makes sense. You can justify the relationship and explain why a is a . Now reverse the relationship to see if it makes sense. A is a because its area is calculated from the product of its times its . The difference is that and can change independently. It also makes sense. You can justify the relationship and describe the special constraints for each class. This is a good sign that these two classes should never derive from each other. You might have seen other examples that derive from to explain inheritance. You might be skeptical with the little test that you just did. Fair enough. Next, you’ll write a program that illustrates the problem with deriving from . First, you implement . You’re even going to encapsulate the attributes to ensure that you’re meeting all the constraints: You initialize the class with a and a , and the class provides an property that returns the area. The and are encapsulated as and to avoid changing them directly. Now, you derive from and override the necessary interface to meet the constraints of a : You initialize the class with a , which is used to initialize both components of the base class. Now, you write a small program to test the behavior: The program creates a and a and asserts that their is calculated correctly. You can run the program and see that everything is so far: The program executes correctly, so it seems that is just a special case of a . Later on, you need to support resizing objects, so you make the appropriate changes to the class: Your method takes the and for the object. You can add the following code to the program to verify that it works correctly: You resize the rectangle object and assert that the new area is correct. You can run the program to verify the behavior: The assertion passes, and you see that the program runs correctly. So, what happens if you resize a square? Modify the program, and try to modify the object: You pass the same parameters to that you used with , and print the area. When you run the program you see: The program shows that the new area is like the object. The problem now is that the object no longer meets the class constraint that the length and height must be equal. How can you fix that problem? You can try several approaches, but all of them will be awkward. You can override in and ignore the parameter. However, that will be confusing for people looking at other parts of the program where objects are being resized and some of them are not getting the expected areas because they’re really objects. In a small program like this one, it might be easy to spot the causes of the weird behavior, but in a more complex program, the problem will be harder to find. The reality is that if you’re able to justify an inheritance relationship between two classes both ways, then you shouldn’t derive one class from another. In the example, it doesn’t make sense that inherits the interface and implementation of from . That doesn’t mean that objects can’t be resized. It means that the interface is different because it only needs a parameter. This difference in interface justifies not deriving from , like the test above advised. One of the uses of multiple inheritance in Python is to extend class features through mixins. A mixin is a class that provides methods to other classes but isn’t considered a base class. A mixin allows other classes to reuse its interface and implementation without becoming a superclass. It implements a unique behavior that you can aggregate to other unrelated classes. Mixins are similar to composition, but they create a stronger relationship. Say you want to convert objects of certain types in your application to a dictionary representation of the object. You could provide a method in every class that you want to support this feature, but the implementation of seems to be very similar. This could be a good candidate for a mixin. You start by slightly modifying the class from the composition example: The changes are minimal. You just changed the and attributes to be internal by adding a leading underscore to their names. You’ll see soon why you’re making that change. Now, you create an class in a new file called : The class exposes a method that returns the representation of itself as a dictionary. The method is implemented as a comprehension that creates a dictionary mapping to for each item in if the isn’t internal. Note: This is why you made the role and payroll attributes internal in the class—because you don’t want to represent them in the dictionary. As you saw at the beginning, creating a class inherits some members from , and one of those members is , which is basically a mapping of all the attributes in an object to their values. You iterate through all the items in and filter out the ones that have a name that starts with an underscore using . With , you check the specified value. If the value is an , then the method looks to see if it also has a member and uses it to represent the object. Otherwise, it returns a string representation. If the value isn’t an , then it simply returns the value. You can modify the class to support this mixin: All you have to do is inherit the to support the functionality. It’ll be nice to support the same functionality in the class, so you represent the attribute in the same way: You apply the mixin to the class to support the feature. Now, you can write a small program to test it: The program implements , which converts the dictionary to a JSON string using indentation so the output looks better. Then, it iterates through all the employees, printing the dictionary representation provided by . You can run the program to see its output: You leveraged the implementation of in both and classes even when they’re not related. Because only provides behavior, you can reuse it with other classes without causing problems. Composition models a has a relationship. With composition, a class has an instance of the class and can leverage its implementation. You can reuse the class in other classes completely unrelated to the . In the composition example above, the class has an object. implements all the functionality to handle addresses, and other classes can reuse it. Other classes like or can reuse without being related to . They can leverage the same implementation, ensuring that addresses are handled consistently across the application. A problem that you may run into when using composition is that some of your classes may start growing by using multiple components. Your classes may require multiple parameters in the constructor just to pass in the components that they’re made of. This can make your classes hard to use. A way to avoid the problem is by using the factory method to construct your objects. You did that with the composition example. If you look at the implementation of the class, then you’ll notice that it uses to construct an object with the right parameters. This design will work, but ideally, you should be able to construct an object just by specifying an ID, for example . The following changes might improve your design. You can start with the module: First, you make the class internal by prepending an underscore to the class name. Then you provide a internal variable to the module. You’re communicating to other developers that they shouldn’t create or use directly. Instead, you provide two functions, and , as the public interface to the module. This is what other modules should use. What you’re saying is that is a singleton, and there should only be one object created from it. Now, you can do the same with the module: Again, you make internal and provide a public interface to it. The application will use the public interface to get policies and calculate payroll. You’ll now do the same with the module: You’re basically saying that there should only be one , one , and one . Again, this design pattern is called the singleton design pattern, which comes in handy for classes from which there should only be one single instance. Now, you can work on the module. You’ll also mark the as internal and make a singleton out of it, but you’ll make some additional changes: You first import the relevant public functions and classes from other modules. You make internal, and at the bottom, you create a single instance. This instance is public and part of the interface because you’ll want to use it in the application. You changed the attribute to a dictionary where the key is the employee ID and the value is the employee information. You also exposed a method to return the information for the specified employee . The property now sorts the keys to return the employees sorted by their . You replaced the method that constructed the objects with calls to the initializer directly. The class now is initialized with the ID and uses the public functions exposed in the other modules to initialize its attributes. You can now change the program to test the changes: You import the relevant functions from the and modules, as well as the and class. The program is cleaner because you exposed the required interface and encapsulated how to access objects. Notice that you can now create an object directly just using its ID. You can run the program to see its output: The program works the same as before, but now you can see that you can create a single object from its ID and display its dictionary representation. Take a closer look at the class: The class is a composite that contains multiple objects providing different functionality. It contains an that implements all the functionality related to where the employee lives. also contains a productivity role from the module, and a payroll policy from the module. These two objects provide implementations that the class leverages to track work in the method and to calculate the payroll in the method. You’re using composition in two different ways. The class provides additional data to , while the role and payroll objects provide additional behavior. Still, the relationship between and those objects is loosely coupled, which provides some interesting capabilities that you’ll see in the next section. Inheritance, as opposed to composition, is a tightly coupled relationship. With inheritance, there’s only one way to change and customize behavior. Method overriding is the only way to customize the behavior of a base class. This creates rigid designs that are difficult to change. Composition, on the other hand, provides a loosely coupled relationship that enables flexible designs and can be used to change behavior at runtime. Imagine you need to support a long-term disability (LTD) policy when calculating payroll. The policy states that an employee on LTD should be paid 60 percent of their weekly salary, assuming forty hours of work. With an inheritance design, this can be a very difficult requirement to support. Adding it to the composition example is a lot simpler. Start by adding the policy class: Notice that doesn’t inherit from , but implements the same interface. This is because the implementation is completely different, so you don’t want to inherit any of the implementation. The initializes to and provides an internal method that raises an exception if the hasn’t been applied. Then, it provides an method to assign . The public interface first checks that has been applied, and then it implements the functionality in terms of that base policy. The method just delegates to the base policy, and uses it to calculate the and then return the 60 percent. You can now make a small change to the class: You added an method that applies the existing payroll policy to the new policy and then substitutes it. You can now modify the program to apply the policy to an object: The program accesses located at index , creates the object, and applies the policy to the employee. When you call , the change is reflected. You can run the program to evaluate the output: The check amount for employee Kevin Bacon, who’s the sales employee, is now for 1080 dollars instead of 1800 dollars. That’s because the has been applied to the salary. As you can see, you were able to support the changes just by adding a new policy and modifying a couple of interfaces. This is the kind of flexibility that policy design based on composition gives you. Choosing Between Inheritance and Composition in Python Python, as an object-oriented programming language, supports both inheritance and composition. You saw that inheritance is best used to model an is a relationship, whereas composition models a has a relationship. Sometimes, it’s hard to see what the relationship between two classes should be, but you can follow these guidelines:\n• Use inheritance over composition in Python to model a clear is a relationship. First, justify the relationship between the derived class and its base. Then, reverse the relationship and try to justify it. Only if you can’t justify the relationship in both directions should you use inheritance between them.\n• Use inheritance over composition in Python to leverage both the interface and implementation of the base class.\n• Use inheritance over composition in Python to provide mixin features to several unrelated classes when there’s only one implementation of that feature.\n• Use composition over inheritance in Python to model a has a relationship that leverages the implementation of the component class.\n• Use composition over inheritance in Python to create components that multiple classes in your Python applications can reuse.\n• Use composition over inheritance in Python to implement groups of behaviors and policies that can be applied interchangeably to other classes to customize their behavior.\n• Use composition over inheritance in Python to enable runtime behavior changes without affecting existing classes. With that, you have a strong understanding of when to use inheritance vs composition."
    },
    {
        "link": "https://thedigitalcatonline.com/blog/2014/05/19/method-overriding-in-python",
        "document": ""
    }
]